[{"title":"2018 TODO","url":"%2F2018%2F12%2F2018-12-31-todo%2F","content":"\n### 2018\n\n#### Short Term TODO\n\n* Hive - Transactions, Locks, Authorization\n\n* File Formats, SerDes, Compression\n\n* Scheduling Algorithm\n\n* Data Government, Data Warehouse, Data Mart\n\n* ElasticSearch\n\n* JVM & GC\n\n* Spark\n\n* Flink\n\n* Netty\n\n* Kafka\n\n* HBase\n\n#### Long Term TODO\n\n* Linear Algebra\n\n* Probability and Information Theory\n\n* Dataset Transformations\n\n* Model Selection and Evaluation\n\n* Machine Learning\n\n* Deep Learning\n\n### Links\n\n* [TODO](http://blog.hyperj.net/todo/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[2018 TODO](http://blog.hyperj.net/2018/12/2018-12-31-todo/)","tags":["TODO"],"categories":["TODO"]},{"title":"Service Log","url":"%2F2018%2F06%2F2018-06-01-service-log%2F","content":"\n### Log\n\nWho When Where What Content\n\n### Level\n\n- ERROR\n- WARN\n- INFO\n- DEBUG\n\n### Data\n\n- Base Data\n- Service Data\n\n### Component\n\n- SDK/Agent\n- Collector\n- Kafka\n- Gobblin/Spark/Flink\n- ES/Hive/HBase\n\n### Other\n\n- Data Size < 100KB-1MB(Suggest < 1-10KB)\n- Schema: Json/Avro\n\n### Links\n\n* [Apache Logging Log4J2](https://github.com/apache/logging-log4j2)\n* [Apache Gobblin](https://github.com/apache/incubator-gobblin)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Service Log](http://blog.hyperj.net/2018/06/2018-06-01-service-log/)","tags":["Service"],"categories":["Log"]},{"title":"Canal","url":"%2F2018%2F05%2F2018-05-29-canal%2F","content":"\n### 类型\n\n- 全量\n- 增量\n- 快照\n\n### 问题\n\n- 分库分表\n- 库表变更\n- 回溯数据\n- 事务\n- 主键\n- 特殊语句\n\n### Links\n\n* [Canal](https://github.com/alibaba/canal)\n* [Canal Wiki](https://github.com/alibaba/canal/wiki)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Canal](http://blog.hyperj.net/2018/05/2018-05-29-canal/)","tags":["Canal"],"categories":["Canal"]},{"title":"分布式架构","url":"%2F2018%2F03%2F2018-03-01-distributed-architecture%2F","content":"\n### 从集中式到分布式\n\n##### 集中式的特点\n\n##### 分布式的特点\n\n分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。——《分布式系统概念与设计》\n\n- 分布性\n\n- 对等性\n\n- 并发性\n\n- 缺乏全局时钟（事件、消息的顺序）\n\n- 故障总是会发生\n\n##### 分布式环境的各种问题\n\n- 通信异常\n\n- 网络分区（脑裂）\n\n- 三态（成功、失败、超时）\n\n- 节点故障\n\n### 从ACID到CAP/BASE\n\n##### ACID（Transaction）\n\n- 原子性（Atomicity）\n\n- 一致性（Consistency）\n\n- 隔离性（Isolation）\n\n| 隔离级别 | 脏读（Dirty Read） | 不可重复读（NonRepeatable Read） | 幻读（Phantom Read） |\n| ------- | ----------------- | ------------------------------ | ------------------- |\n| 未提交读（Read Uncommitted） | 可能 | 可能 | 可能 |\n| 已提交读（Read Committed） | 不可能 | 可能 | 可能 |\n| 可重复读（Repeatable Read） | 不可能 | 不可能 | 可能 |\n| 可串行化（Serializable ） | 不可能 | 不可能 | 不可能 |\n    \n- 持久性（Durability）\n\n##### 分布式事务\n\n##### CAP和BASE理论\n\n###### CAP\n\n- 一致性（Consistency）\n\n- 可用性（Availability）\n\n- 分区容错性（Partition Tolerance）\n\n###### BASE\n\n- Basically Available（基本可用）\n\n- Soft state（软状态）\n\n- Eventually consistent（最终一致性）\n    \n    - 因果一致性（Causal consistency）\n\n    - 读己之所写（Read your writes）\n\n    - 会话一致性（Session consistency）\n\n    - 单调读一致性（Monotonic read consistency）\n\n    - 单调写一致性（Monotoic write consistency）\n\n### Links\n\n* [从Paxos到Zookeeper：分布式一致性原理与实践](https://book.douban.com/subject/26292004/)\n* [从ACID到CAP到BASE](http://blog.hyperj.net/2016/2016-02-21-acid-cap-base/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[分布式架构](http://blog.hyperj.net/2018/03/2018-03-01-distributed-architecture/)","tags":["Distributed"],"categories":["Distributed"]},{"title":"YARN Fair Scheduler","url":"%2F2018%2F02%2F2018-02-28-yarn-fair-scheduler%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN Fair Scheduler](http://blog.hyperj.net/2018/02/2018-02-28-yarn-fair-scheduler/)","tags":["Fair"],"categories":["YARN"]},{"title":"YARN Capacity Scheduler","url":"%2F2018%2F02%2F2018-02-27-yarn-capacity-scheduler%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN Capacity Scheduler](http://blog.hyperj.net/2018/02/2018-02-27-yarn-capacity-scheduler/)","tags":["Capacity"],"categories":["YARN"]},{"title":"YARN NodeManager","url":"%2F2018%2F02%2F2018-02-26-yarn-nodemanager%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN NodeManager](http://blog.hyperj.net/2018/02/2018-02-26-yarn-nodemanager/)","tags":["NodeManager"],"categories":["YARN"]},{"title":"YARN ResourceManager","url":"%2F2018%2F02%2F2018-02-25-yarn-resourcemanager%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN ResourceManager](http://blog.hyperj.net/2018/02/2018-02-25-yarn-resourcemanager/)","tags":["ResourceManager"],"categories":["YARN"]},{"title":"YARN Overview","url":"%2F2018%2F02%2F2018-02-24-yarn-overview%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN Overview](http://blog.hyperj.net/2018/02/2018-02-24-yarn-overview/)","tags":["HyperJ"],"categories":["YARN"]},{"title":"HDFS Datanode Overview","url":"%2F2018%2F02%2F2018-02-23-hdfs-datanode-overview%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Datanode Overview](http://blog.hyperj.net/2018/02/2018-02-23-hdfs-datanode-overview/)","tags":["Datanode"],"categories":["HDFS"]},{"title":"HDFS Namenode Overview","url":"%2F2018%2F02%2F2018-02-22-hdfs-namenode-overview%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Namenode Overview](http://blog.hyperj.net/2018/02/2018-02-22-hdfs-namenode-overview/)","tags":["Namenode"],"categories":["HDFS"]},{"title":"HDFS Client Append","url":"%2F2018%2F02%2F2018-02-21-hdfs-client-append%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Client Append](http://blog.hyperj.net/2018/02/2018-02-21-hdfs-client-append/)","tags":["Client"],"categories":["HDFS"]},{"title":"HDFS Client Write","url":"%2F2018%2F02%2F2018-02-20-hdfs-client-write%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Client Write](http://blog.hyperj.net/2018/02/2018-02-20-hdfs-client-write/)","tags":["Client"],"categories":["HDFS"]},{"title":"HDFS Client Read","url":"%2F2018%2F02%2F2018-02-19-hdfs-client-read%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Client Read](http://blog.hyperj.net/2018/02/2018-02-19-hdfs-client-read/)","tags":["Client"],"categories":["HDFS"]},{"title":"HDFS RPC","url":"%2F2018%2F02%2F2018-02-18-hdfs-rpc%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS RPC](http://blog.hyperj.net/2018/02/2018-02-18-hdfs-rpc/)","tags":["RPC"],"categories":["HDFS"]},{"title":"HDFS Overview","url":"%2F2018%2F02%2F2018-02-17-hdfs-overvew%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Overview](http://blog.hyperj.net/2018/02/2018-02-17-hdfs-overvew/)","tags":["HDFS"],"categories":["HDFS"]},{"title":"Java Memory Model","url":"%2F2018%2F02%2F2018-02-16-java-memory-model%2F","content":"\n### TODO\n\n### Links\n\n* [The Java Memory Model](http://www.cs.umd.edu/~pugh/java/memoryModel/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Java Memory Model](http://blog.hyperj.net/2018/02/2018-02-16-java-memory-model/)","tags":["Memory Model"],"categories":["Java"]},{"title":"Preprocessing Data Practice","url":"%2F2018%2F02%2F2018-02-15-preprocessing-data-practice%2F","content":"\n### Data \n\n* missing\n \n* mismatch\n\n### Preprocessing\n\n* OneHotEncoding\n\n* Standardized\n\n* Normalize\n\n### Links\n\n* [Preprocessing Data](http://scikit-learn.org/stable/modules/preprocessing.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Preprocessing Data Practice](http://blog.hyperj.net/2018/02/2018-02-16-preprocessing-data-practice/)","tags":["Preprocessing"],"categories":["Feature Engineering"]},{"title":"Preprocessing Data","url":"%2F2018%2F02%2F2018-02-14-preprocessing-data%2F","content":"\n### TODO\n\n### Links\n\n* [Preprocessing Data](http://scikit-learn.org/stable/modules/preprocessing.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Preprocessing Data](http://blog.hyperj.net/2018/02/2018-02-14-preprocessing-data/)","tags":["Preprocessing"],"categories":["Feature Engineering"]},{"title":"Feature Extraction","url":"%2F2018%2F02%2F2018-02-13-feature-extraction%2F","content":"\nThe `sklearn.feature_extraction` module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image.\n\n> Note `Feature extraction` is very different from `Feature selection`: the former consists in transforming arbitrary data, such as text or images, into numerical features usable for machine learning. The latter is a machine learning technique applied on these features.\n\n##### DictVectorizer\n\nDictVectorizer implements what is called one-of-K or “one-hot” coding for categorical (aka nominal, discrete) features. \n\n##### FeatureHasher\n\n##### Text feature extraction\n\n###### CountVectorizer, HashingVectorizer\n\n###### Bag of Words(tokenization, counting and normalization)\n\n   Sparsity\n   Tf–idf term weighting\n   Decode\n\n##### Image feature extraction\n\n### Links\n\n* [Feature Extraction](http://scikit-learn.org/stable/modules/feature_extraction.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Feature Extraction](http://blog.hyperj.net/2018/02/2018-02-13-feature-extraction/)","tags":["Extraction"],"categories":["Feature Engineering"]},{"title":"Spark GraphX Overview","url":"%2F2018%2F02%2F2018-02-12-spark-graphx-overview%2F","content":"\n### 分布式图计算\n\n### GraphX点切分存储\n\n### vertices、edges和triplets\n\n### 图的构建\n\n### GraphX的图运算操作\n\n    转换操作\n    结构操作\n    关联操作\n    聚合操作\n    缓存操作\n    \n### GraphX Pregel API\n\n### 图算法实现\n\n    宽度优先遍历\n    单源最短路径\n    连通组件\n    三角计数\n    PageRank\n\n### Links\n\n* [Spark Graphx 的原理及相关操作的源码解析](https://github.com/endymecy/spark-graphx-source-analysis)\n* [Spark GraphX Programming Guide](http://spark.apache.org/docs/latest/graphx-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark GraphX Overview](http://blog.hyperj.net/2018/02/2018-02-12-spark-graphx-overview/)","tags":["Spark GraphX"],"categories":["Spark"]},{"title":"Spark MLlib Overview","url":"%2F2018%2F02%2F2018-02-11-spark-mllib-overview%2F","content":"\n### 数据类型\n\n* Local vector\n* Labeled point\n* Local matrix\n* Distributed matrix\n\n    RowMatrix\n    IndexedRowMatrix\n    CoordinateMatrix\n    BlockMatrix\n\n### 基本统计\n\n* summary statistics（概括统计）\n* correlations（相关性系数）\n* tratified sampling（分层取样）\n* hypothesis testing（假设检验）\n* random data generation（随机数生成）\n* Kernel density estimation（核密度估计）\n\n### 协同过滤\n\n* 交换最小二乘\n\n### 分类和回归\n\n* 线性模型（SVMs(支持向量机)、逻辑回归、线性回归、广义线性回归）\n* 朴素贝叶斯\n* 决策树\n* 组合树（随机森林、梯度提升树）\n* 生存回归\n* 保序回归\n\n### 聚类\n\n* k-means||算法\n* GMM（高斯混合模型）\n* PIC（快速迭代聚类）\n* LDA（隐式狄利克雷分布)\n* 二分k-means算法\n* 流式k-means算法\n\n### 最优化算法\n\n* 梯度下降算法\n* 拟牛顿法\n* NNLS(非负最小二乘)\n* 带权最小二乘\n* 迭代再加权最小二乘\n\n### 降维\n\n* EVD（特征值分解）\n* SVD（奇异值分解）\n* PCA（主成分分析）\n\n### 特征抽取和转换\n\n* 特征抽取\n* 特征转换\n* 特征选择\n\n### Links\n\n* [spark ml 算法原理剖析以及具体的源码实现分析](https://github.com/endymecy/spark-ml-source-analysis)\n* [Spark Machine Learning Library (MLlib) Guide](http://spark.apache.org/docs/latest/ml-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark MLlib Overview](http://blog.hyperj.net/2018/02/2018-02-11-spark-mllib-overview/)","tags":["Spark MLlib"],"categories":["Spark"]},{"title":"Spark Streaming Optimization","url":"%2F2018%2F02%2F2018-02-10-spark-streaming-optimization%2F","content":"\n### Configuration\n\n##### Spark Streaming\n\n###### spark.streaming.backpressure.enabled(false)\n\nEnables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values spark.streaming.receiver.maxRate and spark.streaming.kafka.maxRatePerPartition if they are set (see below).\n\n###### spark.streaming.backpressure.initialRate\n\nThis is the initial maximum receiving rate at which each receiver will receive data for the first batch when the backpressure mechanism is enabled.\n\n###### spark.streaming.blockInterval(200ms)\n                                             \nInterval at which data received by Spark Streaming receivers is chunked into blocks of data before storing them in Spark. Minimum recommended - 50 ms. See the performance tuning section in the Spark Streaming programing guide for more details.\n\n###### spark.streaming.receiver.maxRate\n\nMaximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details.\n\n###### spark.streaming.receiver.writeAheadLog.enable(false)\n                                                             \nEnable write ahead logs for receivers. All the input data received through receivers will be saved to write ahead logs that will allow it to be recovered after driver failures. See the deployment guide in the Spark Streaming programing guide for more details.\n\n###### spark.streaming.unpersist(true)\n                                        \nForce RDDs generated and persisted by Spark Streaming to be automatically unpersisted from Spark's memory. The raw input data received by Spark Streaming is also automatically cleared. Setting this to false will allow the raw data and persisted RDDs to be accessible outside the streaming application as they will not be cleared automatically. But it comes at the cost of higher memory usage in Spark.\n\n###### spark.streaming.stopGracefullyOnShutdown(false)\n                                                     \nIf true, Spark shuts down the StreamingContext gracefully on JVM shutdown rather than immediately.\n\n###### spark.streaming.kafka.maxRatePerPartition\n                                                \nMaximum rate (number of records per second) at which data will be read from each Kafka partition when using the new Kafka direct stream API. See the Kafka Integration guide for more details.\n\n###### spark.streaming.kafka.maxRetries(1)\n                                         \nMaximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the new Kafka direct stream API.\n\n###### spark.streaming.ui.retainedBatches(1000)\n                                                \nHow many batches the Spark Streaming UI and status APIs remember before garbage collecting.\n\n###### spark.streaming.driver.writeAheadLog.closeFileAfterWrite(false)\n                                                                     \nWhether to close the file after writing a write ahead log record on the driver. Set this to 'true' when you want to use S3 (or any file system that does not support flushing) for the metadata WAL on the driver.\n\n###### spark.streaming.receiver.writeAheadLog.closeFileAfterWrite(false)\n\nWhether to close the file after writing a write ahead log record on the receivers. Set this to 'true' when you want to use S3 (or any file system that does not support flushing) for the data WAL on the receivers.\n\n### Links\n\n* [Structured Streaming Programming Guide](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)\n* [Spark Streaming Programming Guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Streaming Scheduling](http://blog.hyperj.net/2018/02/2018-02-10-spark-streaming-optimization/)","tags":["Spark Streaming"],"categories":["Spark"]},{"title":"Spark Structured Streaming","url":"%2F2018%2F02%2F2018-02-09-spark-structured-streaming%2F","content":"\n### Structured Streaming\n\nSource, Sink, StreamExecution, StateStore, EventTimeWatermark\n\n### Links\n\n* [Structured Streaming 源码解析系列](https://github.com/lw-lin/CoolplaySpark/tree/master/Structured%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97)\n* [A Deep Dive into Structured Streaming](http://www.slideshare.net/databricks/a-deep-dive-into-structured-streaming)\n* [Structured Streaming Programming Guide](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)\n* [Spark Streaming Programming Guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Structured Streaming](http://blog.hyperj.net/2018/02/2018-02-09-spark-structured-streaming/)","tags":["Structured Streaming"],"categories":["Spark"]},{"title":"Spark Streaming Architecture","url":"%2F2018%2F02%2F2018-02-08-spark-streaming-architecture%2F","content":"\n### Concepts\n\n* DStream, DStreamGraph（InputDStream, ForEachDStream）\n\n* JobScheduler, JobGenerator\n\n* Receiver, ReceiverSupervisor, BlockGenerator, ReceivedBlockHandler, ReceiverTraker, ReceivedBlockTracker\n\n* Checkpoint, WAL\n\n### Links\n\n* [Spark Streaming 源码解析系列](https://github.com/lw-lin/CoolplaySpark/tree/master/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97)\n* [Structured Streaming Programming Guide](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)\n* [Spark Streaming Programming Guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Streaming Architecture](http://blog.hyperj.net/2018/02/2018-02-08-spark-streaming-architecture/)","tags":["Spark Streaming"],"categories":["Spark"]},{"title":"Spark Streaming Overview","url":"%2F2018%2F02%2F2018-02-07-spark-streaming-overview%2F","content":"\n### Concepts\n\n* DStream\n\n* DStreamGraph\n\n### Operations\n\n* Input、Receivers\n\n* Transformations\n\n* Output\n\n### Links\n\n* [Structured Streaming Programming Guide](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)\n* [Spark Streaming Programming Guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Streaming Overview](http://blog.hyperj.net/2018/02/2018-02-07-spark-streaming-overview/)","tags":["Spark Streaming"],"categories":["Spark"]},{"title":"Spark SQL Optimization","url":"%2F2018%2F02%2F2018-02-06-spark-sql-optimization%2F","content":"\n### Configuration\n\n##### Application Properties\n\n###### spark.driver.cores(1)\n\nNumber of cores to use for the driver process, only in cluster mode.\n\n###### spark.driver.maxResultSize(1g)\n\nLimit of total size of serialized results of all partitions for each Spark action (e.g. collect). Should be at least 1M, or 0 for unlimited. Jobs will be aborted if the total size is above this limit. Having a high limit may cause out-of-memory errors in driver (depends on spark.driver.memory and memory overhead of objects in JVM). Setting a proper limit can protect the driver from out-of-memory errors.\n\n###### spark.driver.memory(1g)\n\nAmount of memory to use for the driver process, i.e. where SparkContext is initialized. (e.g. 1g, 2g). \nNote: In client mode, this config must not be set through the SparkConf directly in your application, because the driver JVM has already started at that point. Instead, please set this through the --driver-memory command line option or in your default properties file.\n\n###### spark.executor.memory(1g)\n\nA string of extra JVM options to pass to the driver. For instance, GC settings or other logging. Note that it is illegal to set maximum heap size (-Xmx) settings with this option. Maximum heap size settings can be set with spark.driver.memory in the cluster mode and through the --driver-memory command line option in the client mode. \nNote: In client mode, this config must not be set through the SparkConf directly in your application, because the driver JVM has already started at that point. Instead, please set this through the --driver-java-options command line option or in your default properties file.\n\n##### Runtime Environment\n\n###### spark.driver.extraJavaOptions(none)\n\nA string of extra JVM options to pass to the driver. For instance, GC settings or other logging. Note that it is illegal to set maximum heap size (-Xmx) settings with this option. Maximum heap size settings can be set with spark.driver.memory in the cluster mode and through the --driver-memory command line option in the client mode. \n\nNote: In client mode, this config must not be set through the SparkConf directly in your application, because the driver JVM has already started at that point. Instead, please set this through the --driver-java-options command line option or in your default properties file.\n\n###### spark.executor.extraJavaOptions(none)\n\nA string of extra JVM options to pass to the driver. For instance, GC settings or other logging. Note that it is illegal to set maximum heap size (-Xmx) settings with this option. Maximum heap size settings can be set with spark.driver.memory in the cluster mode and through the --driver-memory command line option in the client mode. \nNote: In client mode, this config must not be set through the SparkConf directly in your application, because the driver JVM has already started at that point. Instead, please set this through the --driver-java-options command line option or in your default properties file.\n\n##### Execution Behavior\n\n###### spark.executor.cores(1 in YARN mode, all the available cores on the worker in standalone and Mesos coarse-grained modes.)\n\nThe number of cores to use on each executor. In standalone and Mesos coarse-grained modes, setting this parameter allows an application to run multiple executors on the same worker, provided that there are enough cores on that worker. Otherwise, only one executor per application will run on each worker.\n\n##### Spark Yarn Properties\n\n###### spark.yarn.executor.memoryOverhead(executorMemory * 0.10, with minimum of 384)\n\nThe amount of off-heap memory (in megabytes) to be allocated per executor. This is memory that accounts for things like VM overheads, interned strings, other native overheads, etc. This tends to grow with the executor size (typically 6-10%).\n\n###### spark.yarn.driver.memoryOverhead(driverMemory * 0.10, with minimum of 384)\n\nThe amount of off-heap memory (in megabytes) to be allocated per driver in cluster mode. This is memory that accounts for things like VM overheads, interned strings, other native overheads, etc. This tends to grow with the container size (typically 6-10%).\n\n###### spark.yarn.am.memoryOverhead(AM memory * 0.10, with minimum of 384)\n\nSame as spark.yarn.driver.memoryOverhead, but for the YARN Application Master in client mode.\n\n### Links\n\n* [Spark SQL, DataFrames and Datasets Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n* [Spark Configuration](http://spark.apache.org/docs/latest/configuration.html)\n* [Running Spark on YARN](http://spark.apache.org/docs/latest/running-on-yarn.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark SQL Optimization](http://blog.hyperj.net/2018/02/2018-02-06-spark-sql-optimization/)","tags":["Spark SQL"],"categories":["Spark"]},{"title":"Spark SQL Catalyst","url":"%2F2018%2F02%2F2018-02-05-spark-sql-catalyst%2F","content":"\n### Trees\n\nTreeNode, Expression, LogicalPlan, PhysicalPlan\n\n### Transformations\n\nAnalyzer, Optimizer, Planner\n\n### Rules\n\nRuleExecutor\n\n### Sequence\n\nQuery/Dataset/DataFrame(SessionCatalog) -(Antlr)> Unresolved/Parsed Logical Plan -(Analyser)> Analyzed Logical Plan -(Optimizer)> Optimized Logical Plan -(SparkPlanner)> Physical Plan -> SparkPlan#execute\n\n* 解析(Parse)：将SQL语句通过Parse模块进行词法和语法解析，解析完成后生成未绑定的逻辑执行计划(Unresolved LogicalPlan)，之后步骤在该逻辑执行计划上运用各种规则。\n\n* 绑定(Bind)：使用Analyser中的Analysis规则(Rule)，借助于元数据(Hive Metastore等)，将未绑定的逻辑执行计划转换成绑定元数据的逻辑执行计划(LogicPlan)。\n\n* 优化(Optimizer)：使用Optimization规则(Rule)，将绑定的逻辑执行计划进行合并、列裁剪和过滤器下推等优化后生成优化后的逻辑执行计划(Optimized LogicPlan)。\n\n* 转换(Transform)：使用Planner使用Planning Strategies，对优化后的逻辑执行计划转换(Transform)生成可执行的物理执行计划(PhysicalPlan)。\n\n* 执行(Execution)：调用SparkPlan的execute执行计算RDD。\n\n### Links\n\n* [Deep Dive into Spark SQL’s Catalyst Optimizer](https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html)\n* [Spark SQL: Relational Data Processing in Spark](http://people.csail.mit.edu/matei/papers/2015/sigmod_spark_sql.pdf)\n* [Spark SQL, DataFrames and Datasets Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark SQL Catalyst](http://blog.hyperj.net/2018/02/2018-02-05-spark-sql-catalyst/)","tags":["Catalyst"],"categories":["Spark"]},{"title":"Spark SQL Overview","url":"%2F2018%2F02%2F2018-02-04-spark-sql-overview%2F","content":"\n### Overview\n\nSpark SQL由Core、Catalyst、Hive和Hive-Thriftserver四部分组成，分别对应Spark源码中的spark/sql/core、spark/sql/catalyst、spark/sql/hive和spark/sql/hive-thriftserver。\n\n* Core：用于将Catalyst生成的逻辑执行计划转换为RDD的查询/执行引擎。该组建中还包含一个SQLContext接口，用于对于已经存在的RDD和Parquet文件执行SQL或LINQ语句。\n* Catalyst：负责处理查询语句的整个处理流程，包括解析、绑定、优化、物理计划等。\n* Hive：负责对Hive数据的处理，里面有一个扩展了SQLContext的HiveContext，允许用户使用HQL编写查询语句，并且使用Hive SerDes从Hive Metastore查询数据。还允许你使用UDF、UDAF、UDTF查询。\n* Hive-Thriftserver：提供SQL CLI(bin/spark-sql)和HiveServer2(JDBC/ODBC)兼容服务的支持。\n\nCatalyst是Spark的核心，Spark SQL的执行流程的核心就是Catalyst的执行工作流程。\n\n### Dataset/DataFrame\n\nDataset是从Spark 1.6提供的分布式数据集，它同时提供了RDD(强类型、使用lambda表达式)和Spark SQL(优化执行引擎)各自的优点。Dataset可以通过JVM对象和已有的Dataset转化来构建。Dataset提供了Java和Scala的API。\n\nDataFrame其实要比DataSet出现的早，在Spark1.3版本提供的。DataFrame和DataSet都是在RDD的基础上提供的，DataFrame的使用风格类似R和Pandas风格的DataFrame API，这样大大降低了学习成本。Dataset和DataFrame都是分布式数据集，只不过DataFrame中包含列的命名信息(列的Schema信息)，DataFrame在概念上等同于关系数据库中的表和R/Python中的DataFrame。\n\n在Spark2.0以后，Spark团队就把Dataset和DataFrame进行了合并，把DataFrame作为Dataset中一种具有列Schema信息的Row的集合。所以现在就把DataFrame看作Dataset的一种，只不过包含了列的schema信息。现在DataFrame并没有具体的实现类了，而是把它定义为Dataset中Row组成的集合。Dataset/DataFrame和RDD一样，对于转换操作算子是惰性的，只有遇到action算子才会真正执行，这也使得在构建Dataset/DataFrame的所有操作之间可以进行丰富的优化。\n\n```scala\ntype DataFrame = Dataset[Row]\n```\n\n注：Spark SQL在Spark 1.0版本上线，当时使用的是SchemaRDD，在Spark 1.3版本提供了DataFrame代替了SchemaRDD，在Spark 1.6版本Spark提出了Dataset，在Spark 2.0将DataFrame合并到Dataset中。\n\n### Catalog\n\nSessionCatalog\n\n### Links\n\n* [Spark SQL, DataFrames and Datasets Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark SQL O\\verview](http://blog.hyperj.net/2018/02/2018-02-04-spark-sql-overview/)","tags":["Spark SQL"],"categories":["Spark"]},{"title":"Rancher Overview","url":"%2F2018%2F02%2F2018-02-03-rancher-overview%2F","content":"\n### Overview\n\nRancher is an open source software platform that enables organizations to run and manage Docker and Kubernetes in production. With Rancher, organizations no longer have to build a container services platform from scratch using a distinct set of open source technologies. Rancher supplies the entire software stack needed to manage containers in production.\n\n### INFRASTRUCTURE ORCHESTRATION\n\nRancher takes in raw computing resources from any public or private cloud in the form of Linux hosts. Each Linux host can be a virtual machine or physical machine. Rancher does not expect more from each host than CPU, memory, local disk storage, and network connectivity. From Rancher’s perspective, a VM instance from a cloud provider and a bare metal server hosted at a colo facility are indistinguishable.\n\nRancher implements a portable layer of infrastructure services designed specifically to power containerized applications. Rancher infrastructure services include networking, storage, load balancer, DNS, and security. Rancher infrastructure services are typically deployed as containers themselves, so that the same Rancher infrastructure service can run on any Linux hosts from any cloud.\n\n### CONTAINER ORCHESTRATION AND SCHEDULING\n\nMany users choose to run containerized applications using a container orchestration and scheduling framework. Rancher includes a distribution of all popular container orchestration and scheduling frameworks today, including Docker Swarm, Kubernetes, and Mesos. The same user can create multiple Swarm or Kubernetes clusters. They can then use the native Swarm or Kubernetes tools to manage their applications.\n\nIn addition to Swarm, Kubernetes, and Mesos, Rancher supports its own container orchestration and scheduling framework called Cattle. Cattle is used extensively by Rancher to orchestrate infrastructure services as well as setting up, managing, and upgrading Swarm, Kubernetes, and Mesos clusters.\n\n### APPLICATION CATALOG\n\nRancher users can deploy an entire multi-container clustered application from the application catalog with one click of a button. Users can manage the deployed applications and perform fully automated upgrades when new versions of the application become available. Rancher maintains a public catalog consisting of popular applications contributed by the Rancher community. Rancher users can create their own private catalogs.\n\n### ENTERPRISE-GRADE CONTROL\n\nRancher supports flexible user authentication plugins and comes with pre-built user authentication integration with Active Directory, LDAP, and GitHub. Rancher supports Role-Based Access Control (RBAC) at the level of environments, allowing users and groups to share or deny access to, for example, development and production environments.\n\n### Links\n\n* [Rancher Documentation](http://rancher.com/docs/rancher/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Rancher Overview](http://blog.hyperj.net/2018/02/2018-02-03-rancher-overview/)","tags":["Rancher"],"categories":["Rancher"]},{"title":"Kubernetes Overview","url":"%2F2018%2F02%2F2018-02-02-kubernetes-overview%2F","content":"\n### Overview\n\nKubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\n##### Planet Scale\n\nDesigned on the same principles that allows Google to run billions of containers a week, Kubernetes can scale without increasing your ops team.\n\n##### Never Outgrow\n\nWhether testing locally or running a global enterprise, Kubernetes flexibility grows with you to deliver your applications consistently and easily no matter how complex your need is.\n\n##### Run Anywhere\n\nKubernetes is open source giving you the freedom to take advantage of on-premises, hybrid, or public cloud infrastructure, letting you effortlessly move workloads to where it matters to you.\n\n### Features\n\n##### Automatic binpacking\n\nAutomatically places containers based on their resource requirements and other constraints, while not sacrificing availability. Mix critical and best-effort workloads in order to drive up utilization and save even more resources.\n\n##### Self-healing\n\nRestarts containers that fail, replaces and reschedules containers when nodes die, kills containers that don't respond to your user-defined health check, and doesn't advertise them to clients until they are ready to serve.\n\n##### Horizontal scaling\n\nScale your application up and down with a simple command, with a UI, or automatically based on CPU usage.\n\n##### Service discovery and load balancing\n\nNo need to modify your application to use an unfamiliar service discovery mechanism. Kubernetes gives containers their own IP addresses and a single DNS name for a set of containers, and can load-balance across them.\n\n##### Automated rollouts and rollbacks\n\nKubernetes progressively rolls out changes to your application or its configuration, while monitoring application health to ensure it doesn't kill all your instances at the same time. If something goes wrong, Kubernetes will rollback the change for you. Take advantage of a growing ecosystem of deployment solutions.\n\n##### Secret and configuration management\n\nDeploy and update secrets and application configuration without rebuilding your image and without exposing secrets in your stack configuration.\n\n##### Storage orchestration\n\nAutomatically mount the storage system of your choice, whether from local storage, a public cloud provider such as GCP or AWS, or a network storage system such as NFS, iSCSI, Gluster, Ceph, Cinder, or Flocker.\n\n##### Batch execution\n\nIn addition to services, Kubernetes can manage your batch and CI workloads, replacing containers that fail, if desired.\n\n### Links\n\n* [Kubernetes Documentation](https://kubernetes.io/docs/home/)\n* [Kubernetes Concepts](https://kubernetes.io/docs/concepts/)\n* [Kubernetes Tutorials](https://kubernetes.io/docs/tutorials/)\n* [Kubernetes Reference](https://kubernetes.io/docs/reference/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Kubernetes Overview](http://blog.hyperj.net/2018/02/2018-02-02-kubernetes-overview/)","tags":["Kubernetes"],"categories":["Kubernetes"]},{"title":"Docker Overview","url":"%2F2018%2F02%2F2018-02-01-docker-overview%2F","content":"\n### Container\n\n* [What is a Container](https://www.docker.com/what-container)\n\n### Tools\n\n* Docker Compose: Enables you to define, build, and run multi-container applications\n\n* Docker Machine: Enables you to provision and manage Dockerized hosts\n\n* Docker Notary: Allows the signing of container images to enable Docker Content Trust\n\n* Docker Registry: The software that powers Docker Hub and Docker Store, Registry stores and distributes container images\n\n### File formats\n\n* Dockerfile: Defines the contents and startup behavior of a single container\n\n* Compose file: Defines a multi-container application\n\n### Command-line interfaces (CLIs)\n\n* Engine CLI: The main CLI for Docker, includes all docker and dockerd commands\n\n* Compose CLI: The CLI for Docker Compose, which allows you to build and run multi-container applications\n\n* Machine CLI: Manages virtual machines that are pre-configured to run Docker\n\n### Links\n\n* [Docker Documentation](https://docs.docker.com/)\n* [Docker Product and Tool Manuals](https://docs.docker.com/manuals/)\n* [Docker Glossary](https://docs.docker.com/glossary/)\n* [Docker Reference](https://docs.docker.com/reference/)\n* [Docker Samples](https://docs.docker.com/samples/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Docker Overview](http://blog.hyperj.net/2018/02/2018-02-01-docker-overview/)","tags":["Docker"],"categories":["Docker"]},{"title":"Spark Monitoring","url":"%2F2018%2F01%2F2018-01-31-spark-monitoring%2F","content":"\n### Web UI\n\n* WebUI, WebUITab\n\n    SparkUI, SparkUITab\n    WorkerWebUI, MasterWebUI(Standalone)\n    HistoryServer(Yarn or Mesos)\n\n### Restful\n\n* StandaloneRestServer(RestSubmissionServer)\n\n* StandaloneSubmitRequestServlet, StandaloneKillRequestServlet, StandaloneStatusRequestServlet\n\n### Metrics\n\n* MetricsSystem, MetricsConfig\n\n* Source(MasterSource, ApplicationSource, WorkerSource, ExecutorSource, DAGSchedulerSource, ShuffleMetricsSource, BlockManagerSource, StreamingSource, JvmSource)\n\n* Sink(ConsoleSink, CsvSink, GraphiteSink, JmxSink, MetricsServlet<Web UI>, Slf4jSink, StatsdSink)\n\n### Links\n\n* [Spark Documentation - Monitoring and Instrumentation](http://spark.apache.org/docs/latest/monitoring.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Monitoring](http://blog.hyperj.net/2018/01/2018-01-31-spark-monitoring/)","tags":["Monitoring"],"categories":["Spark"]},{"title":"Spark Fault Tolerance","url":"%2F2018%2F01%2F2018-01-30-spark-fault-tolerance%2F","content":"\n### RDD\n\n* Lineage, Dependencies\n\n* Cache, Checkpoint\n\n* Replication\n\n* Partitions\n\n### Cluster\n\n* Master\n\n* Worker\n\n### Application\n\n* Client\n\n* Driver\n\n* Executor\n\n* Task\n\n### Mechanism\n\n* BlacklistTracker, TaskSetBlacklist\n\n### Links\n\n* [Apache Spark源码走读之15 -- Standalone部署模式下的容错性分析](http://www.cnblogs.com/hseagle/p/3791779.html)\n* [Fault Tolerance in Spark: Lessons Learned from Production: Spark Summit East talk by Jose Soltren](https://www.slideshare.net/SparkSummit/fault-tolerance-in-spark-lessons-learned-from-production-spark-summit-east-talk-by-jose-soltren)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Fault Tolerance](http://blog.hyperj.net/2018/01/2018-01-30-spark-fault-tolerance/)","tags":["Fault Tolerance"],"categories":["Spark"]},{"title":"Spark Scheduling - Strategy","url":"%2F2018%2F01%2F2018-01-29-spark-scheduling-strategy%2F","content":"\n### Driver\n\n##### Standalone(Master)\n\n```scala\n  /**\n   * Schedule the currently available resources among waiting apps. This method will be called\n   * every time a new app joins or resource availability changes.\n   */\n  private def schedule(): Unit = {\n    if (state != RecoveryState.ALIVE) {\n      return\n    }\n    // Drivers take strict precedence over executors\n    val shuffledAliveWorkers = Random.shuffle(workers.toSeq.filter(_.state == WorkerState.ALIVE))\n    val numWorkersAlive = shuffledAliveWorkers.size\n    var curPos = 0\n    for (driver <- waitingDrivers.toList) { // iterate over a copy of waitingDrivers\n      // We assign workers to each waiting driver in a round-robin fashion. For each driver, we\n      // start from the last worker that was assigned a driver, and continue onwards until we have\n      // explored all alive workers.\n      var launched = false\n      var numWorkersVisited = 0\n      while (numWorkersVisited < numWorkersAlive && !launched) {\n        val worker = shuffledAliveWorkers(curPos)\n        numWorkersVisited += 1\n        if (worker.memoryFree >= driver.desc.mem && worker.coresFree >= driver.desc.cores) {\n          launchDriver(worker, driver)\n          waitingDrivers -= driver\n          launched = true\n        }\n        curPos = (curPos + 1) % numWorkersAlive\n      }\n    }\n    startExecutorsOnWorkers()\n  }\n```\n\n##### Yarn(AM)\n\n```java\n  @VisibleForTesting\n  public static final class ScheduleTransition\n      implements\n      MultipleArcTransition<RMAppAttemptImpl, RMAppAttemptEvent, RMAppAttemptState> {\n    @Override\n    public RMAppAttemptState transition(RMAppAttemptImpl appAttempt,\n        RMAppAttemptEvent event) {\n      ApplicationSubmissionContext subCtx = appAttempt.submissionContext;\n      if (!subCtx.getUnmanagedAM()) {\n        // Need reset #containers before create new attempt, because this request\n        // will be passed to scheduler, and scheduler will deduct the number after\n        // AM container allocated\n        \n        // Currently, following fields are all hard coded,\n        // TODO: change these fields when we want to support\n        // priority or multiple containers AM container allocation.\n        for (ResourceRequest amReq : appAttempt.amReqs) {\n          amReq.setNumContainers(1);\n          amReq.setPriority(AM_CONTAINER_PRIORITY);\n        }\n\n        int numNodes =\n            RMServerUtils.getApplicableNodeCountForAM(appAttempt.rmContext,\n                appAttempt.conf, appAttempt.amReqs);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Setting node count for blacklist to \" + numNodes);\n        }\n        appAttempt.getAMBlacklistManager().refreshNodeHostCount(numNodes);\n\n        ResourceBlacklistRequest amBlacklist =\n            appAttempt.getAMBlacklistManager().getBlacklistUpdates();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Using blacklist for AM: additions(\" +\n              amBlacklist.getBlacklistAdditions() + \") and removals(\" +\n              amBlacklist.getBlacklistRemovals() + \")\");\n        }\n        // AM resource has been checked when submission\n        Allocation amContainerAllocation =\n            appAttempt.scheduler.allocate(\n                appAttempt.applicationAttemptId,\n                appAttempt.amReqs,\n                EMPTY_CONTAINER_RELEASE_LIST,\n                amBlacklist.getBlacklistAdditions(),\n                amBlacklist.getBlacklistRemovals(),\n                new ContainerUpdates());\n        if (amContainerAllocation != null\n            && amContainerAllocation.getContainers() != null) {\n          assert (amContainerAllocation.getContainers().size() == 0);\n        }\n        return RMAppAttemptState.SCHEDULED;\n      } else {\n        // save state and then go to LAUNCHED state\n        appAttempt.storeAttempt();\n        return RMAppAttemptState.LAUNCHED_UNMANAGED_SAVING;\n      }\n    }\n  }\n```\n\n### Executor\n\n##### Standalone(Master)\n\n```scala\n  /**\n   * Schedule executors to be launched on the workers.\n   * Returns an array containing number of cores assigned to each worker.\n   *\n   * There are two modes of launching executors. The first attempts to spread out an application's\n   * executors on as many workers as possible, while the second does the opposite (i.e. launch them\n   * on as few workers as possible). The former is usually better for data locality purposes and is\n   * the default.\n   *\n   * The number of cores assigned to each executor is configurable. When this is explicitly set,\n   * multiple executors from the same application may be launched on the same worker if the worker\n   * has enough cores and memory. Otherwise, each executor grabs all the cores available on the\n   * worker by default, in which case only one executor per application may be launched on each\n   * worker during one single schedule iteration.\n   * Note that when `spark.executor.cores` is not set, we may still launch multiple executors from\n   * the same application on the same worker. Consider appA and appB both have one executor running\n   * on worker1, and appA.coresLeft > 0, then appB is finished and release all its cores on worker1,\n   * thus for the next schedule iteration, appA launches a new executor that grabs all the free\n   * cores on worker1, therefore we get multiple executors from appA running on worker1.\n   *\n   * It is important to allocate coresPerExecutor on each worker at a time (instead of 1 core\n   * at a time). Consider the following example: cluster has 4 workers with 16 cores each.\n   * User requests 3 executors (spark.cores.max = 48, spark.executor.cores = 16). If 1 core is\n   * allocated at a time, 12 cores from each worker would be assigned to each executor.\n   * Since 12 < 16, no executors would launch [SPARK-8881].\n   */\n  private def scheduleExecutorsOnWorkers(\n      app: ApplicationInfo,\n      usableWorkers: Array[WorkerInfo],\n      spreadOutApps: Boolean): Array[Int] = {\n    val coresPerExecutor = app.desc.coresPerExecutor\n    val minCoresPerExecutor = coresPerExecutor.getOrElse(1)\n    val oneExecutorPerWorker = coresPerExecutor.isEmpty\n    val memoryPerExecutor = app.desc.memoryPerExecutorMB\n    val numUsable = usableWorkers.length\n    val assignedCores = new Array[Int](numUsable) // Number of cores to give to each worker\n    val assignedExecutors = new Array[Int](numUsable) // Number of new executors on each worker\n    var coresToAssign = math.min(app.coresLeft, usableWorkers.map(_.coresFree).sum)\n\n    /** Return whether the specified worker can launch an executor for this app. */\n    def canLaunchExecutor(pos: Int): Boolean = {\n      val keepScheduling = coresToAssign >= minCoresPerExecutor\n      val enoughCores = usableWorkers(pos).coresFree - assignedCores(pos) >= minCoresPerExecutor\n\n      // If we allow multiple executors per worker, then we can always launch new executors.\n      // Otherwise, if there is already an executor on this worker, just give it more cores.\n      val launchingNewExecutor = !oneExecutorPerWorker || assignedExecutors(pos) == 0\n      if (launchingNewExecutor) {\n        val assignedMemory = assignedExecutors(pos) * memoryPerExecutor\n        val enoughMemory = usableWorkers(pos).memoryFree - assignedMemory >= memoryPerExecutor\n        val underLimit = assignedExecutors.sum + app.executors.size < app.executorLimit\n        keepScheduling && enoughCores && enoughMemory && underLimit\n      } else {\n        // We're adding cores to an existing executor, so no need\n        // to check memory and executor limits\n        keepScheduling && enoughCores\n      }\n    }\n\n    // Keep launching executors until no more workers can accommodate any\n    // more executors, or if we have reached this application's limits\n    var freeWorkers = (0 until numUsable).filter(canLaunchExecutor)\n    while (freeWorkers.nonEmpty) {\n      freeWorkers.foreach { pos =>\n        var keepScheduling = true\n        while (keepScheduling && canLaunchExecutor(pos)) {\n          coresToAssign -= minCoresPerExecutor\n          assignedCores(pos) += minCoresPerExecutor\n\n          // If we are launching one executor per worker, then every iteration assigns 1 core\n          // to the executor. Otherwise, every iteration assigns cores to a new executor.\n          if (oneExecutorPerWorker) {\n            assignedExecutors(pos) = 1\n          } else {\n            assignedExecutors(pos) += 1\n          }\n\n          // Spreading out an application means spreading out its executors across as\n          // many workers as possible. If we are not spreading out, then we should keep\n          // scheduling executors on this worker until we use all of its resources.\n          // Otherwise, just move on to the next worker.\n          if (spreadOutApps) {\n            keepScheduling = false\n          }\n        }\n      }\n      freeWorkers = freeWorkers.filter(canLaunchExecutor)\n    }\n    assignedCores\n  }\n```\n\n### Job\n\n```scala\n  def initialize(backend: SchedulerBackend) {\n    this.backend = backend\n    schedulableBuilder = {\n      schedulingMode match {\n        case SchedulingMode.FIFO =>\n          new FIFOSchedulableBuilder(rootPool)\n        case SchedulingMode.FAIR =>\n          new FairSchedulableBuilder(rootPool, conf)\n        case _ =>\n          throw new IllegalArgumentException(s\"Unsupported $SCHEDULER_MODE_PROPERTY: \" +\n          s\"$schedulingMode\")\n      }\n    }\n    schedulableBuilder.buildPools()\n  }\n```\n\n* FIFO\n\n* FAIR\n\n### Task\n\n* Local\n\n* Lazy\n\n### Links\n\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Scheduling - Strategy](http://blog.hyperj.net/2018/01/2018-01-29-spark-scheduling-strategy/)","tags":["Strategy"],"categories":["Spark"]},{"title":"Spark Scheduling - Algorithm","url":"%2F2018%2F01%2F2018-01-28-spark-scheduling-algorithm%2F","content":"\n### SchedulingAlgorithm\n\n* FIFO: FIFO algorithm between TaskSetManagers\n\n* FS: FS algorithm between Pools, and FIFO or FS within Pools\n\n* Schedulable(Pool, TaskSetManager)\n\n```scala\ndef comparator(s1: Schedulable, s2: Schedulable): Boolean\n```\n\n#### FIFOSchedulingAlgorithm\n\n```scala\noverride def comparator(s1: Schedulable, s2: Schedulable): Boolean = {\n    val priority1 = s1.priority\n    val priority2 = s2.priority\n    var res = math.signum(priority1 - priority2)\n    if (res == 0) {\n      val stageId1 = s1.stageId\n      val stageId2 = s2.stageId\n      res = math.signum(stageId1 - stageId2)\n    }\n    res < 0\n}\n```\n\n#### FairSchedulingAlgorithm\n\n```scala\noverride def comparator(s1: Schedulable, s2: Schedulable): Boolean = {\n    val minShare1 = s1.minShare\n    val minShare2 = s2.minShare\n    val runningTasks1 = s1.runningTasks\n    val runningTasks2 = s2.runningTasks\n    val s1Needy = runningTasks1 < minShare1\n    val s2Needy = runningTasks2 < minShare2\n    val minShareRatio1 = runningTasks1.toDouble / math.max(minShare1, 1.0)\n    val minShareRatio2 = runningTasks2.toDouble / math.max(minShare2, 1.0)\n    val taskToWeightRatio1 = runningTasks1.toDouble / s1.weight.toDouble\n    val taskToWeightRatio2 = runningTasks2.toDouble / s2.weight.toDouble\n\n    var compare = 0\n    if (s1Needy && !s2Needy) {\n      return true\n    } else if (!s1Needy && s2Needy) {\n      return false\n    } else if (s1Needy && s2Needy) {\n      compare = minShareRatio1.compareTo(minShareRatio2)\n    } else {\n      compare = taskToWeightRatio1.compareTo(taskToWeightRatio2)\n    }\n    if (compare < 0) {\n      true\n    } else if (compare > 0) {\n      false\n    } else {\n      s1.name < s2.name\n    }\n}\n```\n\n### Links\n\n* [Spark Documentation - Job Scheduling](http://spark.apache.org/docs/latest/job-scheduling.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Scheduling - Algorithm](http://blog.hyperj.net/2018/01/2018-01-28-spark-scheduling-algorithm/)","tags":["Fair"],"categories":["Spark"]},{"title":"Spark Scheduling - Sequence","url":"%2F2018%2F01%2F2018-01-27-spark-scheduling-sequence%2F","content":"\n### Sequence\n\n* Driver: RDD(foreach, foreachPartition, collect, collectPartitions, toLocalIterator, reduce, fold, aggregate, count, take)#runJob -> DAGScheduler#runJob, submitJob -> DAGSchedulerEventProcessLoop<EventLoop>#doOnReceive(JobSubmitted<DAGSchedulerEvent>) -> DAGScheduler#handleJobSubmitted, submitStage(Submits stage, but first recursively submits any missing parents, BFS.), submitMissingTasks -> TaskScheduler#submitTasks(TaskSet) -> CoarseGrainedSchedulerBackend#reviveOffers\n\n* Executor: Executor#launchTask -> TaskRunner#run -> Task#run -> ShuffleMapTask(MapStatus), ResultTask(func():U)#runTask -> CoarseGrainedExecutorBackend#statusUpdate\n\n* Driver: DAGSchedulerEventProcessLoop<EventLoop>#doOnReceive(CompletionEvent<DAGSchedulerEvent>) -> DAGScheduler#handleTaskCompletion\n\n* DAGSchedulerEvent\n\n    AllJobsCancelled$\n    BeginEvent\n    CompletionEvent\n    DAGSchedulerEvent\n    ExecutorAdded\n    ExecutorLost\n    GettingResultEvent\n    JobCancelled\n    JobGroupCancelled\n    JobSubmitted\n    MapStageSubmitted\n    ResubmitFailedStages$\n    SpeculativeTaskSubmitted\n    StageCancelled\n    TaskSetFailed\n    WorkerRemoved\n\n* Task\n\n    ShuffleMapTask\n    ResultTask\n\n### Links\n\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Scheduling - Sequence](http://blog.hyperj.net/2018/01/2018-01-27-spark-job-scheduling/2018-01-27-spark-scheduling-sequence.md)","tags":["Sequence"],"categories":["Spark"]},{"title":"Spark Configuration","url":"%2F2018%2F01%2F2018-01-26-spark-configuration%2F","content":"\n### Configuration\n\n* Spark Properties\n\n    Application Properties\n    Runtime Environment\n    Shuffle Behavior\n    Spark UI\n    Compression and Serialization\n    Memory Management\n    Execution Behavior\n    Networking\n    Scheduling\n    Dynamic Allocation\n    Security\n    TLS / SSL\n    Spark SQL\n    Spark Streaming\n    SparkR\n    GraphX\n    Deploy\n    Cluster Managers\n\n* Environment Variables\n\n* Configuring Logging\n\n* Overriding configuration directory\n\n* Inheriting Hadoop Cluster Configuration\n\n### Priority\n\nSparkSubmit -> val appArgs = new SparkSubmitArguments(args)\n\n```scala\n  // Init parameters\n  var master: String = null\n  var deployMode: String = null\n  var executorMemory: String = null\n  var executorCores: String = null\n  var totalExecutorCores: String = null\n  var propertiesFile: String = null\n  var driverMemory: String = null\n  var driverExtraClassPath: String = null\n  var driverExtraLibraryPath: String = null\n  var driverExtraJavaOptions: String = null\n  var queue: String = null\n  var numExecutors: String = null\n  var files: String = null\n  var archives: String = null\n  var mainClass: String = null\n  var primaryResource: String = null\n  var name: String = null\n  var childArgs: ArrayBuffer[String] = new ArrayBuffer[String]()\n  var jars: String = null\n  var packages: String = null\n  var repositories: String = null\n  var ivyRepoPath: String = null\n  var packagesExclusions: String = null\n  var verbose: Boolean = false\n  var isPython: Boolean = false\n  var pyFiles: String = null\n  var isR: Boolean = false\n  var action: SparkSubmitAction = null\n  val sparkProperties: HashMap[String, String] = new HashMap[String, String]()\n  var proxyUser: String = null\n  var principal: String = null\n  var keytab: String = null\n  // Standalone cluster mode only\n  var supervise: Boolean = false\n  var driverCores: String = null\n  var submissionToKill: String = null\n  var submissionToRequestStatusFor: String = null\n  var useRest: Boolean = true // used internally\n  \n  // Set parameters from command line arguments\n  try {\n    parse(args.asJava)\n  } catch {\n    case e: IllegalArgumentException =>\n      SparkSubmit.printErrorAndExit(e.getMessage())\n  }\n  \n  // Populate `sparkProperties` map from properties file\n  mergeDefaultSparkProperties()\n  \n  // Remove keys that don't start with \"spark.\" from `sparkProperties`.\n  ignoreNonSparkProperties()\n  \n  // Use `sparkProperties` map along with env vars to fill in any missing parameters\n  loadEnvironmentArguments()\n\n  validateArguments()\n```\n\n**Priority**: code > spark-submit options > spark-defaults.conf > spark-env.sh > default\n\n### Links\n\n* [Spark Configuration](http://spark.apache.org/docs/latest/configuration.html)\n\n* [[源码剖析]Spark读取配置](https://www.jianshu.com/p/f86f7b2e8515)\n\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Configuration](http://blog.hyperj.net/2018/01/2018-01-26-spark-configuration/)","tags":["HyperJ"],"categories":["Spark"]},{"title":"Spark Serialization & Compression","url":"%2F2018%2F01%2F2018-01-25-spark-serialization-and-compression%2F","content":"\n### Serialization\n\n* Serializer\n\n#### Java Serialization\n\n* JavaSerializer\n\n* SerializerInstance(JavaSerializerInstance)\n\n* JavaSerializationStream, JavaDeserializationStream\n\n#### Kryo serialization\n\n* KryoSerializer\n\n* SerializerInstance(KryoSerializerInstance)\n\n* JavaIterableWrapperSerializer, KryoInputObjectInputBridge, KryoOutputObjectOutputBridge\n\n* KryoSerializationStream, KryoDeserializationStream\n\n### Compression\n\n* CompressionCodec\n\n* compressedOutputStream, compressedInputStream\n\n#### lz4\n\n* LZ4CompressionCodec\n\n#### lzf\n\n* LZFCompressionCodec\n\n#### snappy\n\n* SnappyCompressionCodec\n\n#### zstd\n\n* ZStdCompressionCodec\n\n### Links\n\n* [Spark Configuration - Compression and Serialization](http://spark.apache.org/docs/latest/configuration.html#compression-and-serialization)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Serialization & Compression](http://blog.hyperj.net/2018/01/2018-01-25-spark-serialization-and-compression/2018-01-25-spark-serialization-and-compression.md)","tags":["Serialization"],"categories":["Spark"]},{"title":"Spark Shared Variables","url":"%2F2018%2F01%2F2018-01-24-spark-shared-variables%2F","content":"\n### Concept\n\n### Broadcast\n\nBroadcast variables allow the programmer to keep a read-only variable cached on each machine rather than shipping a copy of it with tasks.\n\n#### Broadcast(TorrentBroadcast)\n\n* unpersist(TorrentBroadcast.unpersist(id, removeFromDriver = flase, blocking = flase))\n\n* destroy(TorrentBroadcast.unpersist(id, removeFromDriver = true, blocking = true)) \n\n#### BroadcastFactory(TorrentBroadcastFactory)\n\n* BlockManager\n\n* BroadcastManager -> BroadcastFactory(TorrentBroadcastFactory)#newBroadcast\n\n### Accumulators\n\n#### AccumulatorV2\n\nAccumulatorV2 parameterized class represents an accumulator that accumulates IN values to produce OUT result.\n\n* AccumulatorMetadata\n\n* AccumulatorContext\n\n* LongAccumulator, DoubleAccumulator, CollectionAccumulator\n\n* isZero, copy, reset, add, merge, value\n\n> To be on the safe side, always use accumulators inside actions ONLY.\n\n### Links\n\n* [Broadcast](https://spark-internals.books.yourtion.com/markdown/7-Broadcast.html)\n* [AccumulatorV2](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-accumulators.html)\n* [Spark Accumulators Explained: Apache Spark](https://www.edureka.co/blog/spark-accumulators-explained)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Shared Variables](http://blog.hyperj.net/2018/01/2018-01-24-spark-shared-variables/)","tags":["AccumulatorV2"],"categories":["Spark"]},{"title":"Spark Shuffle","url":"%2F2018%2F01%2F2018-01-23-spark-shuffle%2F","content":"\n### Concept\n\n* Task(ShuffleMapTask, ResultTask)\n\n### Shuffle Write\n\n* ShuffleMapTask#runTask -> ShuffleManager(SortShuffleManager)#getWriter -> ShuffleWriter(SortShuffleWriter, UnsafeShuffleWriter)#write\n\n* ShuffleWriter\n\n   SortShuffleWriter(ExternalSorter, Aggregator, ExternalAppendOnlyMap)\n\n   UnsafeShuffleWriter(ShuffleExternalSorter)\n\n### Shuffle Read\n\n* ShuffledRDD#compute -> ShuffleManager(SortShuffleManager)#getReader -> ShuffleReader(BlockStoreShuffleReader)#read\n\n* BlockStoreShuffleReader(ExternalSorter, Aggregator, ExternalAppendOnlyMap)\n\n### Links\n\n* [Spark Architecture: Shuffle](https://0x0fff.com/spark-architecture-shuffle/)\n* [Shuffle 过程](https://spark-internals.books.yourtion.com/markdown/4-shuffleDetails.html)\n* [详细探究Spark的shuffle实现](http://jerryshao.me/2014/01/04/spark-shuffle-detail-investigation/)\n* [Spark Shuffle的技术演进](https://www.jianshu.com/p/4c5c2e535da5)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Shuffle](http://blog.hyperj.net/2018/01/2018-01-23-spark-shuffle/)","tags":["Shuffle"],"categories":["Spark"]},{"title":"Spark Storage","url":"%2F2018%2F01%2F2018-01-22-spark-storage%2F","content":"\n### Concept\n\n#### Stores\n\n* Memory, Disk, and Off-Heap()\n\n#### Levels\n\n* persist(mark), cache(StorageLevel.MEMORY_ONLY)\n\n```scala\nclass StorageLevel private(\n    private var _useDisk: Boolean,\n    private var _useMemory: Boolean,\n    private var _useOffHeap: Boolean,\n    private var _deserialized: Boolean,\n    private var _replication: Int = 1)\n  extends Externalizable {\n\n  // TODO: Also add fields for caching priority, dataset ID, and flushing.\n  private def this(flags: Int, replication: Int) {\n    this((flags & 8) != 0, (flags & 4) != 0, (flags & 2) != 0, (flags & 1) != 0, replication)\n  }\n\n  def this() = this(false, true, false, false)  // For deserialization\n\n  def useDisk: Boolean = _useDisk\n  def useMemory: Boolean = _useMemory\n  def useOffHeap: Boolean = _useOffHeap\n  def deserialized: Boolean = _deserialized\n  def replication: Int = _replication\n  \n  // ...\n}\n\nobject StorageLevel {\n  val NONE = new StorageLevel(false, false, false, false)\n  val DISK_ONLY = new StorageLevel(true, false, false, false)\n  val DISK_ONLY_2 = new StorageLevel(true, false, false, false, 2)\n  val MEMORY_ONLY = new StorageLevel(false, true, false, true)\n  val MEMORY_ONLY_2 = new StorageLevel(false, true, false, true, 2)\n  val MEMORY_ONLY_SER = new StorageLevel(false, true, false, false)\n  val MEMORY_ONLY_SER_2 = new StorageLevel(false, true, false, false, 2)\n  val MEMORY_AND_DISK = new StorageLevel(true, true, false, true)\n  val MEMORY_AND_DISK_2 = new StorageLevel(true, true, false, true, 2)\n  val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false, false)\n  val MEMORY_AND_DISK_SER_2 = new StorageLevel(true, true, false, false, 2)\n  val OFF_HEAP = new StorageLevel(true, true, true, false, 1)\n\n  // ...\n}\n\n```\n\n#### Master/Slave\n\n* Executor(Driver): SparkContext -> SparkEnv -> BlockTransferService(NettyBlockTransferService), BlockManagerMaster(BlockManagerMasterEndpoint), BlockManager\n\n#### RPC\n\n### Update(Read/Write)\n\nRDD -> BlockManager -> Remote: BlockTransferService(fetch/upload), Local: MemoryStore/DiskStore(get/put)\n\n### MemoryManager\n\n* acquire/release, get/set\n\n* MemoryMode(ON_HEAP, OFF_HEAP)\n\n#### StaticMemoryManager\n\n* MaxStorageMemory = systemMaxMemory * spark.storage.memoryFraction * spark.storage.safetyFraction\n\n* MaxExecutionMemory = systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction\n\n#### UnifiedMemoryManager\n\n* MemoryPool(StorageMemoryPool, ExecutionMemoryPool)\n\n* acquireExecutionMemory, acquireStorageMemory, acquireUnrollMemory\n\n* getMaxMemory = (systemMemory - reservedMemory) * spark.memory.fraction\n\n### Links\n\n* [Apache Spark 内存管理详解](https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/)\n* [Spark Storage ① - Spark Storage 模块整体架构](https://www.jianshu.com/p/730eed6a98d2)\n* [Spark Storage ② - BlockManager 的创建与注册](https://www.jianshu.com/p/356db9726d04)\n* [Spark Storage ③ - Master 与 Slave 之间的消息传递与时机](https://www.jianshu.com/p/7a7ff2c19635)\n* [Spark Storage ④ - 存储执行类介绍（DiskBlockManager、DiskStore、MemoryStore）](https://www.jianshu.com/p/19e36d0781b5)\n* [Spark 内存管理的前世今生（上）](https://www.jianshu.com/p/999ef21dffe8)\n* [Spark 内存管理的前世今生（下）](https://www.jianshu.com/p/211505ae3fb3)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Storage](http://blog.hyperj.net/2018/01/2018-01-22-spark-storage/)","tags":["Storage"],"categories":["Spark"]},{"title":"Spark Network","url":"%2F2018%2F01%2F2018-01-21-spark-network%2F","content":"\n### Role\n\nMaster, Worker, Client, Driver, Executor\n\n### Concept\n\n#### RpcCallContext\n\n* NettyRpcCallContext(LocalNettyRpcCallContext, RemoteNettyRpcCallContext)\n\n#### RpcEnv\n\n* NettyRpcEnv(NettyRpcHandler)\n\n* RpcEnvConfig(SparkConf)\n\n* RpcEnvFileServer(NettyStreamManager<jars, files, directories>)\n\n#### RpcEnvFactory\n\n* NettyRpcEnvFactory\n\n#### RpcEndpoint\n\n* ThreadSafeRpcEndpoint(Master, Worker, ClientEndpoint, DriverEndpoint, HeartbeatReceiver, BlockManagerMasterEndpoint, BlockManagerSlaveEndpoint)\n\n* RpcEndpointVerifier\n\n#### RpcEndpointRef\n\n* NettyRpcEndpointRef\n\n#### Dispatcher\n\n* EndpointData\n\n* MessageLoop\n\n#### Inbox\n\n* InboxMessage\n\n#### Outbox\n\n* OutboxMessage\n\n### Others\n\n* Message, MessageEncoder, MessageDecoder\n* RpcAddress, RpcTimeout\n* Reactor, Proactor\n\n### Links\n\n* [Spark RPC](https://smilekevinsovi.github.io/julyhou24/spark/2016/06/19/Spark-RPC.html)\n* [深入解析Spark中的RPC](https://zhuanlan.zhihu.com/p/28893155)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Network](http://blog.hyperj.net/2018/01/2018-01-21-spark-network/)","tags":["Network"],"categories":["Spark"]},{"title":"Spark RDD Characteristics","url":"%2F2018%2F01%2F2018-01-20-spark-rdd-characteristics%2F","content":"\n### RDD\n\nA Resilient Distributed Dataset (RDD), the basic abstraction in Spark. Represents an immutable, partitioned collection of elements that can be operated on in parallel. This class contains the basic operations available on all RDDs, such as `map`, `filter`, and `persist`. \n\n>  Internally, each RDD is characterized by five main properties:\n> \n>   - A list of partitions\n>   - A function for computing each split\n>   - A list of dependencies on other RDDs\n>   - Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)\n>   - Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)\n\n### Operations\n\n#### Creation Operation\n\n#### Transformation Operation\n\n#### Storage Operation\n\nLRU(Least Recently Used)\n\n* Cache\n\n* Persist(unPersist/destroy)\n\n* Checkpoint\n\n#### Action Operation\n\n### Dependencies\n\n#### Narrow Dependencies\n\n#### Shuffle/Wide Dependencies\n\n### Characteristics\n\n#### Partitions\n\n#### PreferredLocations\n\n#### Dependencies\n\n#### Iterator\n\n#### Partitioner\n\n### Stage\n\n#### ResultStage\n\n#### ShuffleMapStage\n\n### Others\n\n* DAG\n\n* Lineage\n\n* Shared Variables\n\n   Broadcast Variables\n   Accumulators\n\n### Links\n\n* [Resilient Distributed Datasets: A Fault-Tolerant Abstraction for\n   In-Memory Cluster Computing](http://people.csail.mit.edu/matei/papers/2012/nsdi_spark.pdf)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark RDD Characteristics](http://blog.hyperj.net/2018/01/2018-01-20-spark-rdd-characteristics/)","tags":["RDD"],"categories":["Spark"]},{"title":"Data Modeling Paradigm","url":"%2F2018%2F01%2F2018-01-19-data-model-paradigm%2F","content":"\n### Concept\n\n* Business Modeling\n\n* Domain Modeling\n\n* Logical Modeling\n\n* Physical Modeling\n\n### Schema\n\n* Star Schema\n\n* Snowflake Schema\n\n* Fact Constellations Schema\n\n### Paradigm\n\n* Entity-relationship(E-R) Modeling\n\n   3NF, Entity\n\n* Dimension Modeling\n\n   Fact, Dimension\n\n* Data Vault Modeling\n\n   Hub, Link, Satellite\n\n* Anchor Modeling\n\n   Anchors, Attributes, Ties, Knots\n\n### Others\n\n* ETL\n* OLAP, OLTP\n* BI\n\n### Links\n\n* [浅谈数据仓库建设中的数据建模方法](https://www.ibm.com/developerworks/cn/data/library/techarticles/dm-0803zhousb/)\n* [数据仓库](http://www.cnblogs.com/muchen/category/794750.html) \n* [数据仓库之数据模型](http://lxw1234.com/archives/2018/01/890.htm)\n* [数据仓库中的模型设计](http://www.mdjs.info/2017/09/29/data-warehouse/data-model/)\n* [详解维度建模](http://www.mdjs.info/2017/01/05/data-warehouse/dimensona-modeling/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Modeling Paradigm](http://blog.hyperj.net/2018/01/2018-01-19-data-model-paradigm/)","tags":["Paradigm"],"categories":["DataWarehouse"]},{"title":"Data Table","url":"%2F2018%2F01%2F2018-01-18-data-table%2F","content":"\n### Keys\n\n* Natural Key（自然键）\n* Surrogate Key（代理键）\n* Primary Key（主键）\n* Foreign Key（外键）\n* Composite key（组合键）\n* Candidate key（候选键）\n* Alternate key（辅助键）\n\n### Tables\n\n* Integration Table（集成表）\n\n* Dimension Table（维度表）\n\n* Fact Table（事实表）\n\n* Bridge (Fact) Table（桥接表）\n\n* Aggregate (Fact) Table（聚集表）\n\n* Snapshot (Fact) Table（快照表）\n\n* Zipper (Fact) Table（拉链表）\n\n* Related (Fact) Table（连接表）\n\n* Wide Table（宽表）\n\n* Temporary Table（临时表）\n\n   With Table\n   Memory Table\n   Replicated Table\n   \n* External Table（外部表）\n\n### Others\n\n* Index\n* View\n* Data Types(Numeric Types, Date/Time Types, String Types, Misc Types, Complex Types<Array, Map, Struct, Union>)\n* Partitioned\n* Buckets - Clustered[Sorted] - Round Robin, Hash Distributed \n* Skewed\n* Row Format\n* File Format(Orc, Parquet, Avro)\n* Flat\n* Relation\n* Cardinality\n\n### Links\n\n* [Choosing a Primary Key: Natural or Surrogate?](http://www.agiledata.org/essays/keys.html)\n* [Kimball Techniques](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/)\n* [Hive Data Definition Language](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Table](http://blog.hyperj.net/2018/01/2018-01-18-data-table/)","tags":["Table"],"categories":["DataWarehouse"]},{"title":"Data Layer","url":"%2F2018%2F01%2F2018-01-17-data-layer%2F","content":"\n### Concept\n\n#### Source\n\n#### Stage/Buffer\n\n#### SOR(System Of Record)\n\n#### ODS(Operational Data Store)\n\n#### DW(Data Warehouse)\n\n* 维度（Dimension）\n* 字典（Dict）\n* 基数（Cardinality）\n* 度量（Measure）\n* 事实（Fact）\n* 实体（Entity）\n* 指标（Index）\n* 粒度（Granularity）\n* 标准（Standard）\n* 明细（Detail）\n* 计算（Calculate）\n* 聚合（Aggregate）\n* 汇总（Summary）\n* 主题（Topic/Theme）\n* 配置（Config）\n\n##### DWD(Data Warehouse Detail)\n\n##### DIM(Dimension)\n\n##### DWB(Data Warehouse Basis)\n\n##### DWS(Data Warehouse Service)\n\n##### TMP(Temporary)\n\n#### DM(Data Mart)\n\n#### Cude\n\n* OLAP(Online Analytical Process)\n   MOLAP(Multidimensional)\n   ROLAP(Relational)\n   HOLAP(Hybrid)\n* Segment\n* Hierarchy\n* Level\n* Memeber\n* Drill-down\n* Roll-up\n* Slice\n* Dice\n* Pivot\n\n#### APP(Application)\n\n#### ETL(Extract Transform Load)\n\n#### Other\n\n* BI（Business Intelligence）\n* Meta Data\n* Data Manegement\n\n### Links\n\n* [如何优雅地设计数据分层](http://dantezhao.com/2017/05/14/data-warehouse/data-layer/)\n* [数据仓库规范](http://www.cnblogs.com/HondaHsu/p/5314176.html)\n* [IBM数据仓库解决方案(简)](https://wenku.baidu.com/view/8a3d82257375a417866f8f16.html)\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Layer](http://blog.hyperj.net/2018/01/2018-01-17-data-layer/)","tags":["Area"],"categories":["DataWarehouse"]},{"title":"Flink Windows","url":"%2F2018%2F01%2F2018-01-16-flink-window%2F","content":"\n### Lifecycle\n\n### Keyed vs Non-Keyed\n\n### Assigners\n\n#### Tumbling Windows\n\n#### Sliding Windows\n\n#### Session Windows\n\n#### Global Windows\n\n### Window Functions\n\n#### ReduceFunction\n\n#### AggregateFunction\n\n#### FoldFunction\n\n#### ProcessWindowFunction\n\n### Triggers\n\n### Evictors\n\n### Links\n\n* [Flink Windows](https://ci.apache.org/projects/flink/flink-docs-master/dev/stream/operators/windows.html)\n* [Flink 原理与实现：Window 机制](http://wuchong.me/blog/2016/05/25/flink-internals-window-mechanism/)\n* [Flink 原理与实现：Session Window](http://wuchong.me/blog/2016/06/06/flink-internals-session-window/)\n* [Apache Flink源码解析之stream-window](http://vinoyang.com/2016/05/10/flink-stream-window/)\n* [深入理解Apache Flink核心技术](http://geek.csdn.net/news/detail/56272)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Flink Windows](http://blog.hyperj.net/2018/01/2018-01-16-flink-windows/)","tags":["Window"],"categories":["Flink"]},{"title":"Metadata","url":"%2F2018%2F01%2F2018-01-15-metadata%2F","content":"\n### Concept\n  \n* 元数据（Meta Data）\n  \n用于描述数据的数据，描述数据及其环境数据，包括：业务元数据、技术元数据、管理元数据\n\n* 元模型（Meta Model）\n  \n描述元数据的结构和关系的数据模型，是用来描述元数据的模型\n\n* 元元模型（Meta-meta Model）\n  \n元模型的模型，也被称为本体（Ontology），是模型驱动的元数据集成体系结构的基础\n \n* 关系（Relation）\n  \n**依赖关系（Dependence）**\n  \n   对于两个相对独立的元数据，当一个元数据引用了另一个元数据时，这两个元数据之间主要体现为依赖关系\n  \n**组合关系（Combination）**\n  \n   一种强关联关系，是整体和个体的关系，且整体和个体分属不同层，且整体的对象负责代表个体对象的生命周期\n\n* 分析（Analytics）\n\n**影响分析（Impact）**\n  \n   指为向用户直观展示元数据之间的流向关系而进行的以目标为起点往后分析\n  \n**血统分析（Lineage）**\n  \n   指为向用户直观展示元数据之间的流向关系而进行的以目标为起点往前分析\n  \n**全链分析（Link）**\n  \n   指为向用户直观展示元数据之间的流向关系而进行的以目标为起点往前后总体分析\n\n### Other\n\n* CWM（公共仓库元模型）\n* Graph（图谱）\n* Quality（质量）\n* Audit（审计）\n* Collection（采集）\n* Schedule（调度）\n* Adapter（适配器）\n* Template（模版）\n* Mapping（映射）\n* Model（模型）\n* Lifecycle（生命周期）\n* Version（版本）\n* Monitor（监控）\n* Statistics（统计）\n\n### Links\n\n* [元数据集成体系结构](https://www.ibm.com/developerworks/cn/data/library/bd-1503bigdatagovernance2/index.html)\n* [DMBOK：元数据管理](http://www.cnblogs.com/zhoujg/archive/2011/12/26/2301661.html)\n* [THE COMMON WAREHOUSE METAMODEL SPECIFICATION](http://www.omg.org/spec/CWM/)\n* [Common warehouse metamodel](https://en.wikipedia.org/wiki/Common_warehouse_metamodel)\n* [MetaCube Manual](http://doc.primeton.com/display/MetaCube62)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Metadata](http://blog.hyperj.net/2018/01/2018-01-15-metadata/)","tags":["MetaModel"],"categories":["Metadata"]},{"title":"卫星系统——酒店后端全链路日志收集工具介绍","url":"%2F2018%2F01%2F2018-01-15-satellite-system%2F","content":"\n# 背景\n\n随着酒店业务的高速发展，我们为用户、商家提供的服务越来越精细，系统服务化程度、复杂度也逐渐上升。微服务化虽然能够很好地解决问题，但也有副作用，比如，问题定位。\n\n![full_link](/assets/images/2018/01/15/satellite-system/full_link.jpeg)\n\n每次问题定位都需要从源头开始找同事帮我人肉查日志，举一个简单的例子：\n\n“这个详情页的价格是怎么算出来的?”\n\n一次用户酒店可订空房页（POI详情页）访问，流量最多需要经过73个服务节点。查问题的时候需要先后找4~5个关键节点的同学帮我们登录十多个不同节点的机器，查询具体的日志，沟通成本极大，效率很低。\n\n为了解决这个问题，基础架构的同学提供了MTrace（详情可以参考技术博客：《[分布式会话跟踪系统架构设计与实践](https://tech.meituan.com/mt-mtrace.html)》）协助业务方排查长链路问题。\n\n但是与此同时，还有许多不确定性因素，使问题排查过程更加艰难，甚至无果而终：\n\n1. 各服务化节点存储日志的时间长度不一致；\n2. 有的服务节点，因为QPS过高，只能不打或者随机打印日志，会导致最终查问题的时候，线索因为没日志断掉；\n3. 有的服务节点，使用了异步逻辑（线程池、Hystrix、异步RPC等）导致日志中缺失Trace ID，无法关联在一起；\n4. 各服务节点的采样率不一样，链路数据的上报率也是随机性的，线索容易断掉；\n5. MTrace上只有链路信息，没有关联各服务节点的日志信息；\n6. [动态扩容](https://tech.meituan.com/hulk-scheduler-introduction.html)节点上的日志，缩容后无法找到。\n\n总结起来如图所示：\n\n![trace_summury](/assets/images/2018/01/15/satellite-system/trace_summery.png)\n\n# 目标\n\n我们的核心诉求有两个：\n\n1. 根据用户行为快速定位到具体的Trace ID，继而查询到这次服务调用链路上所有节点的日志；\n2. 查询的实时性要能做到准实时（秒级输出），相关链路日志要在独立外部存储系统中保存半年以上。\n\n然后我们对诉求做了进一步的拆分：\n\n1. 全量打日志不现实，需要选择性打，打价值最高部分的日志；\n2. 链路数据需要全服务节点都上传，避免因为异步化等原因造成链路数据中断不上传；\n3. 接入方式尽量简单，避免所有服务节点都需要修改具体业务代码来接入。最好是能通过日志拦截的方式，其它保持透明；\n4. 日志格式化，该有的字段（AppKey、hostname、IP、timestamp等）不需要业务RD反复输入，自动补齐；\n5. 在不阻塞原有业务操作的情况下，做到准实时展示链路、日志；\n6. 链路数据和日志数据存储，不依赖各服务节点，需要在独立的存储系统上存储半年以上。\n\n# 系统\n\n搞清了核心诉求后，我们针对性地做了许多调研，最终定了一个系统的整体设计方案，这就是目前已经上线并实践已久的美团点评酒店「**卫星系统**」。\n\n下面，我们就来对系统做详细介绍，包括一些核心细节点。\n\n## 架构\n\n如下图所示，卫星系统从横向分为链路和日志两个部分。\n\n![现状](/assets/images/2018/01/15/satellite-system/article-jiagou.png)\n\n<center>图2 全链路日志系统整体架构</center>\n\n链路部分是以MTrace为基础，用支持超时fallback下Trace信息传递的Hystrix-Trace插件来覆盖全部场景，保证链路被完整采集。\n\n日志部分在接入端有三大核心步骤，首先是依托于日志拦截组件实现对业务代码零侵入的情况下收集系统中所有日志内容，然后根据统一日志规范对日志进行格式化处理，最后通过基于logcenter日志传输机制实现日志到Kafka的传输。\n\n从纵向又分为：\n\n1. 业务接入层，根据策略采集Trace与业务日志；\n\n2. 数据处理层，通过storm流式处理日志信息；\n\n3. 数据存储层，用于支持实时查询的Squirrel（美团点评Redis集群）与持久存储的ES（ElasticSearch），以及面向用户的展示层。\n\n### 日志采样方案\n\n接入端是所有数据之源，所以方案设计极为关键。要解决的问题有：采集策略、链路完整性保障、日志拦截、日志格式化、日志传输。\n\n有的业务单台机器每天日志总量就有百G以上，更有不少业务因为QPS过高而选择平时不打印日志，只在排查问题时通过动态日志级别调整来临时输出。所以，我们在最初收集日志时必须做出取舍。经过分析，发现在排查问题的时候，绝大多数情况下发起人都是自己人（RD、PM、运营），如果我们只将这些人发起的链路日志记下来，那么目标日志量将会极大减少，由日志量过大而造成的存储时间短、查询时效性差等问题自然得到解决。\n\n所以我们制定了这样的采集策略：\n\n通过在链路入口服务判断发起人是否满足特定人群（住宿事业部员工）来决定是否进行日志采集，将采集标志通过MTrace进行全链路传递。这样就能保证链路上所有节点都能行为一致地去选择是否进行日志上报，保证链路上日志的完整性。\n\n### 日志拦截\n\n作为核心要素的日志，如何进行收集是一个比较棘手的问题。让业务方强制使用我们的接口进行日志输出会带来许多麻烦，一方面会影响业务方原有的日志输出策略；另一方面，系统原有的日志输出点众多，涉及的业务也五花八门，改动一个点很简单，但是全面进行改动难保不会出现未知影响。所以，需要尽可能降低对接入方代码的侵入。\n\n由于目前酒店核心业务已全面接入log4j2，通过研究，发现我们可以注册全局Filter来遍历系统所有日志，这一发现，使我们实现了代码零改动的情况下收集到系统所有日志。\n\n![过滤](/assets/images/2018/01/15/satellite-system/article-filter.png)\n\n<center>图3 基于log4j2 filter机制的日志收集策略</center>\n\n### 日志格式化\n\n业务系统输出的日志格式不一，比如有的没有打印TraceID信息，有的没有打印日志位置信息从而很难进行定位。这主要带来两方面的问题，一方面不利于由人主导的排查分析工作，另一方面也不利于后续的系统优化升级，比如对日志的自动化分析报警等等。\n\n针对这些问题，我们设计了统一日志规范，并由框架完成缺失内容的填充，同时给业务方提供了标准化的日志接口，业务方可以通过该接口定义日志的元数据，为后续支持自动化分析打下基础。\n\n由框架填充统一日志信息这一过程利用到了log4j2的Plugins机制，通过Properties、Lookups、ContextMap实现业务无感知的操作。\n\n![现状](/assets/images/2018/01/15/satellite-system/article-log.png)\n\n<center>图4 通过Plugins机制支持格式化日志属性传递</center>\n\n### 日志处理\n\n我们在最终的日志传输环节利用了日志中心的传输机制，使用日志中心的ScribeAppender实现日志传输至本地agent，然后上报到远端Kafka，这样设计有几点好处：\n\n1. 依赖公司成熟的基础服务相对而言更可靠、更稳定，同时也省去了自己搭建服务、保证服务安全这一过程；\n2. 可以将日志直接转存至日志中心ES做持久化存储，同时支持快速灵活的数据检索；\n3. 可以通过Storm对日志进行流式处理，支持灵活的系统扩展，比如：实时检索、基于日志的实时业务检查、报警等等，为后续系统扩展升级打下基础。\n\n我们的数据处理逻辑全部在Storm进行处理，主要包含日志存储Squirrel（美团点评内部基于Redis Cluster研发的纯内存存储）、实时检索与Trace同步。\n\n目前日志中心ES能保证分钟级别实时性，但是对于RD排查问题还是不够，必须支持秒级别实时性。所以我们选择将特定目标用户的日志直接存入Squirrel，失效时间只有半小时，查询日志时结合ES与Squirrel，这样既满足了秒级别实时性，又保证了日志量不会太大，对Squirrel的压力可以忽略不计。\n\n我们的系统核心数据有链路与日志，链路信息的获取是通过MTrace服务获得，但是MTrace服务对链路数据的保存时间有限，无法满足我们的需求。所以，我们通过延时队列从MTrace获取近期的链路信息进行落地存储，这样就实现了数据的闭环，保证了数据完整性。\n\n### 链路完整性保障\n\nMTrace组件的Trace传递功能基于ThreadLocal，而酒店业务大量使用异步化逻辑（线程池、Hystrix），这样会造成传递信息的损失，破坏链路完整性。\n\n一方面，通过Sonar检查和梳理关键链路，来确保业务方使用类似[transmittable-thread-local](https://github.com/alibaba/transmittable-thread-local)中的`ExecutorServiceTtlWrapper.java`、`ExecutorTtlWrapper.java`的封装，来将ThreadLocal里的Trace信息，也传递到异步线程中（前文提到的MTrace也提供这样的封装）。\n\n另一方面，Hystrix的线程池模式会造成线程变量丢失。为了解决这个问题，MTrace提供了Mtrace Hystrix Support Plugin插件实现跨线程调用时的线程变量传递，但是由于Hystrix有专门的timer线程池来进行超时fallback调用，使得在超时情况下进入fallback逻辑以后的链路信息丢失。\n\n针对这个问题，我们深入研究了Hystrix机制，最终结合Hystrix Command Execution Hook、Hystrix ConcurrencyStrategy、Hystrix Request Context实现了覆盖全场景的Hystrix-Trace插件，保障了链路的完整性。\n\n```java\nHystrixPlugins.getInstance().registerCommandExecutionHook(new HystrixCommandExecutionHook() {\n    @Override\n    public <T> void onStart(HystrixInvokable<T> commandInstance) {\n        // 执行command之前将trace信息保存至hystrix上下文，实现超时子线程的trace传递\n        if (!HystrixRequestContext.isCurrentThreadInitialized()) {\n            HystrixRequestContext.initializeContext();\n        }\n        spanVariable.set(Tracer.getServerSpan());\n    }\n\n    @Override\n    public <T> Exception onError(HystrixInvokable<T> commandInstance, HystrixRuntimeException.FailureType failureType, Exception e) {\n        // 执行结束后清空hystrix上下文信息\n        HystrixRequestContext context = HystrixRequestContext.getContextForCurrentThread();\n        if (context != null) {\n            context.shutdown();\n        }\n        return e;\n    }\n\n    @Override\n    public <T> void onSuccess(HystrixInvokable<T> commandInstance) {\n        // 执行结束后清空hystrix上下文信息\n        HystrixRequestContext context = HystrixRequestContext.getContextForCurrentThread();\n        if (context != null) {\n            context.shutdown();\n        }\n    }\n});\n\nHystrixPlugins.getInstance().registerConcurrencyStrategy(new HystrixConcurrencyStrategy() {\n    @Override\n    public <T> Callable<T> wrapCallable(Callable<T> callable) {\n        // 通过自定义callable保存trace信息\n        return WithTraceCallable.get(callable);\n    }\n});\n```\n\n## 效果展示\n\n比如以排查一次用户点击某POI详情页的TraceID为例子：\n\n我们可以看到他在MTrace中的调用链路是这样的：\n\n![mtrace](/assets/images/2018/01/15/satellite-system/mtrace.png)\n\n在卫星系统中，展示为如下效果：\n\n![satellite](/assets/images/2018/01/15/satellite-system/satellite.png)\n\n可见，在保留了链路数据的基础上，系统还将全链路节点日志聚合到了一起，提升了排查效率。\n\n# 后续规划\n\n目前，系统还处于初级阶段，主要用来解决RD在排查问题时的两大痛点：日志信息的不完整与太分散，现在已经满足了这一需求。但是，全链路日志系统能做的不止这些，后续的主要规划有如下几方面：\n\n1. 支持多链路日志关联搜索，比如一次列表页刷新与后续的详情页展示，虽然链路是多个但是实际处在一个关联的场景中。支持关联搜索就可以可以将日志排查目标从单个动作维度扩展到多动作组成的场景维度。\n2. 支持业务方自定义策略规则进行基于日志的自动化业务正确性检查，如果检查出问题可以直接将详细信息通知相关人员，实现实时监测日志、实时发现问题、实时通知到位，免去人工费时费力的低效劳动。\n\n# 作者简介\n\n* 亚辉，2015年加入美团点评，就职于美团点评酒旅事业群技术研发部酒店后台研发组。\n\n* 曾鋆，2013年加入美团点评，就职于美团点评酒旅事业群技术研发部酒店后台研发组。\n\n---\n\n* Author：亚辉 曾鋆\n* Source：[美团点评技术团队](http://tech.meituan.com)\n* Link：[卫星系统——酒店后端全链路日志收集工具介绍](https://tech.meituan.com/satellite_system.html)","tags":["Satellite System"],"categories":["Log"]},{"title":"Data Analytics Models","url":"%2F2018%2F01%2F2018-01-14-data-analytics-models%2F","content":"\n### Base Data Analytics Models\n\n#### Event Analysis Model\n\n* Who、When、Where、What、How\n* OLAP\n   \n#### Funnel Analysis Model\n   \n#### Retained Analysis Model\n   \n#### Distribution Analysis Model\n   \n#### Path Analysis Model\n   \n#### Sequence Analysis Model\n   \n#### Group Analysis Model\n   \n#### Attribute analysis Model\n\n### Links\n\n* [Sensors Analytics Manual](https://www.sensorsdata.cn/manual/use_guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Analytics Models](http://blog.hyperj.net/2018/01/2018-01-14-data-analytics-models/)","tags":["Models"],"categories":["Analytics"]},{"title":"Kylin Optimization","url":"%2F2018%2F01%2F2018-01-13-kylin-optimization%2F","content":"\n### Cube Optimization\n\n#### Aggregation Group\n\n#### TopN\n\n#### Count Distinct\n\n#### Count Distinct(Precise)\n\n### Dimension Optimization\n\n#### Aggregation Group（聚合组）\n\n#### Hierarchy Dimension（层级维度）\n\n#### Mandatory Dimension（必要维度）\n\n#### Derived Dimension（派生维度）\n\n#### Joint Dimension（联合维度）\n\n#### Extended Dimension（扩展维度）\n\n#### Cardinality Dimension（基数维度）\n\n### Links\n\n* [Kylin Docs](http://kylin.apache.org/docs21/)\n* [KAP Manual](http://docs.kyligence.io/v2.4/en/)\n* [Kylin Category](http://lxw1234.com/archives/category/kylin)\n* [Apache Kylin 维度优化指南](https://blog.bcmeng.com/post/kylin-dimension.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Kylin Optimization](http://blog.hyperj.net/2018/01/2018-01-13-kylin-optimization/)","tags":["Kylin"],"categories":["Optimization"]},{"title":"Data Masking","url":"%2F2018%2F01%2F2018-01-12-data-masking%2F","content":"\n### Concept\n\nData involved in any data-masking or obfuscation must remain meaningful at several levels:\n\n* The data must remain meaningful for the application logic. \n* The data must undergo enough changes so that it is not obvious that the masked data is from a source of production data.\n\n#### Keyword\n\n* PII: Personally Identifiable Information.\n* EI: explicit identifiers.\n* QI: Quasi-identifiers. \n* SD: Sensitive data.\n* NSD: Nonsensitive data.\n\n#### Algorithm\n\n* Randomization\n* Generalization\n* K-Anonimization\n* L-Diversity\n* T-Closeness\n\n#### Static data masking (SDM)\n\ndata at rest.\n\n#### Dynamic data masking (DDM)\n\ndata in transit.\n\n### Techniques\n\n* Substitution\n\n* Shuffling\n\n* Number and date variance\n\n* Encryption\n \n* Nulling out or deletion\n\n* Masking out\n\n* Additional complex rules\n\n### Other\n\n* Management\n* Rule\n* Audit\n\n### Links \n\n* [Data masking](https://en.wikipedia.org/wiki/Data_masking)\n* [Static Versus Dynamic Data Masking](https://www.imperva.com/blog/2017/07/static-versus-dynamic-data-masking/)\n* [美团数据仓库-数据脱敏](http://blog.hyperj.net/2014/2014-04-08-data-mask/)\n* [大数据与数据脱敏](https://zhuanlan.zhihu.com/p/20824603)\n* [Data privacy、Principle and Practices精简（一）](http://blog.csdn.net/sculvlv/article/details/70624625)\n* [Data privacy、Principle and Practices精简（二）](http://blog.csdn.net/sculvlv/article/details/70791169)\n* [k-anonimity、l-diversity 和 t-closeness](http://blog.csdn.net/sculvlv/article/details/71077689)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Masking](http://blog.hyperj.net/2018/01/2018-01-12-data-masking/)\n","tags":["HyperJ"],"categories":["DataMasking"]},{"title":"Slowly Changing Dimensions (SCDs)","url":"%2F2018%2F01%2F2018-01-11-slowly-changing-dimensions%2F","content":"\n### Concept\n\nDimensions in data management and data warehousing contain relatively static data about such entities as geographical locations, customers, or products. Data captured by Slowly Changing Dimensions (SCDs) change slowly but unpredictably, rather than according to a regular schedule.\n\n### Type\n\n![Slowly Changing Dimensions (SCDs)](/assets/images/2018/01/11/slowly-changing-dimensions/slowly-changing-dimensions.png)\n\n#### Type 0: Retain Original\n\nAs Date/Area Dimension Attributes\n\n#### Type 1: Overwritten\n\n#### Type 2: Add New Row\n\n#### Type 3: Add New Attribute\n\n#### Type 4: Add Mini-Dimension\n\n#### Type 5: Add Mini-Dimension and Type 1 Outrigger\n\n#### Type 6: Add Type 1 Attributes to Type 2 Dimension\n\n#### Type 7: Dual Type 1 and Type 2 Dimensions\n\n#### Other\n\n* History / Snapshot / Zipper Table\n\n### Links \n\n* [Slowly changing dimension](https://en.wikipedia.org/wiki/Slowly_changing_dimension)\n* [Slowly Changing Dimensions Are Not Always as Easy as 1, 2, 3](https://www.kimballgroup.com/2005/03/slowly-changing-dimensions-are-not-always-as-easy-as-1-2-3/)\n* [ Design Tip #152 Slowly Changing Dimension Types 0, 4, 5, 6 and 7](https://www.kimballgroup.com/2013/02/design-tip-152-slowly-changing-dimension-types-0-4-5-6-7/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Slowly Changing Dimensions (SCDs)](http://blog.hyperj.net/2018/01/2018-01-11-slowly-changing-dimensions/)\n","tags":["SCD"],"categories":["DataWarehouse"]},{"title":"A/B Testing","url":"%2F2018%2F01%2F2018-01-10-abtesting%2F","content":"\n### Concept\n\n#### APP, Page, Module, Layer\n\n#### Bucket\n\n* Benchmark\n* Fallback\n* Parent\n* Isolation area, parallel area\n\n#### Flow & Strategy\n\n* Orthogonal experiment\n* Mutual exclusion experiment\n* Correlation experiment\n\n#### Task\n\n* Management\n* Mapping\n\n#### Other\n\n* Gray Release\n* Client & Server\n* White List\n* IP/UUID/CityID\n* App Version\n* Period\n* Platform\n\n### Hypothesis Testing\n\n### Links\n\n* [A/B testing](https://en.wikipedia.org/wiki/A/B_testing)\n* [Twitter的A/B测试实践（一）：为什么要测试以及测试的意义](http://www.infoq.com/cn/articles/twitter-ab-test-practise-part01)\n* [Twitter的A/B测试实践（二）：技术概述](http://www.infoq.com/cn/articles/twitter-ab-test-practise-part02)\n* [Twitter的A/B测试实践（三）：检测和避免 A/B Test中 bucket不平衡问题](http://www.infoq.com/cn/articles/twitter-ab-test-practise-part03)\n* [Twitter的A/B测试实践（四）：A/B Test中使用多个控制的启示](http://www.infoq.com/cn/articles/twitter-ab-test-practise-part04)\n* [谈谈A/B Test](http://blog.csdn.net/u012160689/article/details/16343875)\n* [AB测试和灰度发布平台架构设计和实践](http://topic.it168.com/factory/adc2013/doc/oucheng.pdf)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[A/B Testing](http://blog.hyperj.net/2018/01/2018-01-10-abtesting/)","tags":["Bucket Testing"],"categories":["Testing"]},{"title":"Data Development & Testing","url":"%2F2018%2F01%2F2018-01-09-data-development-testing%2F","content":"\n### Workflow Item\n\n#### Check the amount of data\n\n#### Check the diff of data\n\n#### Check the specification & legality of data\n\n#### Check the type of data\n\n#### Check the distribution of data\n\n#### Check the logic of business & data\n\n#### Sampling check\n\n#### Performance check\n\n### Other\n\n* Requirement\n* Business\n* Data caliber\n* Data quality\n* Data granularity\n* Benchmark\n* Review\n* Rerun\n* Update\n* Rollback\n* Important\n* Impact on upstream & downstream data.\n\n### Table Case\n\n| No. | Case | Type | Step | Reason | Status | Result | Summary |\n| --- | ---- | ---- | ---- | ------ | ------ | ------ | ------- |\n| #c1 | desc | logic | 1. 2. 3. 4. | logic | fixed | result | summary |\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Development & Testing](http://blog.hyperj.net/2018/01/2018-01-09-data-development-testing/)\n","tags":["Testing"],"categories":["DataWarehouse"]},{"title":"Hive Optimization","url":"%2F2018%2F01%2F2018-01-08-hive-optimization%2F","content":"\n### Hive\n\n#### Configuration Properties\n\nMore [Hive Configuration Properties](https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties)\n\n##### dynamic partition\n\n###### hive.exec.dynamic.partition\n\n    Default Value: false prior to Hive 0.9.0; true in Hive 0.9.0 and later (HIVE-2835)\n    Added In: Hive 0.6.0\n    Whether or not to allow dynamic partitions in DML/DDL.\n    set hive.exec.dynamic.partition = true\n\n###### hive.exec.dynamic.partition.mode\n\n    Default Value: strict\n    Added In: Hive 0.6.0\n    In strict mode, the user must specify at least one static partition in case the user accidentally overwrites all partitions. In nonstrict mode all partitions are allowed to be dynamic.\n    Set to nonstrict to support INSERT ... VALUES, UPDATE, and DELETE transactions (Hive 0.14.0 and later). For a complete list of parameters required for turning on Hive transactions, see hive.txn.manager.\n    set hive.exec.dynamic.partition.mode = nonstrict\n\n###### hive.exec.max.dynamic.partitions\n\n    Default Value: 1000\n    Added In: Hive 0.6.0\n    Maximum number of dynamic partitions allowed to be created in total.\n    set hive.exec.max.dynamic.partitions = 1000\n\n###### hive.exec.max.dynamic.partitions.pernode\n\n    Default Value: 100\n    Added In: Hive 0.6.0\n    Maximum number of dynamic partitions allowed to be created in each mapper/reducer node.\n    set hive.exec.max.dynamic.partitions.pernode = 100\n\n##### parallel\n\n###### hive.exec.parallel\n\n    Default Value: false\n    Added In: Hive 0.5.0\n    Whether to execute jobs in parallel.  Applies to MapReduce jobs that can run in parallel, for example jobs processing different source tables before a join.  As of Hive 0.14, also applies to move tasks that can run in parallel, for example moving files to insert targets during multi-insert.\n    set hive.exec.parallel = true\n\n###### hive.exec.parallel.thread.number\n\n    Default Value: 8\n    Added In: Hive 0.6.0\n    How many jobs at most can be executed in parallel.\n    set hive.exec.parallel.thread.number = 12\n\n##### merge\n\n###### hive.merge.mapfiles\n\n    Default Value: true\n    Added In: Hive 0.4.0\n    Merge small files at the end of a map-only job.\n    set hive.merge.mapfiles = true\n\n###### hive.merge.mapredfiles\n\n    Default Value: false\n    Added In: Hive 0.4.0\n    Merge small files at the end of a map-reduce job.\n    set hive.merge.mapredfiles = true\n\n##### optimize\n\n###### hive.optimize.groupby\n\n    Default Value: true\n    Added In: Hive 0.5.0\n    Whether to enable the bucketed group by from bucketed partitions/tables.\n    set hive.optimize.groupby = true\n\n#### Deprecated Properties\n\nSee [Hadoop Deprecated Properties](http://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-common/DeprecatedProperties.html)\n\n#### Design \n\n#### Program\n\n##### pruning\n\n##### join\n\n##### count distinct\n\n##### group by\n\n##### (not) in/exists\n\n##### multi insert、union all\n\n#### Other\n\n### Hadoop \n\n#### Core\n\n#### HDFS\n\n#### YARN\n\n#### MapReduce\n\n### Spark\n\n### Server & OS\n\n### Links \n\n* [Hive Wiki](https://cwiki.apache.org/confluence/display/Hive/Home)\n* [Hive Configuration Properties](https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties)\n* [Hadoop Deprecated Properties](http://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-common/DeprecatedProperties.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Hive Optimization](http://blog.hyperj.net/2018/01/2018-01-08-hive-optimization/)\n","tags":["HyperJ"],"categories":["Optimization"]},{"title":"Spark Optimization","url":"%2F2018%2F01%2F2018-01-07-spark-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Optimization](http://blog.hyperj.net/2018/01/2018-01-07-spark-optimization/)","tags":["HyperJ"],"categories":["Optimization"]},{"title":"MapReduce Optimization","url":"%2F2018%2F01%2F2018-01-06-mapreduce-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[MapReduce Optimization](http://blog.hyperj.net/2018/01/2018-01-06-mapreduce-optimization/)","tags":["MapReduce"],"categories":["Optimization"]},{"title":"HBase Optimization","url":"%2F2018%2F01%2F2018-01-05-hbase-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HBase Optimization](http://blog.hyperj.net/2018/01/2018-01-05-hbase-optimization/)","tags":["HyperJ"],"categories":["Optimization"]},{"title":"HDFS Optimization","url":"%2F2018%2F01%2F2018-01-04-hdfs-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Optimization](http://blog.hyperj.net/2018/01/2018-01-04-hdfs-optimization/)","tags":["HDFS"],"categories":["Optimization"]},{"title":"Yarn Optimization","url":"%2F2018%2F01%2F2018-01-03-yarn-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Yarn Optimization](http://blog.hyperj.net/2018/01/2018-01-03-yarn-optimization/)","tags":["Yarn"],"categories":["Optimization"]},{"title":"ElasticSearch Optimization","url":"%2F2018%2F01%2F2018-01-02-elasticsearch-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[ElasticSearch Optimization](http://blog.hyperj.net/2018/01/2018-01-02-elasticsearch-optimization/)","tags":["ES"],"categories":["Optimization"]},{"title":"Java Optimization","url":"%2F2018%2F01%2F2018-01-01-java-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Java Optimization](http://blog.hyperj.net/2018/01/2018-01-01-java-optimization/)\n","tags":["HyperJ"],"categories":["Optimization"]},{"title":"UTM 整理","url":"%2F2017%2F2017-12-07-utm%2F","content":"\n`UTM`是“Urchin Tracking Module”——追踪网址成效表现的简写。通过向在广告系列中使用的目标网址添加广告系列参数，可以收集这些广告系列整体效果的相关信息，还可以了解广告系列在何处投放时效果更好。例如，在“夏季特惠”广告系列可能带来了大量收入，但如果在几个不同的社交应用中投放该广告系列，那么想要知道在哪个应用中投放的广告系列带来了产生最多收益的客户。或者，如果通过电子邮件、视频广告和应用内广告投放不同版本的广告系列，则可以比较具体成效，以了解使用何种方式时的营销举措效果最好。\n\n可以向网址中添加下列 5 个参数：\n\n* `utm_source`：标识媒体资源带来流量的广告客户、网站、出版物等，例如：google、newsletter4、billboard。\n* `utm_medium`：广告媒介或营销媒介，例如：每次点击费用、横幅广告和电子邮件简报。\n* `utm_campaign`：产品的具体广告系列名称、标语、促销代码等。\n* `utm_term`：标识付费搜索关键字。如果采用人工方式标记付费关键字广告系列，那么还应使用 `utm_term` 来指定相应关键字。\n* `utm_content`：用于区分相似内容或同一广告内的链接。例如，如果在同一封电子邮件中使用了两个号召性用语链接，就可以使用 `utm_content` 并为每个链接设置不同的值，以便判断哪个版本的效果更好。\n\n每个参数都必须对应一个分配的值。每个参数-值对都包含广告系列相关信息。\n\n例如，可以对自己的“夏季特惠”广告系列使用下列参数-值对：\n\n`utm_source = summer-mailer` 可标识来自“夏季特惠”电子邮件广告系列的流量\n\n`utm_medium = email` 可标识来自电子邮件广告系列与应用内广告系列的流量\n\n`utm_campaign = summer-sale` 可标识整个广告系列\n\n如果使用了这些参数，则您的自定义广告系列网址会如下所示：\n\n`https://www.example.com/?utm_source=summer-mailer&utm_medium=email&utm_campaign=summer-sale`\n\n向网址中添加参数时，应当始终使用 utm_source、utm_medium 和 utm_campaign。\n\n`utm_term` 和 `utm_content` 是可选项。\n\n`utm_` 只是这些参数的必需前缀。\n\n### Links \n\n* [自定义广告系列](https://support.google.com/analytics/answer/1033863)\n* [自定义自然搜索来源](https://support.google.com/analytics/answer/2795821)\n* [广告系列和流量来源](https://support.google.com/analytics/answer/6205762)\n* [词汇表](https://support.google.com/analytics/topic/6083659)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[UTM 整理](http://blog.hyperj.net/2017/2017-12-07-utm/)\n","tags":["UTM"],"categories":["UTM"]},{"title":"《数据湖架构(Data Lake Architecture)》——读书笔记","url":"%2F2017%2F2017-09-06-data-lake-architecture%2F","content":"\n### 数据湖 基础组件\n\n#### 元数据（metadata）\n\n元数据被分析师用来解密在数据湖中发现的初始数据。元数据是栖息在数据湖中的数据的基本轨迹图。\n\n#### 整合图谱（integration mapping）\n\n整合图谱是数据湖中的数据如何被整合的详细规范。它阐述了如何解决仓罐数据的隔绝性问题。\n\n#### 语境（context）\n\n如果你想把文本放入数据湖，那么你必须把文本语境也放置在其中。或者至少提供找到文本语境的方法。\n\n#### 元过程（metaprocess）\n\n元过程标签是关于数据湖中的数据处理的信息。\n\n### 数据湖 数据分类\n\n模拟信号数据（analog data）和应用程序数据（application data）是具有重复性的，而文本数据则是非重复性的。\n\n#### 模拟信号数据（analog data）\n\n#### 应用程序数据（application data）\n\n#### 文本数据（texture data）\n\n### 数据湖 数据池\n\n初始数据 -> 数据修整 -> 模拟信号数据 | 应用程序数据 | 文本数据 -> 数据池 -> 归档数据池\n\n### Links \n\n* [从数据仓库到数据湖——浅谈数据架构演进(加强版)](http://zhuanlan.51cto.com/art/201701/529077.htm)\n* [漫谈大数据(zhaodedong)](http://blog.csdn.net/column/details/16038.html)\n* [数据仓库（dazheng）](http://blog.csdn.net/dazheng/article/category/5667637)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[《数据湖架构(Data Lake Architecture)》——读书笔记](http://blog.hyperj.net/2017/2017-09-06-data-lake-architecture/)\n","tags":["Data-Lake"],"categories":["Data-Lake"]},{"title":"美团点评数据平台融合实践","url":"%2F2017%2F2017-08-25-dataplat-coalesce%2F","content":"\n**本文根据作者在2017年ArchSummit的分享记录整理而成。**\n\n### 背景\n\n互联网格局复杂多变，大规模的企业合并重组不时发生。原来完全独立甚至相互竞争的两家公司，有着独立的技术体系、平台和团队，如何整合，技术和管理上的难度都很大。2015年10月，美团与大众点评合并为今天的“美团点评”，成为全球规模最大的生活服务平台。主要分布在北京和上海两地的两支技术团队和两套技术平台，为业界提供了一个很好的整合案例。\n\n本文将重点讲述数据平台融合项目的实践思路和经验，并深入地讨论Hadoop多机房架构的一种实现方案，以及大面积SQL任务重构的一种平滑化方法。最后介绍这种复杂的平台系统如何保证平稳平滑地融合。\n\n两家公司融合之后，从业务层面上，公司希望能做到“1+1&gt;2”，所以决定将美团和大众点评两个App的入口同时保留，分别做出各自的特色，但业务要跨团队划分，形成真正的合力。比如丽人、亲子、结婚和休闲娱乐等综合业务以及广告、评价UGC等，都集中到上海团队；而餐饮、酒店旅游等业务集中到北京团队。为了支撑这种整合，后台服务和底层平台也必须相应融合。\n\n点评App和美团App的数据，原来会分别打到上海和北京两地的机房，业务整合之后，数据的生产地和数据分析的使用地可能是不一样的。同时，随着公司的融合，我们跨团队、跨业务线的分析会越来越多，并且还需要一些常态化的集团级报表，包括流量的分析表、交易的数据表，而这些在原来都是独立的。\n\n举个例子，原点评侧的分析师想要分析最近一年访问过美团和大众点评两个App的重合用户数，他需要经过这样一系列的过程：如下图所示，首先他要想办法找到数据，这样就需要学习原美团侧数据平台元数据的服务是怎么用的，然后在元数据服务上去找到数据，才能开始做分析。而做分析其实是一个人工去做SQL分解的过程，他需要把原点评侧的去重购买用户数拉下来，然后发到原美团侧的数据平台，这个环节需要经历一系列的操作，包括申请账号、下载数据、上传数据，可能还会踩到各种上传数据限制的坑等等。最终，如果在这些都走完之后想做一个定期报表，那他可能每天都要去人工处理一回。如果他的分析条件变了怎么办？可能还要再重新走一遍这个流程。\n\n![1](/assets/images/2017/08/25/dataplat_coalesce/1.png)\n\n所以他们特别痛苦，最终的结果是，分析师说：“算了，我们不做明细分析了，我们做个抽样分析吧！”最后他做了一个在Excel里就能做的去重数据量的分析。我们作为平台开发的同学来说，看到这个事情是非常羞愧的。那怎么办呢？\n\n在经过一些磨合后，我们得出一个结论，就是必须进行数据口整合。\n\n### 融合实践\n\n#### 确立目标\n\n我们定了一个整体的目标，希望最终是能做到一个集群、一套数据平台的工具、一套开发规范。但是这个目标有点大，怎么把它变的可控起来呢？首先至少看来是一个集群，也就是说从用户访问的角度上来讲，他通过一个Client或一套用户视图就能访问。工具方面至少明确已有的两套，哪些是新的员工进来之后还需要学，哪些是未来会抛弃掉的。最终，让大家认同我们有了一套数据平台规范，虽然这套规范短期内还没有办法做到完美。我们做的这些权衡其实是为了从整体上能将问题收敛。\n\n但即使我们把这个目标缩小了，想要达到也是很难的。难点在哪呢？\n\n#### 难点\n\n##### 架构复杂，基础设施限制\n\n![2](/assets/images/2017/08/25/dataplat_coalesce/2.png)\n\n如上图所示，整个数据平台基本上分为数据接入、数据开发、数据分析、数据输出等等几个阶段。我这里只列了其中涉及到跨机房、跨地域的部分，还有很多数据平台产品的融合，在这里就不赘述了。在两个公司融合之前，原点评侧和美团侧都已经在同地域进行多机房的部署了，也都很&quot;默契&quot;地抽象出了离线的机房是相对独立的。在线的业务机房不管是通过消息队列还是原点评自己当时做的Blackhole（一个类似DataX的产品），都会有一系列数据收集的过程、对应任务的调度系统和对应的开发工具，也会有一些不在数据开发体系内的、裸的开源客户端的跳板机。虽然架构大体一致，但是融合项目会牵扯整套系统，同时我们有物理上的限制，就是当时跨机房带宽只有10Gb。\n\n##### 可靠性要求\n\n由于团购网站竞争激烈，两家公司对于用数据去优化线上的一些运营策略以控制运营成本，以及用数据指导销售团队的管理与支撑等场景，都有极强的数据驱动意识，管理层对于数据质量的要求是特别高的。我们每天从零点开始进行按天的数据生产，工作日9点，老板们就坐在一起去开会，要看到昨天刚刚发生过什么、昨天的运营数据怎么样、昨天的销售数据怎么样、昨天的流量数据怎么样；工作日10点，分析师们开始写临时查询，写SQL去查数据，包括使用Presto、Hive，一直到22点；同时数据科学家开始去调模型。如果我们集群不能work，几千人每天的工作就只能坐在电脑面前看着Excel……\n\n当时的分析是这样，如果考虑回滚的情况下，我们运维的时间窗口在平日只有一个小时，而且要对全公司所有用数据的同学进行通告，这一个小时就是他们下班之后，晚上6点至7点的时候开始，做一个小时，如果一个小时搞不定，回滚还有一个小时。周末的话好一点，可以做4小时之内，然后做全面的通告，相当于整个周末大家都没法加班了，他们是非常不开心的。\n\n![3](/assets/images/2017/08/25/dataplat_coalesce/3.png)\n![4](/assets/images/2017/08/25/dataplat_coalesce/4.png)\n\n##### 体量\n\n虽然没有到BAT几万台节点的规模，但是也不算小了，融合时原点评的节点数是500个，数据量是11个P；原美团的节点数是3000个，现在整体已经上6000了。这里有一个比较关键的数据就是每天生成的数据量，由于我们的集群上面以数仓的场景为主，会有很多重新计算，比如说我要看去年每月的去重，这些都是经过一些时间变化之后会进行重算的。它对于分析数据的迭代速度要求很高，我每天可能都会有新的需求，如果原来的数据表里面要加一个字段，这个字段是一个新的统计指标，这个时候我就要看历史上所有的数据，就得把这些数据重新跑一遍。这里的生成数据量其中有50%是对历史的替换，50%是今天新增的。这对于后面我们拷数据、挪数据是比较大的挑战。\n\n##### 平台化与复杂度\n\n两家公司其实都已经慢慢变成一个平台，也就是说数据平台团队是平台化的，没法对数据的结果分析负责，数据平台团队其实对外暴露了数据表和计算任务这两种概念。平台化以后，这些数据表的owner和这些数据任务的owner都是业务线的同学们，我们对他们的掌控力其实是非常差的。我们想要改一个表的内容、一个数据任务的逻辑，都是不被允许的，都必须是由业务侧的同学们来做。两侧的平台融合难免存在功能性的差异，数据开发平台的日活跃就有100和240，如果查询就是每天作分析的日活跃的话，原点评和美团加起来有1000多。所以在平台融合过程中，能让这么多用户觉得毫无违和感是非常有挑战的。\n\n综上，我们做了一个项目拆解。\n\n### 项目拆解\n\n#### 数据互访打通\n\n数据互访打通其实是最早开始的，早在公司宣布融合以后，我们两侧平台团队坐在一起讨论先做什么，当时做了一个投入产出比的权衡，首要任务是用相对少的开发，先保障两边分析师至少有能在我们平台上进行分析的能力。接着是让用户可以去配置一些定时任务，通过配置一些数据拷贝任务把两地数据关联起来。\n\n在这方面我们总共做了三件事。\n\n##### 原始层数据收集\n\n![5](/assets/images/2017/08/25/dataplat_coalesce/5.png)\n\n在原美团侧把原点评侧线上业务机房一些DB数据以及Server的log数据同步过来。这个时候流式数据是双跑的，已经可以提供两边数据合在一起的分析能力了。\n\n##### 集群数据互拷\n\n集群数据互拷，也就是DistCp。这里稍微有一点挑战的是两边的调度系统分别开了接口，去做互相回调。如果我们有一份数据，我想它ready之后就立即拷到另外一边，比如原点评侧有个表，我要等它ready了之后拷到原美团侧，这个时候我需要在原美团侧这边配一个任务去依赖原点评侧某一个任务的完成，就需要做调度系统的打通。本文主要讨论大数据框架的部分，所以上面的调度系统还有开发平台的部分都是我们工具链团队去做的，就不多说了，下文重点描述DistCp。\n\n其实Hadoop原生支持DistCp，就是我起一个MapReduce在A集群，然后并行地去从B集群拖数据到A集群，就这么简单。只要你网络是通的，账号能认（比如说你在A集群跑的任务账号能被B集群认），并且有对应的读权限，执行端有计算资源，用开源版本的DistCp就可以搞定。\n\n这方面我们做了一些权衡：\n\n首先是因为涉及到带宽把控的问题，所以同步任务是由平台团队来统一管理，业务侧的同学们提需求。\n\n然后我们两侧集群分别建立一个用于同步的账号，原则是在读的那一端提交任务。什么叫“读的一端”？比如说我想把一个原点评侧的数据同步到原美团侧，原美团侧就是要读的那端，我在原美团侧起这个任务去读原点评侧的数据，然后写到原美团侧。这里的主要考虑是读端更多是需求端，所以，他要在他的资源池里去跑。另外，对集群的影响读小于写，我们希望对于被读集群的影响能尽量减少。\n\n当然，这都是一些临时的项目，投入较小，但收益是磨合了两地团队。\n\n##### Kerberos跨域认证架构\n\n接着介绍一下认证部分是怎么打通的。原美团侧和点评侧恰好都用了Kerberos去做认证服务，这个Kerberos在这我不去详细展开，只是简单介绍一下。首先是KDC会拥有所有的Client和Server，Client就是HDFS Client，Server就是Name Node，KDC会有Client和Server的密钥，然后Client和Server端都会保有自己的密钥，这两个甚至都是明文的。所有的密钥都不在传输过程中参与，只拿这个密钥来进行加密。基于你能把我用你知道的密钥加密的信息解出来，这一假设去做认证。这也是Kerberos架构设计上比较安全的一点。\n\nKerberos不细讲了，下面详细讲一下Kerberos跨域认证架构。\n\n![6](/assets/images/2017/08/25/dataplat_coalesce/6.png)\n\n一般公司都不会需要这个，只有像我们这种两地原来是两套集群的公司合并了才需要这种东西。我们当时做了一些调研，原来的认证过程是Client和KDC去发一个请求拿到对应Server的ticket，然后去访问Server，就结束了。但是如上图所示，在这里它需要走3次，原来是请求2次。大前提是两边的Kerberos服务，KDC其中的TGS部分，下面存储的内容部分分别要有一个配置叫krbtgt，它有A realm依赖 @ B realm这样的一个配置。两边的KDC基于这个配置是要一致的，包括其中的密码，甚至是包括其中的加密方式。那这个时候我们认为这两个KDC之间实际上是相互信任的。\n\n流程是Client发现要请求的Server是在另外一个域，然后需要先去跟Client所属的KDC发请求，拿一个跨域的ticket，就是上图中1右边那个回来的部分，他拿到了这个krbtgt CREALM @ REALM。然后Client拿着跨域的ticket去请求对应它要访问Service那一个域的KDC，再去拿对应那个域的Service的ticket，之后再去访问这个Service。这个流程上看文档相对简单，实则坑很多，下面就讲一下这个。\n\n![7](/assets/images/2017/08/25/dataplat_coalesce/7.png)\n\n上图是Kerberos跨域认证的一些要求。\n\n首先第一个比较大的要求就是密钥的编码一致，这有一个大坑，就是你必须让两个KDC拿到的信息是一样的，它们基于这个信息去互信，去互相访问。然后krb5.conf里面有一些比较诡异的domain_realm策略，这个在你网络环境不一致的时候会有一定的影响，包括DNS也会影响这个。在你的网络环境比较不可知的时候，你需要做做测试，尝试去怎么配，然后在Hadoop端有两个配置需要做，分别在Server端和Client端配置即可。其中比较恶心的是说，在测试的过程当中，需要去看Hadoop的详细日志，需要开一下它的Debug，然后去看一下它真正请求的那个域是什么样的。因为我们翻代码发现，Hadoop底层有对log，Client去请求realm的隐改，就是说我认为我应该是这个realm啊，它为什么传出来的是另外一个realm？这个是比较坑的一点。\n\n我们做完这个项目之后，分析师就可以愉快地配置一些调度任务去同步数据，然后在对应的集群上去关联他们的数据进行分析了。做完这个项目之后，我们两边的团队也相互磨合，相互形成了一定的认可。因为这个小项目涉及到了数据平台的每一个领域，包括工具链、实时计算、离线的团队都做了一些磨合。\n\n#### 集群融合\n\n粗看起来，打通了数据平台，我们的大目标似乎已经完成了：一个集群、一套数据平台的工具、一套开发规范。把数据拷过来，然后重新改它的任务，就可以形成在统一的一套工具和规范里面用一个集群，然后慢慢把原来团队维护的服务都下掉就好了。事实上不是这样的，这里面有大量的坑。如果接下来我们什么都不做的话，会发生什么情况呢？\n\n数据RD会需要在迁移的目标平台重建数据，比如说我们都定了，以后把原美团侧平台砍掉，那么好，以后都在原点评侧的平台，包括平台的上传工具、平台的集群去使用、去开发。这个时候，至少原美团侧的同学会说：“原点评那边平台的那些概念、流程，可能都跟我不一样啊，我还需要有学习的时间，这都还好”。但他们怎么迁移数据呢？只能从源头开始迁移，因为对端什么都没有，所以要先做数据的拷贝，把上游所有的表都拷贝过去。然后一层一层地去改，一整套任务都要完全重新构建一遍。\n\n那我们有多少任务呢？\n\n![8](/assets/images/2017/08/25/dataplat_coalesce/8.png)\n\n我们当时有7000个以上，后来超过8000个任务，然后我们平均深度有10层。也就是说上游先迁过来，然后下游才能迁。整个流程会变成数据表的拷贝，然后上线任务进行双跑。因为必须得有数据的校验，我才能放心地切过来，花的时间大概是拷贝数据1~4天，然后改代码加测试再加双跑，可能要3~5天。这里我们有一个流水线的问题，如上图所示，蓝色的部分只有一层依赖的，当然我把这个左边的ODS都迁完了之后，1层依赖的Task 1、Task 2、Task 3、Task 8中，Task 1、2、3就可以迁了，但是Task 8 还是不能迁的，因为Task 8依赖的Task 7还没过来。我再走一层，Task 4的负责人要等上游相关任务都迁完了之后才能干活，那整个这个迁移就纯线性化，我们大概估了一下，并行度不会超过50。如果是两地两份数据，这个项目的周期会变成特别长，会有长期的两份数据、两份任务。这个时候，第一是我们真存的下吗？第二是如果我要迁移出来那个方向的业务有需求的变更，我怎么改？我要两边都再改一遍？所以这个是非常不可控的。\n\n那这个时候怎么办？\n\n##### 集群融合的问题本质\n\n反思一下这个问题的本质，首先我们是不能双跑的，因为一旦双跑，我们必须有常态化的两份数据，然后衍生一系列的校验、存储量、切换策略等问题。所以我们必须得有一套数据，一套任务执行机制。后续任务的改变，不管是替换工具链上的东西，替换计算引擎，比如说让两边Hive、Spark和UDF去做一致化的时候，其实本质上是说对单个任务的修改，对每个任务灰度的修改就好了。\n\n所以我们推断出，必须自底向上地去进行融合，先合集群，然后后续再推动上游平台和引擎的融合。\n\n##### 集群融合的解决思路\n\n整体我们融合的思路是这样的，集群融合先行，两边的Hadoop的服务架构和代码先进行统一，其次拷贝原点评侧集群的Block，同步到原美团侧机房的两个副本。这里有一个大的前提，第一个是原点评侧的集群节点数相对来讲确实小，再一个就是原点评侧的机房确实放不下了，它当时只能扩容到10月，再往后扩就装不下机器了。\n\n所以我们将原点评侧的集群，合并到原美团侧机房，然后进行拷贝和切换。我们让整个这个集群变成在原美团侧机房一样的样子，然后进行融合。我们会把上面的客户端和元数据统一，使得访问任何一个集群的时候，都可以用一套客户端来做。一旦我们做到这个样子之后，基于统一的数据、集群的元数据和访问入口之后，我们上面的工具链就可以慢慢地去做一个一个机制，一个一个模块的融合了。\n\n简单总结下来就是四步：统一、拷贝、切换、融合，下面我们来展开说一下这四步。\n\n![9](/assets/images/2017/08/25/dataplat_coalesce/9.png)\n\n###### 统一\n\n第一优先级要解决的是上图中标红的部分，两边的Hadoop版本是不一样的，我们需要将原上海侧的版本变成我们的2.7.1带着跨机房架构的版本。同时因为我们后面要持续地去折腾Hadoop集群，所以必须先把原上海侧的HDFS架构改全，改成高可用的。\n\n这里有一个小经验就是，我们自研的patch对改的bug或者是加的feature，一定要有一个机制能够管理起来，我们内部是用Git去管理的，然后我们自研的部分会有特殊的标签，能一下拉出来。我们当时其实互相review了上百个patch，因为当时两个团队都有对集群，包括Hive等等这些开源软件的修改。这是统一的阶段，相对容易，就是一个梳理和上线的过程。接下来是拷贝的阶段。\n\n![10](/assets/images/2017/08/25/dataplat_coalesce/10.png)\n\n###### 拷贝\n\n上图是最终的效果图，同步在运行的打通任务还是用DistCp，然后先把原点评侧的HDFS跨机房部署。但是这个时候原点评侧的YARN还是在上海机房。在这个过程当中，因为HDFS跨机房部署了，所以原新上线的DataNode可以承载更多在原点评侧集群的冷数据。这个过程是慢慢进行拷贝的，大概持续了4个月，中间长期都是10Gbps的小管子。\n\n###### 切换\n\n这个相当于把原点评侧的NameNode（这个时候还没有彻底下线）切换到原美团侧机房，然后把对应的YARN重新启动起来。这里有一个小trick就是原美团侧机房的承载能力，大概是1000多台节点，是原点评侧的两倍，所以我们才能做这个事，最近我们刚刚把上海机房的节点迁完。\n\n那整个集群的拷贝和切换是怎么做的呢？其实就是用我们自研的一套Hadoop多机房架构。可能做Hadoop集群维护管理的同学们对这个有深刻的体会，就是不时地就要从一个机房搬到另一个机房。设计目标是说我们一个Hadoop集群可以跨机房去部署，然后在块的力度上能控制数据副本的放置策略，甚至是进行主动迁移。\n\n设计是怎么做的呢？整个Hadoop原生的架构其实没有机房这个概念，只支持Rack也就是机架，所有服务器都被认为是在同一个机房的。这个时候不可避免地就会有很多跨机房的流量，就如果你真的什么都不干，就把Hadoop跨机房去部署的话，那么不好意思，你中间有好多的调用和带宽都会往这儿走，最大的瓶颈是中间机房网络带宽的资源受限。\n\n我们梳理了一下跨机房部署的时候大概都有哪些场景会真正引发跨机房流量，基本上就这3~4个。首先是写数据的时候，大家知道会3副本，3个DataNode去建pipeline，这个时候由于是机器和机器之间建连接，然后发数据的，如果我要分机房部署的话，肯定会跨机房。那我要怎么应对呢？我们在NameNode专门增加zone的概念，相当于在Rack上面又加了一层概念，简单改了一些代码。然后修改了一下NameNode逻辑。当它去建立pipeline的时候，在那个调用里面hack了一下。建pipeline的时候，我只允许你选当前这个Client所属的zone，这样写数据时就不会跨机房了。\n\n这些Application在调度的时候有可能会在两个机房上，比如说mapper在A机房，reducer在B机房，那么中间的带宽会非常大。我们怎么做的呢？在YARN的队列里面，也增加zone的概念，我们用的是Fair Scheduler。在队列配置里面，对于每一个叶子队列，都增加了一个zone的概念。一个叶子队列，其实就是对应了这个叶子队列下面的所有任务，它在分配资源的时候就只能拿到这个zone的节点。读取数据的时候有可能是跨机房的，那这个时候没有办法，我们只有在读取块选择的时候本地优先。我们有一些跨机房提交job的情况，提交job的时候会把一些job里面的数据进行上传，这个时候加了一些任务的临时文件上传的是任务所在的目标机房。这里做一些简单的改动，最重要的是提供了一个功能，就是我们在拷贝数据的时候，其实用balancer所用的那一套接口，我们在此基础之上做了一层Hack，一层封装。形成了一个工具，我们叫ZoneTransfer，又由它来按照我们一系列的策略配置去驱动DataNode之间的跨机房的block粒度的拷贝。\n\n![11](/assets/images/2017/08/25/dataplat_coalesce/11.png)\n\n上图是我们跨机房架构的架构图，下面的Slave里面有DN(DataNode)和NM(NodeManager)，上面跑的同颜色的是一个App。我们在RM(ResourceManager)里面的叶子队列里配置了zone的概念，然后在调度的时候如大家所见，一个App只会在一个机房。然后下面黑色的线条都是写数据流程，DN之间建立的pipeline也会在一个机房，只有通过root去做的，DN之间做数据transfer的时候才会跨机房进行，这里我们基本上都卡住了这个跨机房的带宽，它会使用多少都是在我们掌控之内的。\n\n在上线和应用这个多机房架构的时候，我们有一些应用经验。\n\n首先在迁移的过程当中我们需要评估一点就是带宽到底用多少，或者说到底多长时间之内能完成这个整体数据的拷贝。这里需要面对的一个现实就是，我们有很多数据是会被持续更新的。比如我昨天看到这个块还在呢，今天可能由于更新被删，那昨天已经同步过来的数据就白费了。那我昨天已经同步过来的数据就白费了。所以我们定义了一个概念叫拷贝留存率。经过4个月的整体拷贝，拷贝留存率大概是70%多，也就是说我们只有70%的带宽是有效的，剩下的30%拷过去的数据，后面都被删了。\n\n第二个是我们必须得有元数据的分析能力，比如说有一个方法能抓到每一个块，我要拷的块当前分布是什么样子。我们最开始是用RPC直接裸抓Active NameNode，其实对线上的影响还是蛮大的。后面变成了我们通过FsImage去拉文件的列表，形成文件和块的列表，然后再到把请求发到standby，那边开了一个小口子，允许它去读。因为FsImage里面是没有block在哪一个DataNode的元信息的。\n\n这里需要注意的一点就是，我们每天都会有一个按天的数据生产，为了保证它的一致性，必须在当天完成。在切换之前，让被切换集群的NN（NameNode）进入SafeMode的状态，然后就不允许写了，所有的写请求停止，所有的任务停止。我们当时上线大概花了5~6个小时吧，先停，然后再去拷贝数据，把当天的所有新生产的数据都拷过来，然后再去做操作。这里最基本的要做到一点就是，我们离线的大数据带宽不能跟线上的服务的带宽抢资源，所以一定要跟基础设施团队去商量，让他们做一些基于打标签的带宽隔离策略。\n\n###### 融合\n\n当我们把集群搬到了原美团侧的机房之后，又做了一层融合。想让它看起来像一个集群的样子，基本上只需要3步。首先是“把冰箱门打开”，把原点评侧集群的那个NN作为一个federation合到原美团侧的集群，只需要改cluster ID，去客户端改mount table配置，cluster ID是在元数据里面。第二个是对Hive进行元数据的融合。我们恰好两侧元数据存储都是用MySQL的，把对应的表导出来，灌到这边，然后持续建一个同步的pipeline。它是长期活动的，到时候把上传的服务一切就可以。\n\n前面说的那个做了跨域认证的配置我们还是要拆掉的，必须进行服务认证的统一，不然的话以后没法看起来像一个集群，这个时候把原来的KDC里面的账号进行导出，之后逐步地去切换每一个配置，让它慢慢切到新的KDC。切的过程当中，我们各种请求还是有跨域情况的，我们认为两个域是一体的，是一样的。等切干净之后，也就是原来的KDC没有请求了之后，我们再把它干掉。\n\n#### 开发工具融合\n\n集群融合结束后，我们就做了开发工具的融合。由于这个跟大数据基础架构这个主题关系不是特别大，开发工具都是我们内部自研的，涉及的程序也很复杂，是一个特别大的项目，涉及一系列复杂的工具，每个模块的融合、打通。所以这个暂时不讲了。另外我觉得比较有意思的是下面这一点，就是原点评侧的一个拆库，这个在很多公司的数据平台慢慢扩大的过程当中可能会用到。\n\n#### 原点评侧拆库\n\n##### 难点\n\n![12](/assets/images/2017/08/25/dataplat_coalesce/12.png)\n\n先说一下背景，由于原点评和原美团整体历史上发展经验、周期和阶段不同，如上图所示，原点评侧的数据仓库是先有的Hadoop集群，后有的数据仓库平台，因此有很多平台完全没法掌控的私有库，但是他们对于数仓所在库的掌控是非常强的，所有的任务都在这一个大的Hive库里面，里面有七八千张表。而原美团侧是先有的数据平台，后来因为数据平台整个体量撑不住了，底层改成了Hadoop。同时在平台化的演进过程中，已经慢慢把各个业务进行独立拆分了，每个业务都有一个独立的私有库，简单来说就是库名和库名的规范不一样。我们希望能让这两套规范进行统一。\n\n我们如何去做呢？\n\n原来任务的内容大概是insert into一个BI库里面的一张表，接着select from BI库里面的某两张表，然后where group by。像这样的任务我们有七八千个，它们在我们平台上配置着每天的依赖调度。我们希望把它都改成下图中的样子。所有涉及到的这些表都需要改名字，说白了就是一个批量改名字的事儿。\n\n![20](/assets/images/2017/08/25/dataplat_coalesce/20.png)\n\n改名字听起来很简单，实际上并不是，我们有近8000个这样的任务需要改，同时这些任务相互之间都有非常复杂的依赖。下图是我随便找的一个，原美团侧某一个任务所有上游和下游的依赖关系图，如此复杂，任务的平均深度大概有10层，这还是平均数，最严重的可能要有大几十层。如果我们改这里面的任务表达，就只能分层推动。但是，当我们每改其中一个的时候，可能上下游都得跟着改，具体是什么样子的呢？\n\n![13](/assets/images/2017/08/25/dataplat_coalesce/13.png)\n\n下图是我们的原始结构，首先这里有一个大前提是每一个任务只对一个结果表。原始的结构中，a表只依赖o1表，b表依赖o1、o2，然后c表只依赖o2，它们之间相互关联。这时候我希望可以对库名和表名进行一次性的修改。那如果我们逐层地去改写怎么办呢？首先要先把最上层的mart表改了，而我一旦改上游的某一个表，所有跟对它有依赖的表都必须改任务内容。每推动一层改动，下面一层都要变动多次，这样一来，我们这个流程就非常受限。\n\n![14](/assets/images/2017/08/25/dataplat_coalesce/14.png)\n\n刚刚那个情况基本上是类似的，就是说我们对它们的改动没法批量化、信息化、流水线化，所有的用户和数据开发们，需要跟我们去聊，最近改了多少，然后谁谁谁没改完，谁谁谁又说要依赖他，整个依赖图是非常大的，我们整个项目又不可控了。那怎么办呢？\n\n##### 解决方案\n\n![15](/assets/images/2017/08/25/dataplat_coalesce/15.png)\n\n很简单，我们只干了一件事情，就是在Hive层面上进行了一波Hack。比如说我要让原来叫bi.o2的表未来会变成mart_b.o2，我就同时允许你以mart_b.o2和bi.o2这两种方式去访问bi.o2这张表就好了。不管是写入还是读取，我们只需要在Hive的元数据层面去做一层Hack，然后做一个对应表，这个对应表我们是有规范的、能梳理出来的。在这之后，任何一个人都可以把他的任务改写成他希望的样子而不受任何影响，他写的那些表还是原来的那些表，真正在物理上的存在还是bi.什么什么这样的表，我们整个项目就run起来了。\n\n具体的实施流程是这样，首先先梳理业务，确定整体的映射关系。然后Hive元数据入口上去做别名能力，我们是在Hive metaserver里面去改的，大部分请求都在这里面，包括Spark的、Presto的、Hive的等，都能兼容掉，推动分批次改写，单任务内以及任务链条内完全不需要做依赖关系的约束，最终真正实现的是自动化地把SQL文本替换掉了。业务的同学们只需要批量看一个检测报告，比如说数据对应上有没有什么问题，然后一键就切了。\n\n我们用了一个季度业务侧来磨合、尝试练习和熟练，同时做工具的开发。然后第二个季度结束后，我们就完成了7000多个任务中90%SQL任务批量的改写。当任务都切完了之后，我们还有手段，因为所有的请求都是从Hive的metaserver去访问的，当你还有原有的访问模式的时候，我就可以找到你，你是哪一个任务来的，然后你什么东西改没改，改完了之后我们可以去进行物理上的真正切分，干掉这种元数据对应关系。\n\n物理上的真正切分其实就是把原来都统一的库，按照配置去散到真实的物理上对应的库上，本质还是改NN一个事情。\n\n### 总结与展望\n\n#### 未来——常态化多机房方案\n\n我们目前正在做的一个项目，就是常态化地把集群跨机房去跑，其中最核心的就是我们需要对跨机房的数据进行非常强的管理能力，本质上是一个Block粒度Cache的事情，比如说Cache的击穿、Cache的预热或者Cache的等待等等，都是一个Cache管理的事情。我们会引入一个新的server，叫zone Server，所有的Client请求，NameNode进行块分布的时候，调整和修改。之后大家会在[美团点评技术博客](tech.meitaun.com)上看到我们的方案。\n\n#### 反思——技术换运营\n\n数据平台做起来是很痛苦的，痛苦在哪儿呢？第一，数据平台对上层提供的不只是RPC接口，它要管的是数据表和计算任务。所以我们做SLA很难，但是我们还在努力去做。第二，就是最开始的时候一定是基于开源系统拼接出来的，然后再到平台化，这一定是一个规范的收敛，也是限制增多的过程。在这个过程中，我们必须去推动上面应用的、不符合规范的部分，推动他们去符合新的规范。平台的变更即使做到兼容，我们的整体收尾还是要尽快扫清的，不然整个平台就会出现同时进行大量灰度、每一个模块当前都有多种状态的情况，这是不可维护的。\n\n综上，我们定义了一个概念叫“可运营性”，推动用户去做迁移、做改动是一个&quot;运营的事情&quot;。可运营性基本上的要求如下。\n\n*   可灰度。任务的改动是可灰度的。\n*   可关门。当某一刻，我不允许你再新增不符合新规范的任务、表或者配置，我们内部叫“关门打狗”，就是说先把新增的部分限制住，然后再去慢慢清理老的。\n*   进度可知。清理老的我们需要有一个进度可知，需要有手段去抓到还有哪些任务不符合我们新的规范。\n*   分工可知。抓到任务的分工是谁，推动相关团队去改动。\n*   变更兼容/替代方案。我们肯定过程中会遇到一些人说：不行，我改不动了，你deadline太早了，我搞不定。这时候得有一些降级或者兼容变更的一些方案。\n\n那我们什么时候去使用技术降低运营成本呢？前面已经有两个例子，就集群的迁移和融合，还有Hive表别名去帮助他们改任务名，这都是用技术手段去降低运营成本的。\n\n怎么做到呢？\n\n第一是找核心问题，我们能否彻底规避运营、能不能自动化？在集群融合的过程当中，其实已经彻底避免了运营的问题，用户根本都不需要感知，相当于在这一层面都抽象掉了。第二，是即使我没法规避，那我能不能让运营变得批量化、并行化、流水线化、自动化？然后当你抓核心问题有了一个方案之后，就小范围去迭代、去测试。最后还有一点，引入架构变更的复杂度最终要能清理掉，新增的临时功能最后是可被下线的。\n\n#### 体会——复杂系统重构与融合\n\n最后稍微聊一下复杂系统的重构与融合。从项目管理的角度上来讲，怎么去管控？复杂系统的重构还有融合本质上最大的挑战其实是一个复杂度管理的事情，我们不可能不出问题，关键是出问题后，对影响的范围可控。\n\n从两个层面去拆分，第一个层面是，先明确定义目标，这个目标是能拆到一个独立团队里去做的，比如说我们最开始那四个大的目标，这样保证团队间能并行地进行推动，其实是一点流水线的思路。第二，我们在团队内进行目标的拆分，拆分就相对清晰了，先确定我要变更什么，然后内部brainstorming，翻代码去查找、测试、分析到底会对什么东西产生影响，然后去改动、测试、制定上线计划。\n\n内部要制定明确的上线流程，我记得当时在做的时候从11月到12月我们拆分了应该是有11次上线，基本上每次大的上线都是在周末做的，10、11、12月总共有12个周末，一共上线11次，大的上线应该是占了7到8个周末吧。要提前准备好如何管理依赖，如何串行化，然后准备上线，上线完怎么管理，这些都是在整个项目管理过程当中需要考虑的。\n\n其中，两个可能大家都持续提的东西，第一个是监控，要知道改完了之后发生了什么，在改的时候就像加测试用例一样把改动部分的监控加好。第二要有抓手，如果我线上垮了，这个时候重复恢复的成本太高，也就是完全重启、完全回滚的成本太高，我能不能线上进行一些改动？\n\n![16](/assets/images/2017/08/25/dataplat_coalesce/16.png)\n\n最后这张图，献给大家，希望大家在对自己系统改动的时候，都能像这哥们一样从容。\n\n---\n\n* Author: 语宸\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [美团点评数据平台融合实践](https://tech.meituan.com/dataplat_coalesce.html)\n","tags":["Coalesce"],"categories":["Data-Platform"]},{"title":"人工智能在线特征系统中的数据存取技术","url":"%2F2017%2F2017-07-06-online-feature-system%2F","content":"\n### 一、在线特征系统\n\n主流互联网产品中，不论是经典的计算广告、搜索、推荐，还是垂直领域的路径规划、司机派单、物料智能设计，建立在人工智能技术之上的策略系统已经深入到了产品功能的方方面面。相应的，每一个策略系统都离不开大量的在线特征，来支撑模型算法或人工规则对请求的精准响应，因此特征系统成为了支持线上策略系统的重要支柱。美团点评技术博客之前推出了多篇关于特征系统的文章，如[《机器学习中的数据清洗与特征处理综述》](http://tech.meituan.com/machinelearning-data-feature-process.html)侧重于介绍特征生产过程中的离线数据清洗、挖掘方法，[《业务赋能利器之外卖特征档案》](http://tech.meituan.com/waimai_data_feature_service.html)侧重于用不同的存储引擎解决不同的特征数据查询需求。而[《外卖排序系统特征生产框架》](http://tech.meituan.com/feature_pipeline.html)侧重介绍了特征计算、数据同步和线上查询的特征生产Pipeline。\n\n本文以美团酒旅在线特征系统为原型，重点从线上数据存取角度介绍一些实践中的通用技术点，以解决在线特征系统在高并发情形下面临的问题。\n\n#### 1.1 在线特征系统框架——生产、调度、服务一体化\n\n在线特征系统就是通过系统上下文，获得相关特征数据的在线服务。其功能可以是一个简单的Key-Value（KV）型存储，对线上提供特征查询服务，也可以辐射到通用特征生产、统一特征调度、实时特征监控等全套特征服务体系。可以说，几个人日就可以完成一个简单能用的特征系统，但在复杂的业务场景中，把这件事做得更方便、快速和稳定，却需要一个团队长期的积累。\n\n![](/assets/images/2017/07/06/online-feature-system/2-1.png)\n\n以上结构图为一体化特征系统的概貌，自底向上为数据流动的方向，各部分的功能如下：\n\n*   **数据源**：用于计算特征的原始数据。根据业务需求，数据来源可能是分布式文件系统（如Hive），关系型数据库（如MySQL），消息队列（如Kafka）等。\n*   **特征生产**：该部分负责从各种数据源读取数据，提供计算框架用于生产特征。生产框架需要根据数据源的类型、不同的计算需求综合设计，因此会有多套生产框架。\n*   **特征导入**：该部分负责将计算好的特征写入到线上存储供特征服务读取。该部分主要关注导入作业之间的依赖、并发写入的速度与一致性等问题。\n*   **特征服务**：该部分为整个特征系统的核心功能部分，提供在线特征的存取服务，直接服务于上层策略系统。\n\n特征的生命周期按照上述过程，可以抽象为五个步骤：读、算、写、存、取。整个流程于特征系统框架内成为一个整体，作为特征工程的一体化解决方案。本文主要围绕特征服务的核心功能“**存**”、“**取**”，介绍一些通用的实践经验。特征系统的延伸部分，如特征生产、系统框架等主题会在后续文章中做详细介绍。\n\n#### 1.2 特征系统的核心——存与取\n\n简单来说，可以认为特征系统的核心功能是一个大号的HashMap，用于存储和快速提取每次请求中相关维度的特征集合。然而实际情况并不像HashMap那样简单，以我们的通用在线特征系统（Datahub）的系统指标为例，它的核心功能主要需面对**存储**与**读取**方面的挑战：\n\n1.  **高并发**：策略系统面向用户端，服务端峰值QPS超过1万，数据库峰值QPS超过100万（批量请求造成）。\n2.  **高吞吐**：每次请求可能包含上千维特征，网络IO高。服务端网络出口流量均值500Mbps，峰值为1.5Gbps。\n3.  **大数据**：虽然线上需要使用的特征数据不会像离线Hive库那样庞大，但数据条数也会超过10亿，字节量会达到TB级。\n4.  **低延迟**：面对用户的请求，为保持用户体验，接口的延迟要尽可能低，服务端TP99指标需要在10ms以下。\n\n以上指标数字仅是以我们系统作为参考，实际各个部门、公司的特征系统规模可能差别很大，但无论一个特征系统的规模怎样，其系统核心目标必定是考虑：高并发、高吞吐、大数据、低延迟，只不过各有不同的优先级罢了。当系统的优化方向是多目标时，我们不可能独立的用任何一种方式，在有限资源的情况下做到面面俱到。留给我们的是业务最重要的需求特性，以及对应这些特性的解决方案。\n\n### 二、在线特征存取技术\n\n本节介绍一些在线特征系统上常用的存取技术点，以丰富我们的武器库。主要内容也并非详细的系统设计，而是一些常见问题的通用技术解决方案。但如上节所说，如何根据策略需求，利用合适的技术，制定对应的方案，才是各位架构师的核心价值所在。\n\n#### 2.1 数据分层\n\n特征总数据量达到TB级后，单一的存储介质已经很难支撑完整的业务需求了。高性能的在线服务内存或缓存在数据量上成了杯水车薪，分布式KV存储能提供更大的存储空间但在某些场景又不够快。开源的分布式KV存储或缓存方案很多，比如我们用到的就有Redis/Memcache，HBase，Tair等，这些开源方案有大量的贡献者在为它们的功能、性能做出不断努力，本文就不更多着墨了。\n\n对构建一个在线特征系统而言，实际上我们需要理解的是我们的特征数据是怎样的。有的数据非常热，我们通过内存副本或者是缓存能够以极小的内存代价覆盖大量的请求。有的数据不热，但是一旦访问要求稳定而快速的响应速度，这时基于全内存的分布式存储方案就是不错的选择。对于数据量级非常大，或者增长非常快的数据，我们需要选择有磁盘兜底的存储方案——其中又要根据各类不同的读写分布，来选择存储技术。\n\n当业务发展到一定层次后，单一的特征类型将很难覆盖所有的业务需求。所以在存储方案选型上，需要根据特征类型进行数据分层。分层之后，不同的存储引擎统一对策略服务提供特征数据，这是保持系统性能和功能兼得的最佳实践。\n\n#### 2.2 数据压缩\n\n海量的离线特征加载到线上系统并在系统间流转，对内存、网络带宽等资源都是不小的开销。数据压缩是典型的以时间换空间的例子，往往能够成倍减少空间占用，对于线上珍贵的内存、带宽资源来说是莫大的福音。数据压缩本质思想是减少信息冗余，针对特征系统这个应用场景，我们积累了一些实践经验与大家分享。\n\n##### 2.2.1 存储格式\n\n特征数据简单来说即特征名与特征值。以用户画像为例，一个用户有年龄、性别、爱好等特征。存储这样的特征数据通常来说有下面几种方式：\n\n1.  JSON格式，完整保留特征名-特征值对，以JSON字符串的形式表示。\n2.  元数据抽取，如Hive一样，特征名（元数据）单独保存，特征数据以String格式的特征值列表表示。\n3.  元数据固化，同样将元数据单独保存，但是采用强类型定义每个特征，如Integer、Double等而非统一的String类型。\n\n三种格式各有优劣：\n\n1.  JSON格式的优点在特征数量可以是变长的。以用户画像为例，A用户可能有年龄、性别标签。B用户可以有籍贯、爱好标签。不同用户标签种类可以差别很大，都能便捷的存储。但缺点是每组特征都要存储特征名，当特征种类同构性很高时，会包含大量冗余信息。\n2.  元数据抽取的特点与JSON格式相反，它只保留特征值本身，特征名作为元数据单独存放，这样减少了冗余特征名的存储，但缺点是数据格式必须是同构的，而且如果需要增删特征，需要更改元数据后刷新整个数据集。\n3.  元数据固化的优点与元数据抽取相同，而且更加节省空间。然而其存取过程需要实现专有序列化，实现难度和读写速度都有成本。\n\n特征系统中，一批特征数据通常来说是完全同构的，同时为了应对高并发下的批量请求，我们在实践中采用了元数据抽取作为存储方案，相比JSON格式，有2~10倍的空间节约（具体比例取决于特征名的长度、特征个数以及特征值的类型）。\n\n##### 2.2.2 字节压缩\n\n提到数据压缩，很容易就会想到利用无损字节压缩算法。无损压缩的主要思路是将频繁出现的**模式**（Pattern）用较短的字节码表示。考虑到在线特征系统的读写模式是一次全量写入，多次逐条读取，因此压缩需要针对单条数据，而非全局压缩。目前主流的Java实现的短文本压缩算法有Gzip、Snappy、Deflate、LZ4等，我们做了两组实验，主要从单条平均压缩速度、单条平均解压速度、压缩率三个指标来对比以上各个算法。\n\n**数据集**：我们选取了2份线上真实的特征数据集，分别取10万条特征记录。记录为纯文本格式，平均长度为300~400字符（600~800字节）。\n\n**压缩算法**：Deflate算法有1~9个压缩级别，级别越高，压缩比越大，操作所需要的时间也越长。而LZ4算法有两个压缩级别，我们用0，1表示。除此之外，LZ4有不同的实现版本：JNI、Java Unsafe、Java Safe，详细区别参考 [https://github.com/lz4/lz4-java](https://github.com/lz4/lz4-java) ，这里不做过多解释。\n\n![](/assets/images/2017/07/06/online-feature-system/compress-alg-cmp.png)\n\n实验结果图中的毫秒时间为单条记录的压缩或解压缩时间。压缩比的计算方式为压缩前字节码长度/压缩后字节码长度。可以看出，所有压缩算法的压缩/解压时间都会随着压缩比的上升而整体呈上升趋势。其中LZ4的Java Unsafe、Java Safe版由于考虑平台兼容性问题，出现了明显的速度异常。\n\n从使用场景（一次全量写入，多次逐条读取）出发，特征系统主要的服务指标是特征高并发下的响应时间与特征数据存储效率。因此特征压缩关注的指标其实是：快速的解压速度与较高的压缩比，而对压缩速度其实要求不高。因此综合上述实验中各个算法的表现，Snappy是较为合适我们的需求。\n\n##### 2.2.3 字典压缩\n\n压缩的本质是利用共性，在不影响信息量的情况下进行重新编码，以缩减空间占用。上节中的字节压缩是单行压缩，因此只能运用到同一条记录中的共性，而无法顾及全局共性。举个例子：假设某个用户维度特征所有用户的特征值是完全一样的，字节压缩逐条压缩不能节省任何的存储空间，而我们却知道实际上只有一个重复的值在反复出现。即便是单条记录内部，由于压缩算法窗口大小的限制，长Pattern也很难被顾及到。因此，对全局的特征值做一次字典统计，自动或人工的将频繁Pattern加入到字典并重新编码，能够解决短文本字节压缩的局限性。\n\n#### 2.3 数据同步\n\n当每次请求，策略计算需要大量的特征数据时（比如一次请求上千条的广告商特征），我们需要非常强悍的在线数据获取能力。而在存储特征的不同方法中，访问本地内存毫无疑问是性能最佳的解决方式。想要在本地内存中访问到特征数据，通常我们有两种有效手段：**内存副本**和**客户端缓存**。\n\n##### 2.3.1 内存副本技术\n\n当数据总量不大时，策略使用方可以在本地完全镜像一份特征数据，这份镜像叫内存副本。使用内存副本和使用本地的数据完全一致，使用者无需关心远端数据源的存在。内存副本需要和数据源通过某些协议进行同步更新，这类同步技术称为内存副本技术。在线特征系统的场景中，数据源可以抽象为一个KV类型的数据集，内存副本技术需要把这样一个数据集完整的同步到内存副本中。\n\n###### 推拉结合——时效性和一致性\n\n一般来说，数据同步为两种类型：**推**（Push）和**拉**（Pull）。Push的技术比较简单，依赖目前常见的消息队列中间件，可以根据需求做到将一个数据变化传送到一个内存副本中。但是，即使实现了不重不漏的高可靠性消息队列通知（通常代价很大），也还面临着初始化启动时批量数据同步的问题——所以，Push只能作为一种提高内存副本时效性的手段，本质上内存副本同步还得依赖Pull协议。Pull类的同步协议有一个非常好的特性就是幂等，一次失败或成功的同步不会影响下一次进行新的同步。\n\nPull协议有非常多的选择，最简单的每次将所有数据全量拉走就是一种基础协议。但是在业务需求中需要追求数据同步效率，所以用一些比较高效的Pull协议就很重要。为了缩减拉取数据量，这些协议本质上来说都是希望高效的计算出尽量精确的_数据差异_（Diff），然后同步这些必要的数据变动。这里介绍两种我们曾经在工程实践中应用过的Pull型数据同步协议。\n\n###### 基于版本号同步——**回放日志**（RedoLog）和退化算法\n\n在数据源更新时，对于每一次数据变化，基于版本号的同步算法会为这次变化分配一个唯一的递增版本号，并使用一个更新队列记录所有版本号对应的数据变化。\n\n内存副本发起同步请求时，会携带该副本上一次完成同步时的最大版本号，这意味着所有该版本号之后的数据变化都需要被拉取过来。数据源方收到请求后，从更新队列中找到大于该版本号的所有数据变化，并将数据变化汇总，得到最终需要更新的Diff，返回给发起方。此时内存副本只需要更新这些Diff数据即可。\n\n![](/assets/images/2017/07/06/online-feature-system/version-diff.png)\n\n对于大多数的业务场景，特征数据的生成会收口到一个统一的更新服务中，所以递增版本号可以串行的生成。如果在分布式的数据更新环境中，则需要利用分布式id生成器来获取递增版本号。\n\n另一个问题则是更新队列的长度。如果不进行任何优化，更新队列理论上是无限长的，甚至会超过数据集的大小。一个优化方法是我们限制住更新队列的最大长度，一旦长度超过限制，则执行**合并**（Merge）操作。Merge操作将队列中的数据进行两两合并，合并后的版本号以较大的版本号为准，合并后的更新数据集是两个数据集的并。Merge后，新的队列长度下降为原更新队列的一半。\n\n![](/assets/images/2017/07/06/online-feature-system/version-merge.png)\n\nMerge之后的更新队列，我们依然可以使用相同的算法进行同步Diff计算：在队列中找到大于上一次更新版本号的所有数据集。可以看到由于版本号的合并，算出的Diff不再是完全精准的更新数据，在队列中最早的更新数据集有可能包含部分已经同步过的数据——但这样的退化并不影响同步正确性，仅仅会造成少量的同步冗余，冗余的量取决于Diff中最早的数据集经过Merge的次数。\n\n![](/assets/images/2017/07/06/online-feature-system/version-merge-diff.png)\n\n###### MerkleTree同步——数据集对比算法\n\n基于版本号的同步使用的是类似RedoLog的思想，将业务变动的历史记录下来，并通过回放未同步的历史记录得到Diff。由于记录不断增长的RedoLog需要不小的开销，所以采用了Merge策略来退化原始**日志**（Log）。对于批量或者微批量的更新来说，基于版本号的同步算法能较好的工作；相反，若数据是实时更新的，将会出现大量的RedoLog，并快速的退化，影响同步的效率。\n\nMerkle Tree同步算法走的是另一条路，简单来说就是通过每次直接比较两个数据集的差异来获取Diff。首先看一个最简单的算法：每次内存副本将所有数据的Hash值发送给数据源，数据源比较整个数据集，对于Hash值不同的数据执行同步操作——这样就精确计算出了两个数据集之间的Diff。但显而易见的问题，是每次传输所有数据的Hash值可能并不比多传几个数据轻松。Merkle Tree同步算法就是使用Merkle Tree数据结构来优化这一比较过程。\n\nMerkle Tree简单来说是就是把所有数据集的hash值组织成一棵树，这棵树的叶子节点描述一个（或一组）数据的Hash值。而中间节点的值由其所有儿子的Hash值再次Hash得到，描述了以它为根的子树所包含的数据的整体Hash。显然，在不考虑Hash冲突的情况下，如果两颗Merkle Tree根节点相同，代表这是两个完全相同的数据集。\n\n![](/assets/images/2017/07/06/online-feature-system/merkle-tree.png)\n\nMerkle Tree同步协议由副本发起，将副本根节点值发送给数据源，若与数据源根节点hash值一致，则没有数据变动，同步完成。否则数据源将把根结点的所有儿子节点的hash发送给副本，进行递归比较。对于不同的hash值，一直持续获取直到叶子节点，就可以完全确定已经改变的数据。以二叉树为例，所有的数据同步最多经过LogN次交互完成。\n\n![](/assets/images/2017/07/06/online-feature-system/merkle-tree-protocal.png)\n\n##### 2.3.2 客户端缓存技术\n\n当数据规模大，无法完全放入到内存中，冷热数据分明，对于数据时效性要求又不高的时候，通常各类业务都会采用客户端缓存。客户端缓存的集中实现，是特征服务延伸的一部分。通用的缓存协议和使用方式不多说，从在线特征系统的业务角度出发，这里给出几个方向的思考和经验。\n\n###### 接口通用化——缓存逻辑与业务分离\n\n一个特征系统要满足各类业务需求，它的接口肯定是丰富的。从数据含义角度分有用户类、商户类、产品类等等，从数据传输协议分有Thrift、HTTP，从调用方式角度分有同步、异步，从数据组织形式角度分有单值、List、Map以及相互嵌套等等……一个良好的架构设计应该尽可能将数据处理与业务剥离开，抽象各个接口的通用部分，一次缓存实现，多处接口同时受益复用。下面以同步异步接口为例介绍客户端接口通用化。\n\n同步接口只有一步：\n\n1.  向服务端发起请求得到结果。\n\n异步接口分为两步：\n\n1.  向服务端发起请求得到Future实例。\n2.  向Future实例发起请求，得到数据。\n\n同步和异步接口的数据处理只有顺序的差别，只需要梳理好各个步骤的执行顺序即可。引入缓存后，数据处理流程对比如下：\n\n![](/assets/images/2017/07/06/online-feature-system/client-cache-sync-and-async.png)\n\n不同颜色的处理框表示不同的请求。异步流程需要使用方的两次请求才能获取到数据。像图中“用服务端数据更新缓存”（update cache）、“服务端数据与缓存数据汇总”（merge data）步骤在异步流程里是在第二次请求中完成的，区别于同步流程第一次请求就完成所有步骤。将数据流程拆分为这些子步骤，同步与异步只是这些步骤的不同顺序的组合。因此读写缓存（search cache、update cache）这两个步骤可以抽象出来，与其余逻辑解耦。\n\n###### 数据存储——时间先于空间，客户端与服务端分离\n\n客户端之于服务端，犹如服务端之于数据库，其实数据存储压缩的思路是完全一样的。具体的数据压缩与存储策略在上文数据压缩章节已经做了详细介绍，这里主要想说明两点问题：\n\n客户端压缩与服务端压缩由于应用场景的不同，其目标是有差异的。服务端压缩使用场景是一次性高吞吐写入，逐条高并发低延迟读取，它主要关注的是读取时的解压时间和数据存储时的压缩比。而客户端缓存属于数据存储分层中最顶端的部分，由于读写的场景都是高并发低延迟的本地内存操作，因此对压缩速度、解压速度、数据量大小都有很高要求，它要做的权衡更多。\n\n其次，客户端与服务端是两个完全独立的模块，说白了，虽然我们会编写客户端代码，但它不属于服务的一部分，而是调用方服务的一部分。客户端的数据压缩应该尽量与服务端解耦，切不可为了贪图实现方便，将两者的数据格式耦合在一起，与服务端的数据通信格式应该理解为一种独立的协议，正如服务端与数据库的通信一样，数据通信格式与数据库的存储格式没有任何关系。\n\n###### 内存管理——缓存与分代回收的矛盾\n\n缓存的目标是让热数据（频繁被访问的数据）能够留在内存，以便提高缓存命中率。而JVM**垃圾回收**（GC）的目标是释放失去引用的对象的内存空间。两者目标看上去相似，但细微的差异让两者在高并发的情景下很难共存。缓存的淘汰会产生大量的内存垃圾，使Full GC变得非常频繁。这种矛盾其实不限于客户端，而是所有JVM堆内缓存共同面临的问题。下面我们仔细分析一个场景：\n\n随着请求产生的数据会不断加入缓存，QPS较高的情形下，Young GC频繁发生，会不断促使缓存所占用的内存从新生代移向老年代。缓存被填满后开始采用Least Recently Used（LRU）算法淘汰，冷数据被踢出缓存，成为垃圾内存。然而不幸的是，由于频繁的Young GC，有很多冷数据进入了老年代，淘汰老年代的缓存，就会产生老年代的垃圾，从而引发Full GC。\n\n![](/assets/images/2017/07/06/online-feature-system/client-cache-full-gc.png)\n\n可以看到，正是由于缓存的淘汰机制与新生代的GC策略目标不一致，导致了缓存淘汰会产生很多老年代的内存垃圾，而且产生垃圾的速度与缓存大小没有太多关系，而与新生代的GC频率以及堆缓存的淘汰速度相关。而这两个指标均与QPS正相关。因此堆内缓存仿佛成了一个通向老年代的垃圾管道，QPS越高，垃圾产生越快！\n\n因此，对于高并发的缓存应用，应该避免采用JVM的分带管理内存，或者可以说，GC内存回收机制的开销和效率并不能满足高并发情形下的内存管理的需求。由于JVM虚拟机的强制管理内存的限制，此时我们可以将对象序列化存储到**堆外**（Off Heap），来达到绕开JVM管理内存的目的，例如Ehcache，BigMemory等第三方技术便是如此。或者改动JVM底层实现（类似[之前淘宝的做法](http://www.infoq.com/cn/presentations/ms-jvm-taobao)），做到堆内存储，免于GC。\n\n### 三、结束语\n\n本文主要介绍了一些在线特征系统的技术点，从系统的高并发、高吞吐、大数据、低延迟的需求出发，并以一些实际特征系统为原型，提出在线特征系统的一些设计思路。正如上文所说，特征系统的边界并不限于数据的存储与读取。像数据导入作业调度、实时特征、特征计算与生产、数据备份、容灾恢复等等，都可看作为特征系统的一部分。本文是在线特征系统系列文章的第一篇，我们的特征系统也在需求与挑战中不断演进，后续会有更多实践的经验与大家分享。一家之言，难免有遗漏和偏颇之处，但是他山之石可以攻玉，若能为各位架构师在面向自己业务时提供一些思路，善莫大焉。\n\n### 作者简介\n\n杨浩，美团平台及酒旅事业群数据挖掘系统负责人，2011年毕业于北京大学，曾担任107间联合创始人兼CTO，2016年加入美团点评。长期致力于计算广告、搜索推荐、数据挖掘等系统架构方向。\n\n伟彬，美团平台及酒旅事业群数据挖掘系统工程师，2015年毕业于大连理工大学，同年加入美团点评，专注于大数据处理技术与高并发服务。\n\n【思考题】\n\n文中提到高QPS下Java堆内缓存容易产生Full GC问题从而影响系统性能，其实GC是Java的一把双刃剑。“Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的‘高墙’，墙外面的人想进去，墙里的人想出来”。聊一聊你在工作中遇到的GC问题，以及如何解决的吧~\n\n---\n\n* Author: 杨浩 伟彬\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [人工智能在线特征系统中的数据存取技术](https://tech.meituan.com/online-feature-system.html)","tags":["Feature"],"categories":["Feature"]},{"title":"孵化业务快速落地与优化","url":"%2F2017%2F2017-06-29-fuhua-haiwai%2F","content":"\n海外酒店是酒旅事业群第一个孵化的业务，从2016年9月份开始到现在已经半年多的时间。在业务后台搭建、成长、优化过程中，经历了很多的思考与选择。\n\n主要分为下面几个阶段：\n\n**初建**：调研、落地，合理复用，高效自建。\n**优化**：量化、决策，寻找瓶颈，优化性能。\n**展望**：梳理、规划，业务展望，未雨绸缪。\n\n本文将分别介绍这几个阶段后台系统相关的思考，此外还会在最后总结**团队建设**方面的经验。  \n\n### 初建\n\n海外酒店作为一个孵化项目，属于新的业务场景，没有完整的学习对象。从业务细节上来讲，孵化业务的属性、流程、发展方向均有自己的特点；但从宏观上考虑，它是已有业务的拓展，各方面也存在一些相似点。从发展速度来讲，新兴业务发展初期，迭代速度非常快，需求变更会非常频繁，业务压力在一段时间内会持续出现。 \n\n综上，在系统后台建设初期需要详细思考：已有后台服务的调研与复用，谨慎合理创建新的业务后台，优先选择成熟框架与技术组件。 \n\n#### 已有后台服务的调研与复用\n\n最终目的：合理的复用资源，避免重复造轮子。 \n\n什么样的系统或者服务可以复用？复用与否从两方面考虑：服务平台能力、涉及需求量。总体的复用判断方案如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/001.png) \n\n基于以上原则，海外酒店在复用抉择时候的判断如下：\n\n① 公司级别基础服务或业务平台\n\n*   基础服务可以复用：如异步消息中心、缓存中心、风控平台等。\n*   业务平台可以复用：如订单平台、支付中心、客服平台等。\n\n② 部门级别已有业务平台化系统\n\n*   部门内已有基础业务平台。如POI中心、订单交易平台、促销平台等。\n*   业务耦合性不高，已建业务支持能力的平台。如UGC中心、主搜平台等。\n\n在部门级的业务平台是复用+定制来完成需求的支持。因为这块有一部分需求内容，现有的能力可能无法满足新业务的要求，所以需要做部分定制。 \n\n#### 合理谨慎的创建新业务后台\n\n思考清楚如何避免重复造轮后，接下来就是孵化业务后台系统的搭建工作。 \n\n孵化业务后台建设有哪些挑战和风险？ \n\n第一：孵化业务需求迭代速度非常快，需要快速落地支持；\n第二：业务需求变更非常频繁，甚至推翻重来；\n第三：系统建设速度非常快，整体架构方式有挑战。\n\n面对上面这些挑战，海外酒店后台系统建设过程中要尽量做到简单、灵活、可扩展。\n\n**简单**：工程目录，代码结构都从简单入手，避免太多复杂设计和复杂代码耦合带来的压力。\n**灵活**：根据前期的需求以及中短期的规划，将系统根据业务划清界限，做到尽可能的微服务化，将系统设计内聚合、外解耦。\n**可扩展**：简单、灵活的同时必须思考可扩展性，为业务持续发展做到未雨绸缪。 \n\n可扩展有资源的预备储备，系统架构的无缝扩展，服务间的扩展交互。 \n\n基于上面的思考，海外酒店后台初期自建的系统如下： \n\nC端系统：API中心、产品中心、报价中心、订单中心、POI缓存中心、黑名单服务。\n\nB端系统：三方直连系统，三方数据同步系统。\n\n每个系统间界限划分清楚，哪些是提供给用户C端展示，哪些是B端三方接口访问，哪些是线下静态数据同步等。 \n\n海外后台初期整体架构落地形式如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/002.png) \n\n##### 优先选择成熟框架与技术组件\n\n业务前期在技术选型方面可能更加偏向于成熟框架，成熟技术组件。这需要我们从两方面考虑：\n\n① 新的技术框架和组件存在风险\n\n*   技术文档支持可能存在不足。*   技术问题解决方案缺失，排查困难程度不可预知。\n\n② 选择成熟框架和组件的好处\n\n*   项目搭建比较迅速。\n*   问题排查解决有经验的积累和参考。*   人员backup比较方便，招聘也比较方便。\n\n### 优化\n\n系统快速搭建的同时，需要考虑前期的必要优化，从而提高系统的健壮性、可用性等方面内容。\n\n海外酒店在建设初期从下面几个内容进行了初期思考：\n\n1.  可用性\n2.  系统性能3.  扩展性\n\n首先介绍一下可用性相关内容。\n\n#### 可用性\n\n可用性是衡量系统服务的一个重要指标。在这里重点介绍海外酒店后台系统前期考虑的几个方面：容灾降级， 限流控制，服务备份，监控覆盖。 \n\n##### 容灾降级\n\n降级策略根据不同的业务场景有不同的方式，例如超时降级、失败次数统计降级、限流降级等。 \n\n目前，降级按方式不同分为：自动降级、手动降级。 \n\n海外酒店后台目前都是采用的手动降级的策略。自动降级策略需要对监控数据有特别高的感知能力和预判能力，这块还需要继续建设完善。 \n\n对于海外酒店后台来讲目前有两块降级的要求。\n\n**业务场景一**\n\n产品售卖可降级，读服务降级。\n\n产品售卖可降级是一种人工开关，当发现大量的产品售卖出现异常时，我们将停止某个产品供应商的产品展示，从而避免造成更大的损失。然后从业务代码来进行相关的开关配置，提供一个可修改的降级开关控制接口。目前海外酒店的降级方案是通过MCC（美团点评公司级的统一配置中心）的配置信息下发来实现整个工程的手动降级。在产品展示信息的接口，通过MCC的Key来进行设置开关的状态。\n\nMCC底层实现组件是ZooKeeper（以下简称“ZK&quot;)，通过对ZK节点信息修改的监听，来进行属性的同步。由于自动降级目前存在很多技术上的不确定性，因此没有考虑根据业务数据的突变，后者如果出现监控数据的异常，会自动触发各种降级开关。 \n\n**业务场景二**\n\nAPI层接口熔断降级，使用Hystrix。\n\n对于API层来说，主要是提供前端展示所需的数据内容。上层直接面向用户需要可靠的服务以及快速的请求响应，下层依赖各种不同的服务然后进行信息的组合拼装。 \n\n所以为了提高接口的稳定性，海外酒店API层接口接入Hystrix实现熔断和降级策略。Hystrix原理可以简单描述为：\n\n1.  对多个依赖服务调用采用线程池分组，达到流量高峰互不影响的目的。\n2.  当某个或某些依赖服务发生故障，采取短时间内熔断方案（快速失败），当熔断一小段时间后，会继续访问出现故障的依赖服务，如果正常则恢复依赖调用，如失败则继续熔断循环这个过程。\n3.  针对依赖方或单依赖方多个接口设置超时，并自动调用异常或超时的灾备处理方案，实现降级。\n再详细的使用方式和底层实现可以参考网上更加详细的[资料](https://github.com/Netflix/Hystrix/wiki)。\n\n##### 限流控制\n\n限流是利用有限的资源，保障业务系统核心流程的高可用。限流本身是通过一种有损的方式来提高可用性。\n\n从限流的机器维度方面来说有单机限流和分布式限流两种，限流算法目前有熟知的令牌桶算法、漏桶算法。\n\n从应用的角度来说，限流可以针对总的并发数、连接数、请求数限流，也可以对某个共享资源来限流，以及针对某个接口请求数来进行平滑限流。 \n\n**单机限流**\n\n从单机维度的限流，我们可以采用Java提供的semaphore来进行简单的支持，或者采用Guava RateLimiter来进行单机限流。\n\n**分布式限流**\n\n而对于分布式服务的限流，就需要采用一个公共资源服务来进行流量的统一控制，目前美团点评内部提供了一个组件，基本原理利是用Tair的资源管理和主键失效策略来进行流量控制。 \n\n分布式流控系统实现原理可以利用Tair或者Redis的原子性加减操作，来进行资源的管理，同时利用失效时间来进行管理一段频率内的资源消耗情况。 \n\n为了提高开发效率，海外酒店使用了公司统一限流组件，该组件利用了Tair的原子性加减功能，进行限流功能的实现。 \n\n**海外酒店限流的业务场景**\n\n某些服务提供商，要求后台访问他们接口频率的总和不能超过 40次/秒、75000次/小时，否则会进行相应的惩罚策略（返回假数据等）。\n\n从这个要求来看，业务场景是针对第三方接口访问的限制，需要的是对接口总体访问量的控制，所以单机的限流策略无法满足这个业务场景，必须采用分布式限流。海外酒店整个限流场景下做了报警功能，并没有做直接禁止接口的访问。这是基于海外酒店前期的流量大小来综合考虑的结果。按照目前的海外酒店访问量级来说，供应商提供的接口访问次数，一段时间内可以满足当前的用户访问量。 \n\n如果超过限制，很可能有异常流量进入，而这种流量必须经过人工排查才能确定，前期如果真的出现这种流量异常，也不会太影响用户的交易行为，综合考虑之后，我们针对限流场景，做了触发报警的策略。 \n\n##### 服务备份\n\n对于分布式系统来讲，虽然其特征决定了整个服务的不可用性大大降低，但对于核心系统我们必须考虑整个系统的容灾备份能力。对于业务系统来讲，容灾能力分为两种需要考虑：\n\n1.  自身服务的容灾特征，如何保证自身服务的高可用状态。\n2.  依赖服务的容灾特征，即依赖的服务出现不可用状态时候，对于业务方来说如何进行灾备。\n\n这种分布式系统容灾的方法有： \n\n1.  跨机房部署、异地多活、防止机房不可用灾备。\n2.  依赖方替换方案，防止依赖方服务不可用状态。\n\n对于海外酒店业务来说：\n\n1.  每个服务都会在两到三个机房进行部署，根据需要可以多申请（也要考虑公司资源）几台备用。\n2.  POI缓存中心强依赖于Redis缓存系统，因此做了一层灾备，也将缓存数据同步了一份到Tair集群。\n\nPOI缓存中心灾备模型如下：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/003.png) \n\n既然是两个缓存中心，那么服务的数据类型接口也都存在差异，就存储信息来说，如果两者都完全保持同步，会造成后期的维护成本比较高。因此作为备份容灾的缓存服务，仅仅存储必要的信息，而且是基本不会变动的数据结构。避免由于业务的修改，造成双缓存中心数据结构的修改适配。 \n\n##### 监控覆盖\n\n海外酒店初期，在监控方面进行了详细的领域拆分，并结合公司的公共日志监控平台来进行相关的监控报警工作。监控方面从监控内容上来分有：网络监控、机器监控、业务监控、日志统计等。\n\n整体的后台监控体系，如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/004.png) \n\n随着业务系统的增加，以及服务的拆分，各个系统间日志的统一查看比较困难，给问题排查带来很多都不便。比如订单交易平台下单异常， 需要排查自身系统的问题，如果发现依赖服务存在问题，就需要依赖服务（产品中心、直连中心、报价中心等等）分别确定排查，查看自身的监控情况，从而协助确定问题。 \n\n因此未来需要将各个业务统计，监控信息统一到一个监控大盘里面，可以一目了然的观察各个维度的信息，从而优化问题排查效率，提高系统可用性。 \n\n#### 系统性能\n\n孵化业务前期，访问量的绝对值虽然还不是太高，但我们仍然需要持续关注接口的性能与响应时间。特别是业务推广初期，用户的第一印象将直接影响其对业务的心理评判。\n\n这些方面业务前期自然需要重点关注和考虑。海外酒店后台在每个环境中都考虑了性能优化相关内容，主要涉及到并发请求，异步解耦，缓存使用。\n\n##### 并发请求\n\n海外酒店POI详情页需要展示产品列表信息，产品列表信息是实时调用多家供应商接口来进行获取，同时还要从POI缓存中心获取房型的图片链接，然后进行结果的聚合组装然后返回。\n\n如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/005.png) \n\n通过并发请求获取，来提高接口的响应时间，在进行并发任务操作时，需要注意线程池的配置和管理。这块内容很多地方都有详解，在这里就不展开介绍了。 \n\n##### 异步解耦\n\n除了用并发请求来优化响应时间以外，还有一种方式是异步解耦。 \n\n异步解耦可以描述为将非主业务功能进行拆分，对返回结果没有影响的功能，进行异步化操作。\n\n异步化的方式常见的有：\n\n1.  启动新的线程，异步化执行。\n2.  通过异步消息，拆分服务执行。\n\n**启动新线程进行异步解耦**\n\n海外酒店业务举例来说，用户进行下单操作：\n\n1.  订单交易平台需要将下单信息同步到直连订单系统。\n2.  然后由直连订单系统去第三方供应商进行下单。\n3.  第三方供应商下单接口很多时候是非实时返回结果，需要定时去拉取结果，然后将结果同步给订单交易平台。\n\n这三步操作如果同步执行，那么结果耗时会很久，用户等待时间非常长。为了提高用户体验，在直连订单系统存储成功下单信息之后，就返回给用户一个结果等待的中间状态，避免用户长时间等待。与此同时后台会启动一个新线程，进行到第三方下单的操作，这就是启动新线程进行异步解耦的过程。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/006.png) \n\n**通过异步消息，拆分服务解耦**\n\n用户在获取产品信息时候，需要将实时获取到的产品信息进行相关的梳理计算并同步到统计中心，进行数据的采集。这块数据梳理同步任务和用户访问主要目的没有太多直接关系，因此可以采用异步消息的方式发送给数据梳理服务，然后由该服务进行相关的数据整理工作，从而实现业务的解耦，优化了接口的响应时间。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/007.png) \n\n##### 缓存使用\n\n缓存的使用分为两种：一种本机缓存，一种是分布式缓存。都是将数据加载到缓存，以此来减轻数据库查询或者接口访问的压力，以及优化服务响应时间。 \n\n###### 本地缓存使用\n\n本地缓存比较合适的使用场景：\n\n1.  数据量比较小（内存资源有限）。\n2.  经常被访问相对稳定信息（效果突出，数据变动小）。\n\n在海外酒店直连工程中，床型映射信息属于比较稳定的存储数据，同时数据量级非常小，但访问量相对比较大，因此符合使用本地缓存的场景。\n\n本地缓存熟知的实现方式：Ehcache、Guava Cache。\n\n在本地缓存使用方面需要注意：本地缓存涉及到多机之间数据不同步风险或者内存消耗方面的影响。因此使用时候需要详细考虑数据的场景。 \n\n###### 分布式缓存使用\n\n当前服务一般都是分布式服务，因此使用比较多的也是分布式缓存来进行相关的优化。下面介绍一下海外酒店对于分布式缓存的使用。\n\n**避免数据库访问压力**\n\n大量的DB访问会造成DB的压力，同时DB的查询效率会随着数据量的增加逐步变差，因此比较常规的做法，是将部分数据同步到缓存中，通过缓存作为中间层，减少DB的访问，与此同时优化服务响应时间。 \n\nDB和缓存数据的同步一般有访问时同步、定时预热同步等。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/008.png) \n\n**避免第三方服务访问压力**\n\n场景一\n\n海外酒店产品信息是实时的调用第三方接口来获取，三方接口性能和稳定性均可能存在未知风险，因此为了提升内部系统整体的性能与稳定性，同时为了避免大访问量对三方接口造成压力， 采用了产品信息缓存的策略，同时根据第三方的要求，进行缓存内容过期时间的合理设定。  \n\n场景二\n\n海外酒店搜索列表页、详情页、下单填写页均需要进行POI（酒店信息）相关信息的展示，对于POI查询接口来说访问量非常大，因此为了避免对POI中心造成流量的冲击，海外酒店POI缓存中心将所有的POI信息每天定时全量的同步到缓存中，同时进行相关信息的整体聚合，提供给业务访问，从而避免了服务接口的压力。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/009.png) \n\n使用分布式缓存的时候需要注意的一点：**数据一致性的问题**。对于海外酒店POI缓存中心通过两种方式来进行数据一致性的保证:\n\n1.  通过接收异步消息，监听缓存信息的变更记录，从而将变更信息同步到缓存；\n2.  间隔一段周期，进行全量缓存数据的更新操作，从而保证数据的准确性。\n\n###### 缓存使用的梳理\n\n缓存使用时候需要注意缓存的雪崩、更改策略问题。\n\n**雪崩**\n\n雪崩的概念可以简单描述为：缓存由于某些原因造成大量的缓存数据失效，大量的访问请求直接打到数据库或者服务接口，造成底层数据源的压力。\n\n有一种常见情况的雪崩，就是在短时间内大量的同步数据到缓存，到了过期时间，导致大量的缓存数据失效，从而形成雪崩现象。 \n\n海外酒店在大量同步POI数据到缓存的时候，采用了少线程、缓慢同步的策略。这块虽然增加了整个缓存的同步总时间，但也让数据的同步进行了有效的分散，从而避免了雪崩现象的产生。\n\n还有一种方式，就是让每个缓存内容的过期时间设置进行不同的赋值，不要统一设定过期时间，使用一个区间内（比如一个小时）随机的选择失效时间，从而可以避免雪崩的危险。 \n\n**穿透**\n\n什么是缓存穿透？一般使用缓存查询的时候，如果在缓存中查询不到结果，就会去DB或者服务中再次查询。但如果大量的访问是因为查询了缓存和数据库中均不存在的数据，从而造成每次查询都要去DB或者服务访问验证一次，就会对后端DB或者服务造成压力。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/010.png) \n\n**海外酒店业务场景**\n\n海外酒店的搜索列表页，会进行酒店最低价的查询，海外酒店的最低价需要准实时（每天两次）从第三方来同步产品最低价信息，然后存储到数据库提供给搜索服务使用。 \n\n搜索列表页是所有服务页面中流量最大，访问最多的页面，因此需要将访问的最低价数据同步到缓存，然后提供服务。\n\n在现实业务中，很多酒店在某些时期没有产品售卖，也就不存在最低价属性，因此在大量访问的时候，就会造成一定的缓存穿透情况。为了避免这种情况，采取如下策略。\n\n**前期**\n\n将所有的没有数据的访问，也存储到缓存当中，防止缓存访问的穿透；同时存储这些无值默认数据的key，也要保持和数据库或者服务数据的一致性。\n\n问题：随着数据量的增加，可能造成缓存空间的严重浪费。 \n\n**后期**\n\n后续再次使用Bloom Filter来进行简单的优化。Bloom Filter算法采用的是部分错误代价、换取空间优化的特点。具体的原理在这里不做过多的介绍。 \n\n#### 扩展性\n\n对于新的业务系统来讲，扩展性的考虑主要有前期的容量评估和服务粒度的拆分。\n\n##### 前期的容量评估\n\n作为新项目，必须进行项目前期的容量评估，从而决定前期项目需要申请的资源，以及未来一段时间需要扩充的资源。容量评估的内容一般包括：访问量评估、数据量评估、带宽/CPU/内存相关的评估。 \n\n访问量评估主要考虑三方面内容：\n\n1.  初期业务访问量的PV有多少，正常的每天访问密集时间段；2.  是否会有促销相关的运营活动，能带来多少流量的增长；\n3.  存储数据的量级范围，包含两个方面：第一是数据库存储数据的量级，第二个是缓存存储的量级。\n\n拿海外酒店举例：\n\n1.  海外业务本身访问量属于缓和类型，与业务方沟通大概的PV量级，以及访问密集程度明显的时间段，根据能够支持正常流量的峰值3倍能力来确定机器的资源。\n2.  海外酒店会有促销运营活动的配置，但不属于短时间内的高并发促销业务，因此促销带来的流量峰值，可以通过简单的机器备份来进行预备。3.  海外酒店后台数据库容量评估方面：主要根据POI存储量级，产品信息存储量级，以及每天信息存储的大小，计算总和。基于5倍容量的评估进行数据库大小的申请。\n4.  缓存存储主要用于POI静态数据存储和部分产品属性的存储，整体量级假设在30G之内，考虑后期的扩展，申请30G*2，方便未来的数据扩展。\n\n##### 服务粒度的拆分\n\n服务的拆分应该遵循单服务高内聚，多服务低耦合。服务的划分应该将经常一起发生变化，业务模型处理相同的模块放在一起，从而实现内聚性； 服务间可以独立部署，负责业务或者功能可以通过接口清晰调用，服务间部署，发布均可以独立进行，从而实现服务间松耦合。\n\n海外酒店后台服务可以从上文中看出：\n\n> POI缓存中心：负责POI相关静态数据的缓存管理；\n> 产品中心：负责同步三方产品数据 同时进行部分缓存操作；\n> 订单中心：负责订单相关的服务，进行交易相关的服务；\n> 报价中心：价格相关展示计算进行服务拆分，统一价格计算，避免同一价格，多出计算逻辑问题。\n\n服务科学的拆分方便系统间处理业务界限清晰，同时管理起来统一方便。 \n\n### 展望\n\n上面总结了项目发展初期一般遇到的问题和思考以及部分解决方案。后续随着业务的发展，还会遇到中期的问题与挑战。根据不同的发展阶段，需要做出不同的规划与策略，未雨绸缪，让系统在业务不断发展的过程中，迭代优化，提早准备，避免系统能力支持出现瓶颈。\n\n海外酒店后台后续的系统建设与优化思路，总体来说可以参考下面的模型：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/011.png) \n\nX轴可以理解为数据库的主从复制，机器的扩充，缓存的扩充。侧重节点能力的无差别复制。\n\nY轴可以理解为将部分目前业务逻辑耦合比较复杂的系统，根据业务特点进行垂直拆分，让系统服务负责业务更加精简明确。\n\nZ轴可以理解为根据用户不同特点或者特殊需求方面进行系统扩展；例如，为了提高在海外的用户访问效率，进行海外服务节点的部署搭建。 \n\n总体来说保证业务需求快速迭代的同时，优化系统架构，保证系统的各方面指标。 \n\n### 团队建设\n\n在文章的最后简单梳理一下孵化业务团队建设相关的内容。\n\n**团队如何建设？**\n\n一般孵化业务面临的问题：项目成员新，组内技术积累弱，业务了解程度浅。 \n\n**面对这种问题如何解决？** \n\n快速招聘、大量进人？这样存在团队管理方面的风险，会造成业务开发过程中沟通、理解方面的偏差不同问题扩大，甚至产生团队的不稳定因素，造成团队整体效率偏低；因此越是孵化项目，越是初创团队，就更需要循序渐进进行人员的扩充，在团队成长的过程中形成自己的文化和节奏，后期进入的员工能快速的从身边老员工身上体会与学习到这些文化和节奏。从而形成统一的团队相处模式。在一个稳定的团队扩建速度下逐步凝聚，提高效率，提升整体战斗力。 \n\n**规范如何树立？**\n\n技术团队建设成长的过程中，技术规范的建设起到很重要的作用，规范建设越迅速、越完整，那么业务开发过程中的风险也就更少。\n海外酒店在团队建设过程中不断加强技术规范的建设，在半年的时间里分别进行了八个技术规范的落地。\n\n![](/assets/images/2017/06/29/fuhua-haiwai/012.png) \n\n这些技术方案的持续建设，大大降低了初创团队的工程风险，同时也让新加入的同学，快速的了解团队开发习惯，迅速进入到生产角色。后续海外酒店后台还需要进行：单元测试规范、监控报警规范等一系列的建设任务。 \n\n### 总结\n\n上面根据孵化业务现实的技术思考，从初建、优化、展望、团队四个方面进行相关的介绍。 整体来看基本上都是根据业务不同发展需求，做出合理的技术选型与设计。 后续随着业务的成长，系统建设与技术架构都会有不同程度的迭代思考与修整。 从各个方面去思考系统对于业务支持的合理性与前瞻性，尽量做到合理演进、灵活扩展、科学设计等各方面的要求。 \n\n### 作者简介\n\n宗起，后台技术专家，2015年加入美团点评，目前负责海外酒店后台研发团队。之前曾在阿里巴巴、腾讯、中国移动研究院从事后台研发工作。\n\n关飞，高级技术专家。之前在阿里、创新工场孵化项目从事研发工程师职位，现在负责酒店后台ehome组，负责酒店核心通路、孵化业务的系统建设、维护工作。\n\n---\n\n* Author: 关飞 宗起\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [孵化业务快速落地与优化](https://tech.meituan.com/fuhua-haiwai.html)","tags":["Business"],"categories":["Business"]},{"title":"Neural Network Zoo Prequel: Cells And Layers","url":"%2F2017%2F2017-05-31-neural-network-zoo-prequel-cells-layers%2F","content":"\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/neuralnetworkcells.png)\n\n### Cells\n\n[The Neural Network Zoo](http://www.asimovinstitute.org/neural-network-zoo/) shows different types of cells and various layer connectivity styles, but it doesn&#8217;t really go into how each cell type works. A number of cell types I originally gave different colours to differentiate the networks more clearly, but I have since found out that these cells work more or less the same way, so you&#8217;ll find descriptions under the basic cell images.\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/ffcell.png)\n\n**A basic neural network cell**, the type one would find in a regular feed forward architecture, is quite simple. The cell is connected to other neurons via weights, i.e. it can be connected to all the neurons in the previous layer. Each connection has its own weight, which is often just a random number at first. A weight can be negative, positive, very small, very big or zero. The value of each of the cells it&#8217;s connected to is multiplied by its respective connection weight. The resulting values are all added together. On top of this, a bias is also added. A bias can prevent a cell from getting stuck on outputting zero and it can speed up some operations, reducing the amount of neurons required to solve a problem. The bias is also a number, sometimes constant (often -1 or 1) and sometimes variable. This total sum is then passed through an activation function, the resulting value of which then becomes the value of the cell.\n\n**Convolutional cells** are much like feed forward cells, except they&#8217;re typically connected to only a few neurons from the previous layer. They are often used to preserve spatial information, because they are connected not to a few random cells but to all cells in a certain proximity. This makes them practical for data with lots of localised information, such as images and sound waves (but mostly images). Deconvolutional cells are just the opposite: these tend to decode spatial information by being locally connected to the next layer. Both cells often have a lot of clones which are trained independently; each clone having it&#8217;s own weights but connected exactly the same way. These clones can be thought of as being located in separate networks which all have the same structure. Both are essentially the same as regular cells, but they are used differently.\n\n**Pooling and interpolating cells** are frequently combined with convolutional cells. These cells are not really cells, more just raw operations. Pooling cells take in the incoming connections and decide which connection gets passed through. In images, this can be thought of as zooming out on a picture. You can no longer see all the pixels, and it has to learn which pixels to keep and which to discard. Interpolating cells perform the opposite operation: they take in some information and map it to more information. The extra information is made up, like if one where to zoom in on a small resolution picture. Interpolating cells are not the only reverse operation of pooling cells, but they are relatively common as they are fast and simple to implement. They are respectively connected much like convolutional and deconvolutional cells.\n\n**Mean and standard deviation cells** (almost exclusively found in couples as probabilistic cells) are used to represent probability distributions. The mean is the average value and the standard deviation represents how far to deviate from this average (in both directions). For example, a probabilistic cell used for images could contain the information on how much red there is in a particular pixel. The mean would say for example 0.5, and the standard deviation 0.2. When sampling from these probabilistic cells, one would enter these values in a Gaussian random number generator, resulting in anything between 0.4 and 0.6 being quite likely results, with values further away from 0.5 being less and less likely (but still possible). They are often fully connected to either the previous or the next layer and they do not have biases.\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/rnncell.png)\n\n**Recurrent cells** have connections not just in the realm of layers, but also over time. Each cell internally stores its previous value. They are updated just like basic cells, but with extra weights: connected to the previous values of the cells and most of the time also to all the cells in the same layer. These weights between the current value and the stored previous value work much like a volatile memory (like RAM), inheriting both properties of having a certain &#8220;state&#8221; and vanishing if not fed. Because the previous value is a value passed through an activation function, and each update passes this activated value along with the other weights through the activation function, information is continually lost. In fact, the retention rate is so low, that only four or five iterations later, almost all of the information is lost.\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/lstmcell.png)\n\n**Long short term memory cells** are used to combat the problem of the rapid information loss occurring in recurrent cells. LSTM cells are logic circuits, copied from how memory cells were designed for computers. Compared to RNN cells which store two states, LSTM cells store four: the current and last value of the output and the current and last values of the state of the &#8220;memory cell&#8221;. They have three &#8220;gates&#8221;: input, output, forget, and they also have just the regular input. Each of these gates has its own weight meaning that connecting to this type of cell entails setting up four weights (instead of just one). The gates function much like flow gates, not fence gates: they can let everything through, just a little bit, nothing, or, anything in between. This works by multiplying incoming information by a value ranging from 0 to 1, which is stored in this gate value. The input gate, then, determines how much of the input is allowed to be added to the cell value. The output gate determines how much of the output value can be seen by the rest of the network. The forget gate is not connected to the previous value of the output cell, but rather connected to the previous memory cell value. It determines how much of the last memory cell state to retain. Because it&#8217;s not connected to the output, much less information loss occurs, because no activation function is placed in the loop.\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/grucell.png)\n\n**Gated recurrent units** (cells) are a variation of LSTM cells. They too use gates to combat information loss, but do so with just 2 gates: update and reset. This makes them slightly less expressive but also slightly faster, as they use less connections everywhere. In essence there are two differences between LSTM cells and GRU cells: GRU cells do not have a hidden cell state protected by an output gate, and they combine the input and forget gate into a single update gate. The idea is that if you want to allow a lot of new information, you can probably forget some old information (and the other way around).\n\n### Layers\n\nThe most basic way of connecting neurons to form graphs is by connecting everything to absolutely everything. This is seen in Hopfield networks and Boltzmann machines. Of course, this means the number of connections grows exponentially, but the expressiveness is uncompromised. This is referred to as completely (or fully) connected.\n\nAfter a while it was discovered that breaking the network up into distinct layers is a useful feature, where the definition of a layer is a set or group of neurons which are not connected to each other, but only to neurons from other group(s). This concept is for instance used in Restricted Boltzmann Machines. The idea of **using layers** is nowadays generalised for any number of layers and it can be found in almost all current architectures. This is (perhaps confusingly) also called fully connected or completely connected, because actually completely connected networks are quite uncommon.\n\n**Convolutionally connected layers** are even more constrained than fully connected layers: we connect every neuron only to neurons in other groups that are close by. Images and sound waves contain a very high amount of information if used to feed directly one-to-one into a network (e.g. using one neuron per pixel). The idea of convolutional connections comes from the observation that spatial information is probably important to retain. It turned out that this is a good guess, as it&#8217;s used in many image and sound wave based neural network applications. This setup is however less expressive than fully connected layers. In essence it is a way of &#8220;importance&#8221; filtering, deciding which of the tightly grouped information packets are important; convolutional connections are great for dimensionality reduction. At what spatial distance neurons can still be connected depends on the implementation, but ranges higher than 4 or 5 neurons are rarely used. Note that &#8220;spatial&#8221; often refers to two-dimensional space, which is why most representations show three-dimensional sheets of neurons being connected; the connection range is applied in all dimensions.\n\nAnother option is of course to **randomly connected neurons**. This comes in two main variations as well: by allowing for some percentage of all possible connections, or to connect some percentage of neurons between layers. Random connections help to linearly reduce the performance of the network and can be useful in large networks where fully connected layers run into performance problems. A slightly more sparsely connected layer with slightly more neurons can perform better in some cases, especially where a lot of information needs to be stored but not as much information needs to be exchanged (a bit similar to the effectiveness of convolutionally connected layers, but then randomised). Very sparsely connected systems (1 or 2%) are also used, as seen in ELMs, ESNs and LSMs. Especially in the case of spiking networks this makes a lot of sense, because the more connections a neuron has, the less energy each weight will carry over, meaning less propagating and repeating patterns.\n\n**Time delayed connections** are connections between neurons (often from the same layer, and even connected with themselves) that don&#8217;t get information from the previous layer, but from a layer from the past (previous iteration, mostly). This allows temporal (time, sequence or order) related information to be stored. These types of connections are often manually reset from time to time, to clear the &#8220;state&#8221; of the network. The key difference with regular connections is that these connections are continuously changing, even when the network isn&#8217;t being trained.\n\nThe following image shows some small sample networks of the types described above, and their connections. I use it when I get stuck on just exactly what is connected to what (which is particularly likely when working with LSTM or GRU cells):\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/neuralnetworkgraphs.png)\n\n---\n\n* Author: [FJODOR VAN VEEN](http://www.asimovinstitute.org/author/fjodorvanveen/)\n* Source: [THE ASIMOV INSTITUTE](http://www.asimovinstitute.org/)\n* Link: [NEURAL NETWORK ZOO PREQUEL: CELLS AND LAYERS](http://www.asimovinstitute.org/neural-network-zoo-prequel-cells-layers/)\n","tags":["Layers"],"categories":["Deep-Learning"]},{"title":"美团点评酒旅数据仓库建设实践","url":"%2F2017%2F2017-05-26-hotel-dw-layer-topic%2F","content":"\n在美团点评酒旅事业群内，业务由传统的团购形式转向预订、直连等更加丰富的产品形式，业务系统也在迅速的迭代变化，这些都对数据仓库的扩展性、稳定性、易用性提出了更高要求。对此，我们采取了分层次、分主题的方式，本文将分享这一过程中的一些经验。\n\n### 技术架构\n\n随着美团点评整体的系统架构调整，我们在分层次建设数据仓库的过程中，不断优化并调整我们的层次结构，下图展示了技术架构的变迁。\n\n![酒旅数据仓库分层](/assets/images/2017/05/26/hotel_dw_layer_topic/001.png)\n\n我们把它们简称为三代数仓模型层次。在第一代数仓模型层次中，由于当时美团整体的业务系统所支持的产品形式比较单一（团购），业务系统中包含了所有业务品类的数据，所以由平台的角色来加工数据仓库基础层是非常合适的，平台统一建设，支持各个业务线使用，所以在本阶段中我们酒旅只是建立了一个相对比较简单的数据集市。\n\n但随着美团原本集中的业务系统不能快速响应各个业务线迅速的发展与业务变化时，酒旅中的酒店业务线开始有了自己的业务系统来支持预订、房惠、团购、直连等产品形式，境内度假业务线也开始有了自己的业务系统来支持门票预订、门票直连、跟团游等复杂业务。我们开始了第二代数仓模型层次的建设，由建设数据集市的形式转变成了直接建设酒旅数据仓库，成为了酒旅自身业务系统数据的唯一加工者。由于系统调整初期给我们带来的重构、修改以及新增等数据处理工作非常大，我们采用了比较短平快的Kimball所提的维度建模的方式建设了酒旅数据仓库。\n\n在第二代数仓模型层次运转一段时间后，我们的业务又迎来了一个巨大的变化，上海团队和我们融合了，同时我们酒旅自身的业务系统重构的频率相对较高，对我们的数仓模型稳定性造成了非常大的影响，原本的维度模型非常难适配这么迅速的变化。下图就是我们数仓模型当时所面临的挑战：\n\n![基础层背景](/assets/images/2017/05/26/hotel_dw_layer_topic/002.png)\n\n于是我们在ODS与多维明细层中间加入了数据整合层，参照Bill Inmon所提出的企业信息工厂建设的模式，基本按照三范式的原则来进行数据整合，由业务驱动调整成了由技术驱动的方式来建设数据仓库基础层。下图是该层次的一些描述：\n\n![基础层](/assets/images/2017/05/26/hotel_dw_layer_topic/003.png)\n使用本基础层的最根本出发点还是在于我们的供应链、业务、数据它们本身的多样性，如果业务、数据相对比较单一、简单，本层次的架构方案很可能将不再适用。\n\n### 业务架构\n\n下面介绍我们的主题建设，实际上在传统的一些如银行、制造业、电信、零售等行业里，都有一些比较成熟的模型，如耳熟能详的BDWM、FS-LDM、MLDM等等模型，它们都是经过一些具有相类似行业的企业在二三十年数据仓库建设中所积累的行业经验，不断的优化并通用化。但我们所处的O2O行业本身就没有可借鉴的成熟的数据仓库主题以及模型，所以，我们在摸索建设两年的时间里，我们目前总结了下面比较适合我们现状的七大主题（后续可能还会新增）：\n\n![数据仓库主题](/assets/images/2017/05/26/hotel_dw_layer_topic/004.png)\n\n#### 参与人主题\n\n用户子主题：使用我们服务的所有人都是我们的用户，这是我们数据中至关重要的实体，也是我们数仓中非常重要的一个主题，对用户数据的系统化建设能够很好的帮助我们企业快速的发展，不断提高用户的体验、扩大我们的用户群。\n\nBD子主题：通过BD的业务扩展，建立我们与商户之间的关系，让用户通过我们的服务访问到商户所发布的信息，对BD数据的建设，能够让我们的商户覆盖更加迅速、让我们和商户之间的关系更加紧密。\n\n供应商子主题：供应商无论作为直签还是作为三方签约对象，对我们的业务发展都非常重要，通过对其数据的建设，可以让我们彼此双赢，通过我们的平台让双方的业务迅速发展。\n\n#### 流量主题\n\n用户通过App或PC或I版、微信等等形式访问我们的服务，形成了对我们企业至关重要的流量，本主题也是比较具有互联网特色的主题，对于流量的数据建设能够让我们不断优化我们的产品、服务，给我们带来更多的流量、更快的扩张。\n\n#### 订单主题\n\n当用户给我们带来流量的同时，他们也会产生交易，订单主题的独立建设以及其重要性我这里就不再赘述了，在所有的互联网以及传统公司里，该主题都是至关重要的。\n\n#### POI主题\n\n这个主题也具有我们自身的O2O特色，实际上这个主题与阿里的商家主题比较类似但又具备自己的特点，对于POI自身的重要性就不再过多介绍，通过对POI的数据集中建设能够让我们给POI带去更好的服务与回报。\n\n#### 产品主题\n\n与POI强相关的就是产品了，如何让产品能够更加的贴近用户的需求以及产生更多的交易、流量，产品数据主题的建设及目的的意义就在于此。\n\n#### 运营主题\n\n我们的业务发展将不再依靠粗暴的补贴式的扩张发展模式，需要依赖现在的精细化运营方式，运营数据主题的建设就有了非常强的必要性，通过数据进行精细化运营已经成为我们运营的主要发展趋势。\n\n#### 结算主题\n\n实际上，这个主题在传统企业里面如银行、电信等等都是至关重要的，对我们酒旅而言，建设它的意义能够不断优化商家体验、提高财务结算与管理能力。\n\n### 整体架构\n\n我们的七个主题基本上都采用6层结构的方式来建设，划分主题更多是从业务的角度出发，而层次划分则是基于技术，实质上我们就是基于业务与技术的结合完成了整体的数据仓库架构。下面介绍一下具体的一些主题案例：\n\n![数据仓库架构](/assets/images/2017/05/26/hotel_dw_layer_topic/005.png)\n\n#### 订单主题\n\n 在订单主题的建设过程中，我们是按照由分到总的结构思路来进行建设，首先分供应链建设订单相关实体（数据整合中间层3NF），然后再进行适度抽象把分供应链的相关订单实体进行合并后生成订单实体（数据整合层3NF），后续在数据整合层的订单实体基础上再扩展部分维度信息来完成后续层次的建设。\n\n![订单主题](/assets/images/2017/05/26/hotel_dw_layer_topic/006.png)\n\n#### 流量主题\n\n流量主题与订单主题的区别是非常大的，它的数据来源具有一定的特殊性，我们的总体建设思路是总-分-总的思路，首先从总的日志数据中剥离出来属于酒旅事业群的数据，后续再从这些数据中分拆到各个具体的页面（可以适当补充些各个页面中所具有的B端信息，如POI详情页中增加POI品类信息），最后再把各个页面进行合并生成总的日志主题表（最终这张表会满足80%以上的相关流量统计需求）。\n\n![流量主题](/assets/images/2017/05/26/hotel_dw_layer_topic/007.png)\n\n#### 运营主题\n\n运营主题与订单、流量主题相比也具有自身的特殊性，主要原因也在于其数据来源本身的特殊性，关于它的建设思路总体也是总-分-总，但我们本身的数据来源大多已经不是最底层的ODS数据，而是一些已经加工过的事实表或维度表，所以我们整体的建模原则基本上都是维度建模。\n\n![运营主题1](/assets/images/2017/05/26/hotel_dw_layer_topic/008.png)\n\n![运营主题2](/assets/images/2017/05/26/hotel_dw_layer_topic/009.png)\n\n基于上面介绍的几个主题，我们实际上在做分主题的层次架构时也是基于本主题的业务、数据特点作为最终的判断条件，没有绝对的一种层次架构适用于所有的主题，需要综合各项要素来进行综合判断才能设计比较合适的层次架构。\n\n### 作者简介\n\n德臣，美团点评酒旅事业群数据仓库专家，2003年毕业于湖南大学，2015年加入美团，整体负责酒旅事业群的离线数据仓库、实时数据仓库建设。\n\n酒旅数据仓库团队，结合酒旅业务的发展，灵活利用大数据生态链的相关技术，致力于离线数据仓库与实时数据仓库的建设，为业务提供多样化的数据服务。\n\n**最后发个广告，美团点评酒旅数据仓库团队长期招聘数据仓库、大数据开发、数据产品开发等方向的技术专家，有兴趣的同学可以发送简历到yangdechen#meituan.com。**\n\n---\n\n* Author: 德臣\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [美团点评酒旅数据仓库建设实践](https://tech.meituan.com/hotel_dw_layer_topic.html)\n","tags":["Topic"],"categories":["Warehouse"]},{"title":"磁盘I/O那些事","url":"%2F2017%2F2017-05-19-about-desk-io%2F","content":"\n### **背景**\n\n计算机硬件性能在过去十年间的发展普遍遵循摩尔定律，通用计算机的CPU主频早已超过3GHz，内存也进入了普及DDR4的时代。然而传统硬盘虽然在存储容量上增长迅速，但是在读写性能上并无明显提升，同时SSD硬盘价格高昂，不能在短时间内完全替代传统硬盘。传统磁盘的I/O读写速度成为了计算机系统性能提高的瓶颈，制约了计算机整体性能的发展。\n\n硬盘性能的制约因素是什么？如何根据磁盘I/O特性来进行系统设计？针对这些问题，本文将介绍硬盘的物理结构和性能指标，以及操作系统针对磁盘性能所做的优化，最后讨论下基于磁盘I/O特性设计的技巧。\n\n### **硬盘的物理结构**\n\n硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：\n\n![磁盘结构](/assets/images/2017/05/19/about-desk-io/001.jpg)\n\n由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区，硬盘中每个扇区的大小固定为512字节。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示：\n\n![磁盘垂直视角](/assets/images/2017/05/19/about-desk-io/002.png)\n\n早期的硬盘每磁道扇区数相同，此时由磁盘基本参数可以计算出硬盘的容量：存储容量=磁头数*磁道（柱面）数*每道扇区数*每扇区字节数。由于每磁道扇区数相同，外圈磁道半径大，里圈磁道半径小，外圈和里圈扇区面积自然会不一样。同时，为了更好的读取数据，即使外圈扇区面积再大也只能和内圈扇区一样存放相同的字节数（512字节）。这样一来，外圈的记录密度就要比内圈小，会浪费大量的存储空间。\n\n如今的硬盘都使用ZBR（Zoned Bit Recording，区位记录）技术，盘片表面由里向外划分为数个区域，不同区域的磁道扇区数目不同，同一区域内各磁道扇区数相同，盘片外圈区域磁道长扇区数目较多，内圈区域磁道短扇区数目较少，大体实现了等密度，从而获得了更多的存储空间。此时，由于每磁道扇区数各不相同，所以传统的容量计算公式就不再适用。实际上如今的硬盘大多使用LBA（Logical Block Addressing）逻辑块寻址模式，知道LBA后即可计算出硬盘容量。\n\n### **影响硬盘性能的因素**\n\n影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。\n\n#### 1. 寻道时间\n\nTseek是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3-15ms。\n\n#### 2. 旋转延迟\n\nTrotation是指盘片旋转将请求数据所在的扇区移动到读写磁盘下方所需要的时间。旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的1/2表示。比如：7200rpm的磁盘平均旋转延迟大约为60*1000/7200/2 = 4.17ms，而转速为15000rpm的磁盘其平均旋转延迟为2ms。\n\n#### 3. 数据传输时间\n\nTtransfer是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前IDE/ATA能达到133MB/s，SATA II可达到300MB/s的接口数据传输率，数据传输时间通常远小于前两部分消耗时间。简单计算时可忽略。\n\n### **衡量性能的指标**\n\n机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。\n\n#### 1. IOPS\n\nIOPS（Input/Output Per Second）即每秒的输入输出量（或读写次数），即指每秒内系统能处理的I/O请求数量。随机读写频繁的应用，如小文件存储等，关注随机读写性能，IOPS是关键衡量指标。可以推算出磁盘的IOPS = 1000ms / (Tseek + Trotation + Transfer)，如果忽略数据传输时间，理论上可以计算出随机读写最大的IOPS。常见磁盘的随机读写最大IOPS为：\n\n*   7200rpm的磁盘 IOPS = 76 IOPS\n*   10000rpm的磁盘IOPS = 111 IOPS\n*   15000rpm的磁盘IOPS = 166 IOPS\n\n#### 2. 吞吐量\n\n吞吐量（Throughput），指单位时间内可以成功传输的数据数量。顺序读写频繁的应用，如视频点播，关注连续读写性能、数据吞吐量是关键衡量指标。它主要取决于磁盘阵列的架构，通道的大小以及磁盘的个数。不同的磁盘阵列存在不同的架构，但他们都有自己的内部带宽，一般情况下，内部带宽都设计足够充足，不会存在瓶颈。磁盘阵列与服务器之间的数据通道对吞吐量影响很大，比如一个2Gbps的光纤通道，其所能支撑的最大流量仅为250MB/s。最后，当前面的瓶颈都不再存在时，硬盘越多的情况下吞吐量越大。\n\n### **操作系统层的优化**\n\n虽然15000rpm的磁盘计算出的理论最大IOPS仅为166，但在实际运行环境中，实际磁盘的IOPS往往能够突破200甚至更高。这其实就是在系统调用过程中，操作系统进行了一系列的优化。\n\n那么操作系统是如何操作硬盘的呢？类似于网络的分层结构，下图显示了Linux系统中对于磁盘的一次读请求在核心空间中所要经历的层次模型。从图中看出：对于磁盘的一次读请求，首先经过虚拟文件系统层（VFS Layer），其次是具体的文件系统层（例如Ext2），接下来是Cache层（Page Cache Layer）、通用块层（Generic Block Layer）、I/O调度层（I/O Scheduler Layer）、块设备驱动层（Block Device Driver Layer），最后是物理块设备层（Block Device Layer）。\n\n![系统调用在核心空间中的处理层次](/assets/images/2017/05/19/about-desk-io/003.png)\n\n#### 虚拟文件系统层（VFS Layer）\n\nVFS（Virtual File System）虚拟文件系统是一种软件机制，更确切的说扮演着文件系统管理者的角色，与它相关的数据结构只存在于物理内存当中。它的作用是：屏蔽下层具体文件系统操作的差异，为上层的操作提供一个统一的接口。正是因为有了这个层次，Linux中允许众多不同的文件系统共存并且对文件的操作可以跨文件系统而执行。\n\nVFS中包含着向物理文件系统转换的一系列数据结构，如VFS超级块、VFS的Inode、各种操作函数的转换入口等。Linux中VFS依靠四个主要的数据结构来描述其结构信息，分别为超级块、索引结点、目录项和文件对象。\n\n1.  超级块（Super Block）：超级块对象表示一个文件系统。它存储一个已安装的文件系统的控制信息，包括文件系统名称（比如Ext2）、文件系统的大小和状态、块设备的引用和元数据信息（比如空闲列表等等）。VFS超级块存在于内存中，它在文件系统安装时建立，并且在文件系统卸载时自动删除。同时需要注意的是对于每个具体的文件系统来说，也有各自的超级块，它们存放于磁盘。\n\n2.  索引结点（Inode）：索引结点对象存储了文件的相关元数据信息，例如：文件大小、设备标识符、用户标识符、用户组标识符等等。Inode分为两种：一种是VFS的Inode，一种是具体文件系统的Inode。前者在内存中，后者在磁盘中。所以每次其实是将磁盘中的Inode调进填充内存中的Inode，这样才是算使用了磁盘文件Inode。当创建一个文件的时候，就给文件分配了一个Inode。一个Inode只对应一个实际文件，一个文件也会只有一个Inode。\n\n3.  目录项（Dentry）：引入目录项对象的概念主要是出于方便查找文件的目的。不同于前面的两个对象，目录项对象没有对应的磁盘数据结构，只存在于内存中。一个路径的各个组成部分，不管是目录还是普通的文件，都是一个目录项对象。如，在路径/home/source/test.java中，目录 /, home, source和文件 test.java都对应一个目录项对象。VFS在查找的时候，根据一层一层的目录项找到对应的每个目录项的Inode，那么沿着目录项进行操作就可以找到最终的文件。\n\n4.  文件对象（File）：文件对象描述的是进程已经打开的文件。因为一个文件可以被多个进程打开，所以一个文件可以存在多个文件对象。一个文件对应的文件对象可能不是惟一的，但是其对应的索引节点和目录项对象肯定是惟一的。\n\n#### Ext2文件系统\n\nVFS的下一层即是具体的文件系统，本节简要介绍下Linux的Ext2文件系统。\n\n一个文件系统一般使用块设备上一个独立的逻辑分区。对于Ext2文件系统来说，硬盘分区首先被划分为一个个的Block，一个Ext2文件系统上的每个Block都是一样大小的。但是不同Ext2文件系统，Block大小可能不同，这是在创建Ext2系统决定的，一般为1k或者4k。由于Block数量很多，为了方便管理，Ext2将这些Block聚集在一起分为几个大的块组（Block Group），每个块组包含的等量的物理块，在块组的数据块中存储文件或目录。Ext2文件系统存储结构如下图所示：\n\n![ext2文件系统存储结构](/assets/images/2017/05/19/about-desk-io/004.png)\n\nExt2中的Super Block和Inode Table分别对应VFS中的超级块和索引结点，存放在磁盘。每个块组都有一个块组描述符GDT（Group Descriptor Table），存储一个块组的描述信息，例如在这个块组中从哪里开始是Inode表，从哪里开始是数据块等等。Block Bitmap和Inode Bitmap分别表示Block和Inode是否空闲可用。Data Block数据块是用来真正存储文件内容数据的地方，下面我们看一下具体的存储规则。\n\n在Ext2文件系统中所支持的Block大小有1K、2K、4K三种。在格式化时Block的大小就固定了，且每个Block都有编号，方便Inode的记录。每个Block内最多只能够放置一个文件的数据，如果文件大于Block的大小，则一个文件会占用多个Block；如果文件小于Block，则该Block的剩余容量就不能够再被使用了，即磁盘空间会浪费。下面看看Inode和Block的对应关系。\n\nInode要记录的数据非常多，但大小仅为固定的128字节，同时记录一个Block号码就需要4字节，假设一个文件有400MB且每个Block为4K时，那么至少也要十万笔Block号码的记录。Inode不可能有这么多的记录信息，因此Ext2将Inode记录Block号码的区域定义为12个直接、一个间接、一个双间接与一个三间接记录区。Inode存储结构如下图所示：\n\n![inode结构示意图](/assets/images/2017/05/19/about-desk-io/005.png)\n\n最左边为Inode本身（128 bytes），里面有12个直接指向Block号码的对照，这12笔记录能够直接取得Block号码。至于所谓的间接就是再拿一个Block来当作记录Block号码的记录区，如果文件太大时，就会使用间接的Block来记录编号。如上图当中间接只是拿一个Block来记录额外的号码而已。 同理，如果文件持续长大，那么就会利用所谓的双间接，第一个Block仅再指出下一个记录编号的Block在哪里，实际记录的在第二个Block当中。依此类推，三间接就是利用第三层Block来记录编号。\n\n#### Page Cache层\n\n引入Cache层的目的是为了提高Linux操作系统对磁盘访问的性能。Cache层在内存中缓存了磁盘上的部分数据。当数据的请求到达时，如果在Cache中存在该数据且是最新的，则直接将数据传递给用户程序，免除了对底层磁盘的操作，提高了性能。Cache层也正是磁盘IOPS为什么能突破200的主要原因之一。\n\n在Linux的实现中，文件Cache分为两个层面，一是Page Cache，另一个Buffer Cache，每一个Page Cache包含若干Buffer Cache。Page Cache主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有read/write操作的时候。Buffer Cache则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。\n\n磁盘Cache有两大功能：预读和回写。预读其实就是利用了局部性原理，具体过程是：对于每个文件的第一个读请求，系统读入所请求的页面并读入紧随其后的少数几个页面（通常是三个页面），这时的预读称为同步预读。对于第二次读请求，如果所读页面不在Cache中，即不在前次预读的页中，则表明文件访问不是顺序访问，系统继续采用同步预读；如果所读页面在Cache中，则表明前次预读命中，操作系统把预读页的大小扩大一倍，此时预读过程是异步的，应用程序可以不等预读完成即可返回，只要后台慢慢读页面即可，这时的预读称为异步预读。任何接下来的读请求都会处于两种情况之一：第一种情况是所请求的页面处于预读的页面中，这时继续进行异步预读；第二种情况是所请求的页面处于预读页面之外，这时系统就要进行同步预读。\n\n回写是通过暂时将数据存在Cache里，然后统一异步写到磁盘中。通过这种异步的数据I/O模式解决了程序中的计算速度和数据存储速度不匹配的鸿沟，减少了访问底层存储介质的次数，使存储系统的性能大大提高。Linux 2.6.32内核之前，采用pdflush机制来将脏页真正写到磁盘中，什么时候开始回写呢？下面两种情况下，脏页会被写回到磁盘：\n\n1.  在空闲内存低于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。\n2.  当脏页在内存中驻留超过一定的阈值时，内核必须将超时的脏页写会磁盘，以确保脏页不会无限期地驻留在内存中。\n\n回写开始后，pdflush会持续写数据，直到满足以下两个条件：\n\n1.  已经有指定的最小数目的页被写回到磁盘。\n2.  空闲内存页已经回升，超过了阈值。\n\nLinux 2.6.32内核之后，放弃了原有的pdflush机制，改成了bdi_writeback机制。bdi_writeback机制主要解决了原有fdflush机制存在的一个问题：在多磁盘的系统中，pdflush管理了所有磁盘的Cache，从而导致一定程度的I/O瓶颈。bdi_writeback机制为每个磁盘都创建了一个线程，专门负责这个磁盘的Page Cache的刷新工作，从而实现了每个磁盘的数据刷新在线程级的分离，提高了I/O性能。\n\n回写机制存在的问题是回写不及时引发数据丢失（可由sync|fsync解决），回写期间读I/O性能很差。\n\n#### 通用块层\n\n通用块层的主要工作是：接收上层发出的磁盘请求，并最终发出I/O请求。该层隐藏了底层硬件块设备的特性，为块设备提供了一个通用的抽象视图。\n\n对于VFS和具体的文件系统来说，块（Block）是基本的数据传输单元，当内核访问文件的数据时，它首先从磁盘上读取一个块。但是对于磁盘来说，扇区是最小的可寻址单元，块设备无法对比它还小的单元进行寻址和操作。由于扇区是磁盘的最小可寻址单元，所以块不能比扇区还小，只能整数倍于扇区大小，即一个块对应磁盘上的一个或多个扇区。一般来说，块大小是2的整数倍，而且由于Page Cache层的最小单元是页（Page），所以块大小不能超过一页的长度。\n\n大多情况下，数据的传输通过DMA方式。旧的磁盘控制器，仅仅支持简单的DMA操作：每次数据传输，只能传输磁盘上相邻的扇区，即数据在内存中也是连续的。这是因为如果传输非连续的扇区，会导致磁盘花费更多的时间在寻址操作上。而现在的磁盘控制器支持“分散/聚合”DMA操作，这种模式下，数据传输可以在多个非连续的内存区域中进行。为了利用“分散/聚合”DMA操作，块设备驱动必须能处理被称为段（segments）的数据单元。一个段就是一个内存页面或一个页面的部分，它包含磁盘上相邻扇区的数据。\n\n通用块层是粘合所有上层和底层的部分，一个页的磁盘数据布局如下图所示：\n\n![页内磁盘数据布局](/assets/images/2017/05/19/about-desk-io/006.png)\n\n#### I/O调度层\n\nI/O调度层的功能是管理块设备的请求队列。即接收通用块层发出的I/O请求，缓存请求并试图合并相邻的请求。并根据设置好的调度算法，回调驱动层提供的请求处理函数，以处理具体的I/O请求。 \n\n如果简单地以内核产生请求的次序直接将请求发给块设备的话，那么块设备性能肯定让人难以接受，因为磁盘寻址是整个计算机中最慢的操作之一。为了优化寻址操作，内核不会一旦接收到I/O请求后，就按照请求的次序发起块I/O请求。为此Linux实现了几种I/O调度算法，算法基本思想就是通过合并和排序I/O请求队列中的请求，以此大大降低所需的磁盘寻道时间，从而提高整体I/O性能。\n\n常见的I/O调度算法包括Noop调度算法（No Operation）、CFQ（完全公正排队I/O调度算法）、DeadLine（截止时间调度算法）、AS预测调度算法等。\n\n*   Noop算法：最简单的I/O调度算法。该算法仅适当合并用户请求，并不排序请求。新的请求通常被插在调度队列的开头或末尾，下一个要处理的请求总是队列中的第一个请求。这种算法是为不需要寻道的块设备设计的，如SSD。因为其他三个算法的优化是基于缩短寻道时间的，而SSD硬盘没有所谓的寻道时间且I/O响应时间非常短。\n\n*   CFQ算法：算法的主要目标是在触发I/O请求的所有进程中确保磁盘I/O带宽的公平分配。算法使用许多个排序队列，存放了不同进程发出的请求。通过散列将同一个进程发出的请求插入同一个队列中。采用轮询方式扫描队列，从第一个非空队列开始，依次调度不同队列中特定个数（公平）的请求，然后将这些请求移动到调度队列的末尾。\n\n*   Deadline算法：算法引入了两个排队队列分别包含读请求和写请求，两个最后期限队列包含相同的读和写请求。本质就是一个超时定时器，当请求被传给电梯算法时开始计时。一旦最后期限队列中的超时时间已到，就想请求移至调度队列末尾。Deadline算法避免了电梯调度策略（为了减少寻道时间，会优先处理与上一个请求相近的请求）带来的对某个请求忽略很长一段时间的可能。\n\n*   AS算法：AS算法本质上依据局部性原理，预测进程发出的读请求与刚被调度的请求在磁盘上可能是“近邻”。算法统计每个进程I/O操作信息，当刚刚调度了由某个进程的一个读请求之后，算法马上检查排序队列中的下一个请求是否来自同一个进程。如果是，立即调度下一个请求。否则，查看关于该进程的统计信息，如果确定进程p可能很快发出另一个读请求，那么就延迟一小段时间。\n\n前文中计算出的IOPS是理论上的随机读写的最大IOPS，在随机读写中，每次I/O操作的寻址和旋转延时都不能忽略不计，有了这两个时间的存在也就限制了IOPS的大小。现在如果我们考虑在读取一个很大的存储连续分布在磁盘的文件，因为文件的存储的分布是连续的，磁头在完成一个读I/O操作之后，不需要重新寻址，也不需要旋转延时，在这种情况下我们能到一个很大的IOPS值。这时由于不再考虑寻址和旋转延时，则性能瓶颈仅是数据传输时延，假设数据传输时延为0.4ms，那么IOPS=1000 / 0.4 = 2500 IOPS。\n\n在许多的开源框架如Kafka、HBase中，都通过追加写的方式来尽可能的将随机I/O转换为顺序I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高IOPS。\n\n#### 块设备驱动层\n\n驱动层中的驱动程序对应具体的物理块设备。它从上层中取出I/O请求，并根据该I/O请求中指定的信息，通过向具体块设备的设备控制器发送命令的方式，来操纵设备传输数据。这里不再赘述。\n\n### **基于磁盘I/O特性设计的技巧**\n\n在上一节中我们了解了Linux系统中请求到达磁盘的一次完整过程，期间Linux通过Cache以及排序合并I/O请求来提高系统的性能。其本质就是由于磁盘随机读写慢、顺序读写快。本节针对常见开源系统阐述一些基于磁盘I/O特性的设计技巧。\n\n#### 采用追加写\n\n在进行系统设计时，良好的读性能和写性能往往不可兼得。在许多常见的开源系统中都是优先在保证写性能的前提下来优化读性能。那么如何设计能让一个系统拥有良好的写性能呢？一个好的办法就是采用追加写，每次将数据添加到文件。由于完全是顺序的，所以可以具有非常好的写操作性能。但是这种方式也存在一些缺点：从文件中读一些数据时将会需要更多的时间：需要倒序扫描，直到找到所需要的内容。当然在一些简单的场景下也能够保证读操作的性能：\n\n*   数据是被整体访问，比如HDFS\n\n*   HDFS建立在一次写多次读的模型之上。在HDFS中就是采用了追加写并且设计为高数据吞吐量；高吞吐量必然以高延迟为代价，所以HDFS并不适用于对数据访问要求低延迟的场景；由于采用是的追加写，也并不适用于任意修改文件的场景。HDFS设计为流式访问大文件，使用大数据块并且采用流式数据访问来保证数据被整体访问，同时最小化硬盘的寻址开销，只需要一次寻址即可，这时寻址时间相比于传输时延可忽略，从而也拥有良好的读性能。HDFS不适合存储小文件，原因之一是由于NameNode内存不足问题，还有就是因为访问大量小文件需要执行大量的寻址操作，并且需要不断的从一个datanode跳到另一个datanode，这样会大大降低数据访问性能。\n\n*   知道文件明确的偏移量，比如Kafka\n\n*   在Kafka中，采用消息追加的方式来写入每个消息，每个消息读写时都会利用Page Cache的预读和后写特性，同时partition中都使用顺序读写，以此来提高I/O性能。虽然Kafka能够根据偏移量查找到具体的某个消息，但是查找过程是顺序查找，因此如果数据很大的话，查找效率就很低。所以Kafka中采用了分段和索引的方式来解决查找效率问题。Kafka把一个patition大文件又分成了多个小文件段，每个小文件段以偏移量命名，通过多个小文件段，不仅可以使用二分搜索法很快定位消息，同时也容易定期清除或删除已经消费完的文件，减少磁盘占用。为了进一步提高查找效率，Kafka为每个分段后的数据建立了索引文件，并通过索引文件稀疏存储来降低元数据占用大小。一个段中数据对应结构如下图所示：\n\n![kafka中一个段的物理结构](/assets/images/2017/05/19/about-desk-io/007.png)\n\n在面对更复杂的读场景（比如按key）时，如何来保证读操作的性能呢？简单的方式是像Kafka那样，将文件数据有序保存，使用二分查找来优化效率；或者通过建索引的方式来进行优化；也可以采用hash的方式将数据分割为不同的桶。以上的方法都能增加读操作的性能，但是由于在数据上强加了数据结构，又会降低写操作的性能。比如如果采用索引的方式来优化读操作，那么在更新索引时就需要更新B-tree中的特定部分，这时候的写操作就是随机写。那么有没有一种办法在保证写性能不损失的同时也提供较好的读性能呢？一个好的选择就是使用LSM-tree。LSM-tree与B-tree相比，LSM-tree牺牲了部分读操作，以此大幅提高写性能。\n\n*   日志结构的合并树LSM（The Log-Structured Merge-Tree）是HBase，LevelDB等NoSQL数据库的存储引擎。Log-Structured的思想是将整个磁盘看做一个日志，在日志中存放永久性数据及其索引，每次都添加到日志的末尾。并且通过将很多小文件的存取转换为连续的大批量传输，使得对于文件系统的大多数存取都是顺序的，从而提高磁盘I/O。LSM-tree就是这样一种采用追加写、数据有序以及将随机I/O转换为顺序I/O的延迟更新，批量写入硬盘的数据结构。LSM-tree将数据的修改增量先保存在内存中，达到指定的大小限制后再将这些修改操作批量写入磁盘。因此比较旧的文件不会被更新，重复的纪录只会通过创建新的纪录来覆盖，这也就产生了一些冗余的数据。所以系统会周期性的合并一些数据，移除重复的更新或者删除纪录，同时也会删除上述的冗余。在进行读操作时，如果内存中没有找到相应的key，那么就是倒序从一个个磁盘文件中查找。如果文件越来越多那么读性能就会越来越低，目前的解决方案是采用页缓存来减少查询次数，周期合并文件也有助于提高读性能。在文件越来越多时，可通过布隆过滤器来避免大量的读文件操作。LSM-tree牺牲了部分读性能，以此来换取写入的最大化性能，特别适用于读需求低，会产生大量插入操作的应用环境。\n\n##### 文件合并和元数据优化\n\n目前的大多数文件系统，如XFS/Ext4、GFS、HDFS，在元数据管理、缓存管理等实现策略上都侧重大文件。上述基于磁盘I/O特性设计的系统都有一个共性特点就是都运行在这些文件系统之上。这些文件系统在面临海量时在性能和存储效率方面都大幅降低，本节来探讨下海量小文件下的系统设计。\n\n常见文件系统在海量小文件应用下性能表现不佳的根本原因是磁盘最适合顺序的大文件I/O读写模式，而非常不适合随机的小文件I/O读写模式。主要原因体现在元数据管理低效和数据布局低效：\n\n*   元数据管理低效：由于小文件数据内容较少，因此元数据的访问性能对小文件访问性能影响巨大。Ext2文件系统中Inode和Data Block分别保存在不同的物理位置上，一次读操作需要至少经过两次的独立访问。在海量小文件应用下，Inode的频繁访问，使得原本的并发访问转变为了海量的随机访问，大大降低了性能。另外，大量的小文件会快速耗尽Inode资源，导致磁盘尽管有大量Data Block剩余也无法存储文件，会浪费磁盘空间。\n\n*   数据布局低效：Ext2在Inode中使用多级指针来索引数据块。对于大文件，数据块的分配会尽量连续，这样会具有比较好的空间局部性。但是对于小文件，数据块可能零散分布在磁盘上的不同位置，并且会造成大量的磁盘碎片，不仅造成访问性能下降，还大量浪费了磁盘空间。数据块一般为1KB、2KB或4KB，对于小于4KB的小文件，Inode与数据的分开存储破坏了空间局部性，同时也造成了大量的随机I/O。\n\n对于海量小文件应用，常见的I/O流程复杂也是造成磁盘性能不佳的原因。对于小文件，磁盘的读写所占用的时间较少，而用于文件的open()操作占用了绝大部分系统时间，导致磁盘有效服务时间非常低，磁盘性能低下。针对于问题的根源，优化的思路大体上分为：\n\n1.  针对数据布局低效，采用小文件合并策略，将小文件合并为大文件。\n2.  针对元数据管理低效，优化元数据的存储和管理。针对这两种优化方式，业内也出现了许多优秀的开源软件。\n\n**小文件合并**\n\n小文件合并为大文件后，首先减少了大量元数据，提高了元数据的检索和查询效率，降低了文件读写的I/O操作延时。其次将可能连续访问的小文件一同合并存储，增加了文件之间的局部性，将原本小文件间的随机访问变为了顺序访问，大大提高了性能。同时，合并存储能够有效的减少小文件存储时所产生的磁盘碎片问题，提高了磁盘的利用率。最后，合并之后小文件的访问流程也有了很大的变化，由原来许多的open操作转变为了seek操作，定位到大文件具体的位置即可。如何寻址这个大文件中的小文件呢？其实就是利用一个旁路数据库来记录每个小文件在这个大文件中的偏移量和长度等信息。其实小文件合并的策略本质上就是通过分层的思想来存储元数据。中控节点存储一级元数据，也就是大文件与底层块的对应关系；数据节点存放二级元数据，也就是最终的用户文件在这些一级大块中的存储位置对应关系，经过两级寻址来读写数据。\n\n*   淘宝的TFS就采用了小文件合并存储的策略。TFS中默认Block大小为64M，每个块中会存储许多不同的小文件，但是这个块只占用一个Inode。假设一个Block为64M，数量级为1PB。那么NameServer上会有 1 _ 1024 _ 1024 * 1024 / 64 = 16.7M个Block。假设每个Block的元数据大小为0.1K，则占用内存不到2G。在TFS中，文件名中包含了Block ID和File ID，通过Block ID定位到具体的DataServer上，然后DataServer会根据本地记录的信息来得到File ID所在Block的偏移量，从而读取到正确的文件内容。TFS一次读过程如下图所示：\n\n![tfs_read](/assets/images/2017/05/19/about-desk-io/008.png)\n\n**元数据管理优化**\n\n一般来说元数据信息包括名称、文件大小、设备标识符、用户标识符、用户组标识符等等，在小文件系统中可以对元数据信息进行精简，仅保存足够的信息即可。元数据精简可以减少元数据通信延时，同时相同容量的Cache能存储更多的元数据，从而提高元数据使用效率。另外可以在文件名中就包含元数据信息，从而减少一个元数据的查询操作。最后针对特别小的一些文件，可以采取元数据和数据并存的策略，将数据直接存储在元数据之中，通过减少一次寻址操作从而大大提高性能。\n\n*   TFS中文件命名就隐含了位置信息等部分元数据，从而减少了一个元数据的查询操作。在Rerserfs中，对于小于1KB的小文件，Rerserfs可以将数据直接存储在Inode中。\n\n### **总结**\n\n本文从磁盘性能指标出发，探究了操作系统与磁盘的交互以及对磁盘读写的优化，最后列举了一些常用开源系统中基于磁盘I/O特性的设计特点。期望通过展现磁盘I/O的特性，为存储系统设计和解决一些系统性能问题提供一种新思路。 \n\n### **作者介绍**\n\n喻枭，2016年加入美团点评，就职于美团点评酒店旅游事业群境内度假研发组。专注Java后台开发，对并发编程和大数据有浓厚兴趣。\n\n**最后发个广告，美团点评酒旅事业群境内度假研发组长期招聘Java后台、架构方面的人才，有兴趣的同学可以发送简历到jinmengzhe#meituan.com。**\n\n### **参考**\n\n1.  IBM developerWorks，[AIX 下磁盘 I/O 性能分析](https://www.ibm.com/developerworks/cn/aix/library/1203_weixy_aixio/)，2012。\n2.  CSDN博客频道，[磁盘性能评价指标—IOPS和吞吐量](http://blog.csdn.net/hanchengxi/article/details/19089589)，2014。\n3.  IBM developerWorks，[read 系统调用剖析](https://www.ibm.com/developerworks/cn/linux/l-cn-read/)，2008。\n4.  IBM developerWorks，[从文件 I/O 看 Linux 的虚拟文件系统](https://www.ibm.com/developerworks/cn/linux/l-cn-vfs/)，2007。\n5.  CSDN博客频道，[Linux文件系统预读](http://blog.csdn.net/kai_ding/article/details/17322787)，2013。\n6.  Linux Kernel Exploration，[Linux通用块设备层](http://www.ilinuxkernel.com/files/Linux.Generic.Block.Layer.pdf)。\n7.  CSDN博客频道，[Linux块设备的IO调度算法和回写机制](http://blog.csdn.net/hustyangju/article/details/40507647)，2014。\n8.  Apache，[Kafka](http://kafka.apache.org/)。\n9.  Taobao，[Taobao File System](http://tfs.taobao.org/)。\n\n---\n\n* Author: 喻枭\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [磁盘I/O那些事](https://tech.meituan.com/about-desk-io.html)\n","tags":["IO"],"categories":["IO"]},{"title":"从Google白皮书看企业安全最佳实践","url":"%2F2017%2F2017-02-21-google-infrastructure-security-design-overview%2F","content":"\n前不久Google发布了一份安全方面的白皮书[_Google Infrastructure Security Design Overview_](https://cloud.google.com/security/security-design/)，直译的版本可以参考“网路冷眼”这版《[Google基础设施安全设计概述](http://mp.weixin.qq.com/s/ZeWIcLb414J3tlIB-TSbbw)》，直译+点评的版本可以参考“职业欠钱”的《[Google基础设施安全设计概述翻译和导读](https://security.tencent.com/index.php/blog/msg/114)》。\n\n此前Google在安全领域披露的信息一直很少，适逢其大力发展云计算业务，需要展示云安全方面的实力，才有了这份白皮书。它从系统的角度描述了自己安全体系的设计与实现，对广大互联网、云计算公司的安全小伙伴而言可谓一大福利。本文中，笔者将从一个企业安全建设者的角度，说说自己的感想，并做一些解读。\n\n### 几点感想\n\n1.  国内很多公司的安全团队都是游离在产品研发、基础架构和SRE团队之外的，HIDS、WAF、大数据的SOC，说到底这些东西安全团队自己就可以搞定，基本不需要其他部门的支援和介入，这和乙方安全公司提供的一套外科手术般的解决方案的思路是一脉相承的。而Google的安全体系给人的感觉是跟基础设施深度融合，完全内置于产品设计和研发过程之中，从顶层设计的视角看完全是两种流派：内置的安全机制vs外挂的防护体系。\n\n2.  没有业界安全大会上那些花俏的概念和名词，全都是正统的安全设计思路，以既有的简单的安全手段解决复杂的问题，有如教科书般的绅士风格。\n\n3.  工程化大于单点技术突破。尽管Google有Project Zero、有不少牛人，不过似乎没有特别强调单点技术，更多体现的是在一个海量的规模下解决安全问题的工程化能力。\n\n4.  在产品服务基础架构层面可以看到Google有一个清晰的顶层架构设计，例如全局的IAM和Borg服务。尽管可能这个看似完整的体系也是一路迭代而来，但至少从现有的积累看，从全局的层次抽象，全局资源鉴权，收敛统一用户和流量入口，收敛分散的认证&amp;鉴权点，在每一个对应的抽象层次上做纵深防御，全局的访问控制模型等等看上去更像是精心规划和设计出来的。\n\n5.  得益于Google自研的技术栈范围实在太广，因为一切皆自研，所以一切安全皆可DIY，对其他公司而言这反而是一个封闭的王国，因为不太可复制。\n\n6.  能否追的上这个安全体系，已经不取决于单点技术亦或是攻防技术是否ready，甚至不取决于安全团队的强弱，而是取决于公司所处的阶段和整体技术实力。\n\n### 整体安全体系图解\n\nGoogle原来的图有点类似于ISO27001，框架性很好，但也终归是一个对外的版本，信息披露上比较粗线条，对于更想在实践层面模仿的同学来说比较抽象，所以笔者以自己的理解重新归纳了两张图。第一张图展示了Google的整体IT环境，包括办公网络、生产网络以及交互通道的整体安全视图：\n\n![](/assets/images/2017/02/21/google-infrastructure-security-design-overview/1.jpg)\n\n假如一开始不好理解也没关系，先有个框架性认识。总体上可以抽象为办公网络和IDC都有纵深防御体系，研发环境属于办公网络之上的一个特殊子集（这里并没有披露内部IT的其它系统怎么建设的），办公网络和IDC生产环境之间有限的数据通道都做了风险控制，采用“2+2结构（2个纵深防体系+2个数据通道）”。\n\n第二张图再单独分解一下IDC的纵深防御体系：\n\n![](/assets/images/2017/02/21/google-infrastructure-security-design-overview/2.jpg)\n\n更具体的实现在后面的章节里展开，最后可以再回过头来看这张图。\n\n接下来，我们按照白皮书原文的顺序一一解读。\n\n#### CIO视角（宏观）\n\n关于CIO视角，我们要Get几个点：\n\n1.  Google有一个全球范围的基础架构，除了表达IDC基础设施的广泛程度外，也暗含了拥有全球范围的合规性。国内有少数比较大的互联网公司正在国际化的进程中，海外的合规性可能会成为一大挑战，国内公司中拥有成熟的全球合规性及全球化安全运营经验的大约只有华为和联想，其中华为又因为云计算和海外的手机云服务在这方面积累了其它国内公司暂时不可比拟的经验。Google有很多细微之处都提到了隐私保护，国内的因为法制不太成熟，没有太多的强制合规性以及公民隐私数据保护的压力，所以接下去对很多业务开始向海外扩展的公司，这些都会成为安全部门日历表上的待办事项。题外话：笔者在《互联网企业安全高级指南》一书中“隐私保护”一章写的其实是数据保护，意义有所偏差，打算第二版重写，有可能在美团点评技术博客先发表，敬请关注。\n\n2.  安全设计覆盖全生命周期，别提那些连SDL都没有实施的公司了，G厂显然是比SDL更高级的版本，强调“设计”二字。而国内拥有安全设计能力的从业者比较稀少，所以业界的话题和氛围上这方面都相对欠缺。\n\n3.  成本：500个专职工程师，其它方面也都是大手笔，但不确定在安全的投入上是不是“不计成本”的态度。\n\n#### 物理安全\n\nGoogle自有IDC的物理安全手段：生物识别、金属检测、摄像头、路障、激光入侵检测，同时Google要求使用的第三方IDC的物理安全措施对其完全可控。\n\n物理安全这件事哪怕在很多安全从业者心里也不过是ISO27001的一些章节和控制点，并非是很多人对于安全体系建设发自肺腑的真实需求，很多人对安全建设的认知往往是对抗线上入侵者。然而这也暗示了，不同的人、不同的厂商所建立的安全体系用来对抗的目标和范畴是完全不一样的。类似Google、Amazon、Apple这类公司他们的安全体系用来对抗的几大场景可以归纳为：黑客、第三方、雇员、IDC/云服务提供商、商业间谍、政府机构，对抗的强度依次上升。换言之，可以举例翻译为：即便我使用第三方的云服务，仍然可以保证自己的数据不被偷窥。对于成为国家基础设施的服务而言，实际上另一种不能明说的需求就是介于民用领域和军用领域之间的对抗需求。\n\n大量公司的安全体系主要是用来御外而不是防内的，所以供应链安全、数据泄露这等事情都很头疼。基于此推断，即便修完了所有的漏洞，做了入侵检测，也不足以对抗很多威胁，安全这件事做的好不好，更多的还是看你拿什么尺子来衡量。看完Google安全体系，笔者推测大多数人的反应是还是它做的已经远超出一般意义上的防黑客。\n\n#### 硬件安全\n\n对绝大多数公司而言都不会涉及这个章节，因为大多数公司也就顶多白牌服务器，而不是从主板到芯片全都自研。以前觉得华为、Apple这类公司用TC（可信计算）的概念还是用的比较多，但是感觉BAT都不玩这些，到后来分析iOS就一下明白了这个其实是由产品和服务所涉及的技术栈深度决定的，因为华为、Apple这类公司的产品线横跨硬件、OS和上层应用，而BAT等公司造轮子（自研）的范畴大多止于软件，所以很少涉及，甚至在这些公司早期的安全团队里大多数是由Web安全技能的人组成的业务驱动使然。\n\n从描述上看，Google硬件到底层软件栈的安全设计跟iOS基本是一致的，都是基于可信的思路，上一层（软件）验证下一层（硬件/固件）的完整性，并区分唯一标识。用唯一标识+信任链来鉴别是否合法的硬件来源（而不是IDC提供商在机房里偷梁换柱换了台服务器）。\n\n更上层的部分，例如引导程序、内核、启动镜像的完整性都是启动信任链的一般实现，有兴趣的同学可以参考一下iOS的设计与实现。硬件唯一标识会成为后面提到的全局访问控制体系的前提之一。\n\n这里还有一条很重要的信息：Google在自己的生产网络引入了NAC（网络接入控制）机制，这个安全手段本来是为OA办公网络的终端管理场景设计的，目的是区分不信任的终端不能接入（相对可信）的公司网络。这样做可以想象几个场景：假如机房管理员从回收垃圾那儿找到了废弃的服务器，数据也没被删除，即便进入了机房重新插网线也接入不了网络；甚至进一步推测，第三方供应商跑到IDC接上自己的MacBook想用Nmap扫描一把估计也不行。\n\n#### 服务部署\n\nGoogle在IDC内部服务治理上最大的不同是：不信任IDC内网（注明：尽管思路上可能有相似之处，但与G厂自家在办公网络的安全解决方案BeyondCorp不是一件事）。很多公司的IDC生产服务网络被设计为私有云模式（单租户），在安全上相对的信任IDC内网通信，通过2层/3层隔离或者类似IP白名单的方式来建立IDC内网的弱访问控制体系和信任模型。而Google则是天生设计成多租户（公有云）模式，把原本用于对终端用户（2C端）的认证鉴权机制完全用于IDC内网的服务间通讯，服务间通讯有完整的双向鉴权，是一个强访问控制体系。笔者推测这样做可能是有几方面的原因：\n\n*   同一个服务的不同实例可能被部署为跨物理机、跨机架甚至跨IDC，与其它的服务实例混合部署，原来相对集中的通过IP的访问控制模型已经不太适用于完全分布式的架构，过于分散的多点对多点的ACL规则想象一下就头疼，于是就出现一个情况：要么访问控制很粗很大条效果不明显，要么很细但是规则几乎没法写。\n\n*   第二个原因可能是由于server和服务实例规模数巨大引起的海量ACL条目难以维护的问题，干脆扔了，用完全的鉴权。\n\n*   如果用传统的访问控制手段，例如VXLAN隔离、交换机ACL、主机iptables规则会无法维持一个巨大的弹性内部网络，服务扩容时都会受到阻碍，监控、调试和诊断都会更难。之前有同学提出通过主机安全agent动态生成白名单的内网隔离思路，现在Google则在这个问题上给出了自己的解，这也揭开了我在《互联网企业安全高级指南》中没有写出来的部分:)。本质上这是由规模量变到质变引发的问题，如果你的IDC内网只有几台机器真没必要那么做。Google也强调了自己有做网络隔离和防止IP欺骗，但没有把这个当成主要手段。\n\n发布安全：Google的所有代码存储于一个集中的代码仓库，同时保留当前和过去的版本，每一个发布的二进制文件都能关联到构建时的源代码版本，这里暗示了Google有做白名单和完整性校验，其实Google和Amazon都有白名单，但这要求基础架构高度统一。发布时需要至少1人review同意（可以理解为在构建/发布系统中的workflow），任何对某个系统的更改需要系统的owner同意。统一的代码仓库，意味着发布的入口是唯一可控的，版本可唯一追溯，同时交叉的code review可以部分矫正一些内部的不良行为：例如开发人员安置后门，恶意彩蛋等。这实际上是Google研发文化的一部分，不一定是出于安全的原因，不过总而言之，安全是这个流程的受益者。以前有boss问过我离职程序员安置后门程序如何检测的问题，海量Web下不具有webshell &amp; sqli的特征，当初想到结对编程，交叉review，觉得有点理论化。Google给出了的解正好，防止钓鱼，同时防止内鬼，不只是简单的防外，而是防内外，覆盖整个价值链。\n\n同一个机器间的服务隔离，主要通过：Linux原生的用户空间隔离（Android的appid的原理），程序语言和kernel的沙箱，以及硬件虚拟化手段。对于涉及用户提交代码或文件的高风险服务例如Google App Engine &amp; Google Compute Engine会使用多层次隔离和纵深防御（如下图所示），另外对于集群管理和KMS等服务会使用专门的物理机。实际上一般情况下密钥管理会使用专有硬件HSM，至于集群管理服务使用专用机器推测一方面可能有一些完整性校验的安全强相关功能，另一方便可能跟集群管理服务本身的可用性要求及failover机制有关。\n\n![](/assets/images/2017/02/21/google-infrastructure-security-design-overview/3.jpg)\n\n业内一直有HIDS（Host-based Intrusion Detection System，主机入侵检测）的技术路线之争，大规模容器时代即将到来，技术路线的选择更是迫在眉睫。业界的一种看法是私有云以Linux用户态为主，关注运维需求，软件兼容性和server本身的可用性需求；另一种则是内核态，以纯安全视角的强掌控型实现为主。从Google的实现里似乎也可以得到启示：G厂走的是公有云，天然多租户模式，使用了内核态路线。当然对于效仿者而言，前提是：\n\n*   你有很强的保证kernel代码工程质量的能力。\n*   内部基础架构、组件高度统一，否则很可能会东施效颦。\n\nGoogle的内部服务访问控制可配置为特定的服务只允许指定的API或者指定的人才可以访问的模式，实现上通过Machine ID、Service ID、User ID放在一个全局命名空间来做访问控制的基础（注：2C端的访问控制是另外一套体系），支持Group对Group来做多对多的访问控制，同时提供了“two-party control”，即一个变更提交后需要由同group的另外一个管理员approve才能生效，这其实跟分布式事务中二阶段式提交是一个原理，为了保证最终一致性。Google在这些流程的问题上直接套用了工程理论。\n\nGoogle自身的工程师访问内部API需要通过这种认证鉴权模式，实际上暗含了另外一个课题：数据安全。这部分在业界比较受重视，但需求往往比较抽象，而在实现方式上更是没有统一的标准，Google的这种方式貌似歪打正着，把2C的鉴权模式用在生产网络和后台系统，实际上是对原来运维通道获取数据途径的更进一步收敛，保留强审计和日志，这样一并连数据安全也算解决了一部分，虽然不是全部。\n\nGoogle的内部服务提供全加密通讯的能力，例如HTTP封装成RPC，而RPC默认提供几种不同的加密强度：低价值数据只做完整性校验，高价值的用更强壮的加密等级，跨IDC传输流量自动加密。\n\n最后举了一个Gmail服务访问联系簿（contacts服务）例子来说明RPC调用的鉴权细粒度，如果ACL设置为允许Gmail访问联系簿这种细粒度是不够的，因为用户A可以越权访问用户B的联系簿，水平权限的这类问题扫描器不容易覆盖，干脆在架构设计上一并解决：RPC请求带用户的ticket走一个内部的SSO（单点认证鉴权）以验证是否可以访问对应的数据，这样就相当于内部的API调用在用户这个细粒度上做了一次全流量的鉴权，从架构上避免了水平权限类的问题。再次回到安全架构的顶层设计，Google的思路就是把所有分散的鉴权点集中起来，在一个高度抽象的层次上做好一件事，最大程度的隔离。\n\n#### 数据安全\n\nGoogle在数据安全（狭义的，指在IDC侧的部分）上实践的几点：\n\n*   Google是做静态数据全盘加密的。\n*   不直接写硬盘，而是通过BigTable、Spanner这种存储服务间接写持久化数据。\n*   数据加密与KMS关联，可以理解为用了对称加密，密钥中的一部分来自KMS。\n*   与用户ticket相关，可以推测为加密密钥链的顶层密钥每个用户唯一，且动态转换（rotate）。\n*   为了加解密性能采用硬件加速。\n*   数据销毁流程会使用两道独立的流程来验证（是否删除），不经过此流程的直接物理粉碎。\n*   Google说自己可以追踪每一块硬盘全生命周期的状态。\n\n上面的内容里除了文件加密那块会有一些技术复杂度，其他都是工程化的问题，想象一下随便去机房拔块硬盘偷数据应该是没戏了，但是对于绝大多数公司而言，能在IDC实现全盘加密而且很可能用的不是文件系统加密，这个是一个很大的工程，实现起来比较困难，所以Google能把这些方案都落地，说明领先了很多年。对于很多公司来说，全盘数据加密会导致IOPS大幅下降，依赖KMS服务可用性指标又会下降，数据丢失和恢复又成问题，所以能实施这些方案背后是整体技术的依赖。\n\n#### Internet通讯安全\n\n暴露在互联网通讯的安全部分总结一下就是几个点：\n\n*   有一个统一的接入层GFE（Google Front End）。\n*   接入层统一做TLS加密以及证书管理，避免业务各自为政。\n*   接入层解决了端口暴露外网的问题，虽然选择不信任IDC内网，但是内网仍然是比外网更安全的地方。\n*   接入层拥有规模优势，具备抗DDOS能力。\n*   骨干网传输、4层、7层流量负载均衡都有流量监测和上报流量行为数据的能力（可以理解为Google自己在这些环节实现了Anti-DDOS）。\n*   有一个中央流控服务，负责丢弃流量或限制阈值。\n*   接入层有一定的人机识别能力（根据设备、登录IP等做判断，大概是风控服务的基础组件）。\n*   因为OTP的2FA认证方式容易被钓鱼，所以现在转而用FIDO联盟的U2F的方式代替OTP。\n\n#### 运维安全\n\n1.  Google有一套完整的SDL机制来尽可能的保证交付的代码是安全的，这些手段包括：\n\n*   内部：集中代码管理，交叉review，安全的代码框架和Lib库、fuzzer、静态代码扫描、Web安全扫描器，有Web安全、密码学、操作系统安全等各领域的专家团负责安全设计review＆威胁建模，并且会持续的将这些安全经验沉淀为通用的安全库和工具等。\n*   外部：高额的漏洞奖励计划。\n*   开源软件：大多数公司对待开源软件的态度可能是跟随策略，即社区发布了补丁我跟着patching，而Google表现出的态度则是，将开源软件和自研软件同等对待，都实施SDL那套安全审计，在例如OpenSSL，KVM等软件上发现了不少CVE漏洞。\n\n2.  Google投入很多来保证自己的雇员设备不被黑：\n\n*   其中最重要的就是BeyondCorp项目，对办公网络进行改造、取消内网、整个OA系统云化，把原来基于物理位置的信任模型（公司办公网络的内网或者VPN接入到内网）改成根据雇员设备状态，用户生命周期内的行为动态的生成访问控制策略，访问控制的细粒度从VLAN/IP收敛为应用级别，例如到一个系统中的某些URL这样的权限。这种访问控制模型可以抑制被APT后横向渗透的受害范围，同时基于云化的方案可以为监控提供更多的数据来源。\n*   为了抵抗钓鱼攻击，雇员认证从OTP改成U2F。\n*   大量的终端管理行为：包括OS最新补丁、限制客户端软件安装、监控下载、浏览器扩展、访问的内容等。\n\n3.  降低内部风险：\n\n*   监控有基础设施访问权限的雇员（SRE、DBA……）的终端行为，持续评估并赋予工作所需要的最小权限。\n*   数据安全的场景再次出现：Google对生产环境debug数据脱敏，并且雇员对线上用户数据的访问会被底层hook的日志追踪，是否异常行为由安全团队监控，底层的hook在这里大约可以理解为劫持了一些终端和访问通道以及命令执行的信息，而数据脱敏则是一个很大的课题，尤其是海量数据。\n\n4.  入侵检测\n\n*   Google有成熟的基于各种设备、主机、网络、服务的日志监控，这个大约得益于Google自研的技术栈比较深，所以日志“打点”这块是不愁了，而对于很多其他公司而言还要自研一堆安全产品，可惜的是Google在这块几乎没怎么开源过。\n*   红蓝军对抗，基本上大公司的标配，有钱就可以玩的起来。\n\n#### Google云平台安全\n\nGCP（Google Cloud Platform）继承前述所有的安全能力。除此之外云平台特有的一些安全属性包括：\n\n*   给VM和VMM分配两个独立的服务ID，这样就可以区分哪些流量来自VM而哪些来自VMM。\n*   GCE（Google Compute Engine）持久化磁盘的静态数据会使用KMS产生的密钥自动加密。\n*   VM广域网之间的流量可自动加密。\n*   计划推VM内网的流量自动加密。\n*   KVM定制过，把一些控制和硬件模拟从内核转移到用户态进程中。\n*   对KVM做过模糊测试、静态扫描和人工审计，大部分KVM的漏洞都由Google发现。\n*   Google承诺不碰用户数据，但除了通篇提及的方式外好像也没特殊说明不碰用户数据的保证手段是什么。\n\n### 如何才能赶上Google\n\n尽管这有可能是一个伪命题，不过从积极的角度不妨来分析一下：\n\n首先这是一个公司规模强相关的命题，如果你的IT整体投入还比较小，或者IDC规模仍然不大的情况，上述安全体系方法论应该是不适用的，因为这是一个依靠大量自研，大型安全团队才能做起来的事情。在规模更小的情况下，很多场景会有TCO更低，更简单的解。但对于从业者来说显然还是大规模下的经验更有利于自身价值提升，所以后面还是要打个小广告。\n\n其次，跟公司所处的阶段强相关，如果公司处于相对早期，或者野蛮生长阶段，目标基本都是为了满足业务需求，风险偏好会更倾向于接受风险，同时公司所处的阶段会侧面反映出工程技术整体的成熟度，安全要做到Google那样是工程技术整体领先的结果，而不是安全单个职能突出的结果。\n\n第三方面跟文化和基因也有很大的关系，基因上看公司整体是由产品、运营还是技术驱动，由技术驱动或者有工程师文化的公司比较容易实现这一点，这点不展开想必读者也能理解。文化方面，长期有耐心的公司文化比经常拥抱变化的公司更容易实现，Google的安全建设体现的都是大工程，也许你会发现，把其中的技术点单拉出来很多都没有遥不可及，甚至在大一点的国内互联网公司单点技术都是ready的，但是要全面落地却要花上几年的时间，所以最大的差距不在于单点技术，而在于G厂已经all done并且很可能已经在新技术和新方向的路上。如同Apple在业务相对早期的时候就把iOS的整套安全体系都落地了，这才是最大的挑战。如果在一个需要短期见效，不行则拥抱变化的环境里，安全团队要推行这种工程化改造需要长期忍受绩效中下，对Leader和成员来说压力都会很大。\n\n第四点是工程技术团队的整体能力，因为技术团队整体很弱单安全团队特别强的存在本身就是一个伪命题。\n\n更多因素全都写在《互联网企业安全高级指南》这本书里了，不再赘述。\n\n---\n\n* Author: 赵彦\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [从Google白皮书看企业安全最佳实践](http://tech.meituan.com/GoogleSecurity_ayazero.html)","tags":["Security"],"categories":["Security"]},{"title":"深度学习在美团点评的应用","url":"%2F2017%2F2017-02-10-meituan-deeplearning-application%2F","content":"\n### 前言\n\n近年来，深度学习在语音、图像、自然语言处理等领域取得非常突出的成果，成了最引人注目的技术热点之一。美团点评这两年在深度学习方面也进行了一些探索，其中在自然语言处理领域，我们将深度学习技术应用于文本分析、语义匹配、搜索引擎的排序模型等；在计算机视觉领域，我们将其应用于文字识别、目标检测、图像分类、图像质量排序等。下面我们就以语义匹配、图像质量排序及文字识别这三个应用场景为例，来详细介绍美团点评在深度学习技术及应用方面的经验和方法论。\n\n### 基于深度学习的语义匹配\n\n语义匹配技术，在信息检索、搜索引擎中有着重要的地位，在结果召回、精准排序等环节发挥着重要作用。\n\n传统意义上讲的语义匹配技术，更加注重文字层面的语义吻合程度，我们暂且称之为语言层的语义匹配；而在美团点评这样典型的O2O应用场景下，我们的结果呈现除了和用户表达的语言层语义强相关之外，还和用户意图、用户状态强相关。\n\n用户意图即用户是来干什么的？比如用户在百度上搜索“关内关外”，他的意图可能是想知道关内和关外代表的地理区域范围，“关内”和“关外”被作为两个词进行检索，而在美团上搜索“关内关外”，用户想找的就是“关内关外”这家饭店，“关内关外”被作为一个词来对待。\n\n再说用户状态，一个在北京和另一个在武汉的用户，在百度或淘宝上搜索任何一个词条，可能得到的结果不会差太多；但是在美团这样与地理位置强相关的场景下就会完全不一样。比如我在武汉搜“黄鹤楼”，用户找的可能是景点门票，而在北京搜索“黄鹤楼”，用户找的很可能是一家饭店。\n\n如何结合语言层信息和用户意图、状态来做语义匹配呢？\n\n我们的思路是在短文本外引入部分O2O业务场景特征，融合到所设计的深度学习语义匹配框架中，通过点击/下单数据来指引语义匹配模型的优化方向，最终把训练出的点击相关性模型应用到搜索相关业务中。下图是针对美团点评场景设计的点击相似度框架ClickNet，是比较轻量级的模型，兼顾了效果和性能两方面，能很好地推广到线上应用。   \n\n![图1 clicknet框架](/assets/images/2017/02/10/meituan-deeplearning-application/clicknet_framework.png)\n\n#### 表示层\n\n对Query和商家名分别用语义和业务特征表示，其中语义特征是核心，通过DNN/CNN/RNN/LSTM/GRU方法得到短文本的整体向量表示，另外会引入业务相关特征，比如用户或商家的相关信息，比如用户和商家距离、商家评价等，最终结合起来往上传。\n\n#### 学习层\n\n通过多层全连接和非线性变化后，预测匹配得分，根据得分和Label来调整网络以学习出Query和商家名的点击匹配关系。\n\n在该算法框架上要训练效果很好的语义模型，还需要根据场景做模型调优：首先，我们从训练语料做很多优化，比如考虑样本不均衡、样本重要度、位置Bias等方面问题。其次，在模型参数调优时，考虑不同的优化算法、网络大小层次、超参数的调整等问题。经过模型训练优化，我们的语义匹配模型已经在美团点评平台搜索、广告、酒店、旅游等召回和排序系统中上线，有效提升了访购率/收入/点击率等指标。\n\n#### 小结\n\n深度学习应用在语义匹配上，需要针对业务场景设计合适的算法框架，此外，深度学习算法虽然减少了特征工程工作，但模型调优上难度会增加，因此可以从框架设计、业务语料处理、模型参数调优三方面综合起来考虑，实现一个效果和性能兼优的模型。\n\n### 基于深度学习的图像质量排序\n\n国内外各大互联网公司（比如腾讯、阿里和Yelp）的线上广告业务都在关注展示什么样的图像能吸引更多点击。在美团点评，商家的首图是由商家或运营人工指定的，如何选择首图才能更好地吸引用户呢？图像质量排序算法目标就是做到自动选择更优质的首图，以吸引用户点击。\n\n传统的图像质量排序方法主要从美学角度进行质量评价，通过颜色统计、主体分布、构图等来分析图片的美感。但在实际业务场景中，用户对图片质量优劣的判断主观性很强，难以形成统一的评价标准。比如:  \n\n1.  有的用户对清晰度或分辨率更敏感；\n2.  有的用户对色彩或构图更敏感；\n3.  有的用户偏爱有视觉冲击力的内容而非平淡无奇的环境图。\n\n因此我们使用深度学习方法，去挖掘图片的哪些属性会影响用户的判断，以及如何有效融合这些属性对图片进行评价。\n\n我们使用AlexNet去提取图片的高层语义描述，学习美感、可记忆度、吸引度、品类等High Level特征，并补充人工设计的Low Level特征（比如色彩、锐度、对比度、角点）。在获得这些特征后，训练一个浅层神经网络对图像整体打分。该框架（如图2所示）的一个特点是联合了深度学习特征与传统特征，既引入高层语义又保留了低层通用描述，既包括全局特征又有局部特征。 \n\n![图2 图像质量排序技术框架](/assets/images/2017/02/10/meituan-deeplearning-application/image-quality-sorting-technology-framework.png)\n\n对于每个维度图片属性的学习，都需要大量的标签数据来支撑，但完全通过人工标记代价极大，因此我们借鉴了美团点评的图片来源和POI标签体系。关于吸引度属性的学习，我们选取了美团Deal相册中点击率高的图片（多数是摄影师通过单反相机拍摄）作为正例，而选取UGC相册中点击率低的图片（多数是低端手机拍摄）作为负例。关于品类属性的学习，我们将美团一级品类和常见二级品类作为图片标签。基于上述质量排序模型，我们为广告POI挑选最合适的优质首图进行展示，起到吸引用户点击，提高业务指标的目的。图3给出了基于质量排序的首图优选结果。\n\n![图3 基于图像质量排序的首图优选](/assets/images/2017/02/10/meituan-deeplearning-application/optimization-based-image-quality-ranking.png)\n\n### 基于深度学习的OCR\n\n为了提升用户体验，O2O产品对OCR技术的需求已渗透到上单、支付、配送和用户评价等环节。OCR在美团点评业务中主要起着两方面作用。一方面是辅助录入，比如在移动支付环节通过对银行卡卡号的拍照识别，以实现自动绑卡，又如辅助BD录入菜单中菜品信息。另一方面是审核校验，比如在商家资质审核环节对商家上传的身份证、营业执照和餐饮许可证等证件照片进行信息提取和核验以确保该商家的合法性，比如机器过滤商家上单和用户评价环节产生的包含违禁词的图片。相比于传统OCR场景（印刷体、扫描文档），美团的OCR场景主要是针对手机拍摄的照片进行文字信息提取和识别，考虑到线下用户的多样性，因此主要面临以下挑战：\n\n> *   成像复杂：噪声、模糊、光线变化、形变；\n> *   文字复杂：字体、字号、色彩、磨损、笔画宽度不固定、方向任意；\n> *   背景复杂：版面缺失，背景干扰。\n\n对于上述挑战，传统的OCR解决方案存在着以下不足：\n\n1.  通过版面分析（二值化，连通域分析）来生成文本行，要求版面结构有较强的规则性且前背景可分性强（例如文档图像、车牌），无法处理前背景复杂的随意文字（例如场景文字、菜单、广告文字等）。\n2.  通过人工设计边缘方向特征（例如HOG）来训练字符识别模型，此类单一的特征在字体变化，模糊或背景干扰时泛化能力迅速下降。\n3.  过度依赖字符切分的结果，在字符扭曲、粘连、噪声干扰的情况下，切分的错误传播尤其突出。\n\n针对传统OCR解决方案的不足，我们尝试基于深度学习的OCR。\n\n#### 1. 基于Faster R-CNN和FCN的文字定位\n\n首先，我们根据是否有先验信息将版面划分为受控场景（例如身份证、营业执照、银行卡）和非受控场景（例如菜单、门头图）。\n\n对于受控场景，我们将文字定位转换为对特定关键字目标的检测问题。主要利用Faster R-CNN进行检测，如下图所示。为了保证回归框的定位精度同时提升运算速度，我们对原有框架和训练方式进行了微调:  \n\n> *   考虑到关键字目标的类内变化有限，我们裁剪了ZF模型的网络结构，将5层卷积减少到3层。*   训练过程中提高正样本的重叠率阈值，并根据业务需求来适配RPN层Anchor的宽高比。\n\n![图4 基于Faster R-CNN的受控场景文字定位](/assets/images/2017/02/10/meituan-deeplearning-application/faster_rcnn.png)  \n\n对于非受控场景，由于文字方向和笔画宽度任意变化，目标检测中回归框的定位粒度不够，我们利用语义分割中常用的全卷积网络（FCN）来进行像素级别的文字/背景标注，如下图所示。为了同时保证定位的精度和语义的清晰，我们不仅在最后一层进行反卷积，而且融合了深层Layer和浅层Layer的反卷积结果  \n\n![图5 基于FCN的非受控场景文字定位](/assets/images/2017/02/10/meituan-deeplearning-application/norestrict_fcnn.png)\n\n#### 2. 基于序列学习框架的文字识别\n\n为了有效控制字符切分和识别后处理的错误传播效应，实现端到端文字识别的可训练性，我们采用如下图所示的序列学习框架。框架整体分为三层：卷积层，递归层和翻译层。其中卷积层提特征，递归层既学习特征序列中字符特征的先后关系，又学习字符的先后关系，翻译层实现对时间序列分类结果的解码。  \n\n![图6 基于序列学习的端到端识别框架](/assets/images/2017/02/10/meituan-deeplearning-application/e2e_framework.png)  \n\n由于序列学习框架对训练样本的数量和分布要求较高，我们采用了真实样本+合成样本的方式。真实样本以美团点评业务来源（例如菜单、身份证、营业执照）为主，合成样本则考虑了字体、形变、模糊、噪声、背景等因素。基于上述序列学习框架和训练数据，在多种场景的文字识别上都有较大幅度的性能提升，如下图所示。  \n\n![图7 深度学习OCR和传统OCR的性能比较](/assets/images/2017/02/10/meituan-deeplearning-application/ocr_compare.png)\n\n### 总结\n\n本文主要以深度学习在自然语言处理、图像处理两个领域的应用为例进行了介绍，但深度学习在美团点评可能发挥的价值远远不限于此。未来，我们将继续在各个场景深入挖掘，比如在智能交互、配送调度、智能运营等，在美团点评产品的智能化道路上贡献一份力量。\n\n### 作者简介\n\n文竹，美团点评美团平台与酒旅事业群智能技术中心负责人，2010年从清华硕士毕业后，加入百度，先后从事机器翻译的研发及多个技术团队的管理工作。2015年4月加入美团，负责智能技术中心的管理工作，致力于推动自然语言处理、图像处理、机器学习、用户画像等技术在公司业务上的落地。\n\n李彪，美团点评美团平台及酒旅事业群NLP技术负责人，曾就职搜狗、百度。2015年加入美团点评，致力于NLP技术积累和业务的落地，负责的工作包括深度学习平台和模型，文本分析在搜索、广告、推荐等业务上应用，智能客服和交互。\n\n晓明，美团点评平台及酒旅事业群图像技术负责人，曾就职于三星研究院。2015年加入美团点评，主要致力于图像识别技术的积累和业务落地，作为技术负责人主导了图像机审、首图优选和OCR等项目的上线，推进了美团产品的智能化体验和人力成本的节省。\n\n---\n\n* Author: 文竹 李彪 晓明\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [深度学习在美团点评的应用](http://tech.meituan.com/deeplearning_application.html)","tags":["Deep-Learning"],"categories":["Deep-Learning"]},{"title":"MTDDL——美团点评分布式数据访问层中间件","url":"%2F2016%2F2016-12-19-meituan-distributed-data-layer%2F","content":"\n# 背景\n\n2016年Q3季度初，在美团外卖上单2.0项目上线后，商家和商品数量急速增长，预估商品库的容量和写峰值QPS会很快遇到巨大压力。随之而来也会影响线上服务的查询性能、DB（数据库，以下统一称DB）主从延迟、表变更困难等一系列问题。\n\n要解决上面所说的问题，通常有两种方案。第一种方案是直接对现有的商品库进行垂直拆分，可以缓解目前写峰值QPS过大、DB主从延迟的问题。第二种方案是对现有的商品库大表进行分库分表，从根本上解决现有问题。方案一实施起来周期较短，但只能解决一时之痛，由此可见，分库分表是必然的。\n\n在确定分库分表的方案之后，我们调研了外卖订单、结算以及主站等业务的分库分表实现方案，也调研了业界很多分库分表中间件。在综合考虑性能、稳定性及实现成本的前提下，最终决定自主研发客户端分库分表中间件MTDDL来支撑外卖商品分库分表项目，这也就是MTDDL的由来。\n\n当然，在MTDDL的设计研发过程中，我们充分考虑了MTDDL的通用性、可扩展性、功能的全面性和接入的便利性。到目前为止一共开发了四期，实现了MySQL动态数据源、读写分离、分布式唯一主键生成器、分库分表、连接池及SQL监控、动态化配置等一系列功能，支持分库分表算法、分布式唯一主键生成算法的高可扩展性，而且支持全注解的方式接入，业务方不需要引入任何配置文件。\n\n下面就部分业界方案及MTDDL的设计目标详细展开下，然后从源码的角度来剖析下MTDDL的整个逻辑架构和具体实现。\n\n# 业界调研\n\n\n| 业界组件 | 简介 | 实现方案 | 功能特性 | 优点 | 缺点 |\n| ------- | --- | ------- | ------- | --- | ---- |\n| Atlas | Qihoo 360开发维护的一个基于MySQL协议的数据中间层项目。它实现了MySQL的客户端与服务端协议，作为服务端与应用程序通信，同时作为客户端与MySQL通信 | proxy-based | 实现读写分离、单库分表 | 功能简单，性能跟稳定性较好 | 不支持分库分表 |\n| MTAtlas | 原美团DBA团队在开源Atlas基础上做的一系列升级改造 | proxy-based | 在读写分离、单库分表的基础上，完成了分库分表的功能开发 | 在Atlas基础上支持了分库分表 | 当时还处于测试阶段，暂不推荐业务方使用 |\n| TDDL | 淘宝根据自己的业务特点开发了TDDL框架，主要解决了分库分表对应用的透明化以及异构数据库之间的数据复制，它是一个基于集中式配置的JDBC datasource实现 | client-based | 实现动态数据源、读写分离、分库分表 | 功能齐全 | 分库分表功能还未开源，当前公布文档较少，并且需要依赖diamond（淘宝内部使用的一个管理持久配置的系统） |\n| Zebra | Zebra是原点评内部使用数据源、DAO以及监控等和数据库打交道的中间件集 | client-based | 实现动态数据源、读写分离、分库分表、CAT监控 | 功能齐全且有监控 | 接入较为复杂，当时只支持c3p0、Druid、Tomcat JDBC等连接池，且分库分表算法只支持Groovy表达式不易扩展 |\n\n# 设计目标\n\nMTDDL（Meituan Distributed Data Layer），美团点评分布式数据访问层中间件，旨在为全公司提供一个通用数据访问层服务，支持MySQL动态数据源、读写分离、分布式唯一主键生成器、分库分表、动态化配置等功能，并且支持从客户端角度对数据源的各方面（比如连接池、SQL等）进行监控，后续考虑支持NoSQL、Cache等多种数据源。\n\n# 功能特性\n\n*   动态数据源\n*   读写分离\n*   分布式唯一主键生成器\n*   分库分表\n*   连接池及SQL监控\n*   动态化配置\n\n# 逻辑架构\n\n下图是一次完整的DAO层insert方法调用时序图，简单阐述了MTDDL的整个逻辑架构。其中包含了分布式唯一主键的获取、动态数据源的路由以及SQL埋点监控等过程：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/001.png)\n\n# 具体实现\n\n## 动态数据源及读写分离\n\n在Spring JDBC AbstractRoutingDataSource的基础上扩展出MultipleDataSource动态数据源类，通过动态数据源注解及AOP实现。\n\n### 动态数据源\n\nMultipleDataSource动态数据源类，继承于Spring JDBC AbstractRoutingDataSource抽象类，实现了determineCurrentLookupKey方法，通过setDataSourceKey方法来动态调整dataSourceKey，进而达到动态调整数据源的功能。其类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/002.png)\n\n### 动态数据源AOP\n\nShardMultipleDataSourceAspect动态数据源切面类，针对DAO方法进行功能增强，通过扫描DataSource动态数据源注解来获取相应的dataSourceKey，从而指定具体的数据源。具体流程图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/003.png)\n\n### 配置和使用方式举例\n\n```xml\n    <!-- 参考配置 -->\n    <bean id=\"multipleDataSource\" class=\"com.sankuai.meituan.waimai.datasource.multi.MultipleDataSource\">\n        /** 数据源配置 */\n        <property name=\"targetDataSources\">\n            <map key-type=\"java.lang.String\"> \n                /** 写数据源 */\n                <entry key=\"dbProductWrite\" value-ref=\"dbProductWrite\"/>\n                /** 读数据源 */\n                <entry key=\"dbProductRead\" value-ref=\"dbProductRead\"/>\n            </map>\n        </property>  \n    </bean>\n```\n\n```java\n    /**\n     * DAO使用动态数据源注解\n     */\n    public interface WmProductSkuDao {\n\n        /** 增删改走写数据源 */\n        @DataSource(\"dbProductWrite&quot\")\n        public void insert(WmProductSku sku);\n\n        /** 查询走读数据源 */\n        @DataSource(\"dbProductRead\")\n        public void getById(long sku_id);\n    }\n```\n\n## 分布式唯一主键生成器\n\n众所周知，分库分表首先要解决的就是分布式唯一主键的问题，业界也有很多相关方案：\n\n\n| 序号 | 实现方案 | 优点 | 缺点 |\n| --- | -------- | --- | --- |\n| 1 | UUID | 本地生成，不需要RPC，低延时；扩展性好，基本没有性能上限 | 无法保证趋势递增；UUID过长128位，不易存储，往往用字符串表示 |\n| 2 | Snowflake或MongoDB ObjectId | 分布式生成，无单点；趋势递增，生成效率快 | 没有全局时钟的情况下，只能保证趋势递增；当通过NTP进行时钟同步时可能会出现重复ID；数据间隙较大 |\n| 3 | proxy服务+数据库分段获取ID | 分布式生成，段用完后需要去DB获取，同server有序 | 可能产生数据空洞，即有些ID没有分配就被跳过了，主要原因是在服务重启的时候发生；无法保证有序，需要未来解决，可能会通过其他接口方案实现 |\n\n综上，方案3的缺点可以通过一些手段避免，但其他方案的缺点不好处理，所以选择第3种方案。目前该方案已由美团点评技术工程部实现——分布式ID生成系统Leaf，MTDDL集成了此功能。\n\n### 分布式ID生成系统Leaf\n\n美团点评分布式ID生成系统Leaf，其实是一种基于DB的Ticket服务，通过一张通用的Ticket表来实现分布式ID的持久化，执行update更新语句来获取一批Ticket，这些获取到的Ticket会在内存中进行分配，分配完之后再从DB获取下一批Ticket。整体架构图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/004.png)\n\n每个业务tag对应一条DB记录，DB MaxID字段记录当前该Tag已分配出去的最大ID值。\n\nIDGenerator服务启动之初向DB申请一个号段，传入号段长度如 genStep = 10000，DB事务置 MaxID = MaxID + genStep，DB设置成功代表号段分配成功。每次IDGenerator号段分配都通过原子加的方式，待分配完毕后重新申请新号段。\n\n### 唯一主键生成算法扩展\n\nMTDDL不仅集成了Leaf算法，还支持唯一主键算法的扩展，通过新增唯一主键生成策略类实现IDGenStrategy接口即可。IDGenStrategy接口包含两个方法：getIDGenType用来指定唯一主键生成策略，getId用来实现具体的唯一主键生成算法。其类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/005.png)\n\n## 分库分表\n\n在动态数据源AOP的基础上扩展出分库分表AOP，通过分库分表ShardHandle类实现分库分表数据源路由及分表计算。ShardHandle关联了分库分表上下文ShardContext类，而ShardContext封装了所有的分库分表算法。其类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/006.png)\n\n分库分表流程图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/007.png)\n\n### 分库分表取模算法\n\n分库分表目前默认使用的是取模算法，分表算法为 (#shard_key % (group_shard_num * table_shard_num))，分库算法为 (#shard_key % (group_shard_num * table_shard_num)) / table_shard_num，其中group_shard_num为分库个数，table_shard_num为每个库的分表个数。\n\n例如把一张大表分成100张小表然后散到2个库，则0-49落在第一个库、50-99落在第二个库。核心实现如下：\n\n```java\npublic class ModStrategyHandle implements ShardStrategy {\n\n        @Override\n        public String getShardType() {\n            return \"mod\";\n        }\n\n        @Override\n        public DataTableName handle(String tableName, String dataSourceKey, int tableShardNum, \n            int dbShardNum, Object shardValue) {\n\n            /** 计算散到表的值 */\n            long shard_value = Long.valueOf(shardValue.toString());\n            long tablePosition = shard_value % tableShardNum;\n            long dbPosition = tablePosition / (tableShardNum / dbShardNum);\n            String finalTableName = new StringBuilder().append(tableName).append(\"_\").append(tablePosition).toString();\n            String finalDataSourceKey = new StringBuilder().append(dataSourceKey).append(dbPosition).toString();\n\n            return new DataTableName(finalTableName, finalDataSourceKey);\n        }\n    }\n```\n\n### 分库分表算法扩展\n\nMTDDL不仅支持分库分表取模算法，还支持分库分表算法的扩展，通过新增分库分表策略类实现ShardStrategy接口即可。ShardStrategy接口包含两个方法：getShardType用来指定分库分表策略，handle用来实现具体的数据源及分表计算逻辑。其类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/008.png)\n\n### 全注解方式接入\n\n为了尽可能地方便业务方接入，MTDDL采用全注解方式使用分库分表功能，通过ShardInfo、ShardOn、IDGen三个注解实现。\n\nShardInfo注解用来指定具体的分库分表配置：包括分表名前缀tableName、分表数量tableShardNum、分库数量dbShardNum、分库分表策略shardType、唯一键生成策略idGenType、唯一键业务方标识idGenKey；ShardOn注解用来指定分库分表字段；IDGen注解用来指定唯一键字段。具体类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/009.png)\n\n### 配置和使用方式举例\n\n```java\n    // 动态数据源\n    @DataSource(\"dbProductSku\")\n\n    // tableName：分表名前缀，tableShardNum：分表数量，dbShardNum：分库数量，shardType：分库分表策略，idGenType：唯一键生成策略，idGenKey：唯一键业务方标识\n    @ShardInfo(tableName=\"wm_food\", tableShardNum=100, dbShardNum=1, shardType=\"mod\", idGenType=IDGenType.LEAF, idGenKey=LeafKey.SKU)  \n\n    @Component\n    public interface WmProductSkuShardDao {\n\n        // @ShardOn(\"wm_poi_id\") 将该注解修饰的对象的wm_poi_id字段作为shardValue\n        // @IDGen(\"id\")  指定要设置唯一键的字段\n        public void insert(@ShardOn(\"wm_poi_id\") @IDGen(\"id\") WmProductSku sku);\n\n        // @ShardOn 将该注解修饰的参数作为shardValue\n        public List<WmProductSku> getSkusByWmPoiId(@ShardOn long wm_poi_id);\n    }\n```\n\n## 连接池及SQL监控\n\nDB连接池使用不合理容易引发很多问题，如连接池最大连接数设置过小导致线程获取不到连接、获取连接等待时间设置过大导致很多线程挂起、空闲连接回收器运行周期过长导致空闲连接回收不及时等等，如果缺乏有效准确的监控，会造成无法快速定位问题以及追溯历史。\n\n再者，如果缺乏SQL执行情况相关监控，会很难及时发现DB慢查询等潜在风险，而慢查询往往就是DB服务端性能恶化乃至宕机的根源（关于慢查询，推荐阅读[《MySQL索引原理及慢查询优化》](http://tech.meituan.com/mysql-index.html)一文）。MTDDL从1.0.2版本开始正式引入连接池及SQL监控等相关功能。\n\n### 连接池监控\n\n#### 实现方案\n\n结合Spring完美适配c3p0、dbcp1、dbcp2、mtthrift等多种方案，自动发现新加入到Spring容器中的数据源进行监控，通过美团点评统一监控组件JMonitor上报监控数据。整体架构图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/010.png)\n\n#### 连接数量监控\n\n监控连接池active、idle、total连接数量，Counter格式：（连接池类型.数据源.active/idle/total_connection），效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/011.png)\n\n#### 获取连接时间监控\n\n监控获取空闲连接时间，Counter格式：（ds.getConnection.数据源.time），效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/012.png)\n\n### SQL监控\n\n#### 实现方案\n\n采用Spring AOP技术对所有DAO方法进行功能增强处理，通过美团点评分布式会话跟踪组件MTrace进行SQL调用数据埋点及上报，进而实现从客户端角度对SQL执行耗时、QPS、调用量、超时率、失败率等指标进行监控。整体架构图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/013.png)\n\n#### 实现效果\n\n登录美团点评的服务治理平台OCTO选择服务查看去向分析，效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/014.png)\n\n## 动态化配置\n\n为了满足业务方一些动态化需求，如解决线上DB紧急事故需动态调整数据源或者分库分表相关配置，要求无需重启在线修改立即生效，MTDDL从1.0.3版本开始正式引入动态化配置相关功能。\n\n### 实现方案\n\n在Spring容器启动的时候自动注册数据源及分库分表相关配置到美团点评的统一配置中心MCC，在MCC配置管理页面可以进行动态调整，MCC客户端在感知到变更事件后会刷新本地配置，如果是数据源配置变更会根据新的配置构造出一个新数据源来替换老数据源，最后再将老的数据源优雅关闭掉。具体流程图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/015.png)\n\n### 动态化数据源\n\n目前支持dbcp、dbcp2、c3p0等数据源，效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/016.png)\n\n### 分库分表动态化\n\n支持动态化配置分库分表数量、分库分表策略、唯一键生成策略、唯一键业务方标识等，效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/017.png)\n\n# 版本迭代\n\nMTDDL到目前为止总共开发了四期，后续考虑逐步开源，具体版本迭代如下：\n\n| 项目名 | 功能 | 开始时间 | 结束时间 | 正式版本 | 快照版本 | 版本备注 |\n| ------ | ---- | -------- | -------- | -------- | -------- | -------- |\n| MTDDL一期 | 动态数据源；读写分离；分布式唯一主键生成器；分库分表 | 2016.05.30 | 2016.06.16 | 0.0.1 | 0.0.1-SNAPSHOT | MTDDL第一版 |\n| MTDDL二期 | 分布式唯一主键生成算法可扩展；支持零配置接入MTDDL；优化shardkey配置方式 | 2016.08.23 | 2016.09.05 | 1.0.1 | 1.0.1-SNAPSHOT | MTDDL接入优化 |\n| MTDDL三期 | 连接池及SQL监控；缓存优化 | 2016.09.06 | 2016.09.20 | 1.0.2 | 1.0.2-SNAPSHOT | MTDDL监控完善 |\n| MTDDL四期 | 唯一主键生成注解化；动态化配置 | 2016.10.11 | 2016.11.08 | 1.0.3 | 1.0.3-SNAPSHOT | MTDDL配置动态化 |\n\n---\n\n* Author: 刘军\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [MTDDL——美团点评分布式数据访问层中间件](http://tech.meituan.com/mtddl.html)","tags":["Data-Access"],"categories":["Distributed"]},{"title":"HDFS NameNode内存详解","url":"%2F2016%2F2016-12-09-namenode-memory-detail%2F","content":"\n## 前言\n\n《[HDFS NameNode内存全景](http://tech.meituan.com/namenode.html)》中，我们从NameNode内部数据结构的视角，对它的内存全景及几个关键数据结构进行了简单解读，并结合实际场景介绍了NameNode可能遇到的问题，还有业界进行横向扩展方面的多种可借鉴解决方案。\n\n事实上，对NameNode实施横向扩展前，会面临常驻内存随数据规模持续增长的情况，为此需要经历不断调整NameNode内存的堆空间大小的过程，期间会遇到几个问题：\n\n*   当前内存空间预期能够支撑多长时间。\n*   何时调整堆空间以应对数据规模增长。\n*   增加多大堆空间。\n\n另一方面NameNode堆空间又不能无止境增加，到达阈值后（与机型、JVM版本、GC策略等相关）同样会存在潜在问题：\n\n*   重启时间变长。\n*   潜在的FGC风险。\n\n由此可见，对NameNode内存使用情况的细粒度掌控，可以为优化内存使用或调整内存大小提供更好的决策支持。\n\n本文在前篇《[HDFS NameNode内存全景](http://tech.meituan.com/namenode.html)》文章的基础上，针对前面的几个问题，进一步对NameNode核心数据结构的内存使用情况进行详细定量分析，并给出可供参考的内存预估模型。根据分析结果可有针对的优化集群存储资源使用模式，同时利用内存预估模型，可以提前对内存资源进行合理规划，为HDFS的发展提供数据参考依据。  \n\n## 内存分析\n\n### NetworkTopology\n\nNameNode通过NetworkTopology维护整个集群的树状拓扑结构，当集群启动过程中，通过机架感知（通常都是外部脚本计算）逐渐建立起整个集群的机架拓扑结构，一般在NameNode的生命周期内不会发生大变化。拓扑结构的叶子节点DatanodeDescriptor是标识DataNode的关键结构，该类继承关系如图1所示。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/datanodeextend.png)\n\n图1 DatanodeDescriptor继承关系\n\n在64位JVM中，DatanodeDescriptor内存使用情况如图2所示（除特殊说明外，后续对其它数据结构的内存使用情况分析均基于64位JVM）。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/datanodedescriptor.png)\n\n图2 DatanodeDescriptor内存使用详解\n\n由于DataNode节点一般会挂载多块不同类型存储单元，如HDD、SSD等，图2中storageMap描述的正是存储介质DatanodeStorageInfo集合，其详细数据结构如图3所示。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/datanodestorageinfo.png)\n\n图3 DatanodeStorageInfo内存使用详解\n\n除此之外，DatanodeDescriptor还包括一部分动态内存对象，如replicateBlocks、recoverBlocks和invalidateBlocks等与数据块动态调整相关的数据结构，pendingCached、cached和pendingUncached等与集中式缓存相关的数据结构。由于这些数据均属动态的形式临时存在，随时会发生变化，所以这里没有做进一步详细统计（结果存在少许误差）。\n\n根据前面的分析，假设集群中包括2000个DataNode节点，NameNode维护这部分信息需要占用的内存总量：\n\n（64 + 114 + 56 + 109 &lowast; 16）&lowast; 2000 = ~4MB\n\n在树状机架拓扑结构中，除了叶子节点DatanodeDescriptor外，还包括内部节点InnerNode描述集群拓扑结构中机架信息。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/innernode.png)\n\n图4 NetworkTopology拓扑结构内部节点内存使用详解\n\n对于这部分描述机架信息等节点信息，假设集群包括80个机架和2000个DataNode节点，NameNode维护拓扑结构中内部节点信息需要占用的内存总量：\n\n（44 + 48) &lowast; 80 + 8 &lowast; 2000 = ~25KB\n\n从上面的分析可以看到，为维护集群的拓扑结构NetworkTopology，当集群规模为2000时，需要的内存空间不超过5MB，按照接近线性增长趋势，即使集群规模接近10000，这部分内存空间~25MB，相比整个NameNode JVM的内存开销微乎其微。\n\n### NameSpace\n\n与传统单机文件系统相似，HDFS对文件系统的目录结构也是按照树状结构维护，NameSpace保存的正是整个目录树及目录树上每个目录/文件节点的属性，包括：名称（name），编号（id），所属用户（user），所属组（group），权限（permission），修改时间（mtime），访问时间（atime），子目录/文件（children）等信息。  \n\n下图5为Namespace中INode的类图结构，从类图可以看出，文件INodeFile和目录INodeDirectory的继承关系。其中目录在内存中由INodeDirectory对象来表示，并用List<INode> children成员列表来描述该目录下的子目录或文件；文件在内存中则由INodeFile来表示，并用BlockInfo[] blocks数组表示该文件由哪些Blocks组成。其它属性由继承关系的各个相应子类成员变量标识。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/inodeextend.png)\n\n图5 文件和目录继承关系\n\n目录和文件结构在继承关系中各属性的内存占用情况如图6所示。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/inodeinfo.png)\n\n图6 目录和文件内存使用详解\n\n除图中提到的属性信息外，一些附加如ACL等非通用属性，没有在统计范围内。在默认场景下，INodeFile和INodeDirectory.withQuotaFeature是相对通用和广泛使用到的两个结构。\n\n根据前面的分析，假设HDFS目录和文件数分别为1亿，Block总量在1亿情况下，整个Namespace在JVM中内存使用情况：\n\nTotal(Directory) = (24 + 96 + 44 + 48) &lowast; 100M + 8 &lowast; num(total children)\nTotal(Files) = (24 + 96 + 48) &lowast; 100M + 8 &lowast; num(total blocks)\nTotal = (24 + 96 + 44 + 48) &lowast; 100M + 8 &lowast; num(total children) +  (24 + 96 + 48) &lowast; 100M + 8 &lowast; num(total blocks) = ~38GB\n\n关于预估方法的几点说明：\n\n1.  对目录树结构中所有的Directory均按照默认INodeDirectory.withQuotaFeature结构进行估算，如果集群开启ACL/Snapshotd等特性，需增加这部分内存开销。\n2.  对目录树结构中所有的File按照INodeFile进行估算。\n3.  从整个目录树的父子关系上看，num(total children)就是目录节点数和文件节点数之和。\n4.  部分数据结构中包括了字符串，按照均值长度为8进行预估，实际情况可能会稍大。\n\nNamespace在JVM堆内存空间中常驻，在NameNode的整个生命周期一直在内存存在，同时为保证数据的可靠性，NameNode会定期对其进行Checkpoint，将Namespace物化到外部存储设备。随着数据规模的增加，文件数/目录树也会随之增加，整个Namespace所占用的JVM内存空间也会基本保持线性同步增加。\n\n### BlocksMap\n\nHDFS将文件按照一定的大小切成多个Block，为了保证数据可靠性，每个Block对应多个副本，存储在不同DataNode上。NameNode除需要维护Block本身的信息外，还需要维护从Block到DataNode列表的对应关系，用于描述每一个Block副本实际存储的物理位置，BlockManager中BlocksMap结构即用于Block到DataNode列表的映射关系。BlocksMap内部数据结构如图7所示。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/blockdetail.png)\n\n图7 BlockInfo继承关系\n\nBlocksMap经过多次优化形成当前结构，最初版本直接使用HashMap解决从Block到BlockInfo的映射。由于在内存使用、碰撞冲突解决和性能等方面存在问题，之后使用重新实现的LightWeightGSet代替HashMap，该数据结构本质上也是利用链表解决碰撞冲突的HashTable，但是在易用性、内存占用和性能等方面表现更好。关于引入LightWeightGSet细节可参考[HDFS-1114](https://issues.apache.org/jira/browse/HDFS-1114)。\n\n与HashMap相比，为了尽可能避免碰撞冲突，BlocksMap在初始化时直接分配整个JVM堆空间的2%作为LightWeightGSet的索引空间，当然2%不是绝对值，如果2%内存空间可承载的索引项超出了Integer.MAX_VALUE/8（注：Object.hashCode()结果是int，对于64位JVM的对象引用占用8Bytes）会将其自动调整到阈值上限。限定JVM堆空间的2%基本上来自经验值，假定对于64位JVM环境，如果提供64GB内存大小，索引项可超过1亿，如果Hash函数适当，基本可以避免碰撞冲突。\n\nBlocksMap的核心功能是通过BlockID快速定位到具体的BlockInfo，关于BlockInfo详细的数据结构如图8所示。BlockInfo继承自Block，除了Block对象中BlockID，numbytes和timestamp信息外，最重要的是该Block物理存储所在的对应DataNode列表信息triplets。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/blocksmap.png)\n\n图8 BlocksMap内存使用详解\n\n其中LightWeightGSet对应的内存空间全局唯一。尽管经过LightWeightGSet优化内存占用，但是BlocksMap仍然占用了大量JVM内存空间，假设集群中共1亿Block，NameNode可用内存空间固定大小128GB，则BlocksMap占用内存情况：  \n\n16 + 24 + 2% &lowast; 128GB +（ 40 + 128 ）&lowast; 100M = ~20GB\n\nBlocksMap数据在NameNode整个生命周期内常驻内存，随着数据规模的增加，对应Block数会随之增多，BlocksMap所占用的JVM堆内存空间也会基本保持线性同步增加。\n\n### 小结\n\nNameNode内存数据结构非常丰富，除了前面详细分析的核心数据结构外，其实还包括如LeaseManager/SnapShotManager/CacheManager等管理的数据，由于内存使用非常有限，或特性未稳定没有开启，或没有通用性，这里都不再展开。\n\n根据前述对NameNode内存的预估，对比Hadoop集群历史实际数据：文件目录总量~140M，数据块总量~160M，NameNode JVM配置72GB，预估内存使用情况：\n\nNamespace：(24 + 96 + 44 + 48) &lowast; 70M + 8 &lowast; 140M +  (24 + 96 + 48) &lowast; 70M + 8 &lowast; 160M = ~27GB\nBlocksMap：16 + 24 + 2% &lowast; 72GB +（ 40 + 128 ）&lowast; 160M = ~26GB\n\n_说明：这里按照目录文件数占比1:1进行了简化，基本与实际情况吻合，且简化对内存预估结果影响非常小。_\n\n二者组合结果~53GB，结果与监控数据显示常驻内存~52GB基本相同，符合实际情况。\n\n从前面讨论可以看出，整个NameNode堆内存中，占空间最大的两个结构为Namespace和BlocksMap，当数据规模增加后，巨大的内存占用势必会给JVM内存管理带来挑战，甚至可能制约NameNode服务能力边界。  \n\n针对Namespace和BlocksMap的空间占用规模，有两个优化方向：\n\n*   合并小文件。使用Hive做数据生产时，为避免严重的数据倾斜、人为调小分区粒度等一些特殊原因，可能会在HDFS上写入大量小文件，会给NameNode带来潜在的影响。及时合并小文件，保持稳定的目录文件增长趋势，可有效避免NameNode内存抖动。\n*   适当调整BlockSize。如前述，更少的Block数也可降低内存使用，不过BlockSize调整会间接影响到计算任务，需要进行适当的权衡。\n\n对比其他Java服务，NameNode场景相对特殊，需要对JVM部分默认参数进行适当调整。比如Young/Old空间比例，为避免CMS GC降级到FGC影响服务可用性，适当调整触发CMS GC开始的阈值等等。关于JVM相关参数调整策略的细节建议参考官方使用文档。  \n\n这里，笔者根据实践提供几点NameNode内存相关的经验供参考：\n\n*   根据元数据增长趋势，参考本文前述的内存空间占用预估方法，能够大体得到NameNode常驻内存大小，一般按照常驻内存占内存总量~60%调整JVM内存大小可基本满足需求。*   为避免GC出现降级的问题，可将CMSInitiatingOccupancyFraction调整到~70。\n*   NameNode重启过程中，尤其是DataNode进行BlockReport过程中，会创建大量临时对象，为避免其晋升到Old区导致频繁GC甚至诱发FGC，可适当调大Young区（-XX:NewRatio）到10~15。\n\n据了解，针对NameNode的使用场景，使用CMS内存回收策略，将HotSpot JVM内存空间调整到180GB，可提供稳定服务。继续上调有可能对JVM内存管理能力带来挑战，尤其是内存回收方面，一旦发生FGC对应用是致命的。这里提到180GB大小并不是绝对值，能否在此基础上继续调大且能够稳定服务不在本文的讨论范围。结合前述的预估方法，当可用JVM内存达180GB时，可管理元数据总量达~700M，基本能够满足中小规模以下集群需求。\n\n## 总结\n\n本文在《[HDFS NameNode内存全景](http://tech.meituan.com/namenode.html)》基础上，对NameNode内存使用占比较高的几个核心数据结构进行了详细的介绍。在此基础上，提供了可供参考的NameNode内存数据空间占用预估模型：\n\n**Total = 198 &lowast; num(Directory + Files) + 176 &lowast; num(blocks) + 2% &lowast; size(JVM Memory Size)**\n\n通过对NameNode内存使用情况的定量分析，可为HDFS优化和发展规划提供可借鉴的数据参考依据。\n\n## 参考文献\n\n[1] Apache Hadoop. [https://hadoop.apache.org/](https://hadoop.apache.org/). 2016.\n[2] Apache Issues. [https://issues.apache.org/](https://issues.apache.org/). 2016.\n[3] Apache Hadoop Source Code. [https://github.com/apache/hadoop/tree/branch-2.4.1/](https://github.com/apache/hadoop/tree/branch-2.4.1/). 2014.\n[4] HDFS NameNode内存全景. [http://tech.meituan.com/namenode.html](http://tech.meituan.com/namenode.html). 2016.\n[5] Java HotSpot VM Options. [http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html](http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html).\n\n---\n\n* Author: 小桥\n* Source: [美团点评技术团队](http://tech.meituan.com/)\n* Link: [HDFS NameNode内存详解](http://tech.meituan.com/namenode-memory-detail.html)","tags":["Memory"],"categories":["Namenode"]},{"title":"外卖排序系统特征生产框架","url":"%2F2016%2F2016-12-09-sorting-system-feature-production-framework%2F","content":"\n# 背景\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/001.png)\n\n图1 外卖排序系统框架\n\n外卖的排序策略是由机器学习模型驱动的，模型迭代效率制约着策略优化效果。如上图所示，在排序系统里，特征是最为基础的部分：有了特征之后，我们离线训练出模型，然后将特征和模型一起推送给线上排序服务使用。特征生产Pipeline对于策略迭代的效率起着至关重要的作用。经过实践中的积累和提炼，我们整理出一套通用的特征生产框架，大大节省开发量，提高策略迭代效率。\n\n外卖排序系统使用GBDT（Gradient Boosting Decision Tree）树模型，比较复杂。受限于计算能力，除了上下文特征（如时间、地域、终端类型、距离等）之外，目前使用的主要是一些宽泛的统计特征，比如商家销量、商家单均价、用户的品类偏好等。这些特征的生产流程包括：离线的统计、离线到在线的同步、在线的加载等。\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/002.png)\n\n图2 特征生产流程\n\n如上图，目前外卖排序的特征生产流程主要有：\n\n1.  **特征统计**：基于基础数据表（如曝光表、点击表、订单表等），统计若干时段内特定维度的总量、分布等，如商家月均销量、用户不同品类下单占比。统计结果存储于Hive表。这部分工作，简单的可基于ETL，复杂的可基于Spark。产出的特征可供离线训练和线上预测，**本文主要围绕线上展开**。\n\n2.  **特征推送**：Hive表里的数据需要存入KV，以便线上实时使用。这一步，首先要将Hive表里的记录映射成POJO类（称为**Domain**类），然后将其序列化，最后将序列化串存入KV。这部分工作比较单一，基于MapReduce实现。\n\n3.  **特征获取**：在线服务根据需求，从KV中取出数据，并反序列化为Domain对象。\n\n4.  **特征加载**：针对模型所需特征列表，取得对应的Domain对象。这步通过调用特征获取实现。\n\n前两步为离线操作，后两步为在线操作。特征同步由离线推送和在线获取共同完成。离线生产流程是一个周期性的Pipeline，目前是以天为周期。\n\n为此，我们设计了一套通用的框架，基于此框架，只需要简单的配置和少量代码开发，就可以新增一组特征。下文将详细介绍框架的各个部分。\n\n# 特征统计\n\n排序模型用到的特征大部分是统计特征。有些特征比较简单，如商家的月均销量、商家单均价等，可用ETL统计(GROUP BY + SUM/AVG)；有些特征稍微复杂，如用户的品类偏好（在不同品类上的占比）、用户的下单额分布（不同金额区段的占比），用ETL就比较繁琐。针对后一种情况，我们开发了一套Spark程序来统计。我们发现，这种统计需求可以规约成一种范式：针对某些**统计对象**（用户、商家）的一些**维度**（品类、下单额），基于某些**度量值**（点击、下单）做**统计**（比例/总和）。\n\n同一对象，可统计不同维度；同一维度，有不同的度量角度；同一度量角度，有不同的统计方式。如下图：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/003.png)\n\n图3 特征统计范式\n\n\n例如，对于用户点击品类偏好、用户下单品类偏好、用户下单额分布、用户下单总额等特征，可做范式分解：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/004.png)\n\n图4 特征统计范式示例\n\n其中，\n\n*   **统计对象、统计维度、度量值**对应于Hive表中的字段（维度一般来自维度表，度量值一般来自事实表，主要是曝光、点击、下单）。为了增加灵活性，我们还允许对原始Hive字段做加工，加工后的值作为统计维度、度量值（加工的接口我们分别称为维度算子和度量算子）。\n\n*   **统计量**基于度量值做的一些聚合操作，如累加、求均值、拼接、求占比、算分位点（分布）。前两者输出一个数值，后三者输出形如&quot;Key1:Value1,Key2:Value2&quot;的KeyValue列表。\n\n另外，统计通常是在一定时间窗口内进行的，由于不同时期的数据价值不同（新数据比老数据更有价值），我们引入了**时间衰减**，对老数据降权。\n\n基于以上考虑，整个统计流程可以分解为（基于Spark）：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/005.png)\n\n图5 特征统计流程\n\n1.  按统计对象字段做聚合（GROUP BY）。统计对象字段由配置给定。对于外卖排序主要为uuid、poi_id。这一步可能会有数据倾斜，需要更多优化。\n\n2.  计算维度。支持维度算子，可以对原始维度字段做处理，如对金额字段做分段处理，以分段后的金额作为维度。\n\n3.  按统计维度聚合（GROUP BY）。这是在对象聚合的基础上做的二次聚合。维度字段由配置给定，可以有多个字段，表示交叉特征统计，如不同时段的品类偏好，维度字段为：时段、品类。\n\n4.  时间衰减并累加。衰减各个时间的度量值，并把所有时间的度量值累加，作为加权后的度量值。时间字段和度量字段由配置给定。时间字段主要为日期，度量字段主要为曝光、点击、下单。经过维度聚合后，度量值都在特定维度值对应的记录集上做累加，每个维度对应一个度量值，维度和度量值是一个KeyValue的映射关系。\n\n5.  计算度量值。度量字段也可以通过度量算子做进一步处理，算子得到的结果作为度量值。也可以有多个字段，如点击和曝光字段，配合除法算子，可以得到点击率作为度量值。\n\n6.  计算统计量。经过对象和维度聚合后，对象、维度、度量值建立了二级映射关系：对象维度度量值，相当于一个二维Map：Map&lt;对象, Map&lt;维度, 度量值&gt;&gt;。统计量是对Map&lt;维度, 度量值&gt;做一个聚合操作。每个统计量对应输出Hive表中的一个字段。现在主要支持如下几种算子：\n\n> *   累加：对该维度的所有度量值求和；\n> *   求均值：该维度所有取值情况对应的度量值的均值；\n> *   拼接：把Map&lt;维度, 度量值&gt;序列化为&quot;Key1:Value1, Key2:Value2&quot;形式，以便以字符串的形式存储于一个输出字段内。为了防止序列化串太长，可通过配置设定只保留度量值最大的top N；\n> *   求占比：该维度所有取值情况对应的度量值占度量值总和的比重，即Map&lt;维度, 度量值/Sum(度量值)&gt;。然后再做拼接输出；\n> *   算分位点：有时候想直到某些维度的分布情况，比如用户下单金额的分布以考察用户的消费能力。分位点可以作为分布的一种简单而有效的表示方法。该算子输出每个分位点的维度值，形如&quot;分位点1:维度值1, 分位点2:维度值2&quot;。此时，度量值只是用来算比值。\n\n**维度算子**、**度量算子**、**统计算子**都可以通过扩展接口的方式实现自定义。\n\n如下是统计用户点击品类偏好、用户下单品类偏好、用户下单额分布的配置文件和Hive表示例([Toml]<sup>[1]</sup>格式)\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/006.png)\n\n图6 特征统计配置示例\n\n相对于ETL，这套Spark统计框架更为简单清晰，还可以同时统计多个相关的特征。通过简单的配置就可以实现特征的统计，开发量比较小。\n\n# 特征同步\n\n离线统计得到的特征存储在Hive表中，出于性能的考虑，不能在线上直接访问。我们需要把特征从Hive中推送到更为高效的KV数据库中，线上服务再从KV中获取。整个同步过程可以分为如下步骤：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/007.png)\n\n图7 特征推送流程\n\n1.  ORM：将Hive表中的每行记录映射为Domain对象（类似于[Hibernate]<sup>[2]</sup>的功能）\n\n2.  **序列化**：将Domain对象序列化，然后存储到KV中。一个Domain类包含一组相关的、可同时在一个任务中统计的特征数据。每个Domain对象都有一个key值来作为自己唯一的标志—实现key()接口。同时，由于不同类型的Domain都会存储在一起，我们还需要为每种类型的Domain设定一个Key值前缀prefix以示区别。因此，KV中的Key是Domain.prefix + Domain.key，Value是序列化串。我们支持json和protostuff两种序列化方式。\n\n3.  **反序列化**：在线服务根据key和Domain.prefix从KV中得到序列化串，并反序列化为Domain对象。\n\n前两步为离线操作，第三步为在线操作（在预测代码中被调用）。\n\n我们针对Hive开发了一套ORM库（见图8），主要基于Java反射，除了支持基本类型(int/long/float/double/String等)，还支持POJO类型和集合类型(List/Map)。因为ETL不支持json拼接，为了兼容基于ETL统计的特征数据，我们的POJO以及集合类型是基于自定义的规范做编解码。针对Spark统计的特征数据，后续我们可以支持json格式的编解码。\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/008.png)\n\n图8 Hive ORM示意\n\n特征序列化和反序列我们统一封装为通用的**KvService**：负责序列化与反序列，以及读写KV。如下图：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/009.png)\n\n图9 KvService\n\n对于新特征，只需要定义一个Domain类，并实现接口key()即可，KvService自动完成Key值的拼接（以Domain的类名作为Key的prefix），序列化和反序列化，读写KV。\n\n我们通过周期性的离线MapReduce任务，读取Hive表的记录，并调用KvService的put接口，将特征数据推送到KV中。由于KvService能够统一处理各种Domain类型，MapReduce任务也是通用的，无需为每个特征单独开发。\n\n对于特征同步，只需要开发Domain类，并做少量配置，开发量也很小。目前，我们为了代码的可读性，采用Domain这种强类型的方式来定义特征，如果可以弱化这种需求的话，还可以做更多的框架优化，省去Domain类开发这部分工作。\n\n# 特征加载\n\n通过前面几步，我们已经准备好特征数据，并存储于KV中。线上有诸多模型在运行，不同模型需要不同的特征数据。特征加载这一步主要解决怎么高效便捷地为模型提供相应的特征数据。\n\n离线得到的只是一些原始特征，在线还可能需要基于原始特征做更多的处理，得到高阶特征。比如离线得到了商家和用户的下单金额分布，在线我们可能需要基于这两个分布计算一个匹配度，以表征该商家是否在用户消费能力的承受范围之内。\n\n我们把在线特征抽象为一个特征算子：**FeatureOperator**。类似的，一个特征算子包含了一组相关的在线特征，且可能依赖一组相关的离线特征。它除了封装了在线特征的计算过程，还通过两个Java Annotation声明该特征算子产出的特征清单(@**Features**)和所需要的数据清单(@**Fetchers**)。所有的数据获取都是由**DataFetcher**调用**KvService**的get接口实现，拿到的**Domain**对象统一存储在**DataPortal**对象中以便后续使用。\n\n服务启动时，会自动扫描所有的FeatureOperator的Annotation（@Features、@Fetchers），拿到对应的特征清单和数据清单，从而建立起映射关系：FeatureFeatureOperatorDataFetcher。而每个模型通过配置文件给定其所需要的特征清单，这样就建立起模型到特征的映射关系（如图9）： \n\n> **Model → Feature → FeatureOperator → DataFetcher**\n\n不同的在线特征可能会依赖相同的离线特征，也就是FeatureOperatorDataFetcher是多对多的关系。为了避免重复从KV读取相同的数据以造成性能浪费，离线特征的获取和在线特征的抽取被划分成两步：先汇总所有离线特征需求，统一获取离线特征；得到离线特征后，再进行在线特征的抽取。这样，我们也可以在离线特征加载阶段采用并发以减少网络IO延时。整个流程如图10所示：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/010.png)\n\n图10 模型和特征数据的映射关系\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/011.png)\n\n图11 特征加载流程\n\n对于新特征，我们需要实现对应的FeatureOperator、DataFetcher。DataFetcher主要封装了Domain和DataPortal的关系。类似的，如果我们不需要以强类型的方式来保证代码的业务可读性，也可以通过优化框架省去DataFetcher和DataPortal的定制开发。\n\n# 总结\n\n我们在合理抽象特征生产过程的各个环节后，设计了一套较为通用的框架，只需要少量的代码开发（主要是自定义一些算子）以及一些配置，就可以很方便地生产一组特征，有效地提高了策略迭代效率。\n\n## _参考文献_\n\n1.  [TOML](https://github.com/toml-lang/toml).\n2.  [Hibernate ORM](http://hibernate.org/orm/).\n\n---\n\n* Author: 海文\n* Source: [美团点评技术团队](http://tech.meituan.com/)\n* Link: [外卖排序系统特征生产框架](http://tech.meituan.com/feature_pipeline.html)\n","tags":["Sorting"],"categories":["Machine-Learning"]},{"title":"Linux沙箱技术","url":"%2F2016%2F2016-11-23-linux-sandbox%2F","content":"\n## Linux沙箱技术介绍\n\n在计算机安全领域，沙箱(Sandbox)是一种程序的隔离运行机制，其目的是限制不可信进程的权限。沙箱技术经常被用于执行未经测试的或不可信的客户程序。为了避免不可信程序可能破坏其它程序的运行，沙箱技术通过为不可信客户程序提供虚拟化的磁盘、内存以及网络资源，而这种虚拟化手段对客户程序来说是透明的。由于沙箱里的资源被虚拟化（或被间接化），所以沙箱里的不可信程序的恶意行为往往会被限制在沙箱中。\n\n沙箱技术一直是系统安全领域的挑战，不存在说哪一种方案是足够安全的。沙箱技术方案通常是需要结合多种系统安全技术来实现，采用防御纵深(Defence in Depth)的设计原则，筑建多道防御屏障，尽可能地将安全风险将为最低。下面我们主要讨论如何利用Linux kernel所提供的安全功能来建立有效的沙箱技术。\n\n在讨论之前，我们简单回顾一下Linux安全模型相关的内容（假设读者已经非常熟悉）：\n\n  (1) 每个进程都有自己的地址空间；\n  \n  (2) MMU硬件机制来保证地址空间的隔离；\n  \n  (3) Kernel是系统的TCB(Trusted Computing Base)，是安全策略的制定者和执行者；\n  \n  (4) 进程是最小的权限边界；\n  \n  (5) root具有最高权限，它能控制一切；\n  \n  (6) 其它用户受DAC(Discretionary Access Control)限制，如文件系统的UGO权限控制。\n\n进程是最小的权限边界，其根本原因是MMU能保证进程地址空间的隔离。\n\nLinux Kernel还提供了与进程降权(drop privilege)相关的一些功能：\n\n1. setuid\n2. POSIX.1e capability\n3. chroot jail\n4. Quota control (eg, cgroup, namespace)\n5. Linux Container\n6. Linux Security Module (LSM)\n\n下面我们会介绍如何在实践中利用这些诀窍来构建一个有效的sandbox.\n\n## setuid sandbox\n\nSetuid Sandbox主要是基于Linux Kernel所提供的安全机制(eg,DAC)来实现。简单地说就是利用 random uid/gid + chroot() + capability的组合出击来达到目标。其实现非常简单，无需修改Kernel。下面分别悉数之：\n\n1. Linux中每个进程都会有一个uid，uid=0则为root用户进程（privileged），uid>0则为普通用户进程（unprivileged）。不同uid进程之间（不包括root进程）是相互隔离的，各自都有自己独立的权限，互不干扰。而root进程具有特权，它能干任何事情。Linux uid/gid机制主要是用于进程的权限隔离。如果你打算执行不可信的程序，那么你可以在启动该程序时为其分配一个random uid。一个可能的执行流程如下：fork() -> setuid() -> {设置相关的进程资源限制, eg, RLIMIT_NPROC (0,0)} -> execv()。注意，setuid()只能由root权限（或拥有 CAP_SETUID capability）才能成功调用，所以这个执行流程需要借助某个拥有root权限的helper。比如，将helper程序设置为setuid root。\n\n2. Chroot是Linux kernel提供的另一个安全功能，它用于修改进程的根目录。比如执行chroot(\"/tmp/sandbox/1/\")则可以设置当前进程的根目录为\"/tmp/sandbox/1/\"，那么该进程的文件操作将被限制在\"/tmp/sandbox/1/\"中。注意，chroot()只能由root权限（或拥有CAP_SYS_CHROOT capability）才能成功调用。也许你马上会想到：在前面的执行流程中，先让具有root权限的helper去执行\"chroot()\"后再调用setuid() -> {...} -> execve()，但这样做是行不通的，因为execve()本要执行的binary文件已经不可用了（进程的根目录已经被重定位了）。Google的一篇文章里给出了一个解决此问题的简单方法：\n\n  (1) Helper创建一个子进程H，注意要用clone()和CLONE_FS，使得Helper和H可以共享根目录、当前目录、等等；\n  \n  (2) Helper降权后执行execve(\"Worker\")；\n  \n  (3) Worker(原Helper进程)请求H去执行chroot()；\n  \n  (4) H执行chroot()，新的根目录会对H和Worker同时生效。\n  \n  (5) H退出。\n\n  这个方法听起来不错，前提是Helper需要设置RLIMIT_NOFILE为(0,0)，并且对于不可信的Worker进程来说，在执行第4步之前应是可控的。\n\n  另外，对于Helper程序来说，由于它是以root身份运行，那么就可能会成为攻击点，比如confused deputy问题。下面我们介绍如何用capability机制来解这个问题。\n\n3. Linux Capability 主要是解决 confused deputy problem. 这类问题的典型代表之一是 CSRF(cross-site request forgery).给一个简单的例子来描述: 假如你刚刚用浏览器访问过你的网上银行，而同时又在逛水木BBS。这时BBS上的某个坏蛋可能正好猜到你在访问网上银行，于是那个坏蛋就编写一个在你的网上银行站点进行转帐的form提交的链接，并将该链接作为他在BBS上传的图片的tag。如果此时你点击了他的图片，并且你的网上银行在cookie中保存的授权信息还没有过期，那么你就倒霉了。此时的你就被称为\"confused deputy\"，因为你糊里糊涂地就授权了那个坏蛋所诱导的这次交易事务。\n\n  Linux支持Capability的主要目的是细化root的特权，以避免confused deputy problem. 比如拿ping程序来说，它需要使用raw_sockets所以需要root特权才能运行；如果有了Capability机制，由于该程序只需要一个CAP_NET_RAW的Capability即可运行，那么根据最小权限原则，该程序运行时可以丢弃所有多余的Capability，以防止被误用或被攻击。所以，Capability机制可以将root特权进行很好的细分，当前kernel(2.6.18)已支持30多种不同的Capability。注意在之前的kernel实现中，Capability只能由root进程持有，非root进程是不能保持任何Capability的。但是在2.6.24及以上的kernel版本中一个普通用户进程也将可以持有capability。\n\n小结：可以看出，setuid sandbox实现是简单易行。在一定程度上，它可以用于隔离不可信的程序。由于它完全依赖于kernel所提供的安全机制，除非攻击者能找到kernel的0-day漏洞并通过攻击获得root权限，否则setuid sandbox所提供的安全隔离是可以保证的。不可信代码的隔离一直都是操作系统安全领域的挑战之一，面对这种挑战，我们应当采用防御纵深（in depth）的方法来解决。而最近，我们发现setuid sandbox已被Google用作Chromium系统的第一道隔离屏障。\n\n## seccomp sandbox\n\nSeccomp(secure computing)是Linux kernel （自从2.6.23版本之后）所支持的一种简洁的sandboxing机制。它能使一个进程进入到一种“安全”运行模式，该模式下的进程只能调用4种系统调用（system calls），即read(), write(), exit()和sigreturn()，否则进程便会被终止。\n\nSeccomp是Andrea Arcangeli在2005年设计的，其目的是解决grid computing中的安全问题，比如你打算出租你的CPU资源，但又担心不可信的代码会破坏你的系统。那么，Seccomp则可以为“不可信的纯计算型代码”提供一个“安全（SAFE, not SECURE）”的运行环境，以保护你的系统和应用程序的正常运行不受不可信代码的干扰。\n\n据说Google Chrome浏览器的开发人员曾经考虑过使用Seccomp来建立Chrome Sandbox，但考虑到Seccomp的一些不足而“另辟蹊径”—— Native Client 。『据了解，Google Chrome 4 在今年 CanSecWest Applied Security 大会上是唯一没有被当场攻破的浏览器，而IE8 on Windows7/Vista/XP, Mozilla Firefox 3 和 Apple Safari 4 都相继被攻破。』\n\n简洁、优美是Seccomp的优点，但只能支持“纯计算型”代码却使得其应用受到很大限制。比如，Seccomp模式的进程不能动态分配内存、不能与其它进程使用共享内存、不能使用新的文件描述符、等等。如果要支持具有丰富功能的应用程序，则需要另外的方法来截获并处理其它系统调用。\n\n有人提议对seccomp进行改进使其支持对系统调用提供更细粒度的控制。比如，对seccomp增加一个新的mode，使用一个bitmap来精确描述哪些系统调用是可以被访问的，而哪些是被禁止的。而进程自己还可以丢弃（但不能重新获取）它所具有的访问哪些系统调用的能力（这种工作方法有点像Linux capability安全机制，尽管这两者是完全正交的）。但是到今天为止，还没有看到相关的进展，据说是因为ftrace也支持类似的功能，如何裁定还需要进一步讨论。\n\n通过截获系统调用来实现sandbox是一贯的做法，它假设Kernel是好人，而User不一定是好人。在现代操作系统中，User和Kernel的空间是隔离的，一个进程只能通过系统调用才能从user空间进入kernel空间。如果一个进程不需要执行系统调用（即不需要kernel提供的丰富功能），那么我们的系统被攻击的风险就小。当然假设进程不使用系统调用是不切实际的，但对今天的多数系统来说，为用户程序提供的丰富功能是以牺牲安全性为代价的。但是，“仅仅通过截获并处理系统调用的方法去实现sandbox”是否是正确的技术方向呢？我们知道，当系统调用的参数保存在用户空间的时候，要想验证该参数是否“安全”是非常困难的，比如TOC2TOU问题便是一个挑战：一个恶意进程可能会在“参数被安全检查”之后、而在“实际使用参数”之前将该参数换掉，这便使截获系统调用时所做的参数检查变得没有意义。要解决这个问题，我们也许不应当只将目光锁定在系统调用的入口处。\n\nsandboxing一直以来都是一个大难题，对于今天的COTS OS来说还不存在一个通用的安全方案。如何去做满足自己需要的sandbox，则需要量体裁衣。\n\n## ptrace sandbox\n\n暂无\n\n## vm sandbox\n\n暂无\n\n## 参考链接：\n\n* [Linux沙箱技术介绍](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=362087)\n* [Linux沙箱(1): setuid sandbox](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=382146)\n* [Linux沙箱(2): seccomp sandbox](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=382621)\n* [Linux沙箱(3): ptrace() sandbox](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=382622)\n* [Linux沙箱(4): vm sandbox](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=382623)\n\n---","tags":["Linux"],"categories":["Linux"]},{"title":"java安全沙箱","url":"%2F2016%2F2016-11-23-java-sandbox%2F","content":" \n参考链接：\n\n* [java安全沙箱（一）之ClassLoader双亲委派机制](https://my.oschina.net/xionghui/blog/501225)\n* [java安全沙箱（二）之.class文件检验器 ](https://my.oschina.net/xionghui/blog/501154)\n* [java安全沙箱（三）之内置于Java虚拟机（及语言）的安全特性](https://my.oschina.net/xionghui/blog/501165)\n* [java安全沙箱（四）之安全管理器及Java API](https://my.oschina.net/xionghui/blog/501225)\n\n---","tags":["Sandbox"],"categories":["Java"]},{"title":"深度解读最流行的优化算法：梯度下降","url":"%2F2016%2F2016-11-21-dl-optimization-gradient-descent%2F","content":"\n梯度下降法，是当今最流行的优化（optimization）算法，亦是至今最常用的优化神经网络的方法。本文旨在让你对不同的优化梯度下降法的算法有一个直观认识，以帮助你使用这些算法。我们首先会考察梯度下降法的各种变体，然后会简要地总结在训练（神经网络或是机器学习算法）的过程中可能遇到的挑战。\n\n## 目录：\n\n* 梯度下降的各种变体\n\n  1. 批量梯度下降（Batch gradient descent）\n  2. 随机梯度下降（Stochastic gradient descent）\n  3. 小批量梯度下降（Mini-batch gradient descent）\n\n* 面临的挑战\n* 梯度下降的优化算法\n\n  1. Momentum法\n  2. Nesterov加速梯度法\n  3. Adagrad法\n  4. Adadelta法\n  5. RMSprop法\n  6. 适应性动量估计法（Adam）\n  7. 几种算法的可视化\n  8. 该选择哪种优化器\n\n* 对SGD进行平行或分布式运算\n\n  1. Hogwild!\n  2. Downpour SGD\n  3. 容忍延迟的SGD算法\n  4. TensorFlow\n  5. 弹性平均梯度下降法（Elastic Averaging SGD）\n\n* 优化SGD的其他手段\n\n  1. 重排（Shuffling ）和递进学习（Curriculum Learning）\n  2. 批量标准化（Batch normalization）\n  3. 早停（Early Stopping）\n  4. 梯度噪声（Gradient noise）\n\n* 结论\n\n* 参考资料\n\n梯度下降法，是当今最流行的优化（optimization）算法，亦是至今最常用的优化神经网络的方法。与此同时，最新的深度学习程序库都包含了各种优化梯度下降的算法（可以参见如lasagne、caffe及Kera等程序库的说明文档）。但它们的算法则不被公开，都作为黑箱优化器被使用，这也就是为什么它们的优势和劣势往往难以被实际地解释。\n\n本文旨在让你对不同的优化梯度下降法的算法有一个直观认识，以帮助你使用这些算法。我们首先会考察梯度下降法的各种变体，然后会简要地总结在训练（神经网络或是机器学习算法）的过程中可能遇到的挑战。接着，我们将会讨论一些最常见的优化算法，研究它们的解决这些挑战的动机及推导出更新规律（update rules）的过程。我们还会简要探讨一下，在平行计算或是分布式处理情况下优化梯度下降法的算法和架构。最后，我们会考虑一下其他有助于优化梯度下降法的策略。\n\n梯度下降法的核心，是最小化目标函数J(θ)，其中θ是模型的参数，θ∈Rd。它的方法是，在每次迭代中，对每个变量，按照目标函数在该变量梯度的相反方向，更新对应的参数值。其中，学习率η决定了函数到达（局部）最小值的迭代次数。换句话说，我们在目标函数的超平面上，沿着斜率下降的方向前进，直到我们遇到了超平面构成的「谷底」。如果你不熟悉梯度下降法的话，你可以在这里找到一个很好的关于优化神经网络的介绍。\n\n## **梯度下降法变体**\n\n本文讨论了三种梯度下降法的变体——它们的不同之处在于，一次性使用多少数据来计算目标函数的梯度。对于不同的数据量，我们需要在参数更新准确性和参数更新花费时间两方面做出权衡。\n\n### **批量梯度下降法（Batch Gradient Descent）**\n\nVanilla 梯度下降法（译者注：Vanilla 是早期机器学习算法相关的名词，也是如今一个机器学习 python 程序库的名字，在该处指的是后者，参见：https://github.com/vinhkhuc/VanillaML，也就是大家所熟知的批量梯度下降法，在整个数据集上求出罚函数 J(θ 并）对每个参数 θ 求目标函数 J(θ) 的偏导数：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/001.png)\n\n在该方法中，每次更新我们都需要在整个数据集上求出所有的偏导数。因此批量梯度下降法的速度会比较慢，甚至对于较大的、内存无法容纳的数据集，该方法都无法被使用。同时，梯度下降法不能以「在线」的形式更新我们的模型，也就是不能再运行中加入新的样本进行运算。\n\n批量梯度下降法的实现代码，如下所示：\n\n```python\nfor i in range(nb_epochs):\n  params_grad = evaluate_gradient(loss_function, data, params)\n  params = params - learning_rate * params_grad\n```\n\n对于给定的迭代次数，我们首先基于输入的罚函数 loss_function 对输入的参数向量 params 计算梯度向量 params_grad。注意，最新的深度学习程序库中，提供了自动求导的功能，能够高效、快速地求给定函数对于特定参数的导数。如果你希望自己写代码求出梯度值，那么「梯度检查」会是一个不错的注意。（你可以参考这里，了解关于如何检查梯度的相关建议。）\n\n然后，我们对参数减去梯度值乘学习率的值，也就是在反梯度方向，更新我们参数。当目标函数 J(θ) 是一凸函数时，则批量梯度下降法必然会在全局最小值处收敛；否则，目标函数则可能会局部极小值处收敛。\n\n### **随机梯度下降法（Stochastic Gradient Descent）**\n\n相比批量梯度下降法，随机梯度下降法的每次更新，是对数据集中的一个样本（x，y）求出罚函数，然后对其求相应的偏导数：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/002.png)\n\n因为批量梯度下降法在每次更新前，会对相似的样本求算梯度值，因而它在较大的数据集上的计算会有些冗余（redundant）。而随机梯度下降法通过每次更新仅对一个样本求梯度，去除了这种冗余的情况。因而，它的运行速度被大大加快，同时也能够「在线」学习。\n\n随机梯度下降法更新值的方差很大，在频繁的更新之下，它的目标函数有着如下图所示的剧烈波动。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/003.png)\n\n_SGD 函数波动，来源：Wikipedia_\n\n相比批量梯度下降法的收敛会使目标函数落入一个局部极小值，SGD 收敛过程中的波动，会帮助目标函数跳入另一个可能的更小的极小值。另一方面，这最终会让收敛到特定最小值的过程复杂化，因为该方法可能持续的波动而不停止。但是，当我们慢慢降低学习率的时候，SGD 表现出了与批量梯度下降法相似的收敛过程，也就是说，对非凸函数和凸函数，必然会分别收敛到它们的极小值和最小值。\n\n相比批量梯度下降法的代码，在如下的代码中，我们仅仅加入了一个循环，用以遍历所有的训练样本并求出相应的梯度值。注意，如这里所说，在每次迭代中，我们会打乱训练数据集。\n\n```python\nfor i in range(nb_epochs):\n  np.random.shuffle(data)\n  for example in data:\n    params_grad = evaluate_gradient(loss_function, example, params)\n    params = params - learning_rate * params_grad\n```\n\n### **小批量梯度下降法（Mini-Batch Gradient Descent）**\n\n小批量梯度下降法集合了上述两种方法的优势，在每次更新中，对 n 个样本构成的一批数据，计算罚函数 J(θ)，并对相应的参数求导：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/004.png)\n\n这种方法，(a) 降低了更新参数的方差（variance），使得收敛过程更为稳定；(b) 能够利用最新的深度学习程序库中高度优化的矩阵运算器，能够高效地求出每小批数据的梯度。通常一小批数据含有的样本数量在 50 至 256 之间，但对于不同的用途也会有所变化。小批量梯度下降法，通常是我们训练神经网络的首选算法。同时，有时候我们也会使用随机梯度下降法，来称呼小批量梯度下降法（译者注：在下文中，我们就用 SGD 代替随机梯度下降法）。注意：在下文对于随机梯度法优化的介绍中，为方便起见，我们会省略式子中的参数 x(i:i+n),y(i:i+n)。\n\n如下的代码所示，我们不再对每个样本进行循环，而是对每批带有 50 个样本的小批数据进行循环：\n\n```python\nfor i in range(nb_epochs):\n  np.random.shuffle(data)\n  for batch in get_batches(data, batch_size=50):\n    params_grad = evaluate_gradient(loss_function, batch, params)\n    params = params - learning_rate * params_grad\n```\n\n## **面临的挑战**\n\n由于 Vanilla 小批量梯度下降法并不能保证良好地收敛，这给我们留下了如下待解决的挑战：\n\n* 选择适当的学习率是一个难题。太小的学习率会导致较慢的收敛速度，而太大的学习率则会阻碍收敛，并会引起罚函数在最小值处震荡，甚至有可能导致结果发散；\n* 我们可以设置一个关于学习率地列表，通过如退火的方法，在学习过程中调整学习率——按照一个预先定义的列表、或是当每次迭代中目标函数的变化小于一定阈值时来降低学习率。但这些列表或阈值，需要根据数据集地特性，被提前定义。\n* 此外，我们对所有的参数都采用了相同的学习率。但如果我们的数据比较稀疏，同时特征有着不同的出现频率，那么我们不希望以相同的学习率来更新这些变量，我们希望对较少出现的特征有更大的学习率。\n\n在对神经网络最优化非凸的罚函数时，另一个通常面临的挑战，是如何避免目标函数被困在无数的局部最小值中，以导致的未完全优化的情况。Dauphin 及其他人 [19] 认为，这个困难并不来自于局部最小值，而是来自于「鞍点」，也就是在一个方向上斜率是正的、在一个方向上斜率是负的点。这些鞍点通常由一些函数值相同的面环绕，它们在各个方向的梯度值都为 0，所以 SGD 很难从这些鞍点中脱开。\n\n## **梯度下降的优化算法**\n\n在如下的讨论中，我们将会列举一些应对上述问题的算法，它们被广泛应用于深度学习社区。同时，我们不会讨论那些不能应用于高维数据集的方法，例如牛顿法等针对二阶问题的方法。\n\n### **动量法**\n\nSGD 很难在陡谷——一种在一个方向的弯曲程度远大于其他方向的表面弯曲情况——中找到正确更新方向。而这种陡谷，经常在局部极值中出现。在这种情况下，如图 2 所示，SGD 在陡谷的周围震荡，向局部极值处缓慢地前进。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/005.png)\n\n动量法 [2]，如图 3 所示，则帮助 SGD 在相关方向加速前进，并减少它的震荡。他通过修改公式中，在原有项前增加一个折损系数γ，来实现这样的功能：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/006.png)\n\n注意：在其他的一些算法实现中，公式中的符号也许有所不同。动量项 γ 往往被设置为 0.9 或为其他差不多的值。\n\n从本质上说，动量法，就仿佛我们从高坡上推下一个球，小球在向下滚动的过程中积累了动量，在途中他变得越来越快（直到它达到了峰值速度，如果有空气阻力的话，γ&lt;1）。在我们的算法中，相同的事情发生在我们的参数更新上：动量项在梯度指向方向相同的方向逐渐增大，对梯度指向改变的方向逐渐减小。由此，我们得到了更快的收敛速度以及减弱的震荡。\n\n### **Nesterov 加速梯度法**\n\n但当一个小球从山谷上滚下的时候，盲目的沿着斜率方向前行，其效果并不令人满意。我们需要有一个更「聪明」的小球，它能够知道它再往哪里前行，并在知道斜率再度上升的时候减速。\n\nNesterov 加速梯度法（NAG）是一种能给予梯度项上述「预测」功能的方法。我们知道，我们使用动量项γvt-1 来「移动」参数项θ。通过计算θ-γvt-1，我们能够得到一个下次参数位置的近似值——也就是能告诉我们参数大致会变为多少。那么，通过基于未来参数的近似值而非当前的参数值计算相得应罚函数 J(θ-γvt-1) 并求偏导数，我们能让优化器高效地「前进」并收敛：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/007.png)\n\n在该情况下，我们依然设定动量系数γ 在 0.9 左右。如下图 4 所示，动量法首先计算当前的梯度值（小蓝色向量），然后在更新的积累向量（大蓝色向量）方向前进一大步。但 NAG 法则首先（试探性地）在之前积累的梯度方向（棕色向量）前进一大步，再根据当前地情况修正，以得到最终的前进方向（绿色向量）。这种基于预测的更新方法，使我们避免过快地前进，并提高了算法地响应能力（responsiveness），大大改进了 RNN 在一些任务上的表现 [8]。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/008.png)\n\n_Nesterov Update 法，来源：G. Hinton's lecture 6c_\n\n参考这里，以查看 Ilya Sutskever 在它博士论文中，对 NAG 机理的更为详尽的解释 [9]。\n\n因为我们现在能根据我们罚函数的梯度值来调整我们的更新，并能相应地加速 SGD，我们也希望能够对罚函数中的每个参数调整我们的更新值，基于它们的重要性以进行或大或小的更新。\n\n### **Adagrad法**\n\nAdagrad[3] 是一个基于梯度的优化算法，它的主要功能是：它对不同的参数调整学习率，具体而言，对低频出现的参数进行大的更新，对高频出现的参数进行小的更新。因此，他很适合于处理稀疏数据。Dean 等人 [14] 发现，Adagrad 法大大提升了 SGD 的鲁棒性，并在谷歌使用它训练大规模的神经网络，其诸多功能包括识别 Youtube 视频中的猫。此外，Pennington 等人 [5] 使用它训练 GloVe 单词向量映射（Word Embedding），在其中不频繁出现的词语需要比频繁出现的更大的更新值。\n\n在这之前，我们对于所有的参数使用相同的学习率进行更新。但 Adagrad 则不然，对不同的训练迭代次数 t，adagrad 对每个参数都有一个不同的学习率。我们首先考察 adagrad 每个参数的的更新过程，然后我们再使之向量化。为简洁起见，我们记在迭代次数 t 下，对参数θi 求目标函数梯度的结果为 gt,i：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/009.png)\n\n那么普通 SGD 的更新规则为：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/010.png)\n\n而 adagrad 将学习率η进行了修正，对迭代次数 t，基于每个参数之前计算的梯度值，将每个参数的学习率η按如下方式修正：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/011.png)\n\n其中 是一个对角阵，其中对角线上的元素是从一开始到 时刻目标函数对于参数 梯度的平方和。是一个平滑项，以避免分母为 0 的情况，它的数量级通常在。有趣的是，如果不开方的话，这个算法的表现会变得很糟。\n\n因为 在其对角线上，含有过去目标函数对于参数 梯度的平方和，我们可以利用一个元素对元素的向量乘法，将我们的表达式向量化：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/012.png)\n\nAdagrad 主要优势之一，是它不需要对每个学习率手工地调节。而大多数算法，只是简单地使用一个相同地默认值如 0.1，来避免这样地情况。\n\nAdagrad 地主要劣势，是他在分母上的项中积累了平方梯度和。因为每次加入的项总是一个正值，所以累积的和将会随着训练过程而增大。因而，这会导致学习率不断缩小，并最终变为一个无限小值——此时，这个算法已经不能从数据中学到额外的信息。而下面的算法，则旨在解决这个问题。\n\n### **Adadelta 法**\n\nAdadelta 法 [6] 是 Adagrad 法的一个延伸，它旨在解决它学习率不断单调下降的问题。相比计算之前所有梯度值的平方和，Adadelta 法仅计算在一个大小为 的时间区间内梯度值的累积和。\n\n但该方法并不会存储之前 个梯度的平方值，而是将梯度值累积值按如下的方式递归地定义：它被定义为关于过去梯度值的衰减均值（decade average），当前时间的梯度均值是基于过去梯度均值和当前梯度值平方的加权平均，其中是类似上述动量项的权值。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/013.png)\n\n与动量项的设定类似，我们设定 为以 0.9 左右的值。为明确起见，我们将我们的 SGD 更新规则写为关于参数更新向量 的形式：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/014.png)\n\n由此，我们刚刚在 Adagrad 法中推导的的参数更新规则的向量表示，变为如下形式：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/015.png)\n\n我们现在将其中的对角矩阵 用上述定义的基于过去梯度平方和的衰减均值 替换：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/016.png)\n\n因为分母表达式的形式与梯度值的方均根（root mean squared,RMS）形式类似，因而我们使用相应的简写来替换：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/017.png)\n\n作者还注意到，在该更新中（在 SGD、动量法或者 Adagrad 也类似）的单位并不一致，也就是说，更新值的量纲与参数值的假设量纲并不一致。为改进这个问题，他们定义了另外一种指数衰减的衰减均值，他是基于参数更新的平方而非梯度的平方来定义的：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/018.png)\n\n因此，对该问题的方均根为：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/019.png)\n\n因为 值未知，所以我们使用 时刻的方均根来近似。将前述规则中的学习率 替换为，我们最终得到了 Adadelta 法的更新规则：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/020.png)\n\n借助 Adadelta 法，我们甚至不需要预设一个默认学习率，因为它已经从我们的更新规则中被删除了。\n\n### **RMSprop 法**\n\nRMSprop 是由 Geoff Hinton 在他 Coursera 课程中提出的一种适应性学习率方法，至今仍未被公开发表。\n\nRMSprop 法和 Adadelta 法几乎同时被发展出来。他们 解决 Adagrad 激进的学习率缩减问题。实际上，RMSprop 和我们推导出的 Adadelta 法第一个更规则相同：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/021.png)\n\nRMSprop 也将学习率除以了一个指数衰减的衰减均值。Hinton 建议设定 为 0.9，对 而言，0.001 是一个较好的默认值。\n\n### **Adam**\n\n适应性动量估计法（Adam）[15] 是另一种能对不同参数计算适应性学习率的方法。除了存储类似 Adadelta 法或 RMSprop 中指数衰减的过去梯度平方均值 外，Adam 法也存储像动量法中的指数衰减的过去梯度值均值 ：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/022.png)\n\n和 分别是梯度的一阶矩（均值）和二阶矩（表示不确定度的方差），这也就是该方法名字的来源。因为当 和 一开始被初始化为 0 向量时，Adam 的作者观察到，该方法会有趋向 0 的偏差，尤其是在最初的几步或是在衰减率很小（即 和 接近 1）的情况下。\n\n他们使用偏差纠正系数，来修正一阶矩和二阶矩的偏差：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/023.png)\n\n他们使用这些来更新参数，更新规则很我们在 Adadelta 和 RMSprop 法中看到的一样，服从 Adam 的更新规则： \n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/024.png)\n\n作者认为参数的默认值应设为：0.9 for β1, 0.999 for β2, and 10−8 for ϵ. 。他们的经验表明，Adam 在实践中表现很好，和其他适应性学习算法相比也比较不错。\n\n### **算法可视化**\n\n如下的两个动画（图像版权：Alec Radford）给了我们关于特定优化算法在优化过程中行为的直观感受。你可以参见这里，以获取 Karpathy 对相同图像的一些描述，及另关于一些相关算法的细致讨论。\n\n在图 5 中，我们可以看到，在罚函数的等高线图中，优化器的位置随时间的变化情况。注意到，Adagrad、 Adadelta 及 RMSprop 法几乎立刻就找到了正确前进方向并以相似的速度很快收敛。而动量法和 NAG 法，则找错了方向，如图所示，让小球沿着梯度下降的方向前进。但 NAG 法能够很快改正它的方向向最小指出前进，因为他能够往前看并对前面的情况做出响应。\n\n图 6 展现了各算法在鞍点附近的表现。如上面所说，这对对于 SGD 法、动量法及 NAG 法制造了一个难题。他们很难打破」对称性「带来的壁垒，尽管最后两者设法逃脱了鞍点。而 Adagrad 法、RMSprop 法及 Adadelta 法都能快速的沿着负斜率的方向前进。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/025.gif)\n\n_图5：SGD optimization on loss surface contours_\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/026.gif)\n\n_图6：SGD optimization on saddle point 10 − 8\n\n如我们所见，适应性学习率方法，也就是 Adagrad 法、Adadelta 法 、RMSprop 法及 Adam 法最适合处理上述情况，并有最好的收敛效果。\n\n### **如何选择优化器？**\n\n那么，我们该如何选择优化器呢？如果你的输入数据较为稀疏（sparse），那么使用适应性学习率类型的算法会有助于你得到好的结果。此外，使用该方法的另一好处是，你在不调参、直接使用默认值的情况下，就能得到最好的结果。\n\n总的来说，RMSprop 法是一种基于 Adagrad 法的拓展，他从根本上解决学习率骤缩的问题。Adadelta 法于 RMSprop 法大致相同，除了前者使用了。而 Adam 法，则基于 RMSprop 法添加了偏差修正项和动量项。在我们地讨论范围中，RMSprop、Adadelta 及 Adam 法都是非常相似地算法，在相似地情况下都能做的很好。Kingma 及其他人 [15] 展示了他们的偏差修正项帮助 Adam 法，在最优化过程快要结束、梯度变得越发稀疏的时候，表现略微优于 RMSprop 法。总的来说，Adam 也许是总体来说最好的选择。\n\n有趣的是，很多最新的论文，都直接使用了（不带动量项的）Vanilla SGD 法，配合一个简单的学习率（退火）列表。如论文所示，这些 SGD 最终都能帮助他们找到一个最小值，但会花费远多于上述方法的时间。并且这些方法非常依赖于鲁棒的初始化值及退火列表。因此，如果你非常在你的模型能快速收敛，或是你需要训练一个深度或复杂模型，你可能需要选择上述的适应性模型。\n\n## **对 SGD 进行平行计算或分布式计算**\n\n现如今，大规模数据集随处可见、小型计算机集群也易于获得。因而，使用分布式方法进一步加速 SGD 是一个惯常的选择。\n\nSGD 它本事是序列化的：通过一步一步的迭代，我们最终求到了最小值。运行它能够得到不错的收敛结果，但是特别是对于大规模的数据集，它的运行速度很慢。相比而言，异步 SGD 的运行速度相对较快，但在不同的工作机之间的关于非完全优化的沟通可能会导致较差的收敛结果。此外，我们能够对 SGD 进行平行运算而不需要一个计算机集群。下文讨论了相关的算法或架构，它们或关于平行计算或者对其进行了分布式优化。\n\n### **Hogwild!**\n\nNiu 等人提出了一种叫做 Hogwild! 的更新规则，它允许在平行 GPU 上进行 SGD 更新。处理器。这仅能在输入数据集是稀疏的时起效，在每次更新过程中仅会修正一部分的参数值。他们展示了，在这种情况下，这个更新规则达到了最优化的收敛速度，因为处理器不太会覆盖有用的信息。\n\n### **Downpour SGD**\n\nDownpour SGD 是一个异步的 SGD 法变体，它被 Dean 等人 [4] 用在了谷歌的 DistBelief 架构中（它是 TensorFlow 的前身）。他对训练集地子集同步地运行模型的多个副本。这些模型将它们的更新值发送到参数服务器，服务器被分为了许多台主机。每一台主机都负责存储和上载模型的一部分参数。但是，副本之间却没有相互的通信——例如，共享权重值或者更新值——其参数面临着发散的风险，会阻止收敛。\n\n### **容忍延迟的 SGD 算法**\n\nMcMahan 和 Streeter [12] 改良了 AdaGrad 法使之能够用于平行运算的场景。通过实现延迟容忍的算法，它不仅能能够适应于过去的梯度，还能够适应于更新的延迟。在实践中，它的表现很好。\n\n### **TensorFlow**\n\nTensorFlow[13] 是谷歌最近开源的一个实现和部署大规模机器学习模型的架构。它基于他们之前对于使用 DistBelief 的经验，并已在内部被部署在一系列的移动设备及大规模的分布式系统上进行计算。为了分布式执行，一个计算图被分为了许多子图给不同的设备，设备之间的通信使用了发送和接受节点对。2016 年 4 月 13 日更新：一个分布式 TensorFlow 的版本已经被发布。\n\n### **弹性平均梯度下降法（Elastic Averaging SGD）**\n\n张等人 [14] 提出了弹性平均梯度下降法（EASGD），他使不同工作机之间不同的 SGD 以一个「弹性力」连接，也就是一个储存于参数服务器的中心变量。这允许局部变量比中心变量更大地波动，理论上允许了对参数空间更多的探索。他们的经验表明，提高的探索能力有助于在寻找新的局部极值中提升（优化器的）表现。\n\n## **优化 SGD 的其他手段**\n\n最后，我们将讨论一些其他手段，他们可以与前述的方法搭配使用，并能进一步提升 SGD 的效果。你可以参考 [22]，以了解一些其他常用策略。\n\n重排法（Shuffling）和递进学习（Curriculum Learning）\n\n总体而言，我们希望避免训练样本以某种特定顺序传入到我们的学习模型中，因为这会向我们的算法引入偏差。因此，在每次迭代后，对训练数据集中的样本进行重排（shuffling），会是一个不错的注意。\n\n另一方面，在某些情况下，我们会需要解决难度逐步提升的问题。那么，按照一定的顺序遍历训练样本，会有助于改进学习效果及加快收敛速度。这种构建特定遍历顺序的方法，叫做递进学习（Curriculum Learning）[16]。*这个词目前没有标准翻译，我根据表意和意义翻译成这个。\n\nZaremba 和 Sutskever [17] 仅使用了递进学习法训练 LSTMs 来学习简单的项目，但结果表明，递进学习法使用的混合策略的表现好于朴素策略——后者不断地重排数据，反而增加了学习过程的难度。\n\n### **批量标准化（Batch Normalization）**\n\n我们通常设置我们参数初值的均值和方差分别为 0 和单位值，以帮助模型进行学习。随着学习过程的进行，每个参数被不同程度地更新，相应地，参数的正则化特征也随之失去了。因此，随着训练网络的越来越深，训练的速度会越来越慢，变化值也会被放大。\n\n批量标准化 [18] 对每小批数据都重新进行标准化，并也会在操作中逆传播（back-propgate）变化量。在模型中加入批量标准化后，我们能使用更高的学习率且不要那么在意初始化参数。此外，批量正则化还可以看作是一种正则化手段，能够减少（甚至去除）留出法的使用。\n\n### **早停（Early Stopping）**\n\n诚如 Geoff Hinton 所言：「Early stopping (is) beautiful free lunch（早停是美妙的免费午餐，又简单效果又好）」（NIPS 2015 Tutorial Sildes, Slide 63）。在训练过程中，你应该时刻关注模型在验证集上的误差情况，并且在改误差没有明显改进的时候停止训练。\n\n### **梯度噪声（Gradient Noise）**\n\nNeelakentan 等人 [21] 在每次梯度的更新中，向其中加入一个服从合高斯分布 N(0,σ^2) 的噪声值：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/027.png)\n\n并按照如下的方式修正方差：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/028.png)\n\n他们指出，这种方式能够提升神经网络在不良初始化前提下的鲁棒性，并能帮助训练特别是深层、复杂的神经网络。他们发现，加入噪声项之后，模型更有可能发现并跳出在深度网络中频繁出现的局部最小值。\n\n## **结论**\n\n在本文中，我们首先分析了梯度下降法的三个变体，在其中小批量梯度下降法最受欢迎。接着，我们研究了常用的优化 SGD 的算法，包括：动量法、Nesterov accelerated gradient 法、Adagrad 法、Adadelta 法、RMSprop 法、Adam 法及其他优化异步 SGD 的算法。最终，我们讨论了另外一些改进 SGD 的策略，包括样本重排法（shuffling）、递进学习（curriculum learning）、批量标准化（Batch Normali&middot;zation）及早停（early stopping）等。\n\n我希望本文能增进读者关于这些优化算法的认识，能对这些算法的行为与动机有一个了解。也许我遗漏了一些常用的优化 SGD 的算法，或是你有一些自己使用 SGD 训练的技巧。如果有的话，请在下方留言区留言让我知道。\n\n## 参考文献\n\n* 原文连接查看：[http://sebastianruder.com/optimizing-gradient-descent/](http://sebastianruder.com/optimizing-gradient-descent/)\n\n---\n\n* Source: [机器之心](http://www.jiqizhixin.com)\n* Link: [深度解读最流行的优化算法：梯度下降](http://www.jiqizhixin.com/article/1857)","tags":["Deep-Learning"],"categories":["Deep-Learning"]},{"title":"服务容错模式","url":"%2F2016%2F2016-11-11-service-fault-tolerant-mode%2F","content":"\n# 背景\n\n随着美团点评服务框架和服务治理体系的逐步成熟，服务化已成为公司内部系统设计的趋势。本着大系统小做、职责单一的原则，我们度假技术团队对业务系统进行了不少服务化拆分工作。随着业务复杂度的增加，依赖的服务也逐步增加，出现了不少由于服务调用出现异常问题而导致的重大事故，如：\n\n1. 系统依赖的某个服务发生延迟或者故障，数秒内导致所有应用资源（线程，队列等）被耗尽，造成所谓的雪崩效应 ([Cascading Failure](https://en.wikipedia.org/wiki/Cascading_failure))，导致整个系统拒绝对外提供服务。\n\n2. 系统遭受恶意爬虫袭击，在放大效应下没有对下游依赖服务做好限速处理，最终导致下游服务崩溃。\n\n容错是一个很大的话题，受篇幅所限，本文将介绍仅限定在服务调用间常用的一些容错模式。\n\n# 设计原则\n\n服务容错的设计有个基本原则，就是“Design for Failure”。为了避免出现“千里之堤溃于蚁穴”这种情况，在设计上需要考虑到各种边界场景和对于服务间调用出现的异常或延迟情况，同时在设计和编程时也要考虑周到。这一切都是为了达到以下目标：\n\n1. 一个依赖服务的故障不会严重破坏用户的体验。\n\n2. 系统能自动或半自动处理故障，具备自我恢复能力。\n\n基于这个原则和目标，衍生出下文将要介绍的一些模式，能够解决分布式服务调用中的一些问题，提高系统在故障发生时的存活能力。\n\n# 一些经典的容错模式\n\n所谓模式，其实就是某种场景下一类问题及其解决方案的总结归纳，往往可以重用。模式可以指导我们完成任务，作出合理的系统设计方案，达到事半功倍的效果。而在服务容错这个方向，行业内已经有了不少实践总结出来的解决方案。\n\n## 超时与重试（Timeout and Retry）\n\n超时模式，是一种最常见的容错模式，在美团点评的工程实践中大量存在。常见的有设置网络连接超时时间，一次RPC的响应超时时间等。在分布式服务调用的场景中，它主要解决了当依赖服务出现建立网络连接或响应延迟，不用无限等待的问题，调用方可以根据事先设计的超时时间中断调用，及时释放关键资源，如Web容器的连接数，数据库连接数等，避免整个系统资源耗尽出现拒绝对外提供服务这种情况。\n\n重试模式，一般和超时模式结合使用，适用于对于下游服务的数据强依赖的场景（不强依赖的场景不建议使用！），通过重试来保证数据的可靠性或一致性，常用于因网络抖动等导致服务调用出现超时的场景。与超时时间设置结合使用后，需要考虑接口的响应时间分布情况，超时时间可以设置为依赖服务接口99.5%响应时间的值，重试次数一般1-2次为宜，否则会导致请求响应时间延长，拖累到整个系统。\n\n一些实现说明：\n\n```java\n    public class RetryCommand<T> {\n        private int maxRetries = 2;// 重试次数 默认2次\n        private long retryInterval = 5;//重试间隔时间ms 默认5ms\n        private Map<String, Object> params;\n\n           public RetryCommand() {\n\n        }\n\n        public RetryCommand(long retryInterval, int maxRetries) {\n               this.retryInterval = retryInterval;\n            this.maxRetries = maxRetries;\n        }\n\n        public T command(Map<String, Object> params){\n              //Some remote service call with timeout\n               serviceA.doSomethingWithTimeOut(timeout);\n        }\n\n        private final T retry() throws RuntimeException {\n            int retryCounter = 0;\n            while (retryCounter < maxRetries) {\n                try {\n                    return command(params);\n                } catch (Exception e) {\n                    retryCounter++;\n                    if (retryCounter >= maxRetries) {\n                        break;\n               }\n            }\n        }\n        throw new RuntimeException(\"Command failed on all of \" + maxRetries + \" retries\");\n    }\n\n        //省略\n    }\n```\n\n## 限流(Rate Limiting/Load Shedder)\n\n限流模式，常用于下游服务容量有限，但又怕出现突发流量猛增（如恶意爬虫，节假日大促等）而导致下游服务因压力过大而拒绝服务的场景。常见的限流模式有控制并发和控制速率，一个是限制并发的数量，一个是限制并发访问的速率。\n\n### 控制并发\n\n属于一种较常见的限流手段，在工程实践中可以通过信号量机制（如Java中的Semaphore）来控制，举个例子：\n\n假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发的读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有十个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，我们就可以使用Semaphore来控制并发数，如：\n\n```java\n    public class SemaphoreTest {\n\n        private static final int THREAD_COUNT = 30;\n\n        private static ExecutorService threadPool = Executors\n            .newFixedThreadPool(THREAD_COUNT);\n\n        private static Semaphore s = new Semaphore(10);\n\n        public static void main(String[] args) {\n            for (int i = 0; i < THREAD_COUNT; i++) {\n                threadPool.execute(new Runnable() {\n                    @Override\n                    public void run() {\n                        try {\n                            s.acquire();\n                            System.out.println(\"save data\");\n                            s.release();\n                        } catch (InterruptedException e) {\n                            e.printStack();\n                        }\n                    }\n                });\n            }\n\n            threadPool.shutdown();\n        }\n    }\n```\n\n在代码中，虽然有30个线程在执行，但是只允许10个并发的执行。Semaphore的构造方法Semaphore(int permits) 接受一个整型的数字，表示可用的许可证数量。Semaphore(10)表示允许10个线程获取许可证，也就是最大并发数是10。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()获取一个许可证，使用完之后调用release()归还许可证，还可以用tryAcquire()方法尝试获取许可证。\n\n### 控制速率\n\n在我们的工程实践中，常见的是使用令牌桶算法来实现这种模式，其他如漏桶算法也可以实现控制速率，但在我们的工程实践中使用不多，这里不做介绍，读者请自行了解。\n\n![令牌桶算法](/assets/images/2016/11/11/service-fault-tolerant-mode/token_bucket.jpg)\n\n在Wikipedia上，令牌桶算法是这么描述的：\n\n1.  每秒会有r个令牌放入桶中，或者说，每过1/r秒桶中增加一个令牌。\n2.  桶中最多存放b个令牌，如果桶满了，新放入的令牌会被丢弃。\n3.  当一个n字节的数据包到达时，消耗n个令牌，然后发送该数据包。\n4.  如果桶中可用令牌小于n，则该数据包将被缓存或丢弃。\n\n令牌桶控制的是一个时间窗口内通过的数据量，在API层面我们常说的QPS、TPS，正好是一个时间窗口内的请求量或者事务量，只不过时间窗口限定在1s罢了。以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。令牌桶的另外一个好处是可以方便的改变速度，一旦需要提高速率，则按需提高放入桶中的令牌的速率。\n\n在我们的工程实践中，通常使用Guava中的Ratelimiter来实现控制速率，如我们不希望每秒的任务提交超过两个：\n\n```java\n    //速率是每秒两个许可\n    final RateLimiter rateLimiter = RateLimiter.create(2.0);\n\n    void submitTasks(List tasks, Executor executor) {\n        for (Runnable task : tasks) {\n            rateLimiter.acquire(); // 也许需要等待\n            executor.execute(task);\n        }\n    }\n```\n\n## 电路熔断器(Circuit Breaker)\n\n在我们的工程实践中，偶尔会遇到一些服务由于网络连接超时，系统有异常或load过高出现暂时不可用等情况，导致对这些服务的调用失败，可能需要一段时间才能修复，这种对请求的阻塞可能会占用宝贵的系统资源，如：内存，线程，数据库连接等等，最坏的情况下会导致这些资源被消耗殆尽，使得系统里不相关的部分所使用的资源也耗尽从而拖累整个系统。在这种情况下，调用操作能够立即返回错误而不是等待超时的发生或者重试可能是一种更好的选择，只有当被调用的服务有可能成功时我们再去尝试。\n\n熔断器模式可以防止我们的系统不断地尝试执行可能会失败的调用，使得我们的系统继续执行而不用等待修正错误，或者浪费CPU时间去等到长时间的超时产生。熔断器模式也可以使我们系统能够检测错误是否已经修正，如果已经修正，系统会再次尝试调用操作。下图是个使用熔断器模式的调用流程：\n\n![熔断器模式](/assets/images/2016/11/11/service-fault-tolerant-mode/circuit1.png)\n\n可以从图中看出，当超时出现的次数达到一定条件后，熔断器会触发打开状态，客户端的下次调用将直接返回，不用等待超时产生。\n\n在熔断器内部，往往有以下几种状态：\n\n![熔断器模式](/assets/images/2016/11/11/service-fault-tolerant-mode/circuit2.png)\n\n1）闭合（closed）状态：该状态下能够对目标服务或方法进行正常的调用。熔断器类维护了一个时间窗口内调用失败的次数，如果某次调用失败，则失败次数加1。如果最近失败次数超过了在给定的时间窗口内允许失败的阈值(可以是数量也可以是比例)，则熔断器类切换到断开(Open)状态。此时熔断器设置了一个计时器，当时钟超过了该时间，则切换到半断开（Half-Open）状态，该睡眠时间的设定是给了系统一次机会来修正导致调用失败的错误。\n\n2）断开(Open)状态：在该状态下，对目标服务或方法的请求会立即返回错误响应，如果设置了fallback方法，则会进入fallback的流程。\n\n3）半断开（Half-Open）状态：允许对目标服务或方法的一定数量的请求可以去调用服务。如果这些请求对服务的调用成功，那么可以认为之前导致调用失败的错误已经修正，此时熔断器切换到闭合状态（并且将错误计数器重置）；如果这一定数量的请求有调用失败的情况，则认为导致之前调用失败的问题仍然存在，熔断器切回到断开方式，然后开始重置计时器来给系统一定的时间来修正错误。半断开状态能够有效防止正在恢复中的服务被突然而来的大量请求再次拖垮。\n\n在我们的工程实践中，熔断器模式往往应用于服务的自动降级，在实现上主要基于Netflix开源的组件Hystrix来实现，下图和代码分别是Hystrix中熔断器的原理和定义，更多了解可以查看Hystrix的源码：\n\n![模式组合](/assets/images/2016/11/11/service-fault-tolerant-mode/circuit3.png)\n\n```java\n    public interface HystrixCircuitBreaker {\n\n        /**\n         * Every {@link HystrixCommand} requests asks this if it is allowed to proceed or not.\n          * <p>\n          * This takes into account the half-open logic which allows some requests through when determining if it should be closed again.\n          *\n          * @return boolean whether a request should be permitted\n          */\n         public boolean allowRequest();\n\n         /**\n          * Whether the circuit is currently open (tripped).\n          *\n          * @return boolean state of circuit breaker\n         */\n         public boolean isOpen();\n\n        /**\n         * Invoked on successful executions from {@link HystrixCommand} as part of feedback mechanism when in a half-open state.\n         */\n        public void markSuccess();\n    }\n```\n\n## 舱壁隔离(Bulkhead Isolation)\n\n在造船行业，往往使用此类模式对船舱进行隔离，利用舱壁将不同的船舱隔离起来，这样如果一个船舱破了进水，只损失一个船舱，其它船舱可以不受影响，而借鉴造船行业的经验，这种模式也在软件行业得到使用。\n\n线程隔离(Thread Isolation)就是这种模式的常见的一个场景。例如，系统A调用了ServiceB/ServiceC/ServiceD三个远程服务，且部署A的容器一共有120个工作线程，采用线程隔离机制，可以给对ServiceB/ServiceC/ServiceD的调用各分配40个线程。当ServiceB慢了，给ServiceB分配的40个线程因慢而阻塞并最终耗尽，线程隔离可以保证给ServiceC/ServiceD分配的80个线程可以不受影响。如果没有这种隔离机制，当ServiceB慢的时候，120个工作线程会很快全部被对ServiceB的调用吃光，整个系统会全部慢下来，甚至出现系统停止响应的情况。\n\n这种Case在我们实践中经常遇到，如某接口由于数据库慢查询，外部RPC调用超时导致整个系统的线程数过高，连接数耗尽等。我们可以使用舱壁隔离模式，为这种依赖服务调用维护一个小的线程池，当一个依赖服务由于响应慢导致线程池任务满的时候，不会影响到其他依赖服务的调用，它的缺点就是会增加线程数。\n\n![舱壁隔离模式](/assets/images/2016/11/11/service-fault-tolerant-mode/bulkhead.png)\n\n无论是超时/重试，熔断器，还是舱壁隔离模式，它们在使用过程中都会出现异常情况，异常情况的处理方式间接影响到用户的体验，针对异常情况的处理也有一种模式支撑，这就是回退(fallback)模式。\n\n## 回退(Fallback)\n\n在超时，重试失败，熔断或者限流发生的时候，为了及时恢复服务或者不影响到用户体验，需要提供回退的机制，常见的回退策略有：\n\n1.  自定义处理：在这种场景下，可以使用默认数据，本地数据，缓存数据来临时支撑，也可以将请求放入队列，或者使用备用服务获取数据等，适用于业务的关键流程与严重影响用户体验的场景，如商家/产品信息等核心服务。\n\n2.  故障沉默（fail-silent）：直接返回空值或缺省值，适用于可降级功能的场景，如产品推荐之类的功能，数据为空也不太影响用户体验。\n\n3.  快速失败（fail-fast）：直接抛出异常，适用于数据非强依赖的场景，如非核心服务超时的处理。\n\n# 应用实例\n\n在实际的工程实践中，这四种模式既可以单独使用，也可以组合使用，为了让读者更好的理解这些模式的应用，下面以Netflix的开源组件Hystrix的流程为例说明。\n\n![模式组合](/assets/images/2016/11/11/service-fault-tolerant-mode/patterns.png)\n\n图中流程的说明:\n\n1.  将远程服务调用逻辑封装进一个HystrixCommand。\n\n2.  对于每次服务调用可以使用同步或异步机制，对应执行execute()或queue()。\n\n3.  判断熔断器(circuit-breaker)是否打开或者半打开状态，如果打开跳到步骤8，进行回退策略，如果关闭进入步骤4。\n\n4.  判断线程池/队列/信号量（使用了舱壁隔离模式）是否跑满，如果跑满进入回退步骤8，否则继续后续步骤5。\n\n5.  run方法中执行了实际的服务调用。\n\n    a. 服务调用发生超时时，进入步骤8。\n\n6.  判断run方法中的代码是否执行成功。\n\n    a. 执行成功返回结果。\n\n    b. 执行中出现错误则进入步骤8。\n\n7.  所有的运行状态(成功，失败，拒绝，超时)上报给熔断器，用于统计从而影响熔断器状态。\n\n8.  进入getFallback()回退逻辑。\n\n    a. 没有实现getFallback()回退逻辑的调用将直接抛出异常。\n\n    b. 回退逻辑调用成功直接返回。\n\n    c. 回退逻辑调用失败抛出异常。\n\n9.  返回执行成功结果。\n\n# 总结\n\n服务容错模式在美团点评系统的稳定性保障方面应用很多，学习模式有助于新人直接利用熟练软件工程师的经验，对于提升系统的稳定性有很大的帮助。服务容错的目的主要是为了防微杜渐，除此之外错误的及时发现和监控其实同等重要。随着技术的演化，新的模式在不断的学习与实践中沉淀出来，美团点评度假技术团队在构建一个高可用高性能的系统目标之外，让系统越来越有弹性（Resilience）也是我们新的追求。\n\n# 参考文献\n\n1.  [Netflix Hystrix Wiki](https://github.com/Netflix/Hystrix/wiki)\n2.  Martin Fowler. [CircuitBreaker](http://martinfowler.com/bliki/CircuitBreaker.html)\n3.  Hanmer R. Patterns for Fault Tolerant Software. Wiley, 2007.\n4.  Nygard M. 发布！软件的设计与部署. 凃鸣 译. 人民邮电出版社, 2015.\n\n---\n\n* Author: 绿麟\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [服务容错模式](http://tech.meituan.com/service-fault-tolerant-pattern.html)","tags":["Design"],"categories":["Service"]},{"title":"Java NIO浅析","url":"%2F2016%2F2016-11-04-java-nio%2F","content":" \nNIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O处理问题的有效方式。\n\n那么NIO的本质是什么样的呢？它是怎样与事件模型结合来解放线程、提高系统吞吐的呢？\n\n本文会从传统的阻塞I/O和线程池模型面临的问题讲起，然后对比几种常见I/O模型，一步步分析NIO怎么利用事件模型处理I/O，解决线程池瓶颈处理海量连接，包括利用面向事件的方式编写服务端/客户端程序。最后延展到一些高级主题，如Reactor与Proactor模型的对比、Selector的唤醒、Buffer的选择等。\n\n注：本文的代码都是伪代码，主要是为了示意，不可用于生产环境。\n\n# 传统BIO模型分析\n\n让我们先回忆一下传统的服务器端同步阻塞I/O处理（也就是BIO，Blocking I/O）的经典编程模型：\n\n```java\n{\n  ExecutorService executor = Excutors.newFixedThreadPollExecutor(100);//线程池\n\n  ServerSocket serverSocket = new ServerSocket();\n  serverSocket.bind(8088);\n  while(!Thread.currentThread.isInturrupted()){//主线程死循环等待新连接到来\n    Socket socket = serverSocket.accept();\n    executor.submit(new ConnectIOnHandler(socket));//为新的连接创建新的线程\n  }\n}\n\nclass ConnectIOnHandler extends Thread{\n   private Socket socket;\n   public ConnectIOnHandler(Socket socket){\n      this.socket = socket;\n   }\n   public void run(){\n      while(!Thread.currentThread.isInturrupted()&&!socket.isClosed()){死循环处理读写事件\n         String someThing = socket.read()....//读取数据\n         if(someThing!=null){\n             ......//处理数据\n             socket.write()....//写数据\n         }\n      }\n   }\n}\n```\n\n这是一个经典的每连接每线程的模型，之所以使用多线程，主要原因在于socket.accept()、socket.read()、socket.write()三个主要函数都是同步阻塞的，当一个连接在处理I/O的时候，系统是阻塞的，如果是单线程的话必然就挂死在那里；但CPU是被释放出来的，开启多线程，就可以让CPU去处理更多的事情。其实这也是所有使用多线程的本质：\n\n1.  利用多核。\n2.  当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。\n\n现在的多线程一般都使用线程池，可以让线程的创建和回收成本相对较低。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的I/O并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。\n\n不过，这个模型最本质的问题在于，严重依赖于线程。但线程是很&quot;贵&quot;的资源，主要表现在：\n\n1.  线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。\n2.  线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。\n3.  线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。\n4.  容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。\n\n所以，当面对十万甚至百万级连接的时候，传统的BIO模型是无能为力的。随着移动端应用的兴起和各种网络游戏的盛行，百万级长连接日趋普遍，此时，必然需要一种更高效的I/O处理模型。\n\n# NIO是怎么工作的\n\n很多刚接触NIO的人，第一眼看到的就是Java相对晦涩的API，比如：Channel，Selector，Socket什么的；然后就是一坨上百行的代码来演示NIO的服务端Demo……瞬间头大有没有？\n\n我们不管这些，抛开现象看本质，先分析下NIO是怎么工作的。\n\n## 常见I/O模型对比\n\n所有的系统I/O都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。\n\n需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻塞是使用CPU的，真正在&quot;干活&quot;，而且这个过程非常快，属于memory copy，带宽通常在1GB/s级别以上，可以理解为基本不耗时。\n\n下图是几种常见I/O模型的对比：\n\n![](/assets/images/2016/11/04/java-nio/nio2.jpg)\n\n以socket.read()为例子：\n\n传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据。\n\n对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。\n\n最新的AIO(Async I/O)里面会更进一步：不但等待就绪是非阻塞的，就连数据从网卡到内存的过程也是异步的。\n\n换句话说，BIO里用户最关心“我要读”，NIO里用户最关心&quot;我可以读了&quot;，在AIO模型里用户更需要关注的是“读完了”。\n\nNIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）。\n\n## 如何结合事件模型使用NIO同步非阻塞特性\n\n回忆BIO模型，之所以需要多线程，是因为在进行I/O操作的时候，一是没有办法知道到底能不能写、能不能读，只能&quot;傻等&quot;，即使通过各种估算，算出来操作系统没有能力进行读写，也没法在socket.read()和socket.write()函数中返回，这两个函数无法进行有效的中断。所以除了多开线程另起炉灶，没有好的办法利用CPU。\n\nNIO的读写函数可以立刻返回，这就给了我们不开线程利用CPU的最好机会：如果一个连接不能读写（socket.read()返回0或者socket.write()返回0），我们可以把这件事记下来，记录的方式通常是在Selector上注册标记位，然后切换到其它就绪的连接（channel）继续进行读写。\n\n下面具体看下如何利用事件模型单线程处理所有I/O请求：\n\nNIO的主要事件有几个：读就绪、写就绪、有新连接到来。\n\n我们首先需要注册当这几个事件到来的时候所对应的处理器。然后在合适的时机告诉事件选择器：我对这个事件感兴趣。对于写操作，就是写不出去的时候对写事件感兴趣；对于读操作，就是完成连接和系统没有办法承载新读入的数据的时；对于accept，一般是服务器刚启动的时候；而对于connect，一般是connect失败需要重连或者直接异步调用connect的时候。\n\n其次，用一个死循环选择就绪的事件，会执行系统调用（Linux 2.6之前是select、poll，2.6之后是epoll，Windows是IOCP），还会阻塞的等待新事件的到来。新事件到来的时候，会在selector上注册标记位，标示可读、可写或者有连接到来。\n\n注意，select是阻塞的，无论是通过操作系统的通知（epoll）还是不停的轮询(select，poll)，这个函数是阻塞的。所以你可以放心大胆地在一个while(true)里面调用这个函数而不用担心CPU空转。\n\n所以我们的程序大概的模样是：\n\n```java\ninterface ChannelHandler{\n   void channelReadable(Channel channel);\n   void channelWritable(Channel channel);\n}\nlass Channel{\n   Socket socket;\n   Event event;//读，写或者连接\n}\n\n   //IO线程主循环:\nclass IoThread extends Thread{\n   public void run(){\n      Channel channel;\n      while(channel=Selector.select()){//选择就绪的事件和对应的连接\n         if(channel.event==accept){\n            registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器\n         }\n         if(channel.event==write){\n            getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件\n         }\n         if(channel.event==read){\n            getChannelHandler(channel).channelReadable(channel);//如果可以读，则执行读事件\n         }\n      }\n   }\n   Map<Channel，ChannelHandler> handlerMap;//所有channel的对应事件处理器\n}\n```\n\n这个程序很简短，也是最简单的Reactor模式：注册所有感兴趣的事件处理器，单线程轮询选择就绪事件，执行事件处理器。\n\n## 优化线程模型\n\n由上面的示例我们大概可以总结出NIO是怎么解决掉线程的瓶颈并处理海量连接的：\n\nNIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I/O操作都是纯CPU操作，没有必要开启多线程。\n\n并且由于线程的节约，连接数大的时候因为线程切换带来的问题也随之解决，进而为处理海量连接提供了可能。\n\n单线程处理I/O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I/O，无疑对效率会有更大的提高。\n\n仔细分析一下我们需要的线程，其实主要包括以下几种：\n\n1.  事件分发器，单线程选择就绪的事件。\n2.  I/O处理器，包括connect、read、write等，这种纯CPU操作，一般开启CPU核心个线程就可以。\n3.  业务线程，在处理完I/O后，业务一般还会有自己的业务逻辑，有的还会有其他的阻塞I/O，如DB操作，RPC等。只要有阻塞，就需要单独的线程。\n\nJava的Selector对于Linux系统来说，有一个致命限制：同一个channel的select不能被并发的调用。因此，如果有多个I/O线程，必须保证：一个socket只能属于一个IoThread，而一个IoThread可以管理多个socket。\n\n另外连接的处理和读写的处理通常可以选择分开，这样对于海量连接的注册和读写就可以分发。虽然read()和write()是比较高效无阻塞的函数，但毕竟会占用CPU，如果面对更高的并发则无能为力。\n\n![](/assets/images/2016/11/04/java-nio/reactor.png)\n\n# NIO在客户端的魔力\n\n通过上面的分析，可以看出NIO在服务端对于解放线程，优化I/O和处理海量连接方面，确实有自己的用武之地。那么在客户端上，NIO又有什么使用场景呢?\n\n常见的客户端BIO+连接池模型，可以建立n个连接，然后当某一个连接被I/O占用的时候，可以使用其他连接来提高性能。\n\n但多线程的模型面临和服务端相同的问题：如果指望增加连接数来提高性能，则连接数又受制于线程数、线程很贵、无法建立很多线程，则性能遇到瓶颈。\n\n## 每连接顺序请求的Redis\n\n对于Redis来说，由于服务端是全局串行的，能够保证同一连接的所有请求与返回顺序一致。这样可以使用单线程＋队列，把请求数据缓冲。然后pipeline发送，返回future，然后channel可读时，直接在队列中把future取回来，done()就可以了。\n\n伪代码如下：\n\n```java\nclass RedisClient Implements ChannelHandler{\n   private BlockingQueue CmdQueue;\n   private EventLoop eventLoop;\n   private Channel channel;\n   class Cmd{\n      String cmd;\n      Future result;\n   }\n   public Future get(String key){\n      Cmd cmd= new Cmd(key);\n      queue.offer(cmd);\n      eventLoop.submit(new Runnable(){\n         List list = new ArrayList();\n         queue.drainTo(list);\n         if(channel.isWritable()){\n            channel.writeAndFlush(list);\n         }\n      });\n   }\n   public void ChannelReadFinish(Channel channel，Buffer Buffer){\n      List result = handleBuffer();//处理数据\n      //从cmdQueue取出future，并设值，future.done();\n   }\n   public void ChannelWritable(Channel channel){\n      channel.flush();\n   }\n}\n```\n\n这样做，能够充分的利用pipeline来提高I/O能力，同时获取异步处理能力。\n\n## 多连接短连接的HttpClient\n\n类似于竞对抓取的项目，往往需要建立无数的HTTP短连接，然后抓取，然后销毁，当需要单机抓取上千网站线程数又受制的时候，怎么保证性能呢?\n\n何不尝试NIO，单线程进行连接、写、读操作？如果连接、读、写操作系统没有能力处理，简单的注册一个事件，等待下次循环就好了。\n\n如何存储不同的请求/响应呢？由于http是无状态没有版本的协议，又没有办法使用队列，好像办法不多。比较笨的办法是对于不同的socket，直接存储socket的引用作为map的key。\n\n## 常见的RPC框架，如Thrift，Dubbo\n\n这种框架内部一般维护了请求的协议和请求号，可以维护一个以请求号为key，结果的result为future的map，结合NIO+长连接，获取非常不错的性能。\n\n# NIO高级主题\n\n## Proactor与Reactor\n\n 一般情况下，I/O 复用机制需要事件分发器（event dispatcher）。 事件分发器的作用，即将那些读写事件源分发给各读写事件的处理者，就像送快递的在楼下喊: 谁谁谁的快递到了， 快来拿吧！开发人员在开始的时候需要在分发器那里注册感兴趣的事件，并提供相应的处理者（event handler)，或者是回调函数；事件分发器在适当的时候，会将请求的事件分发给这些handler或者回调函数。\n\n 涉及到事件分发器的两种模式称为：Reactor和Proactor。 Reactor模式是基于同步I/O的，而Proactor模式是和异步I/O相关的。在Reactor模式中，事件分发器等待某个事件或者可应用或个操作的状态发生（比如文件描述符可读写，或者是socket可读写），事件分发器就把这个事件传给事先注册的事件处理函数或者回调函数，由后者来做实际的读写操作。\n\n 而在Proactor模式中，事件处理者（或者代由事件分发器发起）直接发起一个异步读写操作（相当于请求），而实际的工作是由操作系统来完成的。发起时，需要提供的参数包括用于存放读到数据的缓存区、读的数据大小或用于存放外发数据的缓存区，以及这个请求完后的回调函数等信息。事件分发器得知了这个请求，它默默等待这个请求的完成，然后转发完成事件给相应的事件处理者或者回调。举例来说，在Windows上事件处理者投递了一个异步IO操作（称为overlapped技术），事件分发器等IO Complete事件完成。这种异步模式的典型实现是基于操作系统底层异步API的，所以我们可称之为“系统级别”的或者“真正意义上”的异步，因为具体的读写是由操作系统代劳的。\n\n 举个例子，将有助于理解Reactor与Proactor二者的差异，以读操作为例（写操作类似）。\n\n### 在Reactor中实现读\n\n*   注册读就绪事件和相应的事件处理器。\n*   事件分发器等待事件。\n*   事件到来，激活分发器，分发器调用事件对应的处理器。\n*   事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。\n\n### 在Proactor中实现读：\n\n*   处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。\n*   事件分发器等待操作完成事件。\n*   在分发器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分发器读操作完成。\n*   事件分发器呼唤处理器。\n*   事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分发器。\n\n可以看出，两个模式的相同点，都是对某个I/O事件的事件通知（即告诉某个模块，这个I/O操作可以进行或已经完成)。在结构上，两者也有相同点：事件分发器负责提交IO操作（异步)、查询设备是否可操作（同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下（Proactor)，当回调handler时，表示I/O操作已经完成；同步情况下（Reactor)，回调handler时，表示I/O设备可以进行某个操作（can read 或 can write)。\n\n下面，我们将尝试应对为Proactor和Reactor模式建立可移植框架的挑战。在改进方案中，我们将Reactor原来位于事件处理器内的Read/Write操作移至分发器（不妨将这个思路称为“模拟异步”），以此寻求将Reactor多路同步I/O转化为模拟异步I/O。以读操作为例子，改进过程如下：\n\n*   注册读就绪事件和相应的事件处理器。并为分发器提供数据缓冲区地址，需要读取数据量等信息。\n*   分发器等待事件（如在select()上等待）。\n*   事件到来，激活分发器。分发器执行一个非阻塞读操作（它有完成这个操作所需的全部信息），最后调用对应处理器。\n*   事件处理器处理用户自定义缓冲区的数据，注册新的事件（当然同样要给出数据缓冲区地址，需要读取的数据量等信息），最后将控制权返还分发器。\n如我们所见，通过对多路I/O模式功能结构的改造，可将Reactor转化为Proactor模式。改造前后，模型实际完成的工作量没有增加，只不过参与者间对工作职责稍加调换。没有工作量的改变，自然不会造成性能的削弱。对如下各步骤的比较，可以证明工作量的恒定：\n\n### 标准/典型的Reactor：\n\n*   步骤1：等待事件到来（Reactor负责）。\n*   步骤2：将读就绪事件分发给用户定义的处理器（Reactor负责）。\n*   步骤3：读数据（用户处理器负责）。\n*   步骤4：处理数据（用户处理器负责）。\n\n### 改进实现的模拟Proactor：\n\n*   步骤1：等待事件到来（Proactor负责）。\n*   步骤2：得到读就绪事件，执行读数据（现在由Proactor负责）。\n*   步骤3：将读完成事件分发给用户处理器（Proactor负责）。\n*   步骤4：处理数据（用户处理器负责）。\n对于不提供异步I/O API的操作系统来说，这种办法可以隐藏Socket API的交互细节，从而对外暴露一个完整的异步接口。借此，我们就可以进一步构建完全可移植的，平台无关的，有通用对外接口的解决方案。\n\n代码示例如下：\n\n```java\ninterface ChannelHandler{\n   void channelReadComplate(Channel channel，byte[] data);\n   void channelWritable(Channel channel);\n}\nclass Channel{\n   Socket socket;\n   Event event;//读，写或者连接\n}\n\n//IO线程主循环：\nclass IoThread extends Thread{\n   public void run(){\n      Channel channel;\n      while(channel=Selector.select()){//选择就绪的事件和对应的连接\n         if(channel.event==accept){\n            registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器\n            Selector.interested(read);\n         }\n         if(channel.event==write){\n            getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件\n         }\n         if(channel.event==read){\n            byte[] data = channel.read();\n            if(channel.read()==0){//没有读到数据，表示本次数据读完了\n               getChannelHandler(channel).channelReadComplate(channel，data;//处理读完成事件\n            }\n            if(过载保护){\n               Selector.interested(read);\n            }\n         }\n      }\n   }\n   Map<Channel，ChannelHandler> handlerMap;//所有channel的对应事件处理器\n}\n```\n\n### 主要作用\n\n解除阻塞在Selector.select()/select(long)上的线程，立即返回。\n\n两次成功的select之间多次调用wakeup等价于一次调用。\n\n如果当前没有阻塞在select上，则本次wakeup调用将作用于下一次select——“记忆”作用。\n\n为什么要唤醒？\n\n注册了新的channel或者事件。\n\nchannel关闭，取消注册。\n\n优先级更高的事件触发（如定时器事件），希望及时处理。\n\n### 原理\n\nLinux上利用pipe调用创建一个管道，Windows上则是一个loopback的tcp连接。这是因为win32的管道无法加入select的fd set，将管道或者TCP连接加入select fd set。\n\nwakeup往管道或者连接写入一个字节，阻塞的select因为有I/O事件就绪，立即返回。可见，wakeup的调用开销不可忽视。\n\n## Buffer的选择\n\n通常情况下，操作系统的一次写操作分为两步：\n\n1.  将数据从用户空间拷贝到系统空间。\n2.  从系统空间往网卡写。同理，读操作也分为两步：\n① 将数据从网卡拷贝到系统空间；\n② 将数据从系统空间拷贝到用户空间。\n\n对于NIO来说，缓存的使用可以使用DirectByteBuffer和HeapByteBuffer。如果使用了DirectByteBuffer，一般来说可以减少一次系统空间到用户空间的拷贝。但Buffer创建和销毁的成本更高，更不宜维护，通常会用内存池来提高性能。\n\n如果数据量比较小的中小应用情况下，可以考虑使用heapBuffer；反之可以用directBuffer。\n\n# NIO存在的问题\n\n使用NIO != 高性能，当连接数&lt;1000，并发程度不高或者局域网环境下NIO并没有显著的性能优势。\n\nNIO并没有完全屏蔽平台差异，它仍然是基于各个操作系统的I/O系统实现的，差异仍然存在。使用NIO做网络编程构建事件驱动模型并不容易，陷阱重重。\n\n推荐大家使用成熟的NIO框架，如Netty，MINA等。解决了很多NIO的陷阱，并屏蔽了操作系统的差异，有较好的性能和编程模型。\n\n# 总结\n\n最后总结一下到底NIO给我们带来了些什么：\n\n*   事件驱动模型\n*   避免多线程\n*   单线程处理多任务\n*   非阻塞I/O，I/O读写不再阻塞，而是返回0\n*   基于block的传输，通常比基于流的传输更高效\n*   更高级的IO函数，zero-copy\n*   IO多路复用大大提高了Java网络应用的可伸缩性和实用性\n\n本文抛砖引玉，诠释了一些NIO的思想和设计理念以及应用场景，这只是从冰山一角。关于NIO可以谈的技术点其实还有很多，期待未来有机会和大家继续探讨。\n\n# 作者简介\n\n王烨，现在是美团旅游后台研发组的RD，之前曾经在百度、去哪儿和优酷工作过，专注Java后台开发。对于网络编程和并发编程具有浓厚的兴趣，曾经做过一些基础组件，也翻过一些源码，属于比较典型的宅男技术控。期待能够与更多知己，在coding的路上并肩前行~\n\n---\n\n* Author: 王烨\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [Java NIO浅析](http://tech.meituan.com/nio.html)\n","tags":["NIO"],"categories":["Java"]},{"title":"自然语言处理","url":"%2F2016%2F2016-10-19-nlp%2F","content":"\n## 自然语言处理的简介\n\n首先，介绍一下什么是自然语言处理（也叫自然语言理解）：\n\n语言学家刘涌泉在《大百科全书(2002)》中对自然语言处理的定义为：“自然语言处理是人工智能领域的主要内容，即利用电子计算机等工具对人类所特有的语言信息（包括口语信息和文字信息）进行各种加工，并建立各种类型的人-机-人系统，自然语言理解是其核心，其中包括语音和语符的自动识别以及语音的自动合成。”\n\n从微观上讲，自然语言理解是指从自然语言到机器(计算机系统)内部之间的一种映射。\n\n从宏观上看，自然语言理解是指机器能够执行人类所期望的某些语言功能。这些功能包括：\n\n* 回答有关提问；计算机正确地回答用自然语言输入的有关问题\n* 提取材料摘要；机器能产生输入文本的摘要\n* 同词语叙述；机器能用不同的词语和句型来复述输入的自然语言信息\n* 不同语言翻译；机器能把一种语言翻译成另外一种语言\n\n## 自然语言处理的关键技术\n\n自然语言处理的关键技术包括：词法分析、句法分析、语义分析、语用分析和语句分析。\n\n### 词法分析\n\n词法分析的主要目的是从句子中切分出单词，找出词汇的各个词素，并确定其词义。\n\n词法分析包括词形和词汇两个方面。一般来讲，词形主要表现在对单词的前缀、后缀等的分析，而词汇则表现在对整个词汇系统的控制。在中文全文检索系统中，词法分析主要表现在对汉语信息进行词语切分，即汉语自动分词技术。通过这种技术能够比较准确的分析用户输入信息的特征，从而完成准确的搜索过程。它是中文全文检索技术的重要发展方向。\n\n不同的语言对词法分析有不同的要求，例如英语和汉语就有较大的差距\n\n汉语中的每个字就是一个词素，所以要找出各个词素是相当容易的，但要切分出各个词就非常难。\n\n如“我们研究所有东西”，可以是“我们—研究所—有—东西”也可是“我们—研究—所有—东西” 。\n\n英语等语言的单词之间是用空格自然分开的，很容易切分一个单词，因而很方便找出句子的每个词汇，不过英语单词有词性、数、时态、派生、变形等变化，因而要找出各个词素就复杂得多，需要对词尾和词头进行分析。如uncomfortable可以是un-comfort-able或uncomfort-able，因为un、comfort、able都是词素。\n\n### 句法分析\n\n句法分析是对用户输入的自然语言进行词汇短语的分析，目的是识别句子的句法结构，实现自动句法分析过程。其基本方法有线图分析法、短语结构分析、完全句法分析、局部句法分析、依存句法分析等。\n\n分析的目的就是找出词、短语等的相互关系以及各自在句子中的作用等，并以一种层次结构来加以表达。这种层次结构可以是从属关系、直接成分关系，也可以是语法功能关系。\n\n句法分析是由专门设计的分析器进行的，其分析过程就是构造句法树的过程，将每个输入的合法语句转换为一棵句法分析树。\n\n一个句子是由各种不同的句子成分组成的。这些成分可以是单词、词组或从句。句子成分还可以按其作用分为主语、谓语、宾语、宾语补语、定语、状语、表语等。这种关系可用一棵树来表示，如对句子： He wrote a book.\n\n可用图示的树型结构表示:\n\n![](/assets/images/2016/10/19/nlp/001.png)\n\n### 语义分析\n\n语义分析是基于自然语言语义信息的一种分析方法，其不仅仅是词法分析和句法分析这样语法水平上的分析，而是涉及到了单词、词组、句子、段落所包含的意义。其目的是从句子的语义结构表示言语的结构。中文语义分析方法是基于语义网络的一种分析方法。语义网络则是一种结构化的，灵活、明确、简洁的表达方式。\n\n### 语用分析\n\n语用分析相对于语义分析又增加了对上下文、语言背景、环境等的分析，从文章的结构中提取到意象、人际关系等的附加信息，是一种更高级的语言学分析。它将语句中的内容与现实生活的细节相关联，从而形成动态的表意结构。\n\n### 语境分析\n\n语境分析主要是指对原查询语篇以外的大量“空隙”进行分析从而更为正确地解释所要查询语言的技术。这些“空隙”包括一般的知识，特定领域的知识以及查询用户的需要等。它将自然语言与客观的物理世界和主观的心理世界联系起来，补充完善了词法、语义、语用分析的不足。\n\n## 自然语言处理的工具\n\n* OpenNLP\n\n   OpenNLP是一个基于Java机器学习工具包，用于处理自然语言文本。支持大多数常用的 NLP 任务，例如：标识化、句子切分、部分词性标注、名称抽取、组块、解析等。\n\n* FudanNLP\n\n   FudanNLP主要是为中文自然语言处理而开发的工具包，也包含为实现这些任务的机器学习算法和数据集。本工具包及其包含数据集使用LGPL3.0许可证。开发语言为Java。\n\n自然语言处理工具的主要功能有：\n\n1. 文本分类、新闻聚类\n2. 中文分词、词性标注、实体识别、关键词抽取、依存句法分析、时间短语识别\n3. 结构化学习、在线学习、层次分类、聚类、精确推理。\n\n## 自然语言处理的过程\n\n获取原始文本-文本预处理-分词-去停用词-特征选择-利用算法进行文本挖掘\n\n文本中起到关键作用的是一些词，甚至主要词就能起到决定文本取向，因此分词是中文文本处理比较重要的部分\n\n中文分词，出现了很多分词的算法，有最大匹配法、最优匹配法、机械匹配法、逆向匹配法、双向匹配法等。 \n\n中科院张华平博士研发的分词工具ICTCLAS，该算法经过众多科学家的认定是当今中文分词中最好的，并且支持用户自定义词典，加入词典；对新词，人名，地名等的发现也具有良好的效果。\n\n常见的分词工具有：word分词器、Ansj分词器、Stanford分词器、FudanNLP分词器、Jieba分词器、Jcseg分词器、MMSeg4j分词器、IKAnalyzer分词器、Paoding分词器、smartcn分词器、HanLP分词器等。\n\n在文本处理建模的预处理过程中，我们得到文本特征维度常常非常大，要得到一个好的模型，需要做两个工作:1、降维。模型的维度常常很大，这会加大模型的运行成本，并且不利于研究人员理解模型。2、去燥。维度很大时，特征之间会相互依赖，甚至很多特征对模型分类是有干扰作用的，去除这一部分特征将对模型有提升作用。特征选择和特征抽取都能完成上面的工作。\n\n在文本处理中常采用特征选择而非特征抽取， 原因是特征选择保持了特征原来的面貌，有利于挖掘人员理解模型。\n\n常见的特征选择算法有以下几种：\n\n* TF-IDF\n\n词频(TF)即为词在一篇文档中出现的频率。\n\n![](/assets/images/2016/10/19/nlp/002.png)\n\n其中T Ft，d表示词t在第d个文档的词频，nt表示词t在文档d出现的次数，Nd表示文档d 中词的总数。 \n\n逆向文档频率(IDF)值衡量词在某个文档中是否有代表性，其计算公式：\n\n![](/assets/images/2016/10/19/nlp/003.png)\n\n其中IDFt是词t的逆向文档频率，D是语料集的总文档数，Dt是包含t的文档数量，加 1是做平滑处理。\n\nTF-IDF是和标签无关的，这意味着计算过程是无监督的，由于TF-IDF无监督的特征，常常被用来表示文档向量空间模型的向量，从而能够运用于文档的相似度计算和关键词提取等。\n\n* 信息增益(Information Gain)\n\n信息增益是信息论中很重要的一个概念。在特征选择中，该方法主要是通过评估词项能够给分类带来多少的信息量，带来的信息量越大，说明该词项越重要。\n\n信息量，也就是熵。对于一个变量X，它可能的取值有n多种，分别是{x1 ，x2 ，...，xn }，每一种取到的概率分别是{p1 ，p2 ，...，pn }，那么X的熵就定义为：\n\n![](/assets/images/2016/10/19/nlp/004.png)\n\n* 互信息(Mutual Information)\n\n互信息是信息论中又一重要的概率，在文本处理中用来说明词t对于类别c的贡献程度，互信息越大则贡献程度越大。互信息计算是类别c关于t后验概率与先验概率的比值的 log。\n\n![](/assets/images/2016/10/19/nlp/005.png)\n\n准备工作完成后，就可以用各种算法进行挖掘，可以对文本、新闻等进行分类、聚类，可以利用KNN算法，朴素贝叶斯算法、决策树算法、神经网络法、线性最小二乘法、K-Means算法等算法。\n\n## 自然语言处理的应用\n\n自然语言处理的范围涉及众多方面，如语音的自动识别与合成，机器翻译，自然语言理解，人机对话，信息检索，文本分类，自动文摘，等等。\n\n这些大致可以归纳为如下四个大的方向：\n\n1. 语言学方向\n\n   它只研究语言及语言处理与计算相关的方面，而不管其在计算机上的具体实现。这个方向最重要的研究领域是语法形式化理论和数学理论。\n\n2. 数据处理方向\n\n   是把自然语言处理作为开发语言研究相关程序以及语言数据处理的学科来研究。这一方向早起的研究有属于数据库的建设、各种机器可读的电子词典的开发，近些年来则有大规模的语料库的涌现。\n\n3. 人工智能和认知科学方向\n\n   在这个方向，自然语言处理被作为在计算机上实现自然语言能力的学科来研究，探索自然语言理解的只能机制和认知机制。这一方向的研究与人工智能以及认知科学关系密切。\n\n4. 语言工程方向\n\n   主要是把自然语言处理作为面向实践的、工程化的语言软件开发来研究，这一方向的研究一般称为“人类语言技术”或者“语言工程”。\n\n## 推荐书籍\n\n《统计自然语言处理(宗成庆)》\n\n参考链接：[信息论：熵与互信息](http://blog.csdn.net/pipisorry/article/details/51695283)","tags":["NLP"],"categories":["NLP"]},{"title":"Categorized overview of Programming Principles & Patterns","url":"%2F2016%2F2016-10-15-programming-principles%2F","content":"\n \n# Programming Principles\n\nEvery programmer benefits from understanding programming principles and patterns. This overview is a reference for myself, and I've just put it here. Maybe it is of help to you during design, discussion, or review. Please note that it's far from complete, and that you often need to make trade-offs between conflicting principles.\n\nThe list was inspired by [The Principles of Good Programming](http://www.artima.com/weblogs/viewpost.jsp?thread=331531). I felt that the list closely, but not completely matches what I would personally put into something similar. Additionally, I wanted a bit more reasoning, details, and links to further resources. [Let me know](https://github.com/webpro/programming-principles/issues) if you have any feedback or suggestions for improvement.\n\n## Contents\n\n### Generic\n\n* [KISS (Keep It Simple Stupid)](#kiss)\n* [YAGNI](#yagni)\n* [Do The Simplest Thing That Could Possibly Work](#do-the-simplest-thing-that-could-possibly-work)\n* [Separation of Concerns](#separation-of-concerns)\n* [Keep Things DRY](#keep-things-dry)\n* [Code For The Maintainer](#code-for-the-maintainer)\n* [Avoid Premature Optimization](#avoid-premature-optimization)\n* [Boy-Scout Rule](#boy-scout-rule)\n\n### Inter-Module/Class\n\n* [Minimise Coupling](#minimise-coupling)\n* [Law of Demeter](#law-of-demeter)\n* [Composition Over Inheritance](#composition-over-inheritance)\n* [Orthogonality](#orthogonality)\n* [Robustness Principle](#robustness-principle)\n\n### Module/Class\n\n* [Maximise Cohesion](#maximise-cohesion)\n* [Liskov Substitution Principle](#liskov-substitution-principle)\n* [Open/Closed Principle](#openclosed-principle)\n* [Single Responsibility Principle](#single-responsibility-principle)\n* [Hide Implementation Details](#hide-implementation-details)\n* [Curly's Law](#curlys-law)\n* [Encapsulate What Changes](#encapsulate-what-changes)\n* [Interface Segregation Principle](#interface-segregation-principle)\n* [Command Query Separation](#command-query-separation)\n\n## KISS\n\nMost systems work best if they are kept simple rather than made complex.\n\nWhy\n\n* Less code takes less time to write, has less bugs, and is easier to modify.\n* Simplicity is the ultimate sophistication.\n* It seems that perfection is reached not when there is nothing left to add, but when there is nothing left to take away.\n\nResources\n\n* [KISS principle](http://en.wikipedia.org/wiki/KISS_principle)\n* [Keep It Simple Stupid (KISS)](http://principles-wiki.net/principles:keep_it_simple_stupid)\n\n## YAGNI\n\nYAGNI stands for \"you aren't gonna need it\": don't implement something until it is necessary.\n\nWhy\n\n* Any work that's only used for a feature that's needed tomorrow, means losing effort from features that need to be done for the current iteration.\n* It leads to code bloat; the software becomes larger and more complicated.\n\nHow\n\n* Always implement things when you actually need them, never when you just foresee that you need them.\n\nResources\n\n* [You Arent Gonna Need It](http://c2.com/xp/YouArentGonnaNeedIt.html)\n* [You’re NOT gonna need it!](http://www.xprogramming.com/Practices/PracNotNeed.html)\n* [You ain't gonna need it](http://en.wikipedia.org/wiki/You_ain't_gonna_need_it)\n\n## Do The Simplest Thing That Could Possibly Work\n\nWhy\n\n* Real progress against the real problem is maximized if we just work on what the problem really is.\n\nHow\n\n* Ask yourself: \"What is the simplest thing that could possibly work?\"\n\nResources\n\n* [Do The Simplest Thing That Could Possibly Work](http://c2.com/xp/DoTheSimplestThingThatCouldPossiblyWork.html)\n\n## Separation of Concerns\n\nSeparation of concerns is a design principle for separating a computer program into distinct sections, such that each section addresses a separate concern. For example the business logic of the application is a concern and the user interface is another concern. Changing the user interface should not require changes to business logic and vice versa.\n\nQuoting [Edsger W. Dijkstra](https://en.wikipedia.org/wiki/Edsger_W._Dijkstra) (1974):\n\n> It is what I sometimes have called \"the separation of concerns\", which, even if not perfectly possible, is yet the only available technique for effective ordering of one's thoughts, that I know of. This is what I mean by \"focusing one's attention upon some aspect\": it does not mean ignoring the other aspects, it is just doing justice to the fact that from this aspect's point of view, the other is irrelevant.\n\nWhy\n\n* Simplify development and maintenance of software applications.\n* When concerns are well-separated, individual sections can be reused, as well as developed and updated independently.\n\nHow\n\n* Break program functionality into separate modules that overlap as little as possible.\n\nResources\n\n* [Separation of Concerns](https://en.wikipedia.org/wiki/Separation_of_concerns)\n\n## Keep things DRY\n\nEvery piece of knowledge must have a single, unambiguous, authoritative representation within a system.\n\nEach significant piece of functionality in a program should be implemented in just one place in the source code. Where similar functions are carried out by distinct pieces of code, it is generally beneficial to combine them into one by abstracting out the varying parts.\n\nWhy\n\n* Duplication (inadvertent or purposeful duplication) can lead to maintenance nightmares, poor factoring, and logical contradictions.\n* A modification of any single element of a system does not require a change in other logically unrelated elements.\n* Additionally, elements that are logically related all change predictably and uniformly, and are thus kept in sync.\n\nHow\n\n* Put business rules, long expressions, if statements, math formulas, metadata, etc. in only one place.\n* Identify the single, definitive source of every piece of knowledge used in your system, and then use that source to generate applicable instances of that knowledge (code, documentation, tests, etc).\n* Apply the [Rule of three](http://en.wikipedia.org/wiki/Rule_of_three_(computer_programming)).\n\nResources\n\n* [Dont Repeat Yourself](http://c2.com/cgi/wiki?DontRepeatYourself)\n* [Don't repeat yourself](http://en.wikipedia.org/wiki/Don't_repeat_yourself)\n* [Don't Repeat Yourself](http://programmer.97things.oreilly.com/wiki/index.php/Don't_Repeat_Yourself)\n\nRelated\n\n* [Abstraction principle](http://en.wikipedia.org/wiki/Abstraction_principle_(computer_programming))\n* [Once And Only Once](http://c2.com/cgi/wiki?OnceAndOnlyOnce) is a subset of DRY (also referred to as the goal of refactoring).\n* [Single Source of Truth](http://en.wikipedia.org/wiki/Single_Source_of_Truth)\n* A violation of DRY is [WET](http://thedailywtf.com/articles/The-WET-Cart) (Write Everything Twice)\n\n## Code For The Maintainer\n\nWhy\n\n* Maintenance is by far the most expensive phase of any project.\n\nHow\n\n* *Be* the maintainer.\n* Always code as if the person who ends up maintaining your code is a violent psychopath who knows where you live.\n* Always code and comment in such a way that if someone a few notches junior picks up the code, they will take pleasure in reading and learning from it.\n* [Don't make me think](http://www.sensible.com/dmmt.html).\n* Use the [Principle of Least Astonishment](http://en.wikipedia.org/wiki/Principle_of_least_astonishment).\n\nResources\n\n* [Code For The Maintainer](http://c2.com/cgi/wiki?CodeForTheMaintainer)\n* [The Noble Art of Maintenance Programming](http://blog.codinghorror.com/the-noble-art-of-maintenance-programming/)\n\n## Avoid Premature Optimization\n\nQuoting [Donald Knuth](http://en.wikiquote.org/wiki/Donald_Knuth):\n\n> Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%.\n\n\nUnderstanding what is and isn’t \"premature\" is critical of course.\n\nWhy\n\n* It is unknown upfront where the bottlenecks will be.\n* After optimization, it might be harder to read and thus maintain.\n\nHow\n\n* [Make It Work Make It Right Make It Fast](http://c2.com/cgi/wiki?MakeItWorkMakeItRightMakeItFast)\n* Don't optimize until you need to, and only after profiling you discover a bottleneck optimise that.\n\nResources\n\n* [Program optimization](http://en.wikipedia.org/wiki/Program_optimization)\n* [Premature Optimization](http://c2.com/cgi/wiki?PrematureOptimization)\n\n## Minimise Coupling\n\nCoupling between modules/components is their degree of mutual interdependence; lower coupling is better. In other words, coupling is the probability that code unit \"B\" will \"break\" after an unknown change to code unit \"A\".\n\nWhy\n\n* A change in one module usually forces a ripple effect of changes in other modules.\n* Assembly of modules might require more effort and/or time due to the increased inter-module dependency.\n* A particular module might be harder to reuse and/or test because dependent modules must be included.\n* Developers might be afraid to change code because they aren't sure what might be affected.\n\nHow\n\n* Eliminate, minimise, and reduce complexity of necessary relationships.\n* By hiding implementation details, coupling is reduced.\n* Apply the [Law of Demeter](#law-of-demeter).\n\nResources\n\n* [Coupling](http://en.wikipedia.org/wiki/Coupling_(computer_programming))\n* [Coupling And Cohesion](http://c2.com/cgi/wiki?CouplingAndCohesion)\n\n## Law of Demeter\n\nDon't talk to strangers.\n\nWhy\n\n* It usually tightens coupling\n* It might reveal too much implementation details\n\nHow\n\nA method of an object may only call methods of:\n\n  1. The object itself.\n  1. An argument of the method.\n  1. Any object created within the method.\n  1. Any direct properties/fields of the object.\n\nResources\n\n* [Law of Demeter](http://en.wikipedia.org/wiki/Law_of_Demeter)\n* [The Law of Demeter Is Not A Dot Counting Exercise](http://haacked.com/archive/2009/07/14/law-of-demeter-dot-counting.aspx/)\n\n## Composition Over Inheritance\n\nWhy\n\n* Less coupling between classes.\n* Using inheritance, subclasses easily make assumptions, and break LSP.\n\nHow\n\n* Test for LSP (substitutability) to decide when to inherit.\n* Compose when there is a \"has a\" (or \"uses a\") relationship, inherit when \"is a\".\n\nResources\n\n* [Favor Composition Over Inheritance](http://blogs.msdn.com/b/thalesc/archive/2012/09/05/favor-composition-over-inheritance.aspx)\n\n## Orthogonality\n\n> The basic idea of orthogonality is that things that are not related conceptually should not be related in the system.\n\nSource: [Be Orthogonal](http://www.artima.com/intv/dry3.html)\n\n> It is associated with simplicity; the more orthogonal the design, the fewer exceptions. This makes it easier to learn, read and write programs in a programming language. The meaning of an orthogonal feature is independent of context; the key parameters are symmetry and consistency.\n\nSource: [Orthogonality](http://en.wikipedia.org/wiki/Orthogonality_(programming))\n\n## Robustness Principle\n\n> Be conservative in what you do, be liberal in what you accept from others\n\nCollaborating services depend on each others interfaces. Often the interfaces need to evolve causing the other end to receive unspecified data. A naive implementation refuses to collaborate if the received data does not strictly follow the specification. A more sophisticated implementation will still work ignoring the data it does not recognize.\n\nWhy\n\n* In order to be able to evolve services you need to ensure that a provider can make changes to support new demands while causing minimal breakage to their existing clients.\n\nHow\n\n* Code that sends commands or data to other machines (or to other programs on the same machine) should conform completely to the specifications, but code that receives input should accept non-conformant input as long as the meaning is clear.\n\nResources\n\n* [Robustness Principle in Wikipedia](https://en.wikipedia.org/wiki/Robustness_principle)\n* [Tolerant Reader](http://martinfowler.com/bliki/TolerantReader.html)\n\n## Maximise Cohesion\n\nCohesion of a single module/component is the degree to which its responsibilities form a meaningful unit; higher cohesion is better.\n\nWhy\n\n* Increased difficulty in understanding modules.\n* Increased difficulty in maintaining a system, because logical changes in the domain affect multiple modules, and because changes in one module require changes in related modules.\n* Increased difficulty in reusing a module because most applications won’t need the random set of operations provided by a module.\n\nHow\n\n* Group related functionalities sharing a single responsibility (e.g. in a class).\n\nResources\n\n* [Cohesion](http://en.wikipedia.org/wiki/Cohesion_(computer_science))\n* [Coupling And Cohesion](http://c2.com/cgi/wiki?CouplingAndCohesion)\n\n## Liskov Substitution Principle\n\nThe LSP is all about expected behavior of objects:\n\n> Objects in a program should be replaceable with instances of their subtypes without altering the correctness of that program.\n\nResources\n\n* [Liskov substitution principle](http://en.wikipedia.org/wiki/Liskov_substitution_principle)\n* [The Liskov Substitution Principle](http://freshbrewedcode.com/derekgreer/2011/12/31/solid-javascript-the-liskov-substitution-principle/)\n\n## Open/Closed Principle\n\nSoftware entities (e.g. classes) should be open for extension, but closed for modification. I.e. such an entity can allow its behavior to be modified without altering its source code.\n\nWhy\n\n* Improve maintainability and stability by minimizing changes to existing code.\n\nHow\n\n* Write classes that can be extended (as opposed to classes that can be modified).\n* Expose only the moving parts that need to change, hide everything else.\n\nResources\n\n* [Open Closed Principle](http://en.wikipedia.org/wiki/Open/closed_principle)\n* [SOLID JavaScript: The Open/Closed Principle](http://freshbrewedcode.com/derekgreer/2011/12/19/solid-javascript-the-openclosed-principle/)\n\n## Single Responsibility Principle\n\nA class should never have more than one reason to change.\n\nLong version: Every class should have a single responsibility, and that responsibility should be entirely encapsulated by the class. Responsibility can be defined as a reason to change, so a class or module should have one, and only one, reason to change.\n\nWhy\n\n* Maintainability: changes should be necessary only in one module or class.\n\nHow\n\n* Apply [Curly's Law](#Curly-s-Law).\n\nResources\n\n* [Single responsibility principle](http://en.wikipedia.org/wiki/Single_responsibility_principle)\n\n## Hide Implementation Details\n\nA software module hides information (i.e. implementation details) by providing an interface, and not leak any unnecessary information.\n\nWhy\n\n* When the implementation changes, the interface clients are using does not have to change.\n\nHow\n\n* Minimize accessibility of classes and members.\n* Don’t expose member data in public.\n* Avoid putting private implementation details into a class’s interface.\n* Decrease coupling to hide more implementation details.\n\nResources\n\n* [Information hiding](http://en.wikipedia.org/wiki/Information_hiding)\n\n## Curly's Law\n\nCurly's Law is about choosing a single, clearly defined goal for any particular bit of code: Do One Thing.\n\n* [Curly's Law: Do One Thing](http://blog.codinghorror.com/curlys-law-do-one-thing/)\n* [The Rule of One or Curly’s Law](http://fortyplustwo.com/2008/09/06/the-rule-of-one-or-curlys-law/)\n\n## Encapsulate What Changes\n\nA good design identifies the hotspots that are most likely to change and encapsulates them behind an API. When an anticipated change then occurs, the modifications are kept local.\n\nWhy\n\n* To minimize required modifications when a change occurs\n\nHow\n\n* Encapsulate the concept that varies behind an API\n* Possibly separate the varying concept into its own module\n\nResources\n\n* [Encapsulate the Concept that Varies](http://principles-wiki.net/principles:encapsulate_the_concept_that_varies)\n* [Encapsulate What Varies](http://blogs.msdn.com/b/steverowe/archive/2007/12/26/encapsulate-what-varies.aspx)\n* [Information Hiding](https://en.wikipedia.org/wiki/Information_hiding)\n\n## Interface Segregation Principle\n\nReduce fat interfaces into multiple smaller and more specific client specific interfaces. An interface should be more dependent on the code that calls it than the code that implements it. \n\nWhy\n\n* If a class implements methods that are not needed the caller needs to know about the method implementation of that class. For example if a class implements a method but simply throws then the caller will need to know that this method shouldn't actually be called.\n\nHow\n\n* Avoid fat interfaces. Classes should never have to implement methods that violate the [Single responsibility principle](#single-responsibility-principle).\n\nResources\n\n* [Interface segregation principle](https://en.wikipedia.org/wiki/Interface_segregation_principle)\n\n## Boy-Scout Rule\n\nThe Boy Scouts of America have a simple rule that we can apply to our profession: \"Leave the campground cleaner than you found it\". The boy-scout rule states that we should always leave the code cleaner than we found it.\n\nWhy\n\n* When making changes to an existing codebase the code quality tends to degrade, accumulating technical debt. Following the boyscout rule, we should mind the quality with each commit. Technical debt is resisted by continuous refactoring, no matter how small.\n\nHow\n\n* With each commit make sure it does not degrade the codebase quality.\n* Any time someone sees some code that isn't as clear as it should be, they should take the opportunity to fix it right there and then.\n\nResources\n\n* [Opportunistic Refactoring](http://martinfowler.com/bliki/OpportunisticRefactoring.html)\n\n## Command Query Separation\n\nThe Command Query Separation principle states that each method should be either a command that performs an action or a query that returns data to the caller but not both. Asking a question should not modify the answer.\n\nWith this principle applied the programmer can code with much more confidence. The query methods can be used anywhere and in any order since they do not mutate the state. With commands one has to be more careful.\n\nWhy\n\n* By clearly separating methods into queries and commands the programmer can code with additional confidence without knowing each method's implementation details.\n\nHow\n\n* Implement each method as either a query or a command\n* Apply naming convention to method names that implies whether the method is a query or a command\n\nResources\n\n* [Command Query Separation in Wikipedia](https://en.wikipedia.org/wiki/Command%E2%80%93query_separation)\n* [Command Query Separation by Martin Fowler](http://martinfowler.com/bliki/CommandQuerySeparation.html)\n\n参考链接：\n\n* [The Principles of Good Programming](http://www.artima.com/weblogs/viewpost.jsp?thread=331531)\n* [Categorized overview of Programming Principles & Patterns](https://github.com/webpro/programming-principles)\n\n---\n\n原文链接：[Programming Principles](http://webpro.github.io/programming-principles/)","tags":["Patterns"],"categories":["Programming"]},{"title":"地方政府财政税收收入预测模型经验","url":"%2F2016%2F2016-10-14-model-local-government-finance-tax-revenue%2F","content":"\n\n### 说明\n\n主要内容是基于某省财政项目的预测模型项目的一些经验和心得。\n\n### 税改历史\n\n该项目的大体背景是基于税费营改增后对地方财政收入的影响做出预测，是典型的通过大数据的方式和手段，解决政府问题的项目。\n\n先普及一下我国的税改历史，以便大家了解我们在做模型时所要考虑的问题的复杂性。\n\n* 1994年分税制施行，地方财权得到了确认。但在二十来年的地方财政管理实践中也出现了诸如区域不平衡和财政竞争等问题。对于公共财政管理者而言，实现对财政收入的精细化控制和预测，是稳定地方财政和经济发展的一项要务。\n* 2012年12月1日，在上海交通运输业和部分现代服务业开展营业税改征增值税试点。\n* 2012年8月1日起至年底，国务院将扩大营改增试点至北京、江苏、安徽、福建、广东、天津、浙江、湖北8省（市）；\n* 2013年8月1日，“营改增”范围已推广到全国试行，将广播影视服务业纳入试点范围。\n* 2014年1月1日起，将铁路运输和邮政服务业纳入营业税改征增值税试点，至此交通运输业已全部纳入营改增范围；\n* 2016年5月1日起，我国全面推开营改增试点，将建筑业、房地产业、金融业、生活服务业全部纳入营改增试点，至此，营业税退出历史舞台，增值税制度将更加规范。\n\n做预测建模，最重要的是需要有时间上连续的数据。可由于税制的改革，人为的造成了数据的不连续性和不完整性，在设计模型时，无形中增加了很大的难度。\n\n今年的“营改增”，更是造成了及其大的数据问题，对预测建模提出了新的挑战。\n\n“营改增”是指将以前缴纳营业税的应税项目改为缴纳增值税，仅对服务或者产品增值的一部分进行缴税，以减少重复缴税的情况。“营改增”的实行，完善了中国流转税的税制，有效解决了双重征税的问题，破解了混合销售、兼营造成的征管困境。“营改增”的实行使小规模纳税人税收减少明显，使一般纳税人税收略有下降；在对企业的结构和管理模式上也都有深刻影响。\n\n因此，在全国开展“营改增”的大环境下，企业、行业、政府都正在或开始经历一场崭新而深刻的变革。如何利用已有试点数据来把握政策改革带来的影响以及对未来进行预测，是当前政府与财税部门的一大痛点。\n\n发现了用户的痛点，解决痛点。\n\n下面简单介绍一下该项目的背景：\n\n某省为更加全面深入掌握市县财源信息，科学分析今后财政收入趋势，更加精准地发挥参谋职能，拟建设集财源信息采集、查询、分析、预测等功能为一体的市县财源库，为省级和市县财政决策提供支持。\n\n为实现其目标，该项目需要建设3大基础平台。\n\n1. 建立财源信息采集平台，实现各市县财政部门负责的财源信息定期录入以及省财政相关处室局部分信息补充录入或审核修改。\n2. 建立系统数据分析平台，能够根据需要，生成各类统计表或统计图，直观反映现阶段财源发展或收入增长变化情况。\n3. 建立财源收入预测平台，能够利用现成数据或预计数据，相对准确地预测今后一段时期收入增长趋势。\n\n有了这3大平台，就可以为数据分析与挖掘提供足够的弹药。\n\n依托上述“三大平台”，实现“三大功能”：\n\n1. 查询功能。根据用户的财源信息需求，即时获取重点企业各项指标数据信息，方便日常工作查询。\n2. 分析功能。便于财源信息数据分析利用，能够分市县、分产业、分行业、分规模分析收入增长或变化情况，科学合理监测财源发展。\n3. 预测功能。基于财源指标数据与收入增长之间的相关性分析，建立收入趋势预测分析模型，能够预测下一年度或今后一段时期财源变动或收入增长情况，为领导决策以及今后政策出台或调整提供参考。\n\n为实现上述“三大功能”需求，需要采集以下五类指标数据信息：\n\n1. 基本信息\n\n    主要包括：入库企业名称、地址、登记注册时间、法人代表、主营范围、所属产业、所属行业、分支机构、注册资本、员工人数等。\n\n2. 财务指标\n\n    主要包括入库企业资产、负债、营业收入、净利润、利润率、销售价格、主要原材料成本等。\n\n3. 税收指标\n\n    主要包括入库企业增值税、消费税、企业所得税、个人所得税、房产税、土地使用税、印花税、城建税、教育费附加等。\n\n4. 投入产出指标\n\n    主要包括入库企业投资额、工资及奖金、工时、主要原材料、能源（包括用电量）以及产品产量、销售量、销售收入、工业总增加值（总产值）等。\n\n5. 财政收入指标\n\n    主要包括全省以及各市县地方财政收入、税收收入、其他收入以及各税种收入情况等。\n\n在明确了项目的建设目标后，明确了所要解决的问题和理解了相应的数据字段信息后，我们变可以开始相应的建模工作了。\n\n由于财政经济系统运行于整个地区的国民经济环境之中，因此，在考虑财政指标的同时，模型还引入了一些财政系统以外的对财政指标变化影响较大的宏观经济指标作为外生变量，首先预测这些宏观指标，然后根据它们的发展趋势，以及与财政重要指标的关联程度来分析和确认财政财力系统主要指标预测的合理性。\n\n数据维度的增加对建模工作的开展是把双刃剑。维度多会导致维度灾难，难以发现数据特征。因此，我们采用了目前先进的组合预测建模方式去解决问题。既能实现较低维度数据的分析与挖掘，又要考虑数据在高维空间上的稀疏性特点。\n\n![](/assets/images/2016/10/14/model-local-government-finance-tax-revenue/001.jpg)\n\n将传统的时间序列分析，与机器学习的SVM和神经网络有效的结合在一起。完成建模工作。\n\n模型设计图最左边部分就是基于传统的时间序列分析和财政上常用的“基年法”进行的常规预测。\n\n由于增加了企业的财务数据信息和纳税信息，右侧部分是对传统分析预测方法所进行的修正。\n\n这套混合，组合建模方法也是目前世界先进的，解决大数据建模的方法。\n\n该预测模型在设计上实现了两个功能：\n\n1. 通过优化了的组合预测模型对财政收入总体及部分进行预测；\n2. 利用某省积累的部分营改增试点行业历史数据训练模型，对营改增全面实行后的影响进行估计与预测；\n\n全部模型设计分为四个步骤：\n\n1. 利用企业数据库数据，对不同行业不同税种的行业财源进行机器学习算法框架内的预测；\n2. 通过组合预测模型，对财政收入中的企业税收部分进行预测，并结合上一步结果进行修正；\n3. 通过组合预测模型，对企业税占财政收入比例进行预测，并结合上一步结果估计政府财政收入；\n4. 通过组合预测模型，对地方政府公共财政预算收入进行预测，并结合上一步结果进行优化。\n\n下面解释整个建模的思路：\n\n建模一定要有相关的理论基础和业务基础，会在稍后的叙述中将这些理论列出来。先普及一个概念，以便讲解建模思路。\n\n地方财政总收入（全口径，如北京市财政收入）= 地方财政收入+上划中央收入 = 地方一般预算财政收入 + 基金预算收入（包括政府性基金收入和社会保险基金收入）+ 上划中央收入（注：包含有基金收入的财政总收入叫做全口径财政收入，否则仅叫财政总收入。）\n\n所以财政收入，不仅仅是税收，还包括其他很多项内容。\n\n建模思路讲解正式开始：\n\n1. 财政收入数据是典型的时间序列型数据，且由于经济发展具有连续性，故采用计量经济学的时间序列分析方法对经济指标进行分析和预测是被理论和实践证实了的有效预测方法之一。为了优化预测结果，在时间序列模型（如指数平滑）之外，采用回归、SVM等算法建立组合预测模型。\n\n2. 由于财政收入数据量及维度较少，考虑使用企业税收预测对政府财政收入预测进行修正，理由如下：\n\na) 企业税收是政府财政收入的主要来源；\n\nb) 财源库内五类数据指标中有四类都与企业相关，数据量相对丰富，且粒度较细；\n\nc) 通过对企业所处细分行业的单项税收进行预测，引入更丰富的变量和机器学习算法，可以实现对预测模型更加精细化的调控；\n\n3. 对企业税收收入的预测：\n\na) 通过国家颁布的行业划分标准、税种分类标准、纳税属性、以及分类算法对每个行业内不同群组的不同税种进行细分，形成行业财源画像；\n\nb) 以行业财源画像属性数据、宏观经济数据、国际经济数据作为自变量，以行业财源数据作为因变量，进行模型构建。由于计划引入的数据维度较多，考虑采用SVM、神经网络等算法进行计算，并综合优化预测结果。\n\n4. 以组合预测模型对企业税的不同税种进行预测。由于“营改增”试行，对应行业营业税与增值税较以往会发生较大改变，通过拆分计算，可以更好地捕捉到税改对税收的影响。\n\n5. 使用由行业财源画像得出的预测结果对企业税各税种的预测进行优化。\n\n6. 以组合预测模型对企业税的财政占比进行预测。\n\n7. 结合企业税收预测和企业税的财政占比预测形成基于企业税的财政收入预测。\n\n8. 对组合预测模型计算的政府财政收入预测结果进行修正。\n\n基于上述思路所创建的模型，理论上经得起推敲。实践中也有相比常规方法更好的效果。\n\n所使用的数据科学理论基础如下：\n\n* 一些关于预测方法精确度回顾和调查指出，大部分关于预测方法研究的文献都认为简单的时间序列模型并不一定比复杂模型差。\n* 还有一些文献则认为不考虑数据趋势或者季节变化的移动自平均以及单指数平滑模型非常的好。\n* 因果分析法(包括回归分析)的一个最大优点在于它能够提供一种使政策制定者通过对收入预测过程以及预测方法的了解过程系统地掌握经济原理。\n* 支持向量机(Support Vector Machines, SVM)，在解决小样本、非线性及高维模式识别问题中表现出了许多特有的优势，并能够应用推广到函数拟合等其他机器学习问题中，支持向量机成功地解决了高维问题和局部极值问题。\n* 在经济系统预测中，包括在电力负荷预测中，组合预测模型的表现较单一预测模型效果要好。\n\n历史年度地方财政经济数据，所使用的数据介绍如下：\n\n* 地方财政收入指标数据\n\n主要包括：全省以及各市县地方财政收入、税收收入、其他收入以及各税种收入情况等。\n\n* 地方经济数据\n\n主要包括：人口数量、GDP、人均收入、住宅（新建/二手）每平米均价、商业地产每平米均价等。\n\n历史年度地方企业数据\n\n* 基本信息\n\n主要包括：入库企业名称、地址、登记注册时间、法人代表、主营范围、所属产业、所属行业、分支机构、注册资本、员工人数等。\n\n* 财务指标\n\n主要包括入库企业资产、负债、营业收入、净利润、利润率、销售价格、主要原材料成本等。\n\n* 税收指标\n\n主要包括入库企业增值税、消费税、企业所得税、个人所得税、房产税、土地使用税、印花税、城建税、教育费附加等。\n\n* 投入产出指标\n\n主要包括入库企业投资额、工资及奖金、工时、主要原材料、能源（包括用电量）以及产品产量、销售量、销售收入、工业总增加值（总产值）等。\n\n宏观经济数据\n\n主要包括：历史年度通货膨胀率、利率、全国GDP、全国人均收入、CPI、上证综指、深证综指等。\n\n国际经济数据\n\n主要包括：人民币对美元汇率、恒生指数、日经指数、道琼斯指数、纳斯达克指数等。\n\n所参考的政策类数据如下：\n\n    政策类数据\n    税制改革类政策\n    宏观调控类政策\n\n政策对预测模型的准确率影响很大，所以必须要考虑进去。\n\n该模型的主要创新点如下：\n\n* 以对企业税收的预测对财政收入预测进行优化；\n* 通过对行业财源进行细分及画像，可以引入更丰富的变量对企业的财源能力进行估计；\n* 通过引入宏观经济等政策性变量，可以较好地捕捉政策变化对某行业财源以及政府财政收入的影响；\n* 通过对企业税进行税种划分预测，可以较好地捕捉到税改（如“营改增”）对行业财源的影响，并为将来进一步积累数据优化模型留出拓展空间。\n\n该模型的设计也并不完美，会存在一定的潜在问题。但是我们也有相对应的解决方案。\n\n潜在问题和对策\n\n* 财政收入数据量较小。由于现行税制是1994年实行的，有效时间序列样本最多仅有21年数据（21条观测值）。即使通过机器学习方法对行业财源进行细分与模拟，在时间维度上的训练样本仍然有限。可以考虑根据城市或行业对企业进行分组，做交叉验证。\n* 在深入到行业层级的数据之后，实现了训练样本容量扩大的同时，也引入了额外的估计误差，而这种误差会在随后的计算中被累加。虽然通过有监督的学习方式，可以对误差进行控制，但时间维度上的数据有限性仍然会局限训练效果。由于SVM算法对小样本具有更好的适应性，在此考虑使用SVM进行模型建立，辅以人工神经网络算法。\n* 由于国家政策的改变或新政策的实行不具有重复性，故无法对模型就某项政策的影响效果进行组间训练。若模拟效果不好，考虑再向上一层，对全行业进行估计，以此对冲掉不同企业对政策的反馈情况。待新政实行较长时间后，积累了足够多的数据，再尝试深入研究。\n\n今后我们会尝试在更多领域进行组合建模的尝试。\n\n基于传统信息化信息孤岛的问题，以及计算能力不足的瓶颈，组合建模是相对合理的建模计算解决方法。\n\n既考虑目前的信息化硬件环境，也考虑大数据的计算能力。\n\n地方政府财政收入结构\n\n地方财政总收入（全口径，如北京市财政收入）= 地方财政收入+上划中央收入 = 地方一般预算财政收入 + 基金预算收入（包括政府性基金收入和社会保险基金收入）+ 上划中央收入（注：包含有基金收入的财政总收入叫做全口径财政收入，否则仅叫财政总收入。）\n \n地方一般预算财政收入：通过一定的形式和程序，有计划有组织并由国家支配的纳入预算管理的资金。包括：\n\n（1） 税收收入。国内增值税的25%、营业税、企业所得税（纳入分享范围的企业所得税的40%+未纳入分享范围企业全部所得税）、个人所得税的40%、资源税、城市维护建设税、房产税、印花税（证券印花税的3%+其余印花税的全部）、城镇土地使用税、土地增值税、车船税、耕地占用税、契税、烟叶税、其他税收收入。\n\n（2） 非税收入。专项收入、行政事业性收费收入、罚没收入、国有资本经营收入、国有资源有偿使用收入、其他收入。\n \n基金预算收入：指按规定收取，转入或通过当年财政安排，由财政管理并具有指定用途的政府性基金预算收入等。主要包括：工业交通部门、商贸部门、文教部门、农业部门、其他部门的基金收入和社会保障基金收入、地方财政税费附加收入、基金预算调拨收入等。\n \n行政区本级财政收入指的是行政区本级政府与下级政府之间经过分享、返还之后可供行政区本级政府支配的财政收入。如，北京市财政收入中还包含了下面区县的财政收入，北京市政府本级财政收入仅占其中的一部分。\n\n![](/assets/images/2016/10/14/model-local-government-finance-tax-revenue/002.jpg)\n\n企业税在地方政府一般预算财政收入中的角色\n\n由于我国改革开放，各地方经济的发展极不平衡。企业税在各地方政府的财政收入中所占比例跨度也非常大。目前没有统一的衡量标准和计量方法。非税收入在地方财政收入所占比重也相对不透明。以罚款，基金收入，土地出让金等方式所带来的财政收入，由于担心发布所带来的社会负面效应，一般不予公开。目前争议比较大，因此企业税在地方政府财政收入中所处的角色也不尽相同。\n\n财政学理论基础\n\n长期以来,我国对来年预算收入的制定都采用“基数法”,即以上年预算收入数作为基数,以一定的增长率来计算,并考虑一些特殊因素进行调整,而在对关键的增长率进行确定时,大多数地方政府都采取在GDP增长率基础上进行相应调整的方法。这种方法割裂了财政收入与经济系统各变量之间的复杂关系,并不能够客观地反映财政收入的数量,对政府预算制定的指导作用有限。因此,通过更合理、更科学的预测方法和技术,结合财政经济以及税收经济理论,建立相应的地方财政收入预测模型,获得更准确的预测数据,对于国家和地方政府编制合理的预算报告、进行宏观经济调控、监测税源稳定情况等都具有非常重要的意义和作用。\n\n这是我们在建模过程中所涉及到的一些理论基础和业务基础知识。\n","tags":["Model"],"categories":["Machine-Learning"]},{"title":"分布式会话跟踪系统架构设计与实践","url":"%2F2016%2F2016-10-14-distributed-session-tracking-system-architecture-design-and-practice%2F","content":"\n**本文整理自美团点评技术沙龙第08期：大规模集群的服务治理设计与实践。**\n\n美团点评技术沙龙由美团点评技术团队主办，每月一期。每期沙龙邀请美团点评及其它互联网公司的技术专家分享来自一线的实践经验，覆盖各主要技术领域。\n\n目前沙龙会分别在北京、上海和厦门等地举行，要参加下一次最新沙龙活动？赶快关注微信公众号“美团点评技术团队”。\n\n这期沙龙主要内容有：分布式服务通信框架及服务治理系统、分布式监控系统实践、分布式会话跟踪系统架构设计与实践，特邀美恰CTO讲解时下热门话题“微服务”。其中既包括关键系统设计、在美团点评内部的实践经验，也包括一些项目在业界开源的运营实践。\n\n# 前言\n\n随着美团点评的业务发展，公司的分布式系统变得越来越复杂，我们亟需一个工具能够梳理内部服务之间的关系，感知上下游服务的形态。比如一次请求的流量从哪个服务而来、最终落到了哪个服务中去？服务之间是RPC调用，还是HTTP调用？一次分布式请求中的瓶颈节点是哪一个，等等。\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace1.png)\n\n# 简介\n\nMTrace，美团点评内部的分布式会话跟踪系统，其核心理念就是调用链：通过一个全局的ID将分布在各个服务节点上的同一次请求串联起来，还原原有的调用关系、追踪系统问题、分析调用数据、统计系统指标。这套系统借鉴了2010年Google发表的一篇论文《dapper》，并参考了Twitter的Zipkin以及阿里的Eagle Eye的实现。\n\n那么我们先来看一下什么是调用链，调用链其实就是将一次分布式请求还原成调用链路。显式的在后端查看一次分布式请求的调用情况，比如各个节点上的耗时、请求具体打到了哪台机器上、每个服务节点的请求状态，等等。它能反映出一次请求中经历了多少个服务以及服务层级等信息（比如你的系统A调用B，B调用C，那么这次请求的层级就是3），如果你发现有些请求层级大于10，那这个服务很有可能需要优化了。\n\n## 网络优化\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace2.png)\n\n如上图所示，红框内显示了一次分布式请求经过各个服务节点的具体IP，通过该IP就可以查询一次分布式请求是否有跨机房调用等信息，优化调用链路的网络结构。\n\n## 瓶颈查询\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace3.png)\n\n再比如上图，红框部分显示的是系统调用的瓶颈节点，由于该节点的耗时，导致了整个系统调用的耗时延长，因此该节点需要进行优化，进而优化整个系统的效率。这种问题通过调用链路能很快发现下游服务的瓶颈节点；但是假如没有这样的系统，我们会怎样做呢？首先我会发现下游服务超时造成了我的服务超时，这时我会去找这个下游服务的负责人，然后该负责人发现也不是他自己服务的问题，而是他们调用了其他人的接口造成的问题，紧接着他又去找下游的服务负责人。我们都知道跨部门之间的沟通成本很高的，这么找下去会花费大量的不必要时间，而有了MTrace之后，你只需要点开链路就能发现超时问题的瓶颈所在。\n\n## 优化链路\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace4.png)\n\n我们再来看下上面这张图，红框部分都是同一个接口的调用，一次请求调用相同的接口10几次甚至是几十次，这是我们不想看到的事情，那么整个系统能不能对这样的请求进行优化，比如改成批量接口或者提高整个系统调用的并行度？在美团点评内部我们会针对这样的链路进行筛选分析，然后提供给业务方进行优化。\n\n## 异常log绑定\n\n通过MTrace不仅能做上述这些事情，通过它的特性，还能携带很多业务感兴趣的数据。因为MTrace可以做到数据和一次请求的绑定以及数据在一次请求的网络中传递。比如一些关键的异常log，一般服务的异常log很有可能是因为上游或者下游的异常造成的，那就需要我们手动地对各个不同服务的异常log做mapping。看这次的异常log对应到上游服务的哪个log上，是不是因为上游传递的一些参数造成了该次异常？而通过MTrace就可以将请求的参数、异常log等信息通过traceId进行绑定，很容易地就把这些信息聚合到了一起，方便业务端查询问题。\n\n## 透明传输数据\n\n业务端往往有这样的需求，它希望一些参数能在一次分布式请求一直传递下去，并且可以在不同的RPC中间件间传递。MTrace对该类需求提供了两个接口：\n\n```\nput(map<String, String> data)\nputOnce(map<String, String> data)\n```\n\n* put 接口：参数可以在一次分布式请求中一直传递。\n* putOnce 接口：参数在一次分布式请求中只传递一级。\n\n如下图所示\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace5.png)\n\n* 左侧绿色部分是put接口，service中调用了put接口传递了uid=123456这个参数，它会在网络中一直传递，可以在服务A中通过get(&quot;uid&quot;)的方式获取参数值，也可以在服务C中通过get(&quot;uid&quot;)的方式获取参数值。\n* 右侧蓝色部分是putOnce接口，service中调用了putOnce接口传递pid=11111，它只会传递一级，可以在服务B中通过get(&quot;pid&quot;)的方式获取参数值，但是在服务D中就获取不到pid的值了。\n\n以上的两种接口可以用于业务自定义传递数据，比如通过传递一个服务标识，用于AB test，下游的所有服务获取到test的标识就会走test的策略，即上游服务可以传递一些参数，控制所有下游服务的逻辑。当然业务也可以通过该接口传递一些临时性的数据。\n\n# 系统架构\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace6.png)\n\n主要分为三层：数据埋点上报、数据收集计算、数据前端展示。\n\n## 基本概念\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace7.png)\n\n### traceId\n\n全局唯一，64位整数，用于标识一次分布式请求，会在RPC调用的网络中传递。\n\n### spanId\n\n签名方式生成:0, 0.1, 0.1.1, 0.2。用于标识一次RPC在分布式请求中的位置，比如0.2就是0节点服务调用的第二个服务。\n\n### annotation\n\n业务端自定义埋点，业务感兴趣的想上传到后端的数据，比如该次请求的用户ID等。\n\n## 数据埋点\n\n### 埋点SDK\n\n提供统一的SDK，在各个中间件中埋点，生成traceID等核心数据，上报服务的调用数据信息。\n\n* 生成调用上下文；\n* 同步调用上下文存放在ThreadLocal, 异步调用通过显式调用API的方式支持；\n* 网络中传输关键埋点数据，用于中间件间的数据传递，支持Thrift, HTTP协议。\n\n业内有些系统是使用注解的方式实现的埋点，这种方式看似很优雅，但是需要业务方显式依赖一些AOP库，这部分很容易出现问题，因为AOP方式太过透明，导致查问题很麻烦，而且业务方配置的东西越多越容易引起一些意想不到的问题，所以我们的经验是尽量在各个统一的中间件中进行显式埋点，虽然会导致代码间耦合度增加，但是方便后续定位问题。其次，为了整个框架的统一，MTrace并非仅支持Java一种语言，而AOP的特性很多语言是不支持的。\n\nAgent\n\n* 透传数据，用作数据转发；\n* 做流量控制；\n* 控制反转，很多策略可以通过agent实现，而不需要每次都升级业务代码中的SDK。\n\nAgent仅仅会转发数据，由Agent判断将数据转发到哪里，这样就可以通过Agent做数据路由、流量控制等操作。也正是由于Agent的存在，使得我们可以在Agent层实现一些功能，而不需要业务端做SDK的升级，要知道业务端SDK升级的过程是很缓慢的，这对于整个调用链的系统来说是不可接受的，因为MTrace整个系统是针对庞大的分布式系统而言的，有一环的服务缺失也会造成一定的问题。\n\n目前MTrace支持的中间件有:\n\n* 公司内部RPC中间件\n* http中间件\n* mysql中间件\n* tair中间件\n* mq中间件\n\n### 数据埋点的四个阶段：\n\n* Client Send: 客户端发起请求时埋点，需要传递一些参数，比如服务的方法名等\n\n```java\nSpan span = Tracer.clientSend(param);\n```\n\n* Server Recieve: 服务端接收请求时埋点，需要回填一些参数，比如traceId，spanId\n\n```java\nTracer.serverRecv(param);\n```\n\n* ServerSend: 服务端返回请求时埋点，这时会将上下文数据传递到异步上传队列中\n\n```java\nTracer.serverSend();\n```\n\n* Client Recieve: 客户端接收返回结果时埋点，这时会将上下文数据传递到异步上传队列中\n\n```java\nTracer.clientRecv();\n```\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace8.png)\n\n### 埋点上下文\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace9.png)\n\n上图CS、SR为创建上下文的位置，CR、SS为归档上下文的位置。\n\n### 上下文归档\n\n上下文归档，会把上下文数据异步上传到后端，为了减轻对业务端的影响，上下文上报采用的是异步队列的方式，数据不会落地，直接通过网络形式传递到后端服务，在传递之前会对数据做一层压缩，主要是压缩比很可观，可以达到10倍以上，所以就算牺牲一点CPU资源也是值得的。具体上报的数据如图所示：\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace10.png)\n\n我们之前在数据埋点时遇到了一些问题：\n\n* 异步调用\n\n  * 异步IO造成的线程切换，不能通过ThreadLocal传递上下文。\n  * 显式的通过API进行埋点传递，切换前保存，切换后还原。\n  * 提供封装好的ThreadPool库。\n\n* 数据量大，每天千亿级别的数据\n\n  * 批量上报\n  * 数据压缩\n  * 极端情况下采样\n\n## 数据存储\n\n### Kafka使用\n\n我们在SDK与后端服务之间加了一层Kafka，这样做既可以实现两边工程的解耦，又可以实现数据的延迟消费。我们不希望因为瞬时QPS过高而引起的数据丢失，当然为此也付出了一些实效性上的代价。\n\n### 实时数据Hbase\n\n调用链路数据的实时查询主要是通过Hbase，使用traceID作为RowKey，能天然的把一整条调用链聚合在一起，提高查询效率。\n\n### 离线数据Hive\n\n离线数据主要是使用Hive，可以通过SQL进行一些结构化数据的定制分析。比如链路的离线形态，服务的出度入度(有多少服务调用了该服务，该服务又调用了多少下游服务)\n\n## 前端展示\n\n前端展示，主要遇到的问题是NTP同步的问题，因为调用链的数据是从不同机器上收集上来的，那么聚合展示的时候就会有NTP时间戳不同步的问题，这个问题很难解决，于是我们采取的方式是前端做一层适配，通过SpanId定位调用的位置而不是时间，比如0.2一定是发生在0.1这个Span之后的调用，所以如果时间出现漂移，就会根据SpanId做一次校正。即判断时间顺序的优先级为最高是spanid,然后是时间戳。\n\n# 总结\n\n核心概念：调用链；\n\n用途：定位系统瓶颈，优化系统结构、统计系统指标、分析系统数据；\n\n架构：埋点上报、收集计算、展示分析。\n\n分布式会话跟踪系统主要的特点就是能关联服务之间的联动关系，通过这层关系可以延伸出来很多有意义的分析数据，统计数据。为优化系统结构，查询系统瓶颈问题带来了极大的便利。\n \n---\n\n* 原文链接：[分布式会话跟踪系统架构设计与实践](http://tech.meituan.com/mt-mtrace.html)\n","tags":["Tracking"],"categories":["Distributed"]},{"title":"深入浅出解析大数据Lambda架构","url":"%2F2016%2F2016-10-10-bigdata-lambda-framework%2F","content":"\n## 前言\n\nHadoop的出现让人们尝到了大数据技术的甜头，它的批处理能力已经被工业界充分认可，但是它的延迟性也一直为大家所诟病。随着各行各业的发展，越来越多的业务要求大数据系统既可以处理历史数据，又可以进行实时计算。比如电商推荐系统，当你在京东浏览商品时，京东会根据你的浏览、加车、收藏、删除等行为，实时为你推荐商品。要实现这个功能，推荐引擎首先需要根据历史数据预先离线计算推荐模型，然后从消息队列中实时拉取用户行为数据，结合两者，实时生成推荐结果。\n\n再举一个智慧交通系统的例子。在智慧交通系统中，需要对未年检、未报废等危险车辆进行实时预警，这就要求该系统预先根据历史数据删选出未年检或未报废的车辆信息库，然后将道路上实时获取到的车辆信息与车辆信息库进行对比，判断有没有违章车辆。\n\n面对这样复杂的业务需求，开发者首先需要一个比较好的架构设计思路，在架构设计完成后再做相应的技术选型。目前业界有几个知名的架构设计来处理此类需求，如Lambda和Summingbird，但是它们在架构的设计上又有比较大的不同。就目前而言，Summingbird和Lambda架构都考虑到了实时计算和批处理相结合的问题，只不过Summingbird主张以统一的方式来执行代码，有关两者的区别，大家可以自行上网了解一下，这里我们只讨论Lambda架构。\n\n## 背景介绍\n\nLambda架构是Nathan Marz提出的一个实时大数据处理框架。Nathan Marz是著名的实时大数据处理框架Storm的作者，Lambda架构就是其根据多年分布式大数据系统的经验总结提炼而成。\n\nNathan Marz 在Big Data:Principles and best practices of scalable real-time data systems一书中提到了很多实时大数据系统的关键特性，包括容错性，健壮性，低延迟，可扩展，通用性，方便查询等，Lambda就是其根据这些特性设计的一个实时大数据框架。需要注意的是，Lambda并不是一个具有实体的软件产品，而是一个指导大数据系统搭建的架构模型，因此，用户可以根据自己的需要，在Lambda的三层模型中，任意集成Hadoop，Kafka，Storm，Spark，Hbase等各类大数据组件，或者选用商用软件来构建系统。\n\n## 原理讲解\n\n### 大数据系统的特性\n\n在讲大数据系统的特性之前，我们先来分析一下数据系统的本质。\n\nNathan Marz认为，数据系统的本质是“查询+数据”，用公式表达如下：\n\n```\nQuery = Function ( All Data )\n```\n\n数据系统其实是一个提供了数据存储和数据查询功能的系统。在数据存储过程中，数据可能会发生丢失，在数据查询的过程中，查询也可能出现错误，因此，数据系统必须能够应对这些问题，这就是我们所说的数据系统的容错性和健壮性。除此之外，随着数据的规模越来越大，查询越来越复杂，我们希望数据系统是易于扩展的，并且是可维护的，最好查询仍然是低延迟的，至此，我们就可以来总结一下大数据系统的关键特性了，具体如下：  \n\n1. 容错性和健壮性：对于分布式系统来说，保证人为操作不出错，程序也不出错是不可能的，因此，大数据系统必须对这样的错误有足够的适应能力。\n2. 低延迟：很多应用对于读和写操作的延时要求非常高，要求对更新和查询的响应是低延时的。\n3. 横向扩容：当数据量/负载增大时，系统可以采用scale out（通过增加机器的个数），而不是scale up（通过增强机器的性能）来维持性能。\n4. 可扩展：当系统需要增加一些新功能或者新特性时，所花费的代价比较小。\n5. 方便查询：数据系统的本质是“查询+数据”，因此，数据系统应具备方便、快速的数据查询功能。\n6. 易于维护：系统要想做到易于维护，其关键是控制其复杂性，越是复杂的系统越容易出错、越难维护。\n\n### Lambda架构的三层模型\n\n前面提到，Query = Function(All Data)，那么大数据系统的关键问题就变成了：如何实时地在任意大数据集上进行查询？如果单纯地对全体数据集进行在线查询，那么计算代价会很大，延迟也会很高，比如Hadoop。\n\nLambda的做法是将大数据系统架构拆分成了三层：Batch Layer，Speed Layer和Serving Layer。Lambda的分层结构图如图1所示：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/001.jpg)\n\n图1  Lambda分层结构图\n\n#### a. Batch Layer  \n\n既然对全体数据集进行在线查询，计算代价会很高，那么如果对查询事先进行预计算，生成对应的Views，并且对Views建立索引，这样，查询的速度会提高很多，这就是Batch Layer所做的事。\n\nBatch Layer层采用不可变模型对所有数据进行了存储，并且根据不同的业务需求，对数据进行了不同的预查询，生成对应的Batch Views，这些Batch Views提供给上层的Serving Layer进行进一步的查询。另外，每隔一段时间都会进行一次预查询，对Batch Views进行更新，Batch Views更新完成后，会立即更新到Serving Layer中去。\n\n预查询的过程是一个批处理的过程，因此，这一层可以选择诸如Hadoop这样的组件。Batch Layer层的结构图如图2所示：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/002.jpg)\n\n图2  Batch Layer结构图\n\n#### b. Speed Layer\n\n如上一节中提到，预查询的过程是一个批处理的过程，该过程花费的时间会比较长，在该过程中，Serving Layer使用的仍然是旧版本的Batch Views，那么仅仅依靠Batch Layer这一层，新进入系统的数据将无法参与最后结果的计算，因此，Marz为Lambda设计了Speed Layer层来处理增量的实时数据。\n\nSpeed Layer和Batch Layer比较类似，对数据计算生成Realtime Views，其主要的区别是：\n\n第一，Speed Layer处理的数据是最近的增量数据流，Batch Layer处理的是全体数据集。\n\n第二，Speed Layer为了效率，接收到新数据时，就更新Realtime Views，并且采用的是Incremental Updates（增量计算模型），而Batch Layer则是根据全体离线数据集得到Batch Views，采用的是Recomputation Updates（重新计算模型）。\n\n#### c. Serving Layer\n\nServing Layer用于响应用户的查询请求，它将Batch Views和Realtime Views的结果进行了合并，得到最后的结果，返回给用户，图3给出了Lambda的整体架构图：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/003.jpg)\n\n图3  Lambda架构图\n\n概括起来，Lambda架构通过Batch Layer和Speed Layer的分层设计来实现在一个系统内同时支持实时和批处理业务，并且通过Serving Layer在逻辑上统一了两种数据源的接口，让应用能够以一个统一的数据视图来开发和部署，从而达到数据和应用的融合。\n\n在每个Layer的实际设计中，开发人员可以根据自身的需求来选择合适的组件或者产品来构建相应的系统，目前有很多开源组件可以用于构建此类系统，如Storm/Spark Streaming/Flink可以用来构建Speed Layer，Spark/MapReduce可以用于构建Batch Layer，HBase/Redis/MongoDB可以用于存储。\n\n由于一套系统需要同时处理实时业务和批处理业务，并且两批业务之间有比较明确的数据耦合，Lambda系统本身的技术复杂度非常高，选择方案的时候需要充分考虑系统构建成本以及稳定性。从笔者了解的情况看，选择开源技术来构建类似系统，目前国内只有很少的成功商业实践。对于技术实力不那么强的企业，选择一个可靠的商业软件往往是个更合适的选择。星环科技在这方面有非常不错的成功经验，结合着Transwarp Data Hub的技术优势，我们帮助客户在智慧交通系统领域完成了非常大规模的实际业务部署。下文我们将以某一个项目来做具体的案例分析，来描述如何使用TDH来完成一个用于大规模生产业务的Lambda系统。\n\n## 案例分析\n\n本案例为某省的智慧交通系统。\n\n### 系统各层组件的选型\n\n根据上面的介绍，Lambda架构包括三层，其中Batch Layer负责数据集的存储和批处理的执行，数据存储我们选择Hyperbase。Hyperbase支持快速高并发的查询，可以方便用户做一些精确类查询（如根据车牌号检索等）。由于此项目还有一些统计类的业务需求，我们选择将部分数据在HDFS上保留一份用作后期的分析之用，Inceptor的强大的数据分析能力可以帮助用户在任意维度上做复杂的数据分析工作。\n\nSpeed Layer主要负责对数据的实时处理，可以使用Transwarp Stream。此外，Kafka选择使用Transwarp Kafka 0.9版本，由于增加了Kafka队列内的kerberos安全认证功能，消息队列中的数据更安全。\n\nHDFS和Hyperbase的数据通过SQL以及JDBC接口开放给用户，企业可以开发Serving Layer中自身需要的业务。由于这些应用程序是具体的企业内部业务，此处不做讨论。\n\n### 系统各层机器规划\n\n有了上面的组件选型，下面我们可以进行机器规划。主要考虑的是以下几个方面：\n\n### 存储能力\n\n就某地市而言，每天约有1000w的过车记录产生，高峰时期每秒能约有1w条过车记录产生，每条过车记录对应的结构化数据约有30个字段，大小为200Byte；每天还有50w张左右大小约为500KB的图片数据，按照规划数据需要存储的周期为2年，因此对集群容量要求如下：\n\n结构化数据存储三份、图片数据存储两份，2年的数据总量约为：\n\n```\n(1000w * 200B *3  +  50 w * 500KB * 2) * 365 * 2  =  344TB\n```\n\n每台机器有8个硬盘，每个硬盘容量为3TB，则需要数据节点数为：\n\n```\n344TB / (3TB*8) = 15台\n```\n\n另外，Hadoop分布式存储集群需要2台管理节点。\n\n### 实时计算的需求\n\n目前需要进行实时处理的业务包括：\n\na. 实时检测业务：逾期未年检、黑名单、逾期未报废、凌晨2点到5点上路行驶的客运车辆、车主驾驶证无效车辆等。\n\nb. 实时分析业务：包括流量统计、旅行时间分析、套牌车检测、区间测速等。\n\n其中实时检测业务以及套牌车检测等要求在秒级别反馈结果以对违法行为进行实时拦截；分析业务要求在分钟级别更新结果。\n\n按照每秒1w条过车记录计算，总共有20+个流处理业务（比对和复杂分析）同时运行，预估需要实时处理集群机器6台。\n\n另外，所有的过车记录都会预先被接入Kafka分布式消息处理集群，每条记录写入3份，保存7天，预估需要Kafka集群机器4台。\n\n### 批处理分析要求\n\n除了实时处理业务之外，还需要对历史数据进行统计分析，对于时间跨度在一个月内的统计分析需要在秒级返回结果；对于时间跨度在三个月以上的复杂统计分析需要在分钟级别返回结果。   \n\n依据上述的要求分析，给出机器数目和配置参考图如下：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/004.jpg)\n\n图4 某智能交通系统的配置情况\n\n### 系统架构\n\n该智慧交通系统的架构图如图5所示：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/005.jpg)\n\n图5  智能交通的整体架构图\n\n前端卡口会实时采集过往车辆信息，采集到的车辆信息首先被接入Kafka分布式消息总线。Kafka分布式消息总线，会对这些数据进行归类分拣，分发给不同的服务集群，比如实时入库服务集群、未年检车监控服务集群等。\n\n假设有部分数据被送入到了未年检车监控服务集群中，该集群需要将待检查车辆与车辆数据库进行数据比对。为了减少数据比对时间，该系统预先根据历史数据生成了未年检车辆数据库，由Batch Layer层的批处理引擎完成。待检查车辆只需与未年检车辆数据库进行在线比对即可，如果发现违章车辆，则进行标记显示，并进行预警。\n\n### 系统支持的业务\n\n#### 1. 实时监控预警任务\n\n实时监控预警业务主要由Speed Layer层的Transwarp Stream负责，按照技术可以分为以下三类：\n\na. ETL功能\n\n   将实时采集的过车数据，按照一定的清洗转化规则进行处理，转化成规范的记录后写入后端存储Hyperbase和 Holodesk。其中Hyperbase为持久化的列式存储，保存所有的历史过车数据；Holodesk为临时存储，提供高速的分析能力，可以保存一周以内的短期数据。\n\nb. 实时检测业务\n\n   最简单的检测规则可以直接根据过车记录判断，例如凌晨2点到5点行驶的车辆；其次是和一些基础表进行比对的业务，例如黑名单车辆/未年检车辆检测，需要事先进行预查询，生成并保存相应的黑名单车辆表/未年检车辆表。 \n\nc. 实时分析业务\n\n   实时统计业务如流量统计，通常基于窗口技术实现。例如需要统计分钟流量、小时流量，可以设定一个长度为1分钟的滚动窗口，统计每分钟的流量，并基于分钟流量对小时流量进行更新。\n\n### 2. 数据统计分析业务\n\na. 基于全量历史数据的统计分析\n\n   通过Inceptor组件能够对存储在Hyperbase中的数据使用SQL语句进行统计分析，比如统计一天的车流量，一个月的碰撞次数等。Hyperbase的Rowkey具有去重的功能，可以帮助用户得到精准的统计结果。\n\nb. 基于临时数据的交互式分析\n\n   除了一些固定的统计报表之外，还需要处理一些突发的临时性统计业务。例如伴随车分析，就是统计出一段时间内和某个车一同行驶的车辆，这在犯罪分析中有很大的作用。TDH中的Holodesk组件能够很好处理这部分业务需求，创建Holodesk上的一张有窗口限制的表（例如窗口长度为1周，超过1周的数据将被删除），通过Transwarp Stream将数据实时写入Holodesk，前端通过Inceptor的SQL实现交互式分析。\n\n## 结语\n\nLambda架构是大数据中一个非常重要的设计，但是由于原理的抽象和系统的复杂性，大数据从业人员要设计出一个有生产质量的Lambda系统是非常有挑战性的。本文通过原理的梳理和具体商业的剖析，希望给读者一个总体的思路，如何从无到有设计出一个有效的系统，同时满足实时和离线业务的需求，帮助企业从数据中创造更大的价值。\n\n---\n\n* Author: BigDater\n* Source: [微信公众号：大数据开放实验室](http://weixin.qq.com/r/mjvM1CPEGH5nrWe3926I)\n* Link: [深入浅出解析大数据Lambda架构](http://mp.weixin.qq.com/s?__biz=MzIzNzU0ODEwOA==&mid=2247483775&idx=1&sn=c482d1e788854f7ba83cdccc9f031ab9&chksm=e8c7a65cdfb02f4a3b482987dcad71423adb69c6a339df1f0dea8cbd29be878d93975ae1a3c2&scene=21#wechat_redirect)","tags":["Framework"],"categories":["Lambda"]},{"title":"分布式系统互斥性与幂等性问题的分析与解决","url":"%2F2016%2F2016-09-29-distributed-system-mutually-exclusive-idempotence-cerberus-gtis%2F","content":"\n### 前言\n\n随着互联网信息技术的飞速发展，数据量不断增大，业务逻辑也日趋复杂，对系统的高并发访问、海量数据处理的场景也越来越多。如何用较低成本实现系统的高可用、易伸缩、可扩展等目标就显得越发重要。为了解决这一系列问题，系统架构也在不断演进。传统的集中式系统已经逐渐无法满足要求，分布式系统被使用在更多的场景中。\n\n分布式系统由独立的服务器通过网络松散耦合组成。在这个系统中每个服务器都是一台独立的主机，服务器之间通过内部网络连接。分布式系统有以下几个特点：\n\n* 可扩展性：可通过横向水平扩展提高系统的性能和吞吐量。\n\n* 高可靠性：高容错，即使系统中一台或几台故障，系统仍可提供服务。\n\n* 高并发性：各机器并行独立处理和计算。\n\n* 廉价高效：多台小型机而非单台高性能机。\n\n然而，在分布式系统中，其环境的复杂度、网络的不确定性会造成诸如时钟不一致、“拜占庭将军问题”（Byzantine failure）等。存在于集中式系统中的机器宕机、消息丢失等问题也会在分布式环境中变得更加复杂。\n\n基于分布式系统的这些特征，有两种问题逐渐成为了分布式环境中需要重点关注和解决的典型问题：\n\n* 互斥性问题。\n\n* 幂等性问题。\n\n今天我们就针对这两个问题来进行分析。\n\n### 互斥性问题\n\n先看两个常见的例子：\n\n**例1**：某服务记录关键数据X，当前值为100。A请求需要将X增加200；同时，B请求需要将X减100。\n\n在理想的情况下，A先读取到X=100，然后X增加200，最后写入X=300。B请求接着从读取X=300，减少100，最后写入X=200。\n\n然而在真实情况下，如果不做任何处理，则可能会出现：A和B同时读取到X=100；A写入之前B读取到X；B比A先写入等等情况。\n\n**例2**：某服务提供一组任务，A请求随机从任务组中获取一个任务；B请求随机从任务组中获取一个任务。\n\n在理想的情况下，A从任务组中挑选一个任务，任务组删除该任务，B从剩下的的任务中再挑一个，任务组删除该任务。\n\n同样的，在真实情况下，如果不做任何处理，可能会出现A和B挑中了同一个任务的情况。\n\n以上的两个例子，都存在操作互斥性的问题。互斥性问题用通俗的话来讲，就是对共享资源的抢占问题。如果不同的请求对同一个或者同一组资源读取并修改时，无法保证按序执行，无法保证一个操作的原子性，那么就很有可能会出现预期外的情况。因此操作的互斥性问题，也可以理解为一个需要保证时序性、原子性的问题。\n\n在传统的基于数据库的架构中，对于数据的抢占问题往往是通过数据库事务（ACID）来保证的。在分布式环境中，出于对性能以及一致性敏感度的要求，使得分布式锁成为了一种比较常见而高效的解决方案。\n\n事实上，操作互斥性问题也并非分布式环境所独有，在传统的多线程、多进程情况下已经有了很好的解决方案。因此在研究分布式锁之前，我们先来分析下这两种情况的解决方案，以期能够对分布式锁的解决方案提供一些实现思路。\n\n#### 多线程环境解决方案及原理\n\n1. **解决方案**\n\n《Thinking in Java》书中写到：\n\n> 基本上所有的并发模式在解决线程冲突问题的时候，都是采用序列化访问共享资源的方案。\n\n在多线程环境中，线程之间因为公用一些存储空间，冲突问题时有发生。解决冲突问题最普遍的方式就是用互斥锁把该资源或对该资源的操作保护起来。\n\nJava JDK中提供了两种互斥锁Lock和synchronized。不同的线程之间对同一资源进行抢占，该资源通常表现为某个类的普通成员变量。因此，利用ReentrantLock或者synchronized将共享的变量及其操作锁住，即可基本解决资源抢占的问题。\n\n下面来简单聊一聊两者的实现原理。\n\n2. **原理**\n\n**ReentrantLock**\n\nReentrantLock主要利用CAS+CLH队列来实现。它支持公平锁和非公平锁，两者的实现类似。\n\n* CAS：Compare and Swap，比较并交换。CAS有3个操作数：内存值V、预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。该操作是一个原子操作，被广泛的应用在Java的底层实现中。在Java中，CAS主要是由sun.misc.Unsafe这个类通过JNI调用CPU底层指令实现。\n\n* CLH队列：带头结点的双向非循环链表(如下图所示)：\n\n![](/assets/images/2016/09/29/distributed-system-mutually-exclusive-idempotence-cerberus-gtis/clh_queue.png)\n\nReentrantLock的基本实现可以概括为：先通过CAS尝试获取锁。如果此时已经有线程占据了锁，那就加入CLH队列并且被挂起。当锁被释放之后，排在CLH队列队首的线程会被唤醒，然后CAS再次尝试获取锁。在这个时候，如果：\n\n* 非公平锁：如果同时还有另一个线程进来尝试获取，那么有可能会让这个线程抢先获取；\n\n* 公平锁：如果同时还有另一个线程进来尝试获取，当它发现自己不是在队首的话，就会排到队尾，由队首的线程获取到锁。\n\n下面分析下两个片段：\n\n```java\nfinal boolean nonfairTryAcquire(int acquires) {\n    final Thread current = Thread.currentThread();\n    int c = getState();\n    if (c == 0) {\n        if (compareAndSetState(0, acquires)) {\n            setExclusiveOwnerThread(current);\n            return true;\n        }\n    }\n    else if (current == getExclusiveOwnerThread()) {\n        int nextc = c + acquires;\n        if (nextc < 0) // overflow\n            throw new Error(\"Maximum lock count exceeded\");\n        setState(nextc);\n        return true;\n    }\n    return false;\n}\n```\n\n在尝试获取锁的时候，会先调用上面的方法。如果状态为0，则表明此时无人占有锁。此时尝试进行set，一旦成功，则成功占有锁。如果状态不为0，再判断是否是当前线程获取到锁。如果是的话，将状态+1，因为此时就是当前线程，所以不用CAS。这也就是可重入锁的实现原理。\n\n```java\nfinal boolean acquireQueued(final Node node, int arg) {\n    boolean failed = true;\n    try {\n        boolean interrupted = false;\n        for (;;) {\n            final Node p = node.predecessor();\n            if (p == head && tryAcquire(arg)) {\n                setHead(node);\n                p.next = null; // help GC\n                failed = false;\n                return interrupted;\n            }\n            if (shouldParkAfterFailedAcquire(p, node) &&\n                parkAndCheckInterrupt())\n                interrupted = true;\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\nprivate final boolean parkAndCheckInterrupt() {\n    LockSupport.park(this);\n    return Thread.interrupted();\n}\n```\n\n该方法是在尝试获取锁失败加入CHL队尾之后，如果发现前序节点是head，则CAS再尝试获取一次。否则，则会根据前序节点的状态判断是否需要阻塞。如果需要阻塞，则调用LockSupport的park方法阻塞该线程。\n\n**synchronized**\n\n在Java语言中存在两种内建的synchronized语法：synchronized语句、synchronized方法。\n\n* synchronized语句：当源代码被编译成字节码的时候，会在同步块的入口位置和退出位置分别插入monitorenter和monitorexit字节码指令;\n\n* synchronized方法：在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1。这个在specification中没有明确说明。\n\n在Java虚拟机的specification中，有关于monitorenter和monitorexit字节码指令的详细描述：http://docs.oracle.com/Javase/specs/jvms/se7/html/jvms-6.html#jvms-6.5.monitorenter 。\n\n**monitorenter**\n\n> The objectref must be of type reference.\n> \n> Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:\n> \n> * If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.\n> \n> * If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.\n> \n> * If another thread already owns the monitor associated with objectref, the thread blocks until the monitor's entry count is zero, then tries again to gain ownership.\n\n每个对象都有一个锁，也就是监视器（monitor）。当monitor被占有时就表示它被锁定。线程执行monitorenter指令时尝试获取对象所对应的monitor的所有权，过程如下：\n\n* 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者;\n\n* 如果线程已经拥有了该monitor，只是重新进入，则进入monitor的进入数加1;\n\n* 如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。\n\n**monitorexit**\n\n> The objectref must be of type reference.\n> \n> The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref.\n> \n> The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so.\n\n执行monitorexit的线程必须是相应的monitor的所有者。\n\n指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权。\n\n在JDK1.6及其之前的版本中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的。然而在现实中的大部分情况下，同步方法是运行在单线程环境（无锁竞争环境）。如果每次都调用Mutex Lock将严重的影响程序的性能。因此在JDK 1.6之后的版本中对锁的实现做了大量的优化，这些优化在很大程度上减少或避免了Mutex Lock的使用。\n\n3. **多进程的解决方案**\n\n在多道程序系统中存在许多进程，它们共享各种资源，然而有很多资源一次只能供一个进程使用，这便是临界资源。多进程中的临界资源大致上可以分为两类，一类是物理上的真实资源，如打印机；一类是硬盘或内存中的共享数据，如共享内存等。而进程内互斥访问临界资源的代码被称为临界区。\n\n针对临界资源的互斥访问，JVM层面的锁就已经失去效力了。在多进程的情况下，主要还是利用操作系统层面的进程间通信原理来解决临界资源的抢占问题。比较常见的一种方法便是使用信号量（Semaphores）。\n\n信号量在POSIX标准下有两种，分别为有名信号量和无名信号量。无名信号量通常保存在共享内存中，而有名信号量是与一个特定的文件名称相关联。信号量是一个整数变量，有计数信号量和二值信号量两种。对信号量的操作，主要是P操作（wait）和V操作（signal）。\n\n* P操作：先检查信号量的大小，若值大于零，则将信号量减1，同时进程获得共享资源的访问权限，继续执行；若小于或者等于零，则该进程被阻塞后，进入等待队列。\n\n* V操作：该操作将信号量的值加1，如果有进程阻塞着等待该信号量，那么其中一个进程将被唤醒。\n\n举个例子，设信号量为1，当一个进程A在进入临界区之前，先进行P操作。发现值大于零，那么就将信号量减为0，进入临界区执行。此时，若另一个进程B也要进去临界区，进行P操作，发现信号量等于0，则会被阻塞。当进程A退出临界区时，会进行V操作，将信号量的值加1，并唤醒阻塞的进程B。此时B就可以进入临界区了。\n\n这种方式，其实和多线程环境下的加解锁非常类似。因此用信号量处理临界资源抢占，也可以简单地理解为对临界区进行加锁。\n\n通过上面的一些了解，我们可以概括出解决互斥性问题，即资源抢占的基本方式为：\n\n*对共享资源的操作前后（进入退出临界区）加解锁，保证不同线程或进程可以互斥有序的操作资源。*\n\n加解锁方式，有显式的加解锁，如ReentrantLock或信号量；也有隐式的加解锁，如synchronized。那么在分布式环境中，为了保证不同JVM不同主机间不会出现资源抢占，那么同样只要对临界区加解锁就可以了。\n\n然而在多线程和多进程中，锁已经有比较完善的实现，直接使用即可。但是在分布式环境下，就需要我们自己来实现分布式锁。\n\n4. **分布式环境下的解决方案——分布式锁**\n\n首先，我们来看看分布式锁的基本条件。\n\n**分布式锁条件**\n\n**4.1 基本条件**\n\n再回顾下多线程和多进程环境下的锁，可以发现锁的实现有很多共通之处，它们都需要满足一些最基本的条件：\n\n* 需要有存储锁的空间，并且锁的空间是可以访问到的。\n\n* 锁需要被唯一标识。\n\n* 锁要有至少两种状态。\n\n仔细分析这三个条件：\n\n* 存储空间\n\n锁是一个抽象的概念，锁的实现，需要依存于一个可以存储锁的空间。在多线程中是内存，在多进程中是内存或者磁盘。更重要的是，这个空间是可以被访问到的。多线程中，不同的线程都可以访问到堆中的成员变量；在多进程中，不同的进程可以访问到共享内存中的数据或者存储在磁盘中的文件。但是在分布式环境中，不同的主机很难访问对方的内存或磁盘。这就需要一个都能访问到的外部空间来作为存储空间。\n\n最普遍的外部存储空间就是数据库了，事实上也确实有基于数据库做分布式锁（行锁、version乐观锁），如quartz集群架构中就有所使用。除此以外，还有各式缓存如Redis、Tair、Memcached、Mongodb，当然还有专门的分布式协调服务Zookeeper，甚至是另一台主机。只要可以存储数据、锁在其中可以被多主机访问到，那就可以作为分布式锁的存储空间。\n\n* 唯一标识\n\n不同的共享资源，必然需要用不同的锁进行保护，因此相应的锁必须有唯一的标识。在多线程环境中，锁可以是一个对象，那么对这个对象的引用便是这个唯一标识。多进程环境中，信号量在共享内存中也是由引用来作为唯一的标识。但是如果不在内存中，失去了对锁的引用，如何唯一标识它呢？上文提到的有名信号量，便是用硬盘中的文件名作为唯一标识。因此，在分布式环境中，只要给这个锁设定一个名称，并且保证这个名称是全局唯一的，那么就可以作为唯一标识。\n\n* 至少两种状态\n\n为了给临界区加锁和解锁，需要存储两种不同的状态。如ReentrantLock中的status，0表示没有线程竞争，大于0表示有线程竞争；信号量大于0表示可以进入临界区，小于等于0则表示需要被阻塞。因此只要在分布式环境中，锁的状态有两种或以上：如有锁、没锁；存在、不存在等等，均可以实现。\n\n有了这三个条件，基本就可以实现一个简单的分布式锁了。下面以数据库为例，实现一个简单的分布式锁：\n\n数据库表，字段为锁的ID（唯一标识），锁的状态（0表示没有被锁，1表示被锁）。\n\n伪代码为：\n\n```java\nlock = mysql.get(id);\nwhile(lock.status == 1) {\n    sleep(100);\n}\nmysql.update(lock.status = 1);\ndoSomething();\nmysql.update(lock.status = 0);\n```\n\n**4.2 问题**\n\n以上的方式即可以实现一个粗糙的分布式锁，但是这样的实现，有没有什么问题呢？\n\n* 问题1：锁状态判断原子性无法保证\n\n从读取锁的状态，到判断该状态是否为被锁，需要经历两步操作。如果不能保证这两步的原子性，就可能导致不止一个请求获取到了锁，这显然是不行的。因此，我们需要保证锁状态判断的原子性。\n\n* 问题2：网络断开或主机宕机，锁状态无法清除\n\n假设在主机已经获取到锁的情况下，突然出现了网络断开或者主机宕机，如果不做任何处理该锁将仍然处于被锁定的状态。那么之后所有的请求都无法再成功抢占到这个锁。因此，我们需要在持有锁的主机宕机或者网络断开的时候，及时的释放掉这把锁。\n\n* 问题3：无法保证释放的是自己上锁的那把锁\n\n在解决了问题2的情况下再设想一下，假设持有锁的主机A在临界区遇到网络抖动导致网络断开，分布式锁及时的释放掉了这把锁。之后，另一个主机B占有了这把锁，但是此时主机A网络恢复，退出临界区时解锁。由于都是同一把锁，所以A就会将B的锁解开。此时如果有第三个主机尝试抢占这把锁，也将会成功获得。因此，我们需要在解锁时，确定自己解的这个锁正是自己锁上的。\n\n**4.3 进阶条件**\n\n如果分布式锁的实现，还能再解决上面的三个问题，那么就可以算是一个相对完整的分布式锁了。然而，在实际的系统环境中，还会对分布式锁有更高级的要求。\n\n* 可重入：线程中的可重入，指的是外层函数获得锁之后，内层也可以获得锁，ReentrantLock和synchronized都是可重入锁；衍生到分布式环境中，一般仍然指的是线程的可重入，在绝大多数分布式环境中，都要求分布式锁是可重入的。\n\n* 惊群效应（Herd Effect）：在分布式锁中，惊群效应指的是，在有多个请求等待获取锁的时候，一旦占有锁的线程释放之后，如果所有等待的方都同时被唤醒，尝试抢占锁。但是这样的情况会造成比较大的开销，那么在实现分布式锁的时候，应该尽量避免惊群效应的产生。\n\n* 公平锁和非公平锁：不同的需求，可能需要不同的分布式锁。非公平锁普遍比公平锁开销小。但是业务需求如果必须要锁的竞争者按顺序获得锁，那么就需要实现公平锁。\n\n* 阻塞锁和自旋锁：针对不同的使用场景，阻塞锁和自旋锁的效率也会有所不同。阻塞锁会有上下文切换，如果并发量比较高且临界区的操作耗时比较短，那么造成的性能开销就比较大了。但是如果临界区操作耗时比较长，一直保持自旋，也会对CPU造成更大的负荷。\n\n保留以上所有问题和条件，我们接下来看一些比较典型的实现方案。\n\n**4.4 典型实现**\n\n**4.4.1 ZooKeeper的实现**\n\nZooKeeper（以下简称“ZK”）中有一种节点叫做顺序节点，假如我们在/lock/目录下创建3个节点，ZK集群会按照发起创建的顺序来创建节点，节点分别为/lock/0000000001、/lock/0000000002、/lock/0000000003。\n\nZK中还有一种名为临时节点的节点，临时节点由某个客户端创建，当客户端与ZK集群断开连接，则该节点自动被删除。EPHEMERAL_SEQUENTIAL为临时顺序节点。\n\n根据ZK中节点是否存在，可以作为分布式锁的锁状态，以此来实现一个分布式锁，下面是分布式锁的基本逻辑：\n\n* 客户端调用create()方法创建名为“/dlm-locks/lockname/lock-”的临时顺序节点。\n\n* 客户端调用getChildren(“lockname”)方法来获取所有已经创建的子节点。\n\n* 客户端获取到所有子节点path之后，如果发现自己在步骤1中创建的节点是所有节点中序号最小的，那么就认为这个客户端获得了锁。\n\n* 如果创建的节点不是所有节点中需要最小的，那么则监视比自己创建节点的序列号小的最大的节点，进入等待。直到下次监视的子节点变更的时候，再进行子节点的获取，判断是否获取锁。\n\n释放锁的过程相对比较简单，就是删除自己创建的那个子节点即可，不过也仍需要考虑删除节点失败等异常情况。\n\n开源的基于ZK的Menagerie的源码就是一个典型的例子：https://github.com/sfines/menagerie 。\n\nMenagerie中的lock首先实现了可重入锁，利用ThreadLocal存储进入的次数，每次加锁次数加1，每次解锁次数减1。如果判断出是当前线程持有锁，就不用走获取锁的流程。\n\n通过tryAcquireDistributed方法尝试获取锁，循环判断前序节点是否存在，如果存在则监视该节点并且返回获取失败。如果前序节点不存在，则再判断更前一个节点。如果判断出自己是第一个节点，则返回获取成功。\n\n为了在别的线程占有锁的时候阻塞，代码中使用JUC的condition来完成。如果获取尝试锁失败，则进入等待且放弃localLock，等待前序节点唤醒。而localLock是一个本地的公平锁，使得condition可以公平的进行唤醒，配合循环判断前序节点，实现了一个公平锁。\n\n这种实现方式非常类似于ReentrantLock的CHL队列，而且zk的临时节点可以直接避免网络断开或主机宕机，锁状态无法清除的问题，顺序节点可以避免惊群效应。这些特性都使得利用ZK实现分布式锁成为了最普遍的方案之一。\n\n**4.4.2 Redis的实现**\n\nRedis的分布式缓存特性使其成为了分布式锁的一种基础实现。通过Redis中是否存在某个锁ID，则可以判断是否上锁。为了保证判断锁是否存在的原子性，保证只有一个线程获取同一把锁，Redis有SETNX（即SET if Not eXists）和GETSET（先写新值，返回旧值，原子性操作，可以用于分辨是不是首次操作）操作。\n\n为了防止主机宕机或网络断开之后的死锁，Redis没有ZK那种天然的实现方式，只能依赖设置超时时间来规避。\n\n以下是一种比较普遍但不太完善的Redis分布式锁的实现步骤（与下图一一对应）：\n\n* 线程A发送SETNX lock.orderid 尝试获得锁，如果锁不存在，则set并获得锁。\n\n* 如果锁存在，则再判断锁的值（时间戳）是否大于当前时间，如果没有超时，则等待一下再重试。\n\n* 如果已经超时了，在用GETSET lock.{orderid} 来尝试获取锁，如果这时候拿到的时间戳仍旧超时，则说明已经获得锁了。\n\n* 如果在此之前，另一个线程C快一步执行了上面的操作，那么A拿到的时间戳是个未超时的值，这时A没有如期获得锁，需要再次等待或重试。\n\n![](/assets/images/2016/09/29/distributed-system-mutually-exclusive-idempotence-cerberus-gtis/redis_lock.png)\n\n该实现还有一个需要考虑的问题是全局时钟问题，由于生产环境主机时钟不能保证完全同步，对时间戳的判断也可能会产生误差。\n\n以上是Redis的一种常见的实现方式，除此以外还可以用SETNX+EXPIRE来实现。Redisson是一个官方推荐的Redis客户端并且实现了很多分布式的功能。它的分布式锁就提供了一种更完善的解决方案，源码：https://github.com/mrniko/redisson 。\n\n**4.4.3 Tair的实现**\n\nTair和Redis的实现类似，Tair客户端封装了一个expireLock的方法：通过锁状态和过期时间戳来共同判断锁是否存在，只有锁已经存在且没有过期的状态才判定为有锁状态。在有锁状态下，不能加锁，能通过大于或等于过期时间的时间戳进行解锁。\n\n采用这样的方式，可以不用在Value中存储时间戳，并且保证了判断是否有锁的原子性。更值得注意的是，由于超时时间是由Tair判断，所以避免了不同主机时钟不一致的情况。\n\n以上的几种分布式锁实现方式，都是比较常见且有些已经在生产环境中应用。随着应用环境越来越复杂，这些实现可能仍然会遇到一些挑战。\n\n* **强依赖于外部组件**：分布式锁的实现都需要依赖于外部数据存储如ZK、Redis等等，因此一旦这些外部组件出现故障，那么分布式锁就不可用了。\n\n* **无法完全满足需求**：不同分布式锁的实现，都有相应的特点，对于一些需求并不能很好的满足，如实现公平锁、给等待锁加超时时间等等。\n\n基于以上问题，结合多种实现方式，我们开发了Cerberus（得名自希腊神话里守卫地狱的猛犬），致力于提供灵活可靠的分布式锁。\n\n**4.4 Cerberus分布式锁**\n\nCerberus有以下几个特点。\n\n**4.4.1 特点一：一套接口多种引擎** \n\nCerberus分布式锁使用了多种引擎实现方式（Tair、ZK、未来支持Redis），支持使用方自主选择所需的一种或多种引擎。这样可以结合引擎特点，选择符合实际业务需求和系统架构的方式。\n\nCerberus分布式锁将不同引擎的接口抽象为一套，屏蔽了不同引擎的实现细节。使得使用方可以专注于业务逻辑，也可以任意选择并切换引擎而不必更改任何的业务代码。\n\n如果使用方选择了一种以上的引擎，那么以配置顺序来区分主副引擎。以下是使用主引擎的推荐：\n\n| 功能需求 | Tair | ZK |\n| ------- | ---- | -- |\n| 并发量高 | ✔ |  |\n| 响应时间敏感 | ✔|  |\n| 临界区执行时间长 |  | ✔ |\n| 公平锁 |  | ✔ |\n| 非公平锁 | ✔ |  |\n| 读写锁 |  | ✔ |\n\n**4.4.2 特点二：使用灵活、学习成本低**\n\n下面是Cerberus的lock方法，这些方法和JUC的ReentrantLock的方式保持一致，使用非常灵活且不需要额外的学习时间。\n\n* void lock();\n\n获取锁，如果锁被占用，将禁用当前线程，并且在获得锁之前，该线程将一直处于阻塞状态。\n\n* boolean tryLock();\n\n仅在调用时锁为空闲状态才获取该锁。\n\n如果锁可用，则获取锁，并立即返回值 true。如果锁不可用，则此方法将立即返回值 false。\n\n* boolean tryLock(long time, TimeUnit unit) throws InterruptedException;\n\n如果锁在给定的等待时间内空闲，并且当前线程未被中断，则获取锁。\n\n如果在给定时间内锁可用，则获取锁，并立即返回值 true。如果在给定时间内锁一直不可用，则此方法将立即返回值false。\n\n* void lockInterruptibly() throws InterruptedException;\n\n获取锁，如果锁被占用，则一直等待直到线程被中断或者获取到锁。\n\n* void unlock();\n\n释放当前持有的锁。\n\n**4.4.3 特点三：支持一键降级**\n\nCerberus提供了实时切换引擎的接口:\n\n* String switchEngine()\n\n   转换分布式锁引擎，按配置的引擎的顺序循环转换。\n\n   返回值：返回当前的engine名字，如：\"zk\"。\n\n* String switchEngine(String engineName)\n\n   转换分布式锁引擎，切换为指定的引擎。\n\n   参数：engineName - 引擎的名字，同配置bean的名字，\"zk\"/\"tair\"。\n\n   返回值：返回当前的engine名字，如：\"zk\"。\n\n当使用方选择了两种引擎，平时分布式锁会工作在主引擎上。一旦所依赖的主引擎出现故障，那么使用方可以通过自动或者手动方式调用该切换引擎接口，平滑的将分布式锁切换到另一个引擎上以将风险降到最低。自动切换方式可以利用Hystrix实现。手动切换推荐的一个方案则是使用美团点评基于Zookeeper的基础组件MCC，通过监听MCC配置项更改，来达到手动将分布式系统所有主机同步切换引擎的目的。需要注意的是，切换引擎目前并不会迁移原引擎已有的锁。这样做的目的是出于必要性、系统复杂度和可靠性的综合考虑。在实际情况下，引擎故障到切换引擎，尤其是手动切换引擎的时间，要远大于分布式锁的存活时间。作为较轻量级的Cerberus来说，迁移锁会带来不必要的开销以及较高的系统复杂度。鉴于此，如果想要保证在引擎故障后的绝对可靠，那么则需要结合其他方案来进行处理。\n\n除此以外，Cerberus还提供了内置公用集群，免去搭建和配置集群的烦恼。Cerberus也有一套完善的应用授权机制，以此防止业务方未经评估使用，对集群造成影响。\n\n目前，Cerberus分布式锁已经持续迭代了8个版本，先后在美团点评多个项目中稳定运行。\n\n### 幂等性问题\n\n所谓幂等，简单地说，就是对接口的多次调用所产生的结果和调用一次是一致的。扩展一下，这里的接口，可以理解为对外发布的HTTP接口或者Thrift接口，也可以是接收消息的内部接口，甚至是一个内部方法或操作。\n\n那么我们为什么需要接口具有幂等性呢？设想一下以下情形：\n\n* 在App中下订单的时候，点击确认之后，没反应，就又点击了几次。在这种情况下，如果无法保证该接口的幂等性，那么将会出现重复下单问题。\n\n* 在接收消息的时候，消息推送重复。如果处理消息的接口无法保证幂等，那么重复消费消息产生的影响可能会非常大。\n\n在分布式环境中，网络环境更加复杂，因前端操作抖动、网络故障、消息重复、响应速度慢等原因，对接口的重复调用概率会比集中式环境下更大，尤其是重复消息在分布式环境中很难避免。Tyler Treat也在《You Cannot Have Exactly-Once Delivery》一文中提到：\n\n> Within the context of a distributed system, you cannot have exactly-once message delivery.\n\n分布式环境中，有些接口是天然保证幂等性的，如查询操作。有些对数据的修改是一个常量，并且无其他记录和操作，那也可以说是具有幂等性的。其他情况下，所有涉及对数据的修改、状态的变更就都有必要防止重复性操作的发生。通过间接的实现接口的幂等性来防止重复操作所带来的影响，成为了一种有效的解决方案。\n\n**GTIS**\n\nGTIS就是这样的一个解决方案。它是一个轻量的重复操作关卡系统，它能够确保在分布式环境中操作的唯一性。我们可以用它来间接保证每个操作的幂等性。它具有如下特点：\n\n* 高效：低延时，单个方法平均响应时间在2ms内，几乎不会对业务造成影响；\n\n* 可靠：提供降级策略，以应对外部存储引擎故障所造成的影响；提供应用鉴权，提供集群配置自定义，降低不同业务之间的干扰；\n\n* 简单：接入简捷方便，学习成本低。只需简单的配置，在代码中进行两个方法的调用即可完成所有的接入工作；\n\n* 灵活：提供多种接口参数、使用策略，以满足不同的业务需求。\n\n**实现原理**\n\n**基本原理**\n\nGTIS的实现思路是将每一个不同的业务操作赋予其唯一性。这个唯一性是通过对不同操作所对应的唯一的内容特性生成一个唯一的全局ID来实现的。基本原则为：相同的操作生成相同的全局ID；不同的操作生成不同的全局ID。\n\n生成的全局ID需要存储在外部存储引擎中，数据库、Redis亦或是Tair等等均可实现。考虑到Tair天生分布式和持久化的优势，目前的GTIS存储在Tair中。其相应的key和value如下：\n\n* key：将对于不同的业务，采用APP_KEY+业务操作内容特性生成一个唯一标识trans_contents。然后对唯一标识进行加密生成全局ID作为Key。\n\n* value：current_timestamp + trans_contents，current_timestamp用于标识当前的操作线程。\n\n判断是否重复，主要利用Tair的SETNX方法，如果原来没有值则set且返回成功，如果已经有值则返回失败。\n\n**内部流程**\n\nGTIS的内部实现流程为：\n\n* 业务方在业务操作之前，生成一个能够唯一标识该操作的transContents，传入GTIS；\n\n* GTIS根据传入的transContents，用MD5生成全局ID；\n\n* GTIS将全局ID作为key，current_timestamp+transContents作为value放入Tair进行setNx，将结果返回给业务方；\n\n* 业务方根据返回结果确定能否开始进行业务操作；\n\n* 若能，开始进行操作；若不能，则结束当前操作；\n\n* 业务方将操作结果和请求结果传入GTIS，系统进行一次请求结果的检验；\n\n* 若该次操作成功，GTIS根据key取出value值，跟传入的返回结果进行比对，如果两者相等，则将该全局ID的过期时间改为较长时间；\n\n* GTIS返回最终结果。\n\n**实现难点**\n\nGTIS的实现难点在于如何保证其判断重复的可靠性。由于分布式环境的复杂度和业务操作的不确定性，在上一章节分布式锁的实现中考虑的网络断开或主机宕机等等问题，同样需要在GTIS中设法解决。这里列出几个典型的场景：\n\n* 如果操作执行失败，理想的情况应该是另一个相同的操作可以立即进行。因此，需要对业务方的操作结果进行判断，如果操作失败，那么就需要立即删除该全局ID；\n\n* 如果操作超时或主机宕机，当前的操作无法告知GTIS操作是否成功。那么我们必须引入超时机制，一旦长时间获取不到业务方的操作反馈，那么也需要该全局ID失效；\n\n* 结合上两个场景，既然全局ID会失效并且可能会被删除，那就需要保证删除的不是另一个相同操作的全局ID。这就需要将特殊的标识记录下来，并由此来判断。这里所用的标识为当前时间戳。\n\n可以看到，解决这些问题的思路，也和上一章节中的实现有很多类似的地方。除此以外，还有更多的场景需要考虑和解决，所有分支流程如下:\n\n![](/assets/images/2016/09/29/distributed-system-mutually-exclusive-idempotence-cerberus-gtis/gtis_principle.jpg)\n\n**使用说明**\n\n使用时，业务方只需要在操作的前后调用GTIS的前置方法和后置方法，如下图所示。如果前置方法返回可进行操作，则说明此时无重复操作，可以进行。否则则直接结束操作。\n\n![](/assets/images/2016/09/29/distributed-system-mutually-exclusive-idempotence-cerberus-gtis/gtis_use.png)\n\n使用方需要考虑的主要是下面两个参数：\n\n* 空间全局性：业务方输入的能够标志操作唯一性的内容特性，可以是唯一性的String类型的ID，也可以是map、POJO等形式。如订单ID等\n\n* 时间全局性：确定在多长时间内不允许重复，1小时内还是一个月内亦或是永久。\n\n此外，GTIS还提供了不同的故障处理策略和重试机制，以此来降低外部存储引擎异常对系统造成的影响。\n\n目前，GTIS已经持续迭代了7个版本，距离第一个版本有近1年之久，先后在美团点评多个项目中稳定运行。\n\n**结语**\n\n在分布式环境中，操作互斥性问题和幂等性问题非常普遍。经过分析，我们找出了解决这两个问题的基本思路和实现原理，给出了具体的解决方案。\n\n针对操作互斥性问题，常见的做法便是通过分布式锁来处理对共享资源的抢占。分布式锁的实现，很大程度借鉴了多线程和多进程环境中的互斥锁的实现原理。只要满足一些存储方面的基本条件，并且能够解决如网络断开等异常情况，那么就可以实现一个分布式锁。目前已经有基于Zookeeper和Redis等存储引擎的比较典型的分布式锁实现。但是由于单存储引擎的局限，我们开发了基于ZooKeeper和Tair的多引擎分布式锁Cerberus，它具有使用灵活方便等诸多优点，还提供了完善的一键降级方案。\n\n针对操作幂等性问题，我们可以通过防止重复操作来间接的实现接口的幂等性。GTIS提供了一套可靠的解决方法：依赖于存储引擎，通过对不同操作所对应的唯一的内容特性生成一个唯一的全局ID来防止操作重复。\n\n目前Cerberus分布式锁、GTIS都已应用在生产环境并平稳运行。两者提供的解决方案已经能够解决大多数分布式环境中的操作互斥性和幂等性的问题。值得一提的是，分布式锁和GTIS都不是万能的，它们对外部存储系统的强依赖使得在环境不那么稳定的情况下，对可靠性会造成一定的影响。在并发量过高的情况下，如果不能很好的控制锁的粒度，那么使用分布式锁也是不太合适的。总的来说，分布式环境下的业务场景纷繁复杂，要解决互斥性和幂等性问题还需要结合当前系统架构、业务需求和未来演进综合考虑。Cerberus分布式锁和GTIS也会持续不断地迭代更新，提供更多的引擎选择、更高效可靠的实现方式、更简捷的接入流程，以期满足更复杂的使用场景和业务需求。\n\n---\n\n* 原文链接：[分布式系统互斥性与幂等性问题的分析与解决](http://tech.meituan.com/distributed-system-mutually-exclusive-idempotence-cerberus-gtis.html)\n","tags":["Idempotency"],"categories":["Distributed"]},{"title":"一篇好TM长的关于配置中心的文章","url":"%2F2016%2F2016-09-28-config-center%2F","content":"\n## 配置(Configuration)\n\n配置(Configuration) 这个概念每个技术人都不陌生，可以说一个不提供几个配置参数的系统都不好意思上线跟别的系统打招呼。那么为什么会是这个样子呢，究其本质是我们人类无法掌控和预知一切，映射到软件领域上，我们总是需要对系统的某些功能特性预留出一些控制的线头，以便我们在未来需要的时候，可以人为的拨弄这些线头从而控制系统的行为特征，我把它叫做 “_系统运行时(runtime)飞行姿态的动态调整_“。\n\n举个简单的例子：logLevel = INFO\n\n系统正常飞行的时候，我们希望其只输出INFO级别的日志信息，在生产环境中我们甚至希望只输出WARNING/ERROR级别的日志，系统出毛病了，再将日志输出动态的调整成包含诊断信息的DEBUG级别或者TRACE级别。\n\n![](/assets/images/2016/09/28/config-center/001.png)\n\n## 软件的老友 - 配置文件\n\n在那个单机即系统的时代，我们基本都是在用配置文件来存储配置项，一个配置项，就是如上面的logLevel那样的一个含有 = 表达式，如下:\n\n```\nconfig_key = config_value  // value1 or value2, you can choose one from the config_value set\n```\n\n一般来说`config_value`应该是一个有限空间的值集合，应该是有选择余地的，如果`config_value`没得选择，那么我只能认为这个配置项一定特么在逗我。而一个配置文件一般是一组配置项的集合或者叫配置集，一个系统根据逻辑模块划分，可以有1到多个配置文件。如下图 :\n\n![](/assets/images/2016/09/28/config-center/002.png)\n\n在集中式开发时代，配置文件基本足够用了，因为那时配置的管理通常不会成为一个很大的问题，简单一点来说，系统上了生产之后，如果需要修改一个配置，登录到这台生产机器上，vi修改这个配置文件，然后reload一下并不是什么很大的负担。\n\n如下图:\n\n![](/assets/images/2016/09/28/config-center/003.png)\n\n所以曾经的企业级应用架构标准J2EE里并没有制定关于配置管理这一块的任何标准。\n当然一些Follow J2EE标准的厂商，如以前Oracle的中间件WebLogic在实际实践时，因为很多大企业客户的环境也挺复杂的，所以WebLogic在这一块还是做了一些工作，其支持一个叫做Deployment Plan的特性，如下图:\n\n![](/assets/images/2016/09/28/config-center/004.png)\n\n其背后的本质就是开发人员(dev)打出来的应用war包里面的配置文件都是一些PlaceHolder, 在部署人员(ops)部署war包的时候，为目标环境提供与之匹配的的depoloy plan xml文件，WebLogic Server本身在deploy这个stage将war包配置项的placeholder值替换成plan里面的值。\n\n## 分布式系统给系统配置管理带来的挑战\n\n关于什么是分布式系统，本文不再赘述，毫无疑问今天阿里的系统就是一个大型的、服务化的、复杂的、分布式系统实现之一。在这个领域有3本书值得反复阅读&lt;&lt;分布式系统概念与设计&gt;&gt; &lt;&lt;分布式系统原理与泛型&gt;&gt; 以及 Distributed Systems For System Architects，有意思的是这三本书只有最后一本在21.3小节简单的提了一下 Configuration Of Distributed Systems，里面简单的说了一下静态配置和动态配置的概念和区别 “…System configuration may be static or dynamic…”. 这说明什么? 这说明我们阿里技术人包括我们中间件今天面临的很多问题和领域已经进入深水区，已经没有人会直接给你提供这个领域清晰的解决方案，我们自己正站在前沿，而我们的成功的或者失败的探索，其经验和成果都应该总结并分享给整个业界。\n\n在过去的大约15年左右，软件工程学在如何持续演进软件以适应一直要变的需求的方法论上有了很多的突破和大量的实践，在这个领域，从面向对象设计方法论，到极限编程，到敏捷开发、持续集成、单元测试等等，理论和实践都已经比较成熟了，关键是配合这一套方法论的配套的工具和软件集都变得非常的成熟。\n\n这里面的一个非常有意思的东西是关于系统的演进或者进化论(Software Evolution),一个系统或者说软件从被创造出来之后会经历研发、测试、到最后的go live，上了生产系统。那么这个之后，如何持续并且无痛的为其添加新行为或者调整已有行为的表现特征? 这确实非常复杂，尤其是要达到无痛的这个目标，毕竟线上系统，调整即意味着可能出故障。系统的动态配置管理毫无疑问是其中的一个小部分，如果每一个系统行为的任何一个微调都需要将整个系统停机，重启或者甚至重新构建、发布部署来实现，那要达到无痛这个目标恐怕难度更高。\n\n在分布式系统中，一次构建、发布、上线是非常非常重的一个过程，它不像单机时代那样重启一台机器、一个进程就可以了，在分布式系统中，它涉及到将软件包(例如war)分发到可能超过几千台机器，然后将几千台机器上的应用进程一一重启这么一个过程，超过2000台机器的一个应用一次完整的发布过程需要多长时间，相信很多核心系统的小二都深有体会。\n\n那么如何在不停应用集群的情况下，调整整个集群的运行时的行为特征（即系统运行时的飞行姿态），是一个分布式系统必须回答的一个问题。从这个角度讲, 我们认为:\n\n![](/assets/images/2016/09/28/config-center/005.png)\n\n现在我们很容易理解，其实我们平时常见的分布式系统的配置变更，诸如:\n\n*   线程池、连接池大小\n*   开关、预案、限流配置\n*   toggleFeature\n*   数据源主备容灾切换\n*   路由规则\n*   我是等等等等\n\n背后的本质都是在做分布式系统运行时行为特征（飞行姿态）的调整。\n\n## 每一个分布式系统都应该有一个动态配置管理系统\n\n是的，你一定注意到了，这里的说法跟图片上的有点不一样，这里想强调的是，未必都需要配置中心，在一个分布式系统规模还较小时，比如一个公司就二个应用集群，那无论你是用配置文件+auto-reload还是用redis，zookeeper什么都可以，这个动态配置管理系统不一定要是一个独立存在的，可以跟其它的系统，例如注册中心，甚至作为消息中间件的一个子系统都没有关系。但是重要的是知道一定要有这么一个东西，它给自己的系统提供了动态调整行为的能力，而配置管理系统基本固有的特性一定要实现。\n\n## 动态配置和静态配置的区别\n\n曾经我也傻傻分不清楚其区别是啥，这很正常。动态和静态这是一个相对的概念，海枯石烂，永远不变的那不叫配置，可能是撩妹的鬼话,即使这个配置可能是放在一个看起来很像配置文件的文本里，配置一定是可能修改其值的，而是否是动态配置主要是看这个配置是不是跟应用的版本构建发布(build-deploy lifetime)强绑定的。如果一个配置项，跟软件的版本构建是不耦合的，在应用进程运行时，可能需要变更配置值的就是动态配置，哪怕是变更频率可能非常低，也许你设计了一个配置项，发现最后下来3年也没变更过一次，那也是动态配置，相反，配置变更只发生在软件版本构建和发布的那个点，那么就是静态配置，哪怕你构建很频繁，1个小时就来一回，那也是个静态配置，举个简单的例子:\n\n```\nbuild-version = 3.4.6-1569965\n```\n\n这个配置项，永远只在某个软件版本被构建出来时会变更其值，一旦这个版本被构建出来，并且在程序运行时，是一定没有变更诉求的，这就是一个跟构建绑定的静态配置。而文章开始时举得logLevel的例子，则是一个动态配置的例子。\n\n所以看一下你的系统的配置项，你会发现动态配置其实更多，而跟行为演进相关的几乎都是动态配置。\n\n## 为什么是淘宝\n\n我在进来阿里做Diamond之后，思考过一个有意思的事情，为什么独立的配置中心这个东西会首先出现在淘宝? 你去国内著名的竞价排名搜索引擎百度上搜”配置中心”，你会发现信息不是特别多，但是排在前面的都是XDiamond, SuperDiamond这种Diamond一族, 反正我们没有为让配置中心跟Diamond这个名字关联给百度付过1毛钱，所以这个搜索结果应该是个自然结果，侧面也反应了在国内说起配置中心在生产上大规模运用是独此一家，别无分号。\n\n而在业界，如下图，Spring Boot/Cloud微服务将注册中心(discovery service)和配置中心(configuration service)提出来还处在布道阶段,\n\n![](/assets/images/2016/09/28/config-center/006.png)\n\n而且从Spring的实现方式的技术局限性来看，应该是还没有哪个公司基于这个配置中心的方案在生产上实际支持大规模分布式系统，毕竟，翻遍所有blog和文章，还没有哪个老外开始提到，这个基于git的方案应该怎么去做多数据中心以及容灾相关的非功能性需求。\n\n回到那个问题，为什么是淘宝，我们都知道在国内业界淘宝率先开启了去IOE,全面采用MYSQL，在这个过程中，在国内，大规模的系统性的解决分库分表这个命题的毫无疑问是阿里以及阿里中间件，在这个过程中，诞生了业内著名的TDDL.而与TDDL关联的一个核心问题是，分库分表之后，这多个库的数据源的配置信息存放在哪里，并对应用屏蔽多库这个事实? 好吧后面的事情也许你知道了，放在配置中心里! 但还是要提的是曾经并没有Diamond, 都在注册中心（ConfigServer）里，后来Diamond从ConfigServer分了出来，这个过程，很多人看到的是数据是持久化和非持久化的区别以及当时产品的稳定性方面的考量，直到今天也还是如此，但是，通过这么多年实践和演进下来，才恍然大悟，拆分的背后其实是服务发现(Service Discovery)和动态配置管理服务(Dynamic Configuration Management)根本就是两个不同的东西，而在当时可能仅是一种直觉。\n\n## 莫道君行早，更有早行人\n\n有时候我们会因为在某个领域我们走的早一点而产生一点点的”优越感”和“虚荣感”, 曾经我们以为Dynamic Configuration For Distributed System这个领域的实践我们不能说在业界独占鳌头，但是绝对位居前列。但是下面这两个老哥再次提醒我们，技术人踏实前行，不要有不必要的想法:\n\n![](/assets/images/2016/09/28/config-center/007.png)\n\n这两位老哥在1985年4月，在IEEE TRANSACTIONS ON SOFTWARE ENGINEERING 上发表了一篇名为 Dynamic Configuration for Distributed Systems的论文(Paper)，奶奶的，1985年！！什么概念，当时我4岁，还在玩泥巴,穿开裆裤。而Diamond现在的主力技术架构研发同学都还没出生呢！！我们能做的,只能是向这两位前辈再次致敬！\n\n在这篇论文中，虽然从现在的观点来看，当时人们对分布式系统的认识跟现在有很大的区别，但是其中的问题识别的非常的准确:\n\n“….Dynamic systemc onfiguration is the ability to modify and extend a system while it is running. The facility is a requirement in large distributed systems where it may not be possible or economic to stop the entire system to allow modification to part of its hardware or software. It is also useful during production of the system to aid incremental integration of component parts, and during operation to aid system evolution.The paper introduces a model of the configuration process which permits dynamic incremental modification and extension. Using this model we determine the properties required by languages and their execution environments to support dynamic configuration…”\n\n并且很清晰的区分了静态配置和动态配置的基本模型:\n\n![](/assets/images/2016/09/28/config-center/008.png)\n\n## 配置与环境\n\n另一个值得从技术上玩味的是关于“配置”的“环境”属性，这个表达可能有点抽象，比较难理解，这有点像技术上常提的一个叫Context的概念，很多Component会关联一个Context，Component+Context才是一个完整的运行时故事。环境恰恰也是热帖中大家可能会产生的疑问之一，为何Diamond会暴露这么多的环境让应用去选择? 而进一步对中间件更熟稔一点的人会问，在单元化场景中，为何注册中心是一个大集群模式，而配置中心又是一个小集群模式?\n\n另一方面，多个环境恰恰也是加重分布式系统需要依赖一个独立的配置管理系统的要素之一，可以说哪个公司的环境越复杂，分布式应用和服务越多，哪个公司诞生出独立的配置中心系统的可能性也就越大。\n\n举几个容易理解的表述，来帮助理解配置的环境属性，\n\n> “在开发环境中将logLevel设置为DEBUG,在预发环境logLevel设置为INFO,生产环境里logLevel设置为WARNING”\n> \n> “在日常环境执行线程池的最大线程数应该设置为15，而生产环境上这个值应该大一点，默认设为150”\n> \n> “在线上环境中，中心机房，应用数据源需要连接A库，而S机房，应用应该就近连接使用B库”\n> \n> “只有在T环境，双向同步开关才应该关闭”\n> \n> “这次的改动有点大，新的特性仅在线上的H单元把该特性开放出来，其它的单元环境先不要开放出来”\n\n是的，相信你一定发现了，我们的某个配置项，其具体的值域的定义往往跟具体的环境相关联，现实中相当一部分配置在不同的环境必须设定不同的值，但是也有相当的另一部分配置在不同的环境要设定为完全一致的值。所以从某个应用的视角看，其100个配置项，可能有50个是每个环境要不同的值的，而另50个是不区分环境，所有环境其配置值都是需要完全一致的。这种异化给配置管理系统的设计带来了复杂性，而且这个最终语义的解释，很显然不应该在配置中心系统本身，应该交给应用，配置管理系统应该做的是提供方便的交互方式保证这两种不同的一致性诉求同时得到很好的满足，这种诉求分为3个方面，如下示意图:\n\n是的，相信你一定发现了，我们的某个配置项，其具体的值域的定义往往跟具体的环境相关联，现实中相当一部分配置在不同的环境必须设定不同的值，但是也有相当的另一部分配置在不同的环境要设定为完全一致的值。所以从某个应用的视角看，其100个配置项，可能有50个是每个环境要不同的值的，而另50个是不区分环境，所有环境其配置值都是需要完全一致的。这种异化给配置管理系统的设计带来了复杂性，而且这个最终语义的解释，很显然不应该在配置中心系统本身，应该交给应用，配置管理系统应该做的是提供方便的交互方式保证这两种不同的一致性诉求同时得到很好的满足，这种诉求分为3个方面，如下示意图:\n\n![](/assets/images/2016/09/28/config-center/009.png)\n\nDiamond 这三个能力都有提供，其中1，2一般都是在配置中心的提供的客户端类库和OPS中体现。其中3这个实现是比较困难的，因为多个环境之间一般来说，都是有一些诸如远距离网络或者网络隔离之类的物理约束的，要做分布式一致性以及诸如分区容忍性之类的考量，目前Diamond只支持线上多单元一致性约束规则，但是因为历史原因大家没有真正用起来，规则本身的抽象度也不够好，不够通用。现在我们正在做改造，未来会将一致性规则做的更通用，后面会引导大家用起来，这样对于那些多环境保持一致的那些配置项，环境复杂性就可以对应用屏蔽掉，如果一个应用的配置项全是要各环境一致的，那么你就有福了，天空飘来五个字，”这么多环境就不是个事”。\n\n另外，一个配置中心也应该具备的能力是配置集的导出\\导入功能，可以让应用将A环境中的配置集方便的导出和导入到环境B中的能力，这对3个场景都有重大意义，一个场景是线上的配置值是经过实践验证的，现在在日常或者预发新建了应用环境，希望将线上的配置copy到线下用起来，第二个是，线下的应用终于调通要发预发或线上了，调较好的配置希望一下子发到线上去，当然这个根据我们的经验，一定要慎重，第三个是新建站或者机房，应用需要在新的机房将所有配置迁移过去，Diamond很快就会将这种能力开放出来。\n\n![](/assets/images/2016/09/28/config-center/010.png)\n\n理解了上面讲的这些，相信你就更能理解Spring Framework 里的两把刷子(抽象） Environment 和 PropertySource 是咋回事了, 详细参见:\n\nSpring 3.1 M1: Unified Property Management\n\n[https://spring.io/blog/2011/02/15/spring-3-1-m1-unified-property-management/](https://spring.io/blog/2011/02/15/spring-3-1-m1-unified-property-management/)\n\n## 配置的三个属性\n\n* 环境属性\n* 稀疏变更属性\n* 快速传播\n\n环境属性我们上文已经讨论过。\n\n稀疏变更讲的是配置的变更基本上都是稀疏的，因为系统的行为不可能非常频繁的需要动态调整，你每100毫秒调整一次系统的行为，估计系统要对你骂娘了。\n\n而快速传播讲的是配置不变则已，一变往往要求目标集群的所有节点要几乎同时收到变更，然后几乎整齐划一的统一调整行为。切库的场景来讲，主备切换之后，应用集群写新的主库这个行为切换的稀稀拉拉，整个收敛了一天，应用肯定是受不了的，而这个属性决定了对配置中心对配置变更推送SLA的高要求。\n\n## 配置中心(Diamond)和注册中心(ConfigServer)的不同\n\n在我们的眼里，用土话讲，这就是乌龟与王八的区别，想用拜金一点的话讲，这就是金条和钻石的区别，说的洋气一点这叫Apple and Pear，但是当初起的名字的给我们带来了大麻烦，现在我们的服务注册中心现在叫Config Server, 你说坑不坑。不过很多中间件产品的名字同时承载了一段8年的历史，这名字也体现中间件持续做技术产品，坚持就是一种力量的信念在里面，n代人持续发展一个产品，说实话，只管生不管养的现象在中间件不能说没有，但确实是很少的。1个8年的产品就像八岁的孩子，已经上小学了，硬要给它改个名字，从朱屎山改成朱宝山，他的同学认不认还要打个非常大的问号，而且还要跑到派出所重新上户口，也是个麻烦事。\n\n所以产品的取名字有大学问和大恐怖，大家取名之前一定要找算命先生给好好算一算，本来我在成为码农之前那也是仙风道骨，江湖人送外号郭半仙，那时候可以钉钉发个红包找我算一下。但成为码农之后嘛，就特么不说了，说起来全是泪，以前get到的很多技能点全丢了，现在就瞅着电脑和代码最顺眼。\n\n2者具体的不同，参见未来会写的&lt;&lt;应用配置中心和服务注册中心究竟有什么不一样?&gt;&gt;\n\n## 关于配置，业界最新动态\n\n业界著名的专职配置中心产品几乎没有（Diamond傲娇ing~）, 基本都是在用git, redis, zookeeper, consul 这些凑活着搞一下，所以要了解配置中心的同学，直接了解Diamond就可以了。:-)\n\n但是针对于配置管理的客户端编程类库这一块有一些类库牛吹得是很大的，感兴趣的同学可以了解一下:\n\n* Apache Commons Configuration （[https://commons.apache.org/proper/commons-configuration/](https://commons.apache.org/proper/commons-configuration/)）\n\n这个类库是在是太繁琐了，用起来总感觉有点杀鸡用牛刀，力用的太大的感觉。\n\n* owner （[http://owner.aeonbits.org/](http://owner.aeonbits.org/)）\n\n简单易上手，特性看起来很多，但是在很多关键常用的特性反倒是没有。\n\n* cfg4j ([http://www.cfg4j.org/](http://www.cfg4j.org/))\n\n简单易上手，cfg4j 支持跟多种后端集成，做配置中心的解决方案，api设计也非常的不错，我们正在设计的新diamond annotation api的时候借鉴了不少其想法。\n\n* Spring Framework ([http://docs.spring.io/spring/docs/current/spring-framework-reference/htmlsingle/#__propertysource](http://docs.spring.io/spring/docs/current/spring-framework-reference/htmlsingle/#__propertysource))\n\nSpring的东西一般都还是很不错的，如果你的应用本身在用Spring，毫无疑问，就这个了，用上面的那些类库实在没有必要。\n\n* Spring Cloud Config Server\n\n![](/assets/images/2016/09/28/config-center/011.png)\n\n如果你仔细读一下其内容，而你又了解Diamond的话，你会发现这就是Diamond这些年在解决的问题啊，Spring 终于从大量配置文件逐渐走向了配置中心（externalized configuration in a distributed system），而这一次我们走在了前面。\n\n看看owner 的宣传，\n\n![](/assets/images/2016/09/28/config-center/012.png)\n\nJava 他妈 properties reinvented！ Java Properties的重新发明！ 屌不屌?! 我僧僧的觉得，我们中国码农有时候就是差了这种提炼和升华的能力，刚入行时觉得维护和修改前人留下的烂代码实在是个很苦逼，很Low的事情，但是Martin Fowler把这叫做”重构”，然后还写了一本书，然后我们读了之后，居然还觉得他妈的，讲的真的非常的有道理！把改烂代码变成叫重构之后，有了理论指导，突然觉得这真是个高逼格的事情！\n\n## 配置(configuration)与元数据(metadata)\n\n很多人没有这种这两个概念的区分，但是对于配置中心，二者其实是有微妙的差别的.\n\n配置如前文有阐述，配置的修改基本上都是由人来驱动，并且在ops上实现变更。\n\n![](/assets/images/2016/09/28/config-center/013.png)\n\n而元数据的本质是一小段程序元数据，它很多时候是程序产生，程序消费，由程序通过调用Diamond的客户端api来实现变更，中间不会有ops 或者人的介入。\n\n![](/assets/images/2016/09/28/config-center/014.png)\n\n知道这个有什么意义？毫无疑问，配置这种需求选型比较明确，而元数据这种，可以选的pub-sub系统太多了，诸如消息队列产品，分布式coordinator产品如zookeeper, 带pub-sub 能力的k-v store 如Redis等等都可以，所以如果是元数据这种，选什么需要慎重，其间运用之妙，存乎一心，要充分评估和把握自己的需求。\n\nDiamond 不光是应用配置存储，其目前存储的数据，很大一部分是metadata，所以Diamond 其实也是一个元数据存储中心。\n\n## 结束语\n\n这么长的文章，你居然能坚持看到这里，说明你是真正的、脱离了低级趣味的，纯粹的码农，猿类中的精英！配置中心，它没有高精尖的技术，难懂的算法，海量的数据，做这个东西只需要一个精神就够了。\n\n![](/assets/images/2016/09/28/config-center/015.png)\n\nowner之前一直在搞配置文件的支持，现在owner也开始转型搞跟zookeeper集成之类的，做配置中心的解决方案了，所以本文开头说业界正在走向配置中心解决方案不是在忽悠，是确实是这个趋势。\n\n---\n\n* 原文链接：[一篇好TM长的关于配置中心的文章](http://jm.taobao.org/2016/09/28/an-article-about-config-center/)\n","tags":["Diamond"],"categories":["Configuration"]},{"title":"The Neural Network Zoo","url":"%2F2016%2F2016-09-14-neural-network-zoo%2F","content":"\nWith new neural network architectures popping up every now and then, it&#8217;s hard to keep track of them all. Knowing all the abbreviations being thrown around (DCIGN, BiLSTM, DCGAN, anyone?) can be a bit overwhelming at first.\n\nSo I decided to compose a cheat sheet containing many of those architectures. Most of these are neural networks, some are completely different beasts. Though all of these architectures are presented as novel and unique, when I drew the node structures&#8230; their underlying relations started to make more sense.\n\n![neuralnetworks](/assets/images/2016/09/14/neural-network-zoo/neuralnetworks.png)\n\nOne problem with drawing them as node maps: it doesn&#8217;t really show how they&#8217;re used. For example, variational autoencoders (VAE) may look just like autoencoders (AE), but the training process is actually quite different. The use-cases for trained networks differ even more, because VAEs are generators, where you insert noise to get a new sample. AEs, simply map whatever they get as input to the closest training sample they &#8220;remember&#8221;. I should add that this overview is in no way clarifying how each of the different node types work internally (but that&#8217;s a topic for another day).\n\nIt should be noted that while most of the abbreviations used are generally accepted, not all of them are. RNNs sometimes refer to recursive neural networks, but most of the time they refer to recurrent neural networks. That&#8217;s not the end of it though, in many places you&#8217;ll find RNN used as placeholder for any recurrent architecture, including LSTMs, GRUs and even the bidirectional variants. AEs suffer from a similar problem from time to time, where VAEs and DAEs and the like are called simply AEs. Many abbreviations also vary in the amount of &#8220;N&#8221;s to add at the end, because you could call it a convolutional neural network but also simply a convolutional network (resulting in CNN or CN).\n\nComposing a complete list is practically impossible, as new architectures are invented all the time. Even if published it can still be quite challenging to find them even if you&#8217;re looking for them, or sometimes you just overlook some. So while this list may provide you with some insights into the world of AI, please, by no means take this list for being comprehensive; especially if you read this post long after it was written.\n\nFor each of the architectures depicted in the picture, I wrote a _very, very_ brief description. You may find some of these to be useful if you&#8217;re quite familiar with some architectures, but you aren&#8217;t familiar with a particular one.\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/ff.png)\n\n**Feed forward neural networks (FF or FFNN) and perceptrons (P)** are very straight forward, they feed information from the front to the back (input and output, respectively). Neural networks are often described as having layers, where each layer consists of either input, hidden or output cells in parallel. A layer alone never has connections and in general two adjacent layers are fully connected (every neuron form one layer to every neuron to another layer). The simplest somewhat practical network has two input cells and one output cell, which can be used to model logic gates. One usually trains FFNNs through back-propagation, giving the network paired datasets of &#8220;what goes in&#8221; and &#8220;what we want to have coming out&#8221;. This is called supervised learning, as opposed to unsupervised learning where we only give it input and let the network fill in the blanks. The error being back-propagated is often some variation of the difference between the input and the output (like MSE or just the linear difference). Given that the network has enough hidden neurons, it can theoretically always model the relationship between the input and output. Practically their use is a lot more limited but they are popularly combined with other networks to form new networks.\n\n_Rosenblatt, Frank. &#8220;The perceptron: a probabilistic model for information storage and organization in the brain.&#8221; Psychological review 65.6 (1958): 386._\n\n[Original Paper PDF](http://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/rbf.png)\n\n**Radial basis function (RBF)** networks are FFNNs with radial basis functions as activation functions. There&#8217;s nothing more to it. Doesn&#8217;t mean they don&#8217;t have their uses, but most FFNNs with other activation functions don&#8217;t get their own name. This mostly has to do with inventing them at the right time.\n\n_Broomhead, David S., and David Lowe. Radial basis functions, multi-variable functional interpolation and adaptive networks. No. RSRE-MEMO-4148. ROYAL SIGNALS AND RADAR ESTABLISHMENT MALVERN (UNITED KINGDOM), 1988._\n\n[Original Paper PDF](http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA196234)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/hn.png)\n\nA **Hopfield network (HN)** is a network where every neuron is connected to every other neuron; it is a completely entangled plate of spaghetti as even all the nodes function as everything. Each node is input before training, then hidden during training and output afterwards. The networks are trained by setting the value of the neurons to the desired pattern after which the weights can be computed. The weights do not change after this. Once trained for one or more patterns, the network will always converge to one of the learned patterns because the network is only stable in those states. Note that it does not always conform to the desired state (it&#8217;s not a magic black box sadly). It stabilises in part due to the total &#8220;energy&#8221; or &#8220;temperature&#8221; of the network being reduced incrementally during training. Each neuron has an activation threshold which scales to this temperature, which if surpassed by summing the input causes the neuron to take the form of one of two states (usually -1 or 1, sometimes 0 or 1). Updating the network can be done synchronously or more commonly one by one. If updated one by one, a fair random sequence is created to organise which cells update in what order (fair random being all options (n) occurring exactly once every n items). This is so you can tell when the network is stable (done converging), once every cell has been updated and none of them changed, the network is stable (annealed). These networks are often called associative memory because the converge to the most similar state as the input; if humans see half a table we can image the other half, this network will converge to a table if presented with half noise and half a table.\n\n_Hopfield, John J. &#8220;Neural networks and physical systems with emergent collective computational abilities.&#8221; Proceedings of the national academy of sciences 79.8 (1982): 2554-2558._\n\n[Original Paper PDF](https://bi.snu.ac.kr/Courses/g-ai09-2/hopfield82.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/mc.png)\n\n**Markov chains (MC or discrete time Markov Chain, DTMC)** are kind of the predecessors to BMs and HNs. They can be understood as follows: from this node where I am now, what are the odds of me going to any of my neighbouring nodes? They are memoryless (i.e. Markov Property) which means that every state you end up in depends completely on the previous state. While not really a neural network, they do resemble neural networks and form the theoretical basis for BMs and HNs. MC aren&#8217;t always considered neural networks, as goes for BMs, RBMs and HNs. Markov chains aren&#8217;t always fully connected either.\n\n_Hayes, Brian. &#8220;First links in the Markov chain.&#8221; American Scientist 101.2 (2013): 252._\n\n[Original Paper PDF](http://www.americanscientist.org/libraries/documents/201321152149545-2013-03Hayes.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/bm.png)\n\n**Boltzmann machines (BM)** are a lot like HNs, but: some neurons are marked as input neurons and others remain &#8220;hidden&#8221;. The input neurons become output neurons at the end of a full network update. It starts with random weights and learns through back-propagation, or more recently through contrastive divergence (a Markov chain is used to determine the gradients between two informational gains). Compared to a HN, the neurons mostly have binary activation patterns. As hinted by being trained by MCs, BMs are stochastic networks. The training and running process of a BM is fairly similar to a HN: one sets the input neurons to certain clamped values after which the network is set free (it doesn&#8217;t get a sock). While free the cells can get any value and we repetitively go back and forth between the input and hidden neurons. The activation is controlled by a global temperature value, which if lowered lowers the energy of the cells. This lower energy causes their activation patterns to stabilise. The network reaches an equilibrium given the right temperature.\n\n_Hinton, Geoffrey E., and Terrence J. Sejnowski. &#8220;Learning and releaming in Boltzmann machines.&#8221; Parallel distributed processing: Explorations in the microstructure of cognition 1 (1986): 282-317._\n\n[Original Paper PDF](https://www.researchgate.net/profile/Terrence_Sejnowski/publication/242509302_Learning_and_relearning_in_Boltzmann_machines/links/54a4b00f0cf256bf8bb327cc.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/rbm.png)\n\n**Restricted Boltzmann machines (RBM)** are remarkably similar to BMs (surprise) and therefore also similar to HNs. The biggest difference between BMs and RBMs is that RBMs are a better usable because they are more restricted. They don&#8217;t trigger-happily connect every neuron to every other neuron but only connect every different group of neurons to every other group, so no input neurons are directly connected to other input neurons and no hidden to hidden connections are made either. RBMs can be trained like FFNNs with a twist: instead of passing data forward and then back-propagating, you forward pass the data and then backward pass the data (back to the first layer). After that you train with forward-and-back-propagation.\n\n_Smolensky, Paul. Information processing in dynamical systems: Foundations of harmony theory. No. CU-CS-321-86. COLORADO UNIV AT BOULDER DEPT OF COMPUTER SCIENCE, 1986._\n\n[Original Paper PDF](http://www.dtic.mil/cgi-bin/GetTRDoc?Location=U2&#038;doc=GetTRDoc.pdf&#038;AD=ADA620727)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/ae.png)\n\n**Autoencoders (AE)** are somewhat similar to FFNNs as AEs are more like a different use of FFNNs than a fundamentally different architecture. The basic idea behind autoencoders is to encode information (as in compress, not encrypt) automatically, hence the name. The entire network always resembles an hourglass like shape, with smaller hidden layers than the input and output layers. AEs are also always symmetrical around the middle layer(s) (one or two depending on an even or odd amount of layers). The smallest layer(s) is|are almost always in the middle, the place where the information is most compressed (the chokepoint of the network). Everything up to the middle is called the encoding part, everything after the middle the decoding and the middle (surprise) the code. One can train them using backpropagation by feeding input and setting the error to be the difference between the input and what came out. AEs can be built symmetrically when it comes to weights as well, so the encoding weights are the same as the decoding weights.\n\n_Bourlard, Hervé, and Yves Kamp. &#8220;Auto-association by multilayer perceptrons and singular value decomposition.&#8221; Biological cybernetics 59.4-5 (1988): 291-294._\n\n[Original Paper PDF](https://pdfs.semanticscholar.org/f582/1548720901c89b3b7481f7500d7cd64e99bd.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/sae.png)\n\n**Sparse autoencoders (SAE)** are in a way the opposite of AEs. Instead of teaching a network to represent a bunch of information in less &#8220;space&#8221; or nodes, we try to encode information in more space. So instead of the network converging in the middle and then expanding back to the input size, we blow up the middle. These types of networks can be used to extract many small features from a dataset. If one were to train a SAE the same way as an AE, you would in almost all cases end up with a pretty useless identity network (as in what comes in is what comes out, without any transformation or decomposition). To prevent this, instead of feeding back the input, we feed back the input plus a sparsity driver. This sparsity driver can take the form of a threshold filter, where only a certain error is passed back and trained, the other error will be &#8220;irrelevant&#8221; for that pass and set to zero. In a way this resembles spiking neural networks, where not all neurons fire all the time (and points are scored for biological plausibility).\n\n_Marc’Aurelio Ranzato, Christopher Poultney, Sumit Chopra, and Yann LeCun. &#8220;Efficient learning of sparse representations with an energy-based model.&#8221; Proceedings of NIPS. 2007._\n\n[Original Paper PDF](https://papers.nips.cc/paper/3112-efficient-learning-of-sparse-representations-with-an-energy-based-model.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/vae.png)\n\n**Variational autoencoders (VAE)** have the same architecture as AEs but are &#8220;taught&#8221; something else: an approximated probability distribution of the input samples. It&#8217;s a bit back to the roots as they are bit more closely related to BMs and RBMs. They do however rely on Bayesian mathematics regarding probabilistic inference and independence, as well as a re-parametrisation trick to achieve this different representation. The inference and independence parts make sense intuitively, but they rely on somewhat complex mathematics. The basics come down to this: take influence into account. If one thing happens in one place and something else happens somewhere else, they are not necessarily related. If they are not related, then the error propagation should consider that. This is a useful approach because neural networks are large graphs (in a way), so it helps if you can rule out influence from some nodes to other nodes as you dive into deeper layers.\n\n_Kingma, Diederik P., and Max Welling. &#8220;Auto-encoding variational bayes.&#8221; arXiv preprint arXiv:1312.6114 (2013)._\n\n[Original Paper PDF](https://arxiv.org/pdf/1312.6114v10.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/dae.png)\n\n**Denoising autoencoders (DAE)** are AEs where we don&#8217;t feed just the input data, but we feed the input data with noise (like making an image more grainy). We compute the error the same way though, so the output of the network is compared to the original input without noise. This encourages the network not to learn details but broader features, as learning smaller features often turns out to be &#8220;wrong&#8221; due to it constantly changing with noise.\n\n_Vincent, Pascal, et al. &#8220;Extracting and composing robust features with denoising autoencoders.&#8221; Proceedings of the 25th international conference on Machine learning. ACM, 2008._\n\n[Original Paper PDF](http://machinelearning.org/archive/icml2008/papers/592.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/dbn.png)\n\n**Deep belief networks (DBN)** is the name given to stacked architectures of mostly RBMs or VAEs. These networks have been shown to be effectively trainable stack by stack, where each AE or RBM only has to learn to encode the previous network. This technique is also known as greedy training, where greedy means making locally optimal solutions to get to a decent but possibly not optimal answer. DBNs can be trained through contrastive divergence or back-propagation and learn to represent the data as a probabilistic model, just like regular RBMs or VAEs. Once trained or converged to a (more) stable state through unsupervised learning, the model can be used to generate new data. If trained with contrastive divergence, it can even classify existing data because the neurons have been taught to look for different features.\n\n_Bengio, Yoshua, et al. &#8220;Greedy layer-wise training of deep networks.&#8221; Advances in neural information processing systems 19 (2007): 153._\n\n[Original Paper PDF](https://papers.nips.cc/paper/3048-greedy-layer-wise-training-of-deep-networks.pdf\n)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/cnn.png)\n\n**Convolutional neural networks (CNN or deep convolutional neural networks, DCNN)** are quite different from most other networks. They are primarily used for image processing but can also be used for other types of input such as as audio. A typical use case for CNNs is where you feed the network images and the network classifies the data, e.g. it outputs &#8220;cat&#8221; if you give it a cat picture and &#8220;dog&#8221; when you give it a dog picture. CNNs tend to start with an input &#8220;scanner&#8221; which is not intended to parse all the training data at once. For example, to input an image of 200 x 200 pixels, you wouldn&#8217;t want a layer with 40 000 nodes. Rather, you create a scanning input layer of say 20 x 20 which you feed the first 20 x 20 pixels of the image (usually starting in the upper left corner). Once you passed that input (and possibly use it for training) you feed it the next 20 x 20 pixels: you move the scanner one pixel to the right. Note that one wouldn&#8217;t move the input 20 pixels (or whatever scanner width) over, you&#8217;re not dissecting the image into blocks of 20 x 20, but rather you&#8217;re crawling over it. This input data is then fed through convolutional layers instead of normal layers, where not all nodes are connected to all nodes. Each node only concerns itself with close neighbouring cells (how close depends on the implementation, but usually not more than a few). These convolutional layers also tend to shrink as they become deeper, mostly by easily divisible factors of the input (so 20 would probably go to a layer of 10 followed by a layer of 5). Powers of two are very commonly used here, as they can be divided cleanly and completely by definition: 32, 16, 8, 4, 2, 1. Besides these convolutional layers, they also often feature pooling layers. Pooling is a way to filter out details: a commonly found pooling technique is max pooling, where we take say 2 x 2 pixels and pass on the pixel with the most amount of red. To apply CNNs for audio, you basically feed the input audio waves and inch over the length of the clip, segment by segment. Real world implementations of CNNs often glue an FFNN to the end to further process the data, which allows for highly non-linear abstractions. These networks are called DCNNs but the names and abbreviations between these two are often used interchangeably.\n\n_LeCun, Yann, et al. &#8220;Gradient-based learning applied to document recognition.&#8221; Proceedings of the IEEE 86.11 (1998): 2278-2324._\n\n[Original Paper PDF](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/dn.png)\n\n**Deconvolutional networks (DN)**, also called inverse graphics networks (IGNs), are reversed convolutional neural networks. Imagine feeding a network the word &#8220;cat&#8221; and training it to produce cat-like pictures, by comparing what it generates to real pictures of cats. DNNs can be combined with FFNNs just like regular CNNs, but this is about the point where the line is drawn with coming up with new abbreviations. They may be referenced as deep deconvolutional neural networks, but you could argue that when you stick FFNNs to the back and the front of DNNs that you have yet another architecture which deserves a new name. Note that in most applications one wouldn&#8217;t actually feed text-like input to the network, more likely a binary classification input vector. Think &lt;0, 1&gt; being cat, &lt;1, 0&gt; being dog and &lt;1, 1&gt; being cat and dog. The pooling layers commonly found in CNNs are often replaced with similar inverse operations, mainly interpolation and extrapolation with biased assumptions (if a pooling layer uses max pooling, you can invent exclusively lower new data when reversing it).\n\n_Zeiler, Matthew D., et al. &#8220;Deconvolutional networks.&#8221; Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on. IEEE, 2010._\n\n[Original Paper PDF](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/dcign.png)\n\n**Deep convolutional inverse graphics networks (DCIGN)** have a somewhat misleading name, as they are actually VAEs but with CNNs and DNNs for the respective encoders and decoders. These networks attempt to model &#8220;features&#8221; in the encoding as probabilities, so that it can learn to produce a picture with a cat and a dog together, having only ever seen one of the two in separate pictures. Similarly, you could feed it a picture of a cat with your neighbours&#8217; annoying dog on it, and ask it to remove the dog, without ever having done such an operation. Demo&#8217;s have shown that these networks can also learn to model complex transformations on images, such as changing the source of light or the rotation of a 3D object. These networks tend to be trained with back-propagation.\n\n_Kulkarni, Tejas D., et al. &#8220;Deep convolutional inverse graphics network.&#8221; Advances in Neural Information Processing Systems. 2015._\n\n[Original Paper PDF](https://arxiv.org/pdf/1503.03167v4.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/gan.png)\n\n**Generative adversarial networks (GAN)** are from a different breed of networks, they are twins: two networks working together. GANs consist of any two networks (although often a combination of FFs and CNNs), with one tasked to generate content and the other has to judge content. The discriminating network receives either training data or generated content from the generative network. How well the discriminating network was able to correctly predict the data source is then used as part of the error for the generating network. This creates a form of competition where the discriminator is getting better at distinguishing real data from generated data and the generator is learning to become less predictable to the discriminator. This works well in part because even quite complex noise-like patterns are eventually predictable but generated content similar in features to the input data is harder to learn to distinguish. GANs can be quite difficult to train, as you don&#8217;t just have to train two networks (either of which can pose it&#8217;s own problems) but their dynamics need to be balanced as well. If prediction or generation becomes to good compared to the other, a GAN won&#8217;t converge as there is intrinsic divergence.\n\n_Goodfellow, Ian, et al. &#8220;Generative adversarial nets.&#8221; Advances in Neural Information Processing Systems. 2014._\n\n[Original Paper PDF](https://arxiv.org/pdf/1406.2661v1.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/rnn.png)\n\n**Recurrent neural networks (RNN)** are FFNNs with a time twist: they are not stateless; they have connections between passes, connections through time. Neurons are fed information not just from the previous layer but also from themselves from the previous pass. This means that the order in which you feed the input and train the network matters: feeding it &#8220;milk&#8221; and then &#8220;cookies&#8221; may yield different results compared to feeding it &#8220;cookies&#8221; and then &#8220;milk&#8221;. One big problem with RNNs is the vanishing (or exploding) gradient problem where, depending on the activation functions used, information rapidly gets lost over time, just like very deep FFNNs lose information in depth. Intuitively this wouldn&#8217;t be much of a problem because these are just weights and not neuron states, but the weights through time is actually where the information from the past is stored; if the weight reaches a value of 0 or 1 000 000, the previous state won&#8217;t be very informative. RNNs can in principle be used in many fields as most forms of data that don&#8217;t actually have a timeline (i.e. unlike sound or video) can be represented as a sequence. A picture or a string of text can be fed one pixel or character at a time, so the time dependent weights are used for what came before in the sequence, not actually from what happened x seconds before. In general, recurrent networks are a good choice for advancing or completing information, such as autocompletion.\n\n_Elman, Jeffrey L. &#8220;Finding structure in time.&#8221; Cognitive science 14.2 (1990): 179-211._\n\n[Original Paper PDF](https://crl.ucsd.edu/~elman/Papers/fsit.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/lstm.png)\n\n**Long / short term memory (LSTM)** networks try to combat the vanishing / exploding gradient problem by introducing gates and an explicitly defined memory cell. These are inspired mostly by circuitry, not so much biology. Each neuron has a memory cell and three gates: input, output and forget. The function of these gates is to safeguard the information by stopping or allowing the flow of it. The input gate determines how much of the information from the previous layer gets stored in the cell. The output layer takes the job on the other end and determines how much of the next layer gets to know about the state of this cell. The forget gate seems like an odd inclusion at first but sometimes it&#8217;s good to forget: if it&#8217;s learning a book and a new chapter begins, it may be necessary for the network to forget some characters from the previous chapter. LSTMs have been shown to be able to learn complex sequences, such as writing like Shakespeare or composing primitive music. Note that each of these gates has a weight to a cell in the previous neuron, so they typically require more resources to run.\n\n_Hochreiter, Sepp, and Jürgen Schmidhuber. &#8220;Long short-term memory.&#8221; Neural computation 9.8 (1997): 1735-1780._\n\n[Original Paper PDF](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/gru.png)\n\n**Gated recurrent units (GRU)** are a slight variation on LSTMs. They have one less gate and are wired slightly differently: instead of an input, output and a forget gate, they have an update gate. This update gate determines both how much information to keep from the last state and how much information to let in from the previous layer. The reset gate functions much like the forget gate of an LSTM but it&#8217;s located slightly differently. They always send out their full state, they don&#8217;t have an output gate. In most cases, they function very similarly to LSTMs, with the biggest difference being that GRUs are slightly faster and easier to run (but also slightly less expressive). In practice these tend to cancel each other out, as you need a bigger network to regain some expressiveness which then in turn cancels out the performance benefits. In some cases where the extra expressiveness is not needed, GRUs can outperform LSTMs.\n\n_Chung, Junyoung, et al. &#8220;Empirical evaluation of gated recurrent neural networks on sequence modeling.&#8221; arXiv preprint arXiv:1412.3555 (2014)._\n\n[Original Paper PDF](https://arxiv.org/pdf/1412.3555v1.pdf)\n\n* * *\n\n&nbsp;\n\n![](/assets/images/2016/09/14/neural-network-zoo/ntm.png)\n\n**Neural Turing machines (NTM)** can be understood as an abstraction of LSTMs and an attempt to un-black-box neural networks (and give us some insight in what is going on in there). Instead of coding a memory cell directly into a neuron, the memory is separated. It&#8217;s an attempt to combine the efficiency and permanency of regular digital storage and the efficiency and expressive power of neural networks. The idea is to have a content-addressable memory bank and a neural network that can read and write from it. The &#8220;Turing&#8221; in Neural Turing Machines comes from them being Turing complete: the ability to read and write and change state based on what it reads means it can represent anything a Universal Turing Machine can represent.\n\n_Graves, Alex, Greg Wayne, and Ivo Danihelka. &#8220;Neural turing machines.&#8221; arXiv preprint arXiv:1410.5401 (2014)._\n\n[Original Paper PDF](https://arxiv.org/pdf/1410.5401v2.pdf)\n\n* * *\n\n**Bidirectional recurrent neural networks, bidirectional long / short term memory networks and bidirectional gated recurrent units (BiRNN, BiLSTM and BiGRU respectively)** are not shown on the chart because they look exactly the same as their unidirectional counterparts. The difference is that these networks are not just connected to the past, but also to the future. As an example, unidirectional LSTMs might be trained to predict the word &#8220;fish&#8221; by being fed the letters one by one, where the recurrent connections through time remember the last value. A BiLSTM would also be fed the next letter in the sequence on the backward pass, giving it access to future information. This trains the network to fill in gaps instead of advancing information, so instead of expanding an image on the edge, it could fill a hole in the middle of an image.\n\n_Schuster, Mike, and Kuldip K. Paliwal. &#8220;Bidirectional recurrent neural networks.&#8221; IEEE Transactions on Signal Processing 45.11 (1997): 2673-2681._\n\n[Original Paper PDF](http://www.di.ufpe.br/~fnj/RNA/bibliografia/BRNN.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/drn.png)\n\n**Deep residual networks (DRN)** are very deep FFNNs with extra connections passing input from one layer to a later layer (often 2 to 5 layers) as well as the next layer. Instead of trying to find a solution for mapping some input to some output across say 5 layers, the network is enforced to learn to map some input to some output + some input. Basically, it adds an identity to the solution, carrying the older input over and serving it freshly to a later layer. It has been shown that these networks are very effective at learning patterns up to 150 layers deep, much more than the regular 2 to 5 layers one could expect to train. However, it has been proven that these networks are in essence just RNNs without the explicit time based construction and they&#8217;re often compared to LSTMs without gates.\n\n_He, Kaiming, et al. &#8220;Deep residual learning for image recognition.&#8221; arXiv preprint arXiv:1512.03385 (2015)._\n\n[Original Paper PDF](https://arxiv.org/pdf/1512.03385v1.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/esn.png)\n\n**Echo state networks (ESN)** are yet another different type of (recurrent) network. This one sets itself apart from others by having random connections between the neurons (i.e. not organised into neat sets of layers), and they are trained differently. Instead of feeding input and back-propagating the error, we feed the input, forward it and update the neurons for a while, and observe the output over time. The input and the output layers have a slightly unconventional role as the input layer is used to prime the network and the output layer acts as an observer of the activation patterns that unfold over time. During training, only the connections between the observer and the (soup of) hidden units are changed.\n\n_Jaeger, Herbert, and Harald Haas. &#8220;Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication.&#8221; science 304.5667 (2004): 78-80._\n\n[Original Paper PDF](https://pdfs.semanticscholar.org/8922/17bb82c11e6e2263178ed20ac23db6279c7a.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/elm.png)\n\n**Extreme learning machines (ELM)** are basically FFNNs but with random connections. They look very similar to LSMs and ESNs, but they are not recurrent nor spiking. They also do not use backpropagation. Instead, they start with random weights and train the weights in a single step according to the least-squares fit (lowest error across all functions). This results in a much less expressive network but it&#8217;s also much faster than backpropagation.\n\n_Cambria, Erik, et al. &#8220;Extreme learning machines [trends &#038; controversies].&#8221; IEEE Intelligent Systems 28.6 (2013): 30-59._\n\n[Original Paper PDF](http://www.ntu.edu.sg/home/egbhuang/pdf/ieee-is-elm.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/lsm.png)\n\n**Liquid state machines (LSM)** are similar soups, looking a lot like ESNs. The real difference is that LSMs are a type of spiking neural networks: sigmoid activations are replaced with threshold functions and each neuron is also an accumulating memory cell. So when updating a neuron, the value is not set to the sum of the neighbours, but rather added to itself. Once the threshold is reached, it releases its&#8217; energy to other neurons. This creates a spiking like pattern, where nothing happens for a while until a threshold is suddenly reached.\n\n_Maass, Wolfgang, Thomas Natschläger, and Henry Markram. &#8220;Real-time computing without stable states: A new framework for neural computation based on perturbations.&#8221; Neural computation 14.11 (2002): 2531-2560._\n\n[Original Paper PDF](https://web.archive.org/web/20120222154641/http://ramsesii.upf.es/seminar/Maass_et_al_2002.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/svm.png)\n\n**Support vector machines (SVM)** find optimal solutions for classification problems. Classically they were only capable of categorising linearly separable data; say finding which images are of Garfield and which of Snoopy, with any other outcome not being possible. During training, SVMs can be thought of as plotting all the data (Garfields and Snoopys) on a graph (2D) and figuring out how to draw a line between the data points. This line would separate the data, so that all Snoopys are on one side and the Garfields on the other. This line moves to an optimal line in such a way that the margins between the data points and the line are maximised on both sides. Classifying new data would be done by plotting a point on this graph and simply looking on which side of the line it is (Snoopy side or Garfield side). Using the kernel trick, they can be taught to classify n-dimensional data. This entails plotting points in a 3D plot, allowing it to distinguish between Snoopy, Garfield AND Simon&#8217;s cat, or even higher dimensions distinguishing even more cartoon characters. SVMs are not always considered neural networks.\n\n_Cortes, Corinna, and Vladimir Vapnik. &#8220;Support-vector networks.&#8221; Machine learning 20.3 (1995): 273-297._\n\n[Original Paper PDF](http://image.diku.dk/imagecanon/material/cortes_vapnik95.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/kn.png)\n\nAnd finally, **Kohonen networks (KN, also self organising (feature) map, SOM, SOFM)** &#8220;complete&#8221; our zoo. KNs utilise competitive learning to classify data without supervision. Input is presented to the network, after which the network assesses which of its neurons most closely match that input. These neurons are then adjusted to match the input even better, dragging along their neighbours in the process. How much the neighbours are moved depends on the distance of the neighbours to the best matching units. KNs are sometimes not considered neural networks either.\n\n_Kohonen, Teuvo. &#8220;Self-organized formation of topologically correct feature maps.&#8221; Biological cybernetics 43.1 (1982): 59-69._\n\n[Original Paper PDF](http://cioslab.vcu.edu/alg/Visualize/kohonen-82.pdf)\n\n* * *\n\nAny feedback and criticism is welcome. At the Asimov Institute we do deep learning research and development, so be sure to follow us on [twitter](http://www.twitter.com/asimovinstitute) for future updates and posts! Thank you for reading!\n\n[UPDATE 15 sept 2016] I would like to thank everybody for their insights and corrections, all feedback is hugely appreciated. I will add links and a couple more suggested networks in a future update, stay tuned.\n\n[UPDATE 29 sept 2016] Added links and citations to all the original papers. A follow up post is planned, since I found at least 9 more architectures. I will not include them in this post for better consistency in terms of content.\n\n---\n\n* Author: [FJODOR VAN VEEN](http://www.asimovinstitute.org/author/fjodorvanveen/)\n* Source: [THE ASIMOV INSTITUTE](http://www.asimovinstitute.org/)\n* Link: [THE NEURAL NETWORK ZOO](http://www.asimovinstitute.org/neural-network-zoo/)\n","tags":["Neural-Network"],"categories":["Deep-Learning"]},{"title":"分布式事务：不过是在一致性、吞吐量和复杂度之间，做一个选择","url":"%2F2016%2F2016-09-08-distributed-transaction%2F","content":"\n# 背景\n\n这是一个开撕的话题，我经历过太多的关于分布式事务的需求：“有没有简便的方案，像使用数据库事务那样，解决分布式数据一致性的问题”。特别是微服务架构流行的今天，一次交易需要跨越多个“服务”、多个数据库来实现，传统的技术手段，已经无法应对和满足微服务情况下这些复杂的场景了。针对微服务下的交易业务如何保障数据一致性，本文尽量做到理论结合实际，将我们在实际产品中用到的分布式事务实现机制，和大家扒一扒，希望能帮助到读者。\n\n谈到分布式事务，必须先把”CAP\"拿出来说说事......，当然还有”BASE\"......\n\n从架构的角度来看，业务拆分（数据分区）、数据一致性、性能（可用性）永远是个平衡的艺术：\n\n* 1）在微服务架构下，为了获得更高的性能与灵活性，将业务应用拆分为多个，交易跨多个微服务编排，数据一致性的问题产生；\n* 2）为了解决数据一致性问题，需要采用不同的事务机制来保障，这又会产生性能（可用性）问题；\n\n在计算机世界里，为了解决一件事情，另外的问题就会接踵而至，从另一个层面印证了IT架构永远是一种平衡的艺术。\n\n“BASE”其核心思想是根据业务特点，采用适当的方式来使系统达到最终一致性(Eventualconsistency)；在互联网领域，通常需要牺牲强一致性来换取系统的高可用性，只需要保证数据的“最终一致”，只是这个最终时间需要在用户可以接受的范围内；但在金融相关的交易领域，仍然需要采用强一致性的方式来保障交易的准确性与可靠性。\n \n# 分布式事务介绍\n\n接下来为大家介绍业界常见的事务处理模式，包括两阶段提交、三阶段提交、Sagas长事务、补偿模式、可靠事件模式（本地事件表、外部事件表）、可靠事件模式（非事务消息、事务消息）、TCC等。不同的事务模型支持不同的数据一致性。如果读者对这几种分布式事务比较熟悉，可以直接参考下图并结合自身业务需求选择合适的事务模型。\n\n![](/assets/images/2016/09/08/distributed-transaction/001.jpg)\n\n## 一、两阶段提交、三阶段提交\n\n这种分布式事务解决方案目前在各种技术平台上已经比较成熟：JavaEE架构下面的JTA事务（各应用服务器均提供了实现，tomcat除外）。\n\n目前两阶段提交、三阶段提交存在如下的局限性，并不适合在微服务架构体系下使用：\n\n* 1）所有的操作必须是事务性资源（比如数据库、消息队列、EJB组件等），存在使用局限性（微服务架构下多数使用HTTP协议），比较适合传统的单体应用；\n* 2）由于是强一致性，资源需要在事务内部等待，性能影响较大，吞吐率不高，不适合高并发与高性能的业务场景；\n\n## 二、Sagas长事务\n\n在Sagas事务模型中，一个长事务是由一个预先定义好执行顺序的子事务集合和他们对应的补偿子事务集合组成的。典型的一个完整的交易由T1、T2、......、Tn等多个业务活动组成，每个业务活动可以是本地操作、或者是远程操作，所有的业务活动在Sagas事务下要么全部成功，要么全部回滚，不存在中间状态。\n\n![](/assets/images/2016/09/08/distributed-transaction/002.jpg)\n\nSagas事务模型的实现机制：\n\n1. 每个业务活动都是一个原子操作；\n2. 每个业务活动均提供正反操作；\n3. 任何一个业务活动发生错误，按照执行的反顺序，实时执行反操作，进行事务回滚；\n4. 回滚失败情况下，需要记录待冲正事务日志，通过重试策略进行重试；\n5. 冲正重试依然失败的场景，提供定时冲正服务器，对回滚失败的业务进行定时冲正；\n6. 定时冲正依然失败的业务，等待人工干预；\n\nSagas长事务模型支持对数据一致性要求比较高的场景比较适用，由于采用了补偿的机制，每个原子操作都是先执行任务，避免了长时间的资源锁定，能做到实时释放资源，性能相对有保障。\n\nSagas长事务方式如果由业务去实现，复杂度与难度并存。在我们实际使用过程中，开发了一套支持Sagas事务模型的框架来支撑业务快速交付。\n\n![](/assets/images/2016/09/08/distributed-transaction/003.jpg)\n\n开发人员：业务只需要进行交易编排，每个原子操作提供正反交易；\n\n配置人员：可以针对异常类型设定事务回滚策略（哪些异常纳入事务管理、哪些异常不纳入事务管理）；每个原子操作的流水是否持久化（为了不同性能可以支持缓存、DB、以及扩展其它持久化方式）；以及冲正选项配置（重试次数、超时时间、是否实时冲正、定时冲正等）；\n\nSagas事务框架：提供事务保障机制，负责原子操作的流水落地，原子操作的执行顺序，提供实时冲正、定时冲正、事务拦截器等基础能力；\n\nSagas框架的核心是IBusinessActivity、IAtomicAction。IBusinessActivity完成原子活动的enlist()、delist()、prepare()、commit()、rollback()等操作；IAtomicAction主要完成对状态上下文、正反操作执行。\n\n![](/assets/images/2016/09/08/distributed-transaction/004.jpg)\n\n限于文章篇幅，本文不对具体实现做详述；后面找时间可以详细介绍基于Sagas长事务模型具体的实现框架。\n\nSagas长事务需要交易提供反操作，支持事务的强一致性，由于没有在整个事务周期内锁定资源，对性能影响较小，适合对数据要求比较高的场景中使用。\n\n## 三、补偿模式\n\nSagas长事务模型本质上是补偿机制的复杂实现，如果实际业务场景上不需要复杂的Sagas事务框架支撑，可以在业务中实现简单的补偿模式。补偿过程往往也同样需要实现最终一致性，需要保证取消服务至少被调用一次和取消服务必须实现幂等性。补偿模式可以参见同事田向阳的技术文章《微服务架构下数据一致性保证（三）》（相关文章：微服务架构下数据一致性保障(一)   微服务架构下数字一致性保证(二)）\n\n![](/assets/images/2016/09/08/distributed-transaction/005.jpg)\n\n补偿机制不推荐在复杂场景（需要多个交易的编排）下使用，优点是非常容易提供回滚，而且依赖的服务也非常少，与Sagas长事务比较来看，使用起来更简便；缺点是会造成代码量庞大，耦合性高，对应无法提供反操作的交易不适合。\n\n## 四、可靠时间模式（本地事件表、外地事件表）\n\n可靠事件模式属于事件驱动架构，当某件重要事情发生时，例如更新一个业务实体，微服务会向消息代理发布一个事件。消息代理会向订阅事件的微服务推送事件，当订阅这些事件的微服务接收此事件时，就可以完成自己的业务，也可能会引发更多的事件发布。\n\n![](/assets/images/2016/09/08/distributed-transaction/006.jpg)\n\n可靠事件模式在于保证可靠事件投递和避免重复消费，靠事件投递定义为:\n\n1）每个服务原子性的业务操作和发布事件;\n2）消息代理确保事件传递至少一次；避免重复消费要求服务实现幂等性。\n\n基于事件模式，需要重点考虑的是事件的可靠到达，在我们产品实际支持过程中，通常有本地事件表、外部事件表两种模式：\n\n1. 本地事件表方法将事件和业务数据保存在同一个数据库中，使用一个额外的“事件恢复”服务来恢复事件，由本地事务保证更新业务和发布事件的原子性。考虑到事件恢复可能会有一定的延时，服务在完成本地事务后可立即向消息代理发布一个事件。\n\n![](/assets/images/2016/09/08/distributed-transaction/007.jpg)\n\n1）微服务在同一个本地事务中记录业务数据和事件；\n\n2）微服务实时发布一个事件立即通知关联的业务服务，如果事件发布成功立即删除记录的事件；\n\n3）事件恢复服务定时从事件表中恢复未发布成功的事件，重新发布，重新发布成功才删除记录的事件；\n\n其中第2条的操作主要是为了增加发布事件的实时性，由第三条保证事件一定被发布。\n\n本地事件表方式业务系统和事件系统耦合比较紧密，额外的事件数据库操作也会给数据库带来额外的压力，可能成为瓶颈。\n\n2. 外部事件表方法将事件持久化到外部的事件系统，事件系统需提供实时事件服务以接受微服务发布事件，同时事件系统还需要提供事件恢复服务来确认和恢复事件。\n\n![](/assets/images/2016/09/08/distributed-transaction/008.jpg)\n\n1）业务服务在事务提交前，通过实时事件服务向事件系统请求发送事件，事件系统只记录事件并不真正发送；     \n\n2）业务服务在提交后，通过实时事件服务向事件系统确认发送，事件得到确认后，事件系统才真正发布事件到消息代理；\n\n3）业务服务在业务回滚时，通过实时事件向事件系统取消事件；\n\n4）如果业务服务在发送确认或取消之前停止服务了怎么办呢？事件系统的事件恢复服务会定期找到未确认发送的事件向业务服务查询状态，根据业务服务返回的状态决定事件是要发布还是取消；\n\n该方式将业务系统和事件系统独立解耦，都可以独立伸缩。但是这种方式需要一次额外的发送操作，并且需要发布者提供额外的查询接口。\n \n基于可靠事件的事务保障模式可以有很多的变种实现，比如对消息可靠性不高的话，有如下做法：\n1）将本地表的方式换做缓存方式；\n为了提高消息投递的效率，可以：\n2）多次消息合并投递模式；\n为了提供强一致性的事务保障，甚至可以采用：\n3）本地消息表持久化（保障发方法消息可靠落地）+远程消息表持久化（保障接收方消息可靠落地）结合的模式。\n   \n在我们的流程产品中针对业务和流程的分布式事务解决方案就采用了多次消息合并投递+本地缓存+远程消息表持久化的模式，接下来为大家介绍具体的使用方式。\n\n使用场景\n在实际业务项目中通常采用业务与流程分布式部署的模式，业务系统通过远程接口访问流程引擎，业务数据同流程数据存放到各自的数据库中。 \n\n![](/assets/images/2016/09/08/distributed-transaction/009.jpg)\n\n在这种场景中，如果业务系统的流程操作和业务操作交叉在一起，当流程操作成功，而业务操作失败时，就会造成业务回滚，而流程在引擎端已经创建，导致业务系统和流程引擎状态不一致。       \n\n![](/assets/images/2016/09/08/distributed-transaction/010.jpg)\n\n在业务应用中对一个事务中的流程操作采用本地缓存+批量投递+远程落地的模式（如果需要在客户端确保消息可靠性，可以将本地缓存换成本地表的方式）；在流程引擎端在消息投递来之后，做了消息表落地的工作，保障可靠执行。在我们流程产品中流程引擎对外提供的客户端提供了统一的分布式事务API，和使用传统本地事务一样进行操作，保证了透明性，简化开发人员的复杂度。分布式事务API支持两种协议模式：\n\n1. http+二进制序列化的模式\n2. WebService模式\n\n后续我们会增加Restful风格的接口。\n     \n可靠事件模式在互联网公司中有着较大规模的应用，该方式适合的业务场景非常广泛，而且能够做到数据的最终一致性，缺点是该模式实现难度较大，依赖数据库实现可靠性，在高并发场景下可能存在性能瓶颈，需要在公司层面搭建一套标准的可靠事件框架来支撑。\n\n## 五、可靠事件模式（非事务消息、事务消息）\n\n可靠事件模式的事件通知可以采用消息的模式来实现，其实现原理和本地事件表、外部事件表一致，本文就不在详述。目前常用的消息框架ActiveMQ、RabbitMQ、Kafka、RocketMQ可以用来作为消息投递的渠道。注意：Kafka通常不适合，因为Kafka的设计存在丢消息的场景。\n\n目前市面上支持事务的消息产品比较少，RocketMQ虽然实现了可靠的事务模式，但并没有开源出来、没有开源出来、没有开源出来，顺便说一下国内的开源有太多需要改进的空间（关键点不开源，开源后没有持续的投入）。\n  \n## 六、TCC模式\n\n一个完整的TCC业务由一个主业务服务和若干个从业务服务组成，主业务服务发起并完成整个业务活动，TCC模式要求从服务提供三个接口：Try、Confirm、Cancel。·\n\n![](/assets/images/2016/09/08/distributed-transaction/011.jpg)\n\n1) Try：完成所有业务检查\n\n预留必须业务资源     \n\n2) Confirm：真正执行业务\n\n不作任何业务检查；只使用Try阶段预留的业务资源；Confirm操作满足幂等性；\n\n3) Cancel：\n\n释放Try阶段预留的业务资源；Cancel操作满足幂等性；\n\n整个TCC业务分成两个阶段完成：\n\n![](/assets/images/2016/09/08/distributed-transaction/012.jpg)\n\n第一阶段：主业务服务分别调用所有从业务的try操作，并在活动管理器中登记所有从业务服务。当所有从业务服务的try操作都调用成功或者某个从业务服务的try操作失败，进入第二阶段。\n\n第二阶段：活动管理器根据第一阶段的执行结果来执行confirm或cancel操作。如果第一阶段所有try操作都成功，则活动管理器调用所有从业务活动的confirm操作。否则调用所有从业务服务的cancel操作。\n\nTCC模式的详细描述可以参见同事田向阳的技术文章《微服务架构下数据一致性保证（三）》\n     \n需要注意的是第二阶段confirm或cancel操作本身也是满足最终一致性的过程，在调用confirm或cancel的时候也可能因为某种原因（比如网络）导致调用失败，所以需要活动管理支持重试的能力，同时这也就要求confirm和cancel操作具有幂等性。\n     \n# 总结\n\n六种分布式事务的实现模式从数据一致性、事务级别、吞吐量、实现的复杂度各有优劣，下图为大家提供选择依据。\n\n![](/assets/images/2016/09/08/distributed-transaction/013.jpg)\n\n站在架构设计的角度，针对数据一致性需要把业务因素考虑进来，这有利于团队在技术上作出更合理的选择。根据具体业务场景，评估出业务对事务的优先级，更有利于作出架构上的取舍。我们经常接触的证券、金融、支付等行业，对数据一致性要求极高，需要严格的实时保证要求；但对于基于社交类的应用场景，可以采用局部实时一致，最终全局一致的能力。因此大家在实践过程中，一定要把技术与业务结合，选择适合自身业务的技术方案。\n \n# 关于作者：\n\n刘相 EAII-企业架构创新研究院 专家委员\n\n计算机应用技术硕士，现任普元软件产品部副总兼SOA产品线总经理。十年IT行业经验，专注于企业软件平台，在SOA、分布式计算、企业架构设计等领域。先后主导公司EOS7、Portal、云PAAS平台、云流程平台、BPM等系列产品的开发和设计工作。著有国内首本解析SpringBatch的中文原创图书《SpringBatch批处理框架》。个人爱好：阅读，慢跑。\n\n---\n\n* Author: 刘相\n* Source: [EAII企业架构创新研究院](http://eaworld.io)\n* Link: [分布式事务：不过是在一致性、吞吐量和复杂度之间，做一个选择](https://mp.weixin.qq.com/s/ONXodrh5XYu5M65mAuKUIA)\n","tags":["Transation"],"categories":["Distributed"]},{"title":"常用推荐算法（50页干货）","url":"%2F2016%2F2016-09-08-common-recommendation-algorithm%2F","content":"\n内容主要围绕电商中用到的一些推荐算法，参考了Xavier Amatriain在CMU的Machine Learning暑期学校上的讲授的内容。\n\n![](/assets/images/2016/09/08/common-recommendation-algorithm/1.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/2.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/3.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/4.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/5.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/6.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/7.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/8.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/9.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/10.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/11.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/12.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/13.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/14.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/15.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/16.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/17.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/18.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/19.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/20.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/21.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/22.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/23.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/24.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/25.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/26.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/27.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/28.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/29.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/30.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/31.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/32.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/33.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/34.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/35.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/36.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/37.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/38.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/39.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/40.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/41.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/42.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/43.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/44.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/45.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/46.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/47.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/48.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/49.jpg)\n\n---\n\n* 原文链接：[常用推荐算法（50页干货）](http://mp.weixin.qq.com/s?src=3&timestamp=1476027251&ver=1&signature=dLgAoBsKg8-yyZDhqIpk7uHXpKEqxm9qEV36xu8QxjtLFBYx1JbN65c5lQNpyS2s-DmOtjubBugx6HQmZbSl*Z9Rclsqh3bWhNZ-Tuf3blRdt-ahtLmThghft*aHDMGJ6iz*oyUWRrZvSa3VfQUBzBR8AEDY72O29Vuy22AXk-k=)\n","tags":["Recommendation"],"categories":["Machine-Learning"]},{"title":"HDFS NameNode 内存全景","url":"%2F2016%2F2016-08-26-hdfs-namenode%2F","content":"\n### 一、概述\n\n从整个HDFS系统架构上看，NameNode是其中最重要、最复杂也是最容易出现问题的地方，而且一旦NameNode出现故障，整个Hadoop集群就将处于不可服务的状态，同时随着数据规模和集群规模地持续增长，很多小量级时被隐藏的问题逐渐暴露出来。所以，从更高层次掌握NameNode的内部结构和运行机制尤其重要。除特别说明外，本文基于社区版本Hadoop-2.4.1[1][2]，虽然2.4.1之后已经有多次版本迭代，但是基本原理相同。\n\nNameNode管理着整个HDFS文件系统的元数据。从架构设计上看，元数据大致分成两个层次：Namespace管理层，负责管理文件系统中的树状目录结构以及文件与数据块的映射关系；块管理层，负责管理文件系统中文件的物理块与实际存储位置的映射关系BlocksMap，如图1所示[1]。Namespace管理的元数据除内存常驻外，也会周期Flush到持久化设备上FsImage文件；BlocksMap元数据只在内存中存在；当NameNode发生重启，首先从持久化设备中读取FsImage构建Namespace，之后根据DataNode的汇报信息重新构造BlocksMap。这两部分数据结构是占据了NameNode大部分JVM Heap空间。\n\n![](/assets/images/2016/08/26/hdfs-namenode/hdfs.png)\n\n图1 HDFS结构图\n\n除了对文件系统本身元数据的管理之外，NameNode还需要维护整个集群的机架及DataNode的信息、Lease管理以及集中式缓存引入的缓存管理等等。这几部分数据结构空间占用相对固定，且占用较小。\n\n测试数据显示，Namespace目录和文件总量到2亿，数据块总量到3亿后，常驻内存使用量超过90GB。\n\n### 二、内存全景\n\n如前述，NameNode整个内存结构大致可以分成四大部分：Namespace、BlocksMap、NetworkTopology及其它，图2为各数据结构内存逻辑分布图示。\n\n![](/assets/images/2016/08/26/hdfs-namenode/namenodemem.png)\n\n图2 NameNode内存全景图\n\nNamespace：维护整个文件系统的目录树结构及目录树上的状态变化；\n\nBlockManager：维护整个文件系统中与数据块相关的信息及数据块的状态变化；\n\nNetworkTopology：维护机架拓扑及DataNode信息，机架感知的基础；\n\n其它：\n\nLeaseManager：读写的互斥同步就是靠Lease实现，支持HDFS的Write-Once-Read-Many的核心数据结构；\n\nCacheManager：Hadoop 2.3.0引入的集中式缓存新特性，支持集中式缓存的管理，实现memory-locality提升读性能；\n\nSnapshotManager：Hadoop 2.1.0引入的Snapshot新特性，用于数据备份、回滚，以防止因用户误操作导致集群出现数据问题；\n\nDelegationTokenSecretManager：管理HDFS的安全访问；\n\n另外还有临时数据信息、统计信息metrics等等。\n\nNameNode常驻内存主要被Namespace和BlockManager使用，二者使用占比分别接近50%。其它部分内存开销较小且相对固定，与Namespace和BlockManager相比基本可以忽略。\n\n### 三、内存分析\n\n#### 3.1 Namespace\n\n与单机文件系统相似，HDFS对文件系统的目录结构也是按照树状结构维护，Namespace保存了目录树及每个目录/文件节点的属性。除在内存常驻外，这部分数据会定期flush到持久化设备上，生成一个新的FsImage文件，方便NameNode发生重启时，从FsImage及时恢复整个Namespace。图3所示为Namespace内存结构。前述集群中目录和文件总量即整个Namespace目录树中包含的节点总数，可见Namespace本身其实是一棵非常巨大的树。\n\n![](/assets/images/2016/08/26/hdfs-namenode/namespace.png)\n\n图3 Namespace内存结构\n\n在整个Namespace目录树中存在两种不同类型的INode数据结构：INodeDirectory和INodeFile。其中INodeDirectory标识的是目录树中的目录，INodeFile标识的是目录树中的文件。由于二者均继承自INode，所以具备大部分相同的公共信息INodeWithAdditionalFields，除常用基础属性外，其中还提供了扩展属性features，如Quota、Snapshot等均通过Feature增加，如果以后出现新属性也可通过Feature方便扩展。不同的是，INodeFile特有的标识副本数和数据块大小组合的header（2.6.1之后又新增了标识存储策略ID的信息）及该文件包含的有序Blocks数组；INodeDirectory则特有子节点的列表children。这里需要特别说明children是默认大小为5的ArrayList，按照子节点name有序存储，虽然在插入时会损失一部分写性能，但是可以方便后续快速二分查找提高读性能，对一般存储系统，读操作比写操作占比要高。具体的继承关系见图4所示。\n\n![](/assets/images/2016/08/26/hdfs-namenode/inode.png)\n\n图4 INode继承关系\n\n#### 3.2 BlockManager\n\nBlocksMap在NameNode内存空间占据很大比例，由BlockManager统一管理，相比Namespace，BlockManager管理的这部分数据要复杂的多。Namespace与BlockManager之间通过前面提到的INodeFile有序Blocks数组关联到一起。图5所示BlockManager管理的内存结构。\n\n![](/assets/images/2016/08/26/hdfs-namenode/blockmanager.png)\n\n图5 BlockManager管理的内存结构\n\n每一个INodeFile都会包含数量不等的Block，具体数量由文件大小及每一个Block大小（默认为64M）比值决定，这些Block按照所在文件的先后顺序组成BlockInfo数组，如图5所示的BlockInfo[A~K]，BlockInfo维护的是Block的元数据，结构如图6所示，数据本身是由DataNode管理，所以BlockInfo需要包含实际数据到底由哪些DataNode管理的信息，这里的核心是名为triplets的Object数组，大小为3*replicas，其中replicas是Block副本数量。triplets包含的信息：\n\n* triplets[i]：Block所在的DataNode；\n\n* triplets[i+1]：该DataNode上前一个Block；\n\n* triplets[i+2]：该DataNode上后一个Block；\n\n其中i表示的是Block的第i个副本，i取值[0,replicas)。\n\n![](/assets/images/2016/08/26/hdfs-namenode/blockinfo.png)\n\n图6 BlockInfo继承关系\n\n从前面描述可以看到BlockInfo几块重要信息：文件包含了哪些Block，这些Block分别被实际存储在哪些DataNode上，DataNode上所有Block前后链表关系。\n\n如果从信息完整度来看，以上数据足够支持所有关于HDFS文件系统的正常操作，但还存在一个使用场景较多的问题：不能通过blockid快速定位Block，所以引入了BlocksMap。\n\nBlocksMap底层通过LightWeightGSet实现，本质是一个链式解决冲突的哈希表。为了避免rehash过程带来的性能开销，初始化时，索引空间直接给到了整个JVM可用内存的2%，并且不再变化。集群启动过程，DataNode会进行BR（BlockReport），根据BR的每一个Block计算其HashCode，之后将对应的BlockInfo插入到相应位置逐渐构建起来巨大的BlocksMap。前面在INodeFile里也提到的BlockInfo集合，如果我们将BlocksMap里的BlockInfo与所有INodeFile里的BlockInfo分别收集起来，可以发现两个集合完全相同，事实上BlocksMap里所有的BlockInfo就是INodeFile中对应BlockInfo的引用；通过Block查找对应BlockInfo时，也是先对Block计算HashCode，根据结果快速定位到对应的BlockInfo信息。至此涉及到HDFS文件系统本身元数据的问题基本上已经解决了。\n\n前面提到部分都属于静态数据部分，NameNode内存中所有数据都要随读写情况发生变化，BlockManager当然也需要管理这部分动态数据。主要是当Block发生变化不符合预期时需要及时调整Blocks的分布。这里涉及几个核心的数据结构：\n\nexcessReplicateMap：若某个Block实际存储的副本数多于预设副本数，这时候需要删除多余副本，这里多余副本会被置于excessReplicateMap中。excessReplicateMap是从DataNode的StorageID到Block集合的映射集。\n\nneededReplications：若某个Block实际存储的副本数少于预设副本数，这时候需要补充缺少副本，这里哪些Block缺少多少个副本都统一存在neededReplications里，本质上neededReplications是一个优先级队列，缺少副本数越多的Block之后越会被优先处理。\n\ninvalidateBlocks：若某个Block即将被删除，会被置于invalidateBlocks中。invalidateBlocks是从DataNode的StorageID到Block集合的映射集。如某个文件被客户端执行了删除操作，该文件所属的所有Block会先被置于invalidateBlocks中。\n\ncorruptReplicas：有些场景Block由于时间戳/长度不匹配等等造成Block不可用，会被暂存在corruptReplicas中，之后再做处理。\n\n前面几个涉及到Block分布情况动态变化的核心数据结构，这里的数据实际上是过渡性质的，BlockManager内部的ReplicationMonitor线程（图5标识Thread/Monitor）会持续从其中取出数据并通过逻辑处理后分发给具体的DatanodeDescriptor对应数据结构（3.3 NetworkTopology里会有简单介绍），当对应DataNode的心跳过来之后，NameNode会遍历DatanodeDescriptor里暂存的数据，将其转换成对应指令返回给DataNode，DataNode收到任务并执行完成后再反馈回NameNode，之后DatanodeDescriptor里对应信息被清除。如BlockB预设副本数为3，由于某种原因实际副本变成4（如之前下线的DataNode D重新上线，其中B正好有BlockB的一个副本数据），BlockManager能及时发现副本变化，并将多余的DataNode D上BlockB副本放置到excessReplicateMap中，ReplicationMonitor线程定期检查时发现excessReplicateMap中数据后将其移到DataNode D对应DatanodeDescriptor中invalidateBlocks里，当DataNode D下次心跳过来后，随心跳返回删除Block B的指令，DataNode D收到指令实际删除其上的Block B数据并反馈回NameNode，此后BlockManager将DataNode D上的Block B从内存中清除，至此Block B的副本符合预期，整个流程如图7所示。\n\n![](/assets/images/2016/08/26/hdfs-namenode/blockreplica.png)\n\n图7 副本数异常时处理过程\n\n#### 3.3 NetworkTopology\n\n前面多次提到Block与DataNode之间的关联关系，事实上NameNode确实还需要管理所有DataNode，不仅如此，由于数据写入前需要确定数据块写入位置，NameNode还维护着整个机架拓扑NetworkTopology。图8所示内存中机架拓扑图。\n\n![](/assets/images/2016/08/26/hdfs-namenode/networktopology.png)\n\n图8 NetworkTopology内存结构\n\n从图8可以看出这里包含两个部分：机架拓扑结构NetworkTopology和DataNode节点信息。其中树状的机架拓扑是根据机架感知（一般都是外部脚本计算得到）在集群启动完成后建立起来，整个机架的拓扑结构在NameNode的生命周期内一般不会发生变化；另一部分是比较关键的DataNode信息，BlockManager已经提到每一个DataNode上的Blocks集合都会形成一个双向链表，更准确的应该是DataNode的每一个存储单元DatanodeStorageInfo上的所有Blocks集合会形成一个双向链表，这个链表的入口就是机架拓扑结构叶子节点即DataNode管理的DatanodeStorageInfo。此外由于上层应用对数据的增删查随时发生变化，随之DatanodeStorageInfo上的Blocks也会动态变化，所以NetworkTopology上的DataNode对象还会管理这些动态变化的数据结构，如replicateBlocks/recoverBlocks/invalidateBlocks，这些数据结构正好和BlockManager管理的动态数据结构对应，实现了数据的动态变化由BlockManager传达到DataNode内存对象最后通过指令下达到物理DataNode实际执行的流动过程，流程在3.2 BlockManager已经介绍。\n\n这里存在一个问题，为什么DatanodeStorageInfo下所有Block之间会以双向链表组织，而不是其它数据结构？如果结合实际场景就不难发现，对每一个DatanodeStorageInfo下Block的操作集中在快速增加/删除（Block动态增减变化）及顺序遍历（BlockReport期间），所以双向链表是非常合适的数据结构。\n\n#### 3.4 LeaseManager\n\nLease 机制是重要的分布式协议，广泛应用于各种实际的分布式系统中。HDFS支持Write-Once-Read-Many，对文件写操作的互斥同步靠Lease实现。Lease实际上是时间约束锁，其主要特点是排他性。客户端写文件时需要先申请一个Lease，一旦有客户端持有了某个文件的Lease，其它客户端就不可能再申请到该文件的Lease，这就保证了同一时刻对一个文件的写操作只能发生在一个客户端。NameNode的LeaseManager是Lease机制的核心，维护了文件与Lease、客户端与Lease的对应关系，这类信息会随写数据的变化实时发生对应改变。\n\n![](/assets/images/2016/08/26/hdfs-namenode/leasemanager.png)\n\n图9 LeaseManager的内存数据结构\n\n图9所示为LeaseManager内存结构，包括以下三个主要核心数据结构：\n\nsortedLeases：Lease集合，按照时间先后有序组织，便于检查Lease是否超时；\n\nleases：客户端到Lease的映射关系；\n\nsortedLeasesByPath：文件路径到Lease的映射关系；\n\n其中每一个写数据的客户端会对应一个Lease，每个Lease里包含至少一个标识文件路径的Path。Lease本身已经维护了其持有者（客户端）及该Lease正在操作的文件路径集合，之所以增加了leases和sortedLeasesByPath为提高通过Lease持有者或文件路径快速索引到Lease的性能。\n\n由于Lease本身的时间约束特性，当Lease发生超时后需要强制回收，内存中与该Lease相关的内容要被及时清除。超时检查及超时后的处理逻辑由LeaseManager.Monitor统一执行。LeaseManager中维护了两个与Lease相关的超时时间：软超时（softLimit）和硬超时（hardLimit），使用场景稍有不同。\n\n正常情况下，客户端向集群写文件前需要向NameNode的LeaseManager申请Lease；写文件过程中定期更新Lease时间，以防Lease过期，周期与softLimit相关；写完数据后申请释放Lease。整个过程可能发生两类问题：（1）写文件过程中客户端没有及时更新Lease时间；（2）写完文件后没有成功释放Lease。两个问题分别对应为softLimit和hardLimit。两种场景都会触发LeaseManager对Lease超时强制回收。如果客户端写文件过程中没有及时更新Lease超过softLimit时间后，另一客户端尝试对同一文件进行写操作时触发Lease软超时强制回收；如果客户端写文件完成但是没有成功释放Lease，则会由LeaseManager的后台线程LeaseManager.Monitor检查是否硬超时后统一触发超时回收。不管是softLimit还是hardLimit超时触发的强制Lease回收，处理逻辑都一样：FSNamesystem.internalReleaseLease，逻辑本身比较复杂，这里不再展开，简单的说先对Lease过期前最后一次写入的Block进行检查和修复，之后释放超时持有的Lease，保证后面其它客户端的写入能够正常申请到该文件的Lease。\n\nNameNode内存数据结构非常丰富，这里对几个重要的数据结构进行了简单的描述，除了前面罗列之外，其实还有如SnapShotManager/CacheManager等，由于其内存占用有限且有一些特性还尚未稳定，这里不再展开。\n\n### 四、问题\n\n随着集群中数据规模的不断积累，NameNode内存占用随之成比例增长。不可避免的NameNode内存将逐渐成为集群发展的瓶颈，并开始暴漏诸多问题。\n\n1、启动时间变长。NameNode的启动过程可以分成FsImage数据加载、editlogs回放、Checkpoint、DataNode的BlockReport几个阶段。数据规模较小时，启动时间可以控制在~10min以内，当元数据规模达到5亿（Namespace中INode数超过2亿，Block数接近3亿），FsImage文件大小将接近到20GB，加载FsImage数据就需要~14min，Checkpoint需要~6min，再加上其它阶段整个重启过程将持续~50min，极端情况甚至超过60min，虽然经过多轮优化重启过程已经能够稳定在~30min，但也非常耗时。如果数据规模继续增加，启动过程将同步增加。\n\n2、性能开始下降。HDFS文件系统的所有元数据相关操作基本上均在NameNode端完成，当数据规模的增加致内存占用变大后，元数据的增删改查性能会出现下降，且这种下降趋势会因规模效应及复杂的处理逻辑被放大，相对复杂的RPC请求（如addblock）性能下降更加明显。\n\n3、NameNode JVM FGC（Full GC）风险较高。主要体现在两个方面：（1）FGC频率增加；（2）FGC时间增加且风险不可控。针对NameNode的应用场景，目前看CMS内存回收算法比较主流，正常情况下，对超过100GB内存进行回收处理时，可以控制到秒级别的停顿时间，但是如果回收失败被降级到串行内存回收时，应用的停顿时间将达到数百秒，这对应用本身是致命的。\n\n4、超大JVM Heap Size调试问题。如果线上集群性能表现变差，不得不通过分析内存才能得到结论时，会成为一件异常困难的事情。且不说Dump本身极其费时费力，Dump超大内存时存在极大概率使NameNode不可服务。\n\n针对NameNode内存增长带来的诸多问题，社区和业界都在持续关注并尝试不同的解决方案。整体上两个思路：（1）扩展NameNode分散单点负载；（2）引入外部系统支持NameNode内存数据。\n\n从2010年开始社区就投入大量精力持续解决，Federation方案[3]通过对NameNode进行水平扩展分散单点负载的方式解决NameNode的问题，经过几年的发展该方案逐渐稳定，目前已经被业界广泛使用。除此之外，社区也在尝试将Namespace存储值外部的KV存储系统如LevelDB[4]，从而降低NameNode内存负载。\n\n除社区外，业界也在尝试自己的解决方案。Baidu HDFS2[5]将元数据管理通过主从架构的集群形式提供服务，本质上是将原生NameNode管理的Namespace和BlockManagement进行物理拆分。其中Namespace负责管理整个文件系统的目录树及文件到BlockID集合的映射关系，BlockID到DataNode的映射关系是按照一定的规则分到多个服务节点分布式管理，这种方案与Lustre有相似之处（Hash-based Partition）。Taobao HDFS2[6]尝试过采用另外的思路，借助高速存储设备，将元数据通过外存设备进行持久化存储，保持NameNode完全无状态，实现NameNode无限扩展的可能。其它类似的诸多方案不一而足。\n\n尽管社区和业界均对NameNode内存瓶颈有成熟的解决方案，但是不一定适用所有的场景，尤其是中小规模集群。结合实践过程和集群规模发展期可能遇到的NameNode内存相关问题这里有几点建议：\n\n1. 合并小文件。正如前面提到，目录/文件和Block均会占用NameNode内存空间，大量小文件会降低内存使用效率；另外，小文件的读写性能远远低于大文件的读写，主要原因对小文件读写需要在多个数据源切换，严重影响性能。\n\n2. 调整合适的BlockSize。主要针对集群内文件较大的业务场景，可以通过调整默认的Block Size大小（参数：dfs.blocksize，默认128M），降低NameNode的内存增长趋势。\n\n3. HDFS Federation方案。当集群和数据均达到一定规模时，仅通过垂直扩展NameNode已不能很好的支持业务发展，可以考虑HDFS Federation方案实现对NameNode的水平扩展，在解决NameNode的内存问题的同时通过Federation可以达到良好的隔离性，不会因为单一应用压垮整集群。\n\n### 五、总结\n\nNameNode在整个HDFS系统架构中占据举足轻重的位置，内部数据和处理逻辑相对复杂，本文简单梳理了NameNode的内存全景及对其中几个关键数据结构，从NameNode内存核心数据视角对NameNode进行了简单的解读，并结合实际场景介绍了随着数据规模的增加，NameNode内存可能遇到的问题及业界各种可借鉴的解决方案。在后续的《HDFS NameNode内存详解》中，我们会详细解读NameNode的几个关键数据结构，分析各数据结构在JVM Heap使用占比情况。\n\n### 六、参考\n\n[1] Apache Hadoop, 2016, [https://hadoop.apache.org/](https://hadoop.apache.org/).\n[2] Apache Hadoop Source Code, 2014, [https://github.com/apache/hadoop/tree/branch-2.4.1/](https://github.com/apache/hadoop/tree/branch-2.4.1/).\n[3] HDFS Federation, 2011, [https://issues.apache.org/jira/browse/HDFS-1052](https://issues.apache.org/jira/browse/HDFS-1052).\n[4] NemeNode Scalability, 2013, [https://issues.apache.org/jira/browse/HDFS-5389](https://issues.apache.org/jira/browse/HDFS-5389).\n[5] Baidu HDFS2, 2013, [http://static.zhizuzhefu.com/wordpress_cp/uploads/2013/04/a9.pdf](http://static.zhizuzhefu.com/wordpress_cp/uploads/2013/04/a9.pdf).\n[6] Taobao HDFS2, 2012, [https://github.com/taobao/ADFS](https://github.com/taobao/ADFS).\n\n---\n\n* 原文链接：[HDFS NameNode 内存全景](http://tech.meituan.com/namenode.html)\n","tags":["NameNode"],"categories":["HDFS"]},{"title":"算法的性能分析","url":"%2F2016%2F2016-08-20-algorithm-performance%2F","content":"\n在程序设计中算法的性能分析是非常重要的，针对一个具体的问题可能提出若干种不同的算法实现。如何从这些算法种找出性能最优的那个？或者说针对一个具体的算法如何评论它的优劣？这里要涉及的一个问题就是如何对算法的性能进行评价？评价算法的性能主要从两个方面着手：\n\n1. 算法的执行时间\n2. 算法所占用的存储空间\n\n这两个指标分别对应算法的`时间复杂度`与`空间复杂度`，下面分别来说.\n\n# 算法的时间复杂度\n\n## 定义\n\n算法的时间复杂度的目的是为了近似的评估算法的执行时间，因为要准确测量一个算法的执行时间多少是非常困难的，它受到计算机软硬件环境的影响。它的定义是这样的:\n\n`T(n) = O(f(n))`\n\n它表示随问题规模n的增大，算法的执行时间的增长率和算法中语句的总的执行次数`f(n)`的增长率相同，称作算法的渐近时间复杂度，简称时间复杂度。其中这里O来表示数量级，`f(n)`一般是算法中频度最大的语句频度.\n\n## 如何求时间复杂度\n\n要求算法的时间复杂度, 关键就在于找到这个算法中执行频度最大的那条语句`f(n)`, 找到了`f(n)`那么时间复杂度`T(n)`自然就出来了.\n\n下面举例说明:\n\n1. 常数阶\n\n```\nO(1)\n\ntemp = i;\ni = j;\nj = temp;\n```\n\n以上3条语句的语句频度都为1, 而且该程序段的执行时间是一个与问题规模`n`无关的常数. 这种类型的算法的时间复杂度:`T(n)=O(1)`.\n\n2. 线性型\n\n```\nO(n)\n\nfor (int i = 0; i < n; i++){\n  n++; //频度最大\n}\n```\n\n很显然这种类型的算法的语句频度与问题规模n刚好是呈正线性相关的, 时间复杂度为`T(n) = O(n)`.\n\n3. 平方型\n\n```\nO(n2)\n\nint[] a = {3, 2, 4, 7, ..., n}\nfor(int i = 0; i < n - 1; i++){\n\tfor (int j = i + 1; j < n; j++){\n\t\tif(a[i] > a[j]){ // do swap, f(n)= n * n\n\t\t\tint temp = a[i]; //频度最大\n\t\t\ta[i] = a[j];\n\t\t\ta[j] = temp;\n\t\t}\n\t}\n}\n```\n\n当有若干个循环语句时, 算法的时间复杂度是由嵌套最深的循环语句中最内层的语句的频度`f(n)`决定.而忽略其它嵌套层次更低的循环.\n\n4. 立方型\n\n```\nO(n3)\n\nfor i..n\n  for ...\n    for ...\n      do something... //频度最大\n```\n\n## 常见的时间复杂度\n\n    O(1)常数型\n    O(log2n)对数型\n    O(nlog2n)二维型\n    O(n)线性型\n    O(n2)平方型\n    O(n3)立方型\n    O(2n)指数型\n\n![时间复杂度图示](/assets/images/2016/08/20/algorithm-performance/algorithm.jpeg)\n\n一般情况下, 随问题规模`n`的增大, 时间复杂度`T(n)`增长最慢的算法为最优算法. 以上几种算法随`n`的不断最加时间复杂度增加越来越快, 因此一般应该选择使用`O(nk)`的算法. 避免使用指数阶的算法.\n\n## 最坏时间复杂度与平均时间复杂度\n\n算法的时间复杂度不仅与问题规模`n`相关还与输入实例的初始状态有关.\n\n看个例子:\n\n```\nT(n) = O(n)\n\ni = n - 1;\nwhile(i >= 0 && (a[i] != k))\n  i--;\n```\n\n上述算法的时间复杂度不仅与`n`相关还与输入的数组a及k的取值情况相关:\n\n最坏情况: 数组`a`中没有与`k`相等的元素.则语句3的频度`f(n) = n`, 时间复杂度`T(n) = O(n)`\n\n最好情况: 或`a`中最后一个元素等于`k`,则语句3的频度`f(n) = 0`, 时间复杂度`T(n) = O(1)`\n\n一般不特别说明, 讨论的时间复杂度均是最坏情况下的时间复杂度, 这样做的原因是能够保证算法在任何输入实例情况下都能够被考虑到. 而平均时间复杂度是指所有可能的输入实例均以等概率出现的情况下的时间复杂度.\n\n因此上述算法的时间复杂度为: `O(n)`\n\n# 算法的空间复杂度\n\n## 辅助存储空间\n\n一般情况下, 一个程序在机器上执行时, 除了需要存储本身所需要的代码/输入数据外, 还需要一些对数据进行操作的辅助存储空间.其中输入数据所占用的具体空间取决于问题本身, 与算法无关. 因此我们所讨论的空间复杂度只与该算法在实现时所需要的辅助空间单元个数相关. 即 空间复杂度讨论的是算法所需要的辅助存储空间.\n\n## 定义\n\n算法的空间复杂度`S(n)`定义为该算法所耗费的存储空间的数量级, 它是问题规模n的函数, 记作:\n\n`S(n) = O(f(n))`\n\n若算法执行时间时所需要的辅助空间相对于输入数据量而言是一个常数, 则称这个算法为原地工作, 辅助空间为`O(1)`. 看个例子:\n将一维数组`a`中的`n`个数据逆序存放到原数组中, 下面是两种算法:\n\n[算法1]\n\n```\nS(n) = O(n)\n\nfor(i = 0; i < n; i++)\n  b[i] = a[n - i - 1];\nfor(i = 0; i < n; i++)\n  a[i] = b[i]\n```\n\n[算法2]\n\n```\nS(n) = O(1)\n\nfor(i=0; i < n/2; i++){\n  t = a[i];\n  a[i] = a[n - i - 1];\n  a[n - i - 1] = t;\n}\n```\n\n算法1的空间复杂度为`O(n)`, 需要一个大小为`n`的辅助数组`b`\n\n算法2的空间复杂度为`O(1)`, 仅需要一个变量`t`, 与问题规模`n`无关\n\n# 总结\n\n算法的空间复杂度与时间复杂度合称为算法的复杂度. 面对不同的算法如何选择主要就从这两个方面去考虑, 理想情况是一个算法的时间与空间复杂度都小, 但这是很难做到的, 面对不同的情况要具体问题具体分析: 是以时间换空间, 还是以空间换时间.\n\n# 参考\n\n[数据结构-用C语言描述](https://book.douban.com/subject/10506484/)\n\n---\n\n* Author: [CoderGhui](https://ghui.me/)\n* Link: [算法的性能分析](https://ghui.me/post/2016/08/algorithm_performance/)","tags":["Performance"],"categories":["Algorithm"]},{"title":"分布式队列编程优化篇","url":"%2F2016%2F2016-08-05-distributed-queue-based-programming-optimization%2F","content":"\n## 前言\n\n“分布式队列编程”是一个系列文，之前我们已经发布了《分布式队列编程模型、实战》，主要剖析了分布式队列编程模型的需求来源、定义、结构以及其变化多样性；根据作者在新美大实际工作经验，给出了队列式编程在分布式环境下的一些具体应用。本文将重点阐述工程师运用分布式队列编程构架的时候，在生产者、分布式队列以及消费者这三个环节的注意点以及优化建议。\n\n确定采用分布式队列编程模型之后，主体架构就算完成了，但工程师的工作还远远未结束。天下事必做于细，细节是一个不错的架构向一个优秀的系统进阶的关键因素。优化篇选取了作者以及其同事在运用分布式队列编程模型架构时所碰到的典型问题和解决方案。这里些问题出现的频率较高，如果你经验不够，很可能会“踩坑”。希望通过这些讲解，帮助读者降低分布式队列编程模型的使用门槛。本文将对分布式队列编程模型的三种角色：生产者（Producer），分布式队列（Queue），消费者（Consumer）分别进行优化讨论。\n\n## 生产者优化\n\n在分布式队列编程中，生产者往往并非真正的生产源头，只是整个数据流中的一个节点，这种生产者的操作是处理－转发（Process-Forward）模式。\n\n这种模式给工程师们带来的第一个问题是吞吐量问题。这种模式下运行的生产者，一边接收上游的数据，一边将处理完的数据发送给下游。本质上，它是一个非常经典的数学问题，其抽象模型是一些没有盖子的水箱，每个水箱接收来自上一个水箱的水，进行处理之后，再将水发送到下一个水箱。工程师需要预测水源的流量、每个环节水箱的处理能力、水龙头的排水速度，最终目的是避免水溢出水箱，或者尽可能地减小溢出事件的概率。实际上流式编程框架以及其开发者花了大量的精力去处理和优化这个问题。下文的缓存优化和批量写入优化都是针对该问题的解决方案。\n\n第二个需要考虑的问题是持久化。由于各种原因，系统总是会宕机。如果信息比较敏感，例如计费信息、火车票订单信息等，工程师们需要考虑系统宕机所带来的损失，找到让损失最小化的解决方案。持久化优化重点解决这一类问题。\n\n### 缓存优化\n\n处于“处理－转发”模式下运行的生产者往往被设计成请求驱动型的服务，即每个请求都会触发一个处理线程，线程处理完后将结果写入分布式队列。如果由于某种原因队列服务不可用，或者性能恶化，随着新请求的到来，生产者的处理线程就会产生堆积。这可能会导致如下两个问题：\n\n* 系统可用性降低。由于每个线程都需要一定的内存开销，线程过多会使系统内存耗尽，甚至可能产生雪崩效应导致最终完全不可用。\n\n* 信息丢失。为了避免系统崩溃，工程师可能会给请求驱动型服务设置一个处理线程池，设置最大处理线程数量。这是一种典型的降级策略，目的是为了系统崩溃。但是，后续的请求会因为没有处理线程而被迫阻塞，最终可能产生信息丢失。例如：对于广告计费采集，如果采集系统因为线程耗尽而不接收客户端的计费行为，这些计费行为就会丢失。\n\n缓解这类问题的思路来自于CAP理论，即通过降低一致性来提高可用性。生产者接收线程在收到请求之后第一时间不去处理，直接将请求缓存在内存中（牺牲一致性），而在后台启动多个处理线程从缓存中读取请求、进行处理并写入分布式队列。与线程所占用的内存开销相比，大部分的请求所占内存几乎可以忽略。通过在接收请求和处理请求之间增加一层内存缓存，可以大大提高系统的处理吞吐量和可扩展性。这个方案本质上是一个内存生产者消费者模型。\n\n### 批量写入优化\n\n如果生产者的请求过大，写分布式队列可能成为性能瓶颈，有如下几个因素：\n\n* 队列自身性能不高。\n\n* 分布式队列编程模型往往被应用在跨机房的系统里面，跨机房的网络开销往往容易成为系统瓶颈。\n\n* 消息确认机制往往会大大降低队列的吞吐量以及响应时间。\n\n如果在处理请求和写队列之间添加一层缓存，消息写入程序批量将消息写入队列，可以大大提高系统的吞吐量。原因如下：\n\n* 批量写队列可以大大减少生产者和分布式队列的交互次数和消息传输量。特别是对于高吞吐小载荷的消息实体，批量写可以显著降低网络传输量。\n\n* 对于需要确认机制的消息，确认机制往往会大大降低队列的吞吐量以及响应时间，某些高敏感的消息需要多个消息中间件代理同时确认，这近一步恶化性能。在生产者的应用层将多条消息批量组合成一个消息体，消息中间件就只需要对批量消息进行一次确认，这可能会数量级的提高消息传输性能。\n\n### 持久化优化\n\n通过添加缓存，消费者服务的吞吐量和可用性都得到了提升。但缓存引入了一个新问题——内存数据丢失。对于敏感数据，工程师需要考虑如下两个潜在问题：\n\n* 如果内存中存在未处理完的请求，而某些原因导致生产者服务宕机，内存数据就会丢失而可能无法恢复。\n\n* 如果分布式队列长时间不可用，随着请求数量的不断增加，最终系统内存可能会耗尽而崩溃，内存的消息也可能丢失。\n\n所以缓存中的数据需要定期被持久化到磁盘等持久层设备中，典型的持久化触发策略主要有两种：\n\n* 定期触发，即每隔一段时间进行一次持久化。\n\n* 定量触发，即每当缓存中的请求数量达到一定阈值后进行持久化。\n   是否需要持久化优化，以及持久化策略应该由请求数据的敏感度、请求量、持久化性能等因素共同决定。\n\n## 中间件选型\n\n分布式队列不等同于各种开源的或者收费的消息中间件，甚至在一些场景下完全不需要使用消息中间件。但是，消息中间件产生的目的就是解决消息传递问题，这为分布式队列编程架构提供了很多的便利。在实际工作中，工程师们应该将成熟的消息中间件作为队列的首要备选方案。\n\n本小节对消息中间件的功能、模型进行阐述，并给出一些消息中间件选型、部署的具体建议。\n\n### 中间件的功能\n\n明白一个系统的每个具体功能是设计和架构一个系统的基础。典型的消息中间件主要包含如下几个功能：\n\n* 消息接收\n\n* 消息分发\n\n* 消息存储\n\n* 消息读取\n\n### 概念模型\n\n抽象的消息中间件模型包含如下几个角色：\n\n* 发送者和接收者客户端（Sender/Receiver Client），在具体实施过程中，它们一般以库的形式嵌入到应用程序代码中。\n\n* 代理服务器（Broker Server），它们是与客户端代码直接交互的服务端代码。\n\n* 消息交换机（Exchanger），接收到的消息一般需要通过消息交换机（Exchanger）分发到具体的消息队列中。\n\n* 消息队列，一般是一块内存数据结构或持久化数据。\n\n概念模型如下图：\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/messagequeue.png)\n\n为了提高分发性能，很多消息中间件把消息代理服务器的拓扑图发送到发送者和接收者客户端（Sender/Receiver Client），如此一来，发送源可以直接进行消息分发。\n\n### 选型标准\n\n要完整的描述消息中间件各个方面非常困难，大部分良好的消息中间件都有完善的文档，这些文档的长度远远超过本文的总长度。但如下几个标准是工程师们在进行消息中间件选型时经常需要考虑和权衡的。\n\n#### 性能\n\n性能主要有两个方面需要考虑：吞吐量（Throughput）和响应时间（Latency）。\n\n不同的消息队列中间件的吞吐量和响应时间相差甚远，在选型时可以去网上查看一些性能对比报告。\n\n对于同一种中间件，不同的配置方式也会影响性能。主要有如下几方面的配置：\n\n* 是否需要确认机制，即写入队列后，或从队列读取后，是否需要进行确认。确认机制对响应时间的影响往往很大。\n\n* 能否批处理，即消息能否批量读取或者写入。批量操作可以大大减少应用程序与消息中间件的交互次数和消息传递量，大大提高吞吐量。\n\n* 能否进行分区（Partition）。将某一主题消息队列进行分区，同一主题消息可以有多台机器并行处理。这不仅仅能影响消息中间件的吞吐量，还决定着消息中间件是否具备良好的可伸缩性（Scalability）。\n\n* 是否需要进行持久化。将消息进行持久化往往会同时影响吞吐量和响应时间。\n\n#### 可靠性\n\n可靠性主要包含：可用性、持久化、确认机制等。\n\n高可用性的消息中间件应该具备如下特征：\n\n* 消息中间件代理服务器（Broker）具有主从备份。即当一台代理服务宕机之后，备用服务器能接管相关的服务。\n\n* 消息中间件中缓存的消息是否有备份、并持久化。\n   根据CAP理论，高可用、高一致性以及网络分裂不可兼得。根据作者的观察，大部分的消息中间件在面临网络分裂的情况下下，都很难保证数据的一致性以及可用性。 很多消息中间件都会提供一些可配置策略，让使用者在可用性和一致性之间做权衡。\n\n高可靠的消息中间件应该确保从发送者接收到的消息不会丢失。中间件代理服务器的宕机并不是小概率事件，所以保存在内存中的消息很容易发生丢失。大部分的消息中间件都依赖于消息的持久化去降低消息丢失损失，即将接收到的消息写入磁盘。即使提供持久化，仍有两个问题需要考虑：\n\n* 磁盘损坏问题。长时间来看，磁盘出问题的概率仍然存在。\n\n* 性能问题。与操作内存相比，磁盘I/O的操作性能要慢几个数量级。频繁持久化不仅会增加响应时间，也会降低吞吐量。\n   解决这两个问题的一个解决方案就是：多机确认，定期持久化。即消息被缓存在多台机器的内存中，只有每台机器都确认收到消息，才跟发送者确认（很多消息中间件都会提供相应的配置选项，让用户设置最少需要多少台机器接收到消息）。由于多台独立机器同时出故障的概率遵循乘法法则，指数级降低，这会大大提高消息中间件的可靠性。\n\n确认机制本质上是通讯的握手机制（Handshaking）。如果没有该机制，消息在传输过程中丢失将不会被发现。高敏感的消息要求选取具备确认机制的消息中间件。当然如果没有接收到消息中间件确认完成的指令，应用程序需要决定如何处理。典型的做法有两个：\n\n* 多次重试。\n\n* 暂存到本地磁盘或其它持久化媒介。\n\n#### 客户端接口所支持语言\n\n采用现存消息中间件就意味着避免重复造轮子。如果某个消息中间件未能提供对应语言的客户端接口，则意味着极大的成本和兼容性问题。\n\n#### 投递策略（Delivery policies）\n\n投递策略指的是一个消息会被发送几次。主要包含三种策略：最多一次（At most Once ）、最少一次（At least Once）、仅有一次（Exactly Once）。\n\n在实际应用中，只考虑消息中间件的投递策略并不能保证业务的投递策略，因为接收者在确认收到消息和处理完消息并持久化之间存在一个时间窗口。例如，即使消息中间件保证仅有一次（Exactly Once），如果接收者先确认消息，在持久化之前宕机，则该消息并未被处理。从应用的角度，这就是最多一次（At most Once）。反之，接收者先处理消息并完成持久化，但在确认之前宕机，消息就要被再次发送，这就是最少一次（At least Once）。 如果消息投递策略非常重要，应用程序自身也需要仔细设计。\n\n## 消费者优化\n\n消费者是分布式队列编程中真正的数据处理方，数据处理方最常见的挑战包括：有序性、串行化（Serializability）、频次控制、完整性和一致性等。\n\n### 挑战\n\n#### 有序性\n\n在很多场景下，如何保证队列信息的有序处理是一个棘手的问题。如下图，假定分布式队列保证请求严格有序，请求ri2和ri1都是针对同一数据记录的不同状态，ri2的状态比ri1的状态新。T1、T2、T3和T4代表各个操作发生的时间，并且 T1 < T2 < T3 < T4（\"<\"代表早于）。\n\n采用多消费者架构，这两条记录被两个消费者（Consumer1和Consumer2）处理后更新到数据库里面。Consumer1虽然先读取ri1但是却后写入数据库，这就导致，新的状态被老的状态覆盖，所以多消费者不保证数据的有序性。\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/sequence.png)\n\n#### 串行化\n\n很多场景下，串行化是数据处理的一个基本需求，这是保证数据完整性、可恢复性、事务原子性等的基础。为了在并行计算系统里实现串行化，一系列的相关理论和实践算法被提出。对于分布式队列编程架构，要在在多台消费者实现串行化非常复杂，无异于重复造轮子。\n\n#### 频次控制\n\n有时候，消费者的消费频次需要被控制，可能的原因包括：\n\n* 费用问题。如果每次消费所引起的操作都需要收费，而同一个请求消息在队列中保存多份，不进行频次控制，就会导致无谓的浪费。\n\n* 性能问题。每次消费可能会引起对其他服务的调用，被调用服务希望对调用量有所控制，对同一个请求消息的多次访问就需要有所控制。\n\n#### 完整性和一致性\n\n完整性和一致性是所有多线程和多进程的代码都面临的问题。在多线程或者多进程的系统中考虑完整性和一致性往往会大大地增加代码的复杂度和系统出错的概率。\n\n### 单例服务优化\n\n几乎所有串行化理论真正解决的问题只有一个：性能。 所以，在性能允许的前提下，对于消费者角色，建议采用单实例部署。通过单实例部署，有序性、串行化、完整性和一致性问题自动获得了解决。另外，单实例部署的消费者拥有全部所需信息，它可以在频次控制上采取很多优化策略。\n\n天下没有免费的午餐。同样，单实例部署并非没有代价，它意味着系统可用性的降低，很多时候，这是无法接受的。解决可用性问题的最直接的思路就是冗余（Redundancy）。最常用的冗余方案是Master-slave架构，不过大部分的Master-slave架构都是Active/active模式，即主从服务器都提供服务。例如，数据库的Master-slave架构就是主从服务器都提供读服务，只有主服务器提供写服务。大部分基于负载均衡设计的Master-slave集群中，主服务器和从服务器同时提供相同的服务。这显然不满足单例服务优化需求。有序性和串行化需要Active/passive架构，即在某一时刻只有主实例提供服务，其他的从服务等待主实例失效。这是典型的领导人选举架构，即只有获得领导权的实例才能充当实际消费者，其他实例都在等待下一次选举。采用领导人选举的Active/passive架构可以大大缓解纯粹的单实例部署所带来的可用性问题。\n\n令人遗憾的是，除非工程师们自己在消费者实例里面实现Paxos等算法，并在每次消息处理之前都执行领导人选举。否则，理论上讲，没有方法可以保障在同一个时刻只有一个领导者。而对每个消息都执行一次领导人选举，显然性能不可行。实际工作中，最容易出现的问题时机发生在领导人交接过程中，即前任领导人实例变成辅助实例，新部署实例开始承担领导人角色。为了平稳过渡，这两者之间需要有一定的通讯机制，但是，无论是网络分区（Network partition）还是原领导人服务崩溃都会使这种通讯机制变的不可能。\n\n对于完整性和一致性要求很高的系统，我们需要在选举制度和交接制度这两块进行优化。\n\n#### 领导人选举架构\n\n典型的领导人选举算法有Paxos、ZAB（ ZooKeeper Atomic Broadcast protocol）。为了避免重复造轮子，建议采用ZooKeeper的分布式锁来实现领导人选举。典型的ZooKeeper实现算法如下（摘自参考资料[4]）：\n\n> Let ELECTION be a path of choice of the application. To volunteer to be a leader:\n> \n> 1.Create znode z with path \"ELECTION/guid-n_\" with both SEQUENCE and EPHEMERAL flags;\n> 2.Let C be the children of \"ELECTION\", and i be the sequence number of z;\n> 3.Watch for changes on \"ELECTION/guid-n_j\", where j is the largest sequence number such that j < i and n_j is a znode in C;\n> \n> Upon receiving a notification of znode deletion:\n> \n> 1.Let C be the new set of children of ELECTION;\n> 2.If z is the smallest node in C, then execute leader procedure;\n> 3.Otherwise, watch for changes on \"ELECTION/guid-n_j\", where j is the largest sequence number such that j < i and n_j is a znode in C;\n\n#### 领导人交接架构\n\n领导人选举的整个过程发生在ZooKeeper集群中，各个消费者实例在这场选举中只充当被告知者角色（Learner）。领导人选举算法，只能保证最终只有一个Leader被选举出来，并不保障被告知者对Leader的理解是完全一致的。本质上，上文的架构里，选举的结果是作为令牌（Token）传递给消费者实例，消费者将自身的ID与令牌进行对比，如果相等，则开始执行消费操作。所以当发生领导人换届的情况，不同的Learner获知新Leader的时间并不同。例如，前任Leader如果因为网络问题与ZooKeeper集群断开，前任Leader只能在超时后才能判断自己是否不再承担Leader角色了，而新的Leader可能在这之前已经产生。另一方面，即使前任Leader和新Leader同时接收到新Leader选举结果，某些业务的完整性要求迫使前任Leader仍然完成当前未完成的工作。以上的讲解非常抽象，生活中却给了一些更加具体的例子。众所周知，美国总统候选人在选举结束后并不直接担任美国总统，从选举到最终承担总统角色需要一个过渡期。对于新当选Leader的候选人而言，过渡期间称之为加冕阶段（Inauguration）。对于即将卸任的Leader，过渡期称为交接阶段（HandOver）。所以一个基于领导人选举的消费者从加冕到卸任经历三个阶段：Inauguration、Execution、HandOver。在加冕阶段，新领导需要进行一些初始化操作。Execution阶段是真正的队列消息处理阶段。在交接阶段，前任领导需要进行一些清理操作。\n\n类似的，为了解决领导人交接问题，所有的消费者从代码实现的角度都需要实现类似ILeaderCareer接口。这个接口包含三个方发inaugurate()，handOver()和execute（）。某个部署实例（Learner）在得知自己承担领导人角色后，需要调用inaugurate()方法，进行加冕。主要的消费逻辑通过不停的执行execute（）实现，当确认自己不再承担领导人之后，执行handOver()进行交接。\n\n```java\npublic interface ILeaderCareer {\n    public void inaugurate();\n    public void handOver();\n    public boolean execute();\n}\n```\n\n如果承担领导人角色的消费者，在执行execute（）阶段得知自己将要下台，根据消息处理的原子性，该领导人可以决定是否提前终止操作。如果整个消息处理是一个原子性事务，直接终止该操作可以快速实现领导人换届。否则，前任领导必须完成当前消息处理后，才进入交接阶段。这意味着新的领导人，在inaugurate()阶段需要进行一定时间的等待。\n\n### 排重优化\n\n频次控制是一个经典问题。对于分布式队列编程架构，相同请求重复出现在队列的情况并不少见。如果相同请求在队列中重复太多，排重优化就显得很必要。分布式缓存更新是一个典型例子，所有请求都被发送到队列中用于缓存更新。如果请求符合典型的高斯分布，在一段时间内会出现大量重复的请求，而同时多线程更新同一请求缓存显然没有太大的意义。\n\n排重优化是一个算法，其本质是基于状态机的编程，整个讲解通过模型、构思和实施三个步骤完成。\n\n#### 模型\n\n进行排重优化的前提是大量重复的请求。在模型这一小节，我们首先阐述重复度模型、以及不同重复度所导致的消费模型，最后基于这两个模型去讲解排重状态机。\n\n##### 重复度模型\n\n首先我们给出最小重复长度的概念。同一请求最小重复长度：同一请求在队列中的重复出现的最小间距。例如，请求ri第一次出现在位置3，第二次出现在10，最小重复长度等于7。\n\n是否需要进行排重优化取决于队列中请求的重复度。由于不同请求之间并不存在重复的问题，不失一般性，这里的模型只考了单个请求的重复度，重复度分为三个类：无重复、稀疏重复、高重复。\n\n* 无重复：在整个请求过程，没有任何一个请求出现一次以上。\n* 稀疏重复：主要的请求最小重复长度大于消费队列长度。\n* 高重复：大量请求最小重复长度小于消费队列长度。\n\n对于不同的重复度，会有不同的消费模型。\n\n##### 无重复消费模型\n\n在整个队列处理过程中，所有的请求都不相同，如下图：\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/nondup.png)\n\n##### 稀疏重复消费模型\n\n当同一请求最小重复长度大于消费者队列长度，如下图。假定有3个消费者，Consumer1将会处理r1，Consumer2将会处理r2，Consumer3将会处理r3，如果每个请求处理的时间严格相等，Consumer1在处理完r1之后，接着处理r4，Consumer2将会处理r2之后会处理r1。虽然r1被再次处理，但是任何时刻，只有这一个消费者在处理r1，不会出现多个消费者同时处理同一请求的场景。\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/sparsedup.png)\n\n##### 高重复消费模型\n\n如下图，仍然假定有3个消费者，队列中前面4个请求都是r1，它会同时被3个消费者线程处理：\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/highdup.png)\n\n显然，对于无重复和稀疏重复的分布式队列，排重优化并不会带来额外的好处。排重优化所针对的对象是高重复消费模型，特别是对于并行处理消费者比较多的情况，重复处理同一请求，资源消耗极大。\n\n##### 排重状态机\n\n排重优化的主要对象是高重复的队列，多个消费者线程或进程同时处理同一个幂等请求只会浪费计算资源并延迟其他待请求处理。所以，排重状态机的一个目标是处理唯一性，即：同一时刻，同一个请求只有一个消费者处理。如果消费者获取一条请求消息，但发现其他消费者正在处理该消息，则当前消费者应该处于等待状态。如果对同一请求，有一个消费者在处理，一个消费者在等待，而同一请求再次被消费者读取，再次等待则没有意义。所以，状态机的第二个目标是等待唯一性，即：同一时刻，同一个请求最多只有一个消费者处于等待状态。总上述，状态机的目标是：处理唯一性和等待唯一性。我们把正在处理的请求称为头部请求，正在等待的请求称为尾部请求。\n\n由于状态机的处理单元是请求，所以需要针对每一个请求建立一个排重状态机。基于以上要求，我们设计的排重状态机包含4个状态Init，Process，Block，Decline。各个状态之间转化过程如下图：\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/dedup-automate.png)\n\n* 状态机创建时处于Init状态。\n\n* 对Init状态进行Enqueue操作，即接收一个请求，开始处理（称为头部请求），状态机进入Process状态。\n\n* 状态机处于Process状态，表明当前有消费者正在处理头部请求。此时，如果进行Dequeue操作，即头部请求处理完成，返回Init状态。如果进行Enqueue操作，即另一个消费者准备处理同一个请求，状态机进入Block状态（该请求称为尾部请求）。\n\n* 状态机处于Block状态，表明头部请求正在处理，尾部请求处于阻塞状态。此时，进行Dequeue操作，即头部请求处理完成，返回Process状态，并且尾部请求变成头部请求，原尾部请求消费者结束阻塞状态，开始处理。进行Enqueue操作，表明一个新的消费者准备处理同一个请求，状态机进入Decline状态。\n\n* 状态机进入Decline状态，根据等待唯一性目标，处理最新请求的消费者将被抛弃该消息，状态机自动转换回Block状态。\n\n#### 构思\n\n状态机描述的是针对单个请求操作所引起状态变化，排重优化需要解决队列中所有请求的排重问题，需要对所有请求的状态机进行管理。这里只考虑单虚拟机内部对所有请求状态机的管理，对于跨虚拟机的管理可以采用类似的方法。对于多状态机管理主要包含三个方面：一致性问题、完整性问题和请求缓存驱逐问题。\n\n##### 一致性问题\n\n一致性在这里要求同一请求的不同消费者只会操作一个状态机。由于每个请求都产生一个状态机，系统将会包含大量的状态机。为了兼顾性能和一致性，我们采用ConcurrentHashMap保存所有的状态机。用ConcurrentHashMap而不是对整个状态机队列进行加锁，可以提高并行处理能力，使得系统可以同时操作不同状态机。为了避免处理同一请求的多消费者线程同时对ConcurrentHashMap进行插入所导致状态机不一致问题，我们利用了ConcurrentHashMap的putIfAbsent（）方法。代码方案如下，key2Status用于存储所有的状态机。消费者在处理请求之前，从状态机队列中读取排重状态机TrafficAutomate。如果没有找到，则创建一个新的状态机，并通过putIfAbsent（）方法插入到状态机队列中。\n\n```java\nprivate ConcurrentHashMap<T, TrafficAutomate> key2Status = new ConcurrentHashMap();\nTrafficAutomate trafficAutomate = key2Status.get(key);\nif(trafficAutomate == null)\n{\n    trafficAutomate = new TrafficAutomate();\n    TrafficAutomate oldAutomate = key2Status.putIfAbsent(key, trafficAutomate);\n    if(oldAutomate != null)\n    {\n        trafficAutomate = oldAutomate;\n    }\n}\n```\n\n##### 完整性问题\n\n完整性要求保障状态机Init，Process，Block，Decline四种状态正确、状态之间的转换也正确。由于状态机的操作非常轻量级，兼顾完整性和降低代码复杂度，我们对状态机的所有方法进行加锁。\n\n##### 请求缓存驱逐问题（Cache Eviction）\n\n如果不同请求的数量太多，内存永久保存所有请求的状态机的内存开销太大。所以，某些状态机需要在恰当的时候被驱逐出内存。这里有两个思路：\n\n* 当状态机返回Init状态时，清除出队列。\n\n* 启动一个后台线程，定时扫描状态机队列，采用LRU等标准缓存清除机制。\n\n##### 标识问题\n\n每个请求对应于一个状态机，不同的状态机采用不同的请求进行识别。\n\n对于同一状态机的不同消费者，在单虚拟机方案中，我们采用线程id进行标识。\n\n#### 实施\n\n排重优化的主要功能都是通过排重状态机（TrafficAutomate）和状态机队列（QueueCoordinator）来实施的。排重状态机描述的是针对单个请求的排重问题，状态机队列解决所有请求状态机的排重问题。\n\n##### 状态机实施（TrafficAutomate）\n\n根据状态机模型，其主要操作为enQueue和deQueue，其状态由头部请求和尾部请求的状态共同决定，所以需要定义两个变量为head和tail，用于表示头部请求和尾部请求。为了确保多线程操作下状态机的完整性（Integraty），所有的操作都将加上锁。\n\n###### enQueue操作\n\n当一个消费者执行enQueue操作时：如果此时尾部请求不为空，根据等待唯一性要求，返回DECLINE，当前消费者应该抛弃该请求；如果头部请求为空，返回ACCPET，当前消费者应该立刻处理该消息；否则，返回BLOCK，该消费者应该等待，并不停的查看状态机的状态，一直到头部请求处理完成。enQueue代码如下：\n\n```java\nsynchronized ActionEnum enQueue(long id)\n{ \n    if(tail != INIT_QUEUE_ID)\n    {\n        return DECLINE;\n    }\n\n    if(head == INIT_QUEUE_ID)\n    {\n        head = id;\n        return ACCEPT;\n    }\n    else\n    {\n        tail = id;\n        return BLOCK;\n    }\n｝\n```\n\n###### deQueue操作\n\n对于deQueue操作，首先将尾部请求赋值给头部请求，并将尾部请求置为无效。deQueue代码如下：\n\n```java\nsynchronized boolean deQueue(long id)\n{\n        head = tail;\n        tail = INIT_QUEUE_ID;\n        return true;\n}\n```\n\n##### 状态机队列实施(QueueCoordinator)\n\n###### 接口定义\n\n状态机队列集中管理所有请求的排重状态机，所以其操作和单个状态机一样，即enQueue和deQueuqe接口。这两个接口的实现需要识别特定请求的状态机，所以它们的入参应该是请求。为了兼容不同类型的请求消息，我们采用了Java泛型编程。接口定义如下：\n\n```java\npublic interface QueueCoordinator<T> {\n\n    public boolean enQueue(T key);\n\n    public void deQueue(T key);\n\n}\n```\n\n###### enQueue操作\n\nenQueue操作过程如下：\n\n首先，根据传入的请求key值，获取状态机， 如果不存在则创建一个新的状态机，并保存在ConcurrentHashMap中。\n\n接下来，获取线程id作为该消费者的唯一标识，并对对应状态机进行enQueue操作。\n\n如果状态机返回值为ACCEPT或者DECLINE，返回业务层处理代码，ACCEPT意味着业务层需要处理该消息，DECLINE表示业务层可以抛弃当前消息。如果状态机返回值为Block，则该线程保持等待状态。\n\n异常处理。在某些情况下，头部请求线程可能由于异常，未能对状态机进行deQueue操作（作为组件提供方，不能假定所有的规范被使用方实施）。为了避免处于阻塞状态的消费者无期限地等待，建议对状态机设置安全超时时限。超过了一定时间后，状态机强制清空头部请求，返回到业务层，业务层开始处理该请求。\n\n代码如下：\n\n```java\npublic boolean enQueue(T key) {\n    _loggingStastic();\n\n    TrafficAutomate trafficAutomate = key2Status.get(key);\n    if(trafficAutomate == null)\n    {\n        trafficAutomate = new TrafficAutomate();\n        TrafficAutomate oldAutomate = key2Status.putIfAbsent(key, trafficAutomate);\n        if(oldAutomate != null)\n        {\n            trafficAutomate = oldAutomate;\n        }\n    }\n    long threadId = Thread.currentThread().getId();\n\n    ActionEnum action = trafficAutomate.enQueue(threadId);\n\n    if(action == DECLINE)\n    {\n        return false;\n    }\n    else if (action == ACCEPT)\n    {\n        return true;\n    }\n    //Blocking status means some other thread are working on this key, so just wait till timeout\n    long start = System.currentTimeMillis();\n    long span = 0;\n    do {\n        _nonExceptionSleep(NAP_TIME_IN_MILL);\n\n        if(trafficAutomate.isHead(threadId))\n        {\n            return true;\n        }\n\n        span = System.currentTimeMillis() - start;\n    }while(span <= timeout);\n\n    //remove head so that it won't block the queue for too long\n    trafficAutomate.evictHeadByForce(threadId);\n\n    return true;\n}\n```\n\n###### deQueue操作\n\ndeQueue操作首先从ConcurrentHashMap获取改请求所对应的状态机，接着获取该线程的线程id，对状态机进行deQueue操作。\n\nenQueue代码如下：\n\n```java\npublic void deQueue(T key) {\n    TrafficAutomate trafficAutomate = key2Status.get(key);\n\n    if(trafficAutomate == null)\n    {\n        logger.error(\"key {} doesn't exist \", key);\n        return;\n    }\n\n    long threadId = Thread.currentThread().getId();\n\n    trafficAutomate.deQueue(threadId)；\n}\n```\n\n##### 源代码\n\n完整源代码可以在[QueueCoordinator](https://github.com/dinglau2008/QueueCoordinator/tree/master/src)获取。\n\n## 参考资料\n\n[1] Rabbit MQ, [Highly Available Queues](https://www.rabbitmq.com/ha.html).\n[2] IBM Knowledge Center, [Introduction to message queuing](https://www.ibm.com/support/knowledgecenter/SSFKSJ_8.0.0/com.ibm.mq.pro.doc/q002620_.htm).\n[3] Wikipedia, [Serializability](https://en.wikipedia.org/wiki/Serializability).\n[4] Hadoop, [ZooKeeper Recipes and Solutions](https://zookeeper.apache.org/doc/trunk/recipes.html#sc_leaderElection).\n[5] [Apache Kafka](http://kafka.apache.org/documentation.html#introduction).\n[6] Lamport L, [Paxos Made Simple](http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf).\n\n---\n\n* 原文链接：[分布式队列编程优化篇](http://tech.meituan.com/distributed_queue_based_programming-optimization.html)\n","tags":["Distributed"],"categories":["Distributed"]},{"title":"深度学习中的激活函数导引","url":"%2F2016%2F2016-08-01-deep-learning-activation-function-guide%2F","content":"\n\n近年来，深度学习在计算机视觉领域取得了引人注目的成果，其中一个重要因素是激活函数的发展。新型激活函数ReLU克服了梯度消失，使得深度网络的直接监督式训练成为可能。本文将对激活函数的历史和近期进展进行总结和概括。\n\n### 激活函数的定义与作用\n\n在人工神经网络中，神经元节点的激活函数定义了对神经元输出的映射，简单来说，神经元的输出（例如，全连接网络中就是输入向量与权重向量的内积再加上偏置项）经过激活函数处理后再作为输出。加拿大蒙特利尔大学的Bengio教授在 ICML 2016 的文章[1]中给出了激活函数的定义：激活函数是映射 h:R→R，且几乎处处可导。\n\n神经网络中激活函数的主要作用是提供网络的非线性建模能力，如不特别说明，激活函数一般而言是非线性函数。假设一个示例神经网络中仅包含线性卷积和全连接运算，那么该网络仅能够表达线性映射，即便增加网络的深度也依旧还是线性映射，难以有效建模实际环境中非线性分布的数据。加入（非线性）激活函数之后，深度神经网络才具备了分层的非线性映射学习能力。因此，激活函数是深度神经网络中不可或缺的部分。\n\n### 激活函数的历史发展与近期进展\n\n从定义来看，几乎所有的连续可导函数都可以用作激活函数。但目前常见的多是分段线性和具有指数形状的非线性函数。下文将依次对它们进行总结。\n\n**Sigmoid**\n\nSigmoid 是使用范围最广的一类激活函数，具有指数函数形状 。正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/1.jpg)\n\n可见，sigmoid 在定义域内处处可导，且两侧导数逐渐趋近于0，即：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/2.jpg)\n\nBengio 教授等[1]将具有这类性质的激活函数定义为软饱和激活函数。与极限的定义类似，饱和也分为左饱和与右饱和：\n\n左饱和：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/3.jpg)\n\n右饱和：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/4.jpg)\n\n与软饱和相对的是硬饱和激活函数，即：\n\n```\nf'(x)=0，当 |x| > c，其中 c 为常数。\n```\n\n同理，硬饱和也分为左饱和和右饱和。常见的 ReLU 就是一类左侧硬饱和激活函数。\n\nSigmoid 的软饱和性，使得深度神经网络在二三十年里一直难以有效的训练，是阻碍神经网络发展的重要原因。具体来说，由于在后向传递过程中，sigmoid向下传导的梯度包含了一个f'(x) 因子（sigmoid关于输入的导数），因此一旦输入落入饱和区，f'(x) 就会变得接近于0，导致了向底层传递的梯度也变得非常小。此时，网络参数很难得到有效训练。这种现象被称为梯度消失。一般来说， sigmoid 网络在 5 层之内就会产生梯度消失现象[2]。梯度消失问题至今仍然存在，但被新的优化方法有效缓解了，例如DBN中的分层预训练，Batch Normalization的逐层归一化，Xavier和MSRA权重初始化等代表性技术。\n\nSigmoid 的饱和性虽然会导致梯度消失，但也有其有利的一面。例如它在物理意义上最为接近生物神经元。 (0, 1) 的输出还可以被表示作概率，或用于输入的归一化，代表性的如Sigmoid交叉熵损失函数\n\n**tanh**\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/5.jpg)\n\n可见，tanh(x)=2sigmoid(2x)-1，也具有软饱和性。Xavier在文献[2]中分析了sigmoid与tanh的饱和现象及特点，具体见原论文。此外，文献 [3] 中提到tanh 网络的收敛速度要比sigmoid快。因为 tanh 的输出均值比 sigmoid 更接近 0，SGD会更接近 natural gradient[4]（一种二次优化技术），从而降低所需的迭代次数。\n\n**ReLU**\n\n虽然2006年Hinton教授提出通过分层无监督预训练解决深层网络训练困难的问题，但是深度网络的直接监督式训练的最终突破，最主要的原因是采用了新型激活函数ReLU[5, 6]。与传统的sigmoid激活函数相比，ReLU能够有效缓解梯度消失问题，从而直接以监督的方式训练深度神经网络，无需依赖无监督的逐层预训练，这也是2012年深度卷积神经网络在ILSVRC竞赛中取得里程碑式突破的重要原因之一。\n\nReLU的 正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/6.jpg)\n\n可见，ReLU 在x<0 时硬饱和。由于 x>0时导数为 1，所以，ReLU 能够在x>0时保持梯度不衰减，从而缓解梯度消失问题。但随着训练的推进，部分输入会落入硬饱和区，导致对应权重无法更新。这种现象被称为“神经元死亡”。\n\nReLU还经常被“诟病”的一个问题是输出具有偏移现象[7]，即输出均值恒大于零。偏移现象和 神经元死亡会共同影响网络的收敛性。本文作者公开在arxiv的文章[8]中的实验表明，如果不采用Batch Normalization，即使用 MSRA 初始化30层以上的ReLU网络，最终也难以收敛。相对的，PReLU和ELU网络都能顺利收敛，这两种改进的激活函数将在后面介绍。实验所用代码见https://github.com/Coldmooon/Code-for-MPELU/ 。\n\nReLU另外一个性质是提供神经网络的稀疏表达能力，在Bengio教授的Deep Sparse Rectifier Neural Network[6]一文中被认为是ReLU带来网络性能提升的原因之一。但后来的研究发现稀疏性并非性能提升的必要条件，文献 RReLU [9]也指明了这一点。\n\nPReLU[10]、ELU[7]等激活函数不具备这种稀疏性，但都能够提升网络性能。本文作者在文章[8]中给出了一些实验比较结果。首先，在cifar10上采用NIN网络，实验结果为 PReLU > ELU > ReLU，稀疏性并没有带来性能提升。其次，在 ImageNet上采用类似于[11] 中model E的15 层网络，实验结果则是ReLU最好。为了验证是否是稀疏性的影响，以 LReLU [12]为例进一步做了四次实验，负半轴的斜率分别为1，0.5，0.25,  0.1，需要特别说明的是，当负半轴斜率为1时，LReLU退化为线性函数，因此性能损失最大。实验结果展现了斜率大小与网络性能的一致性。综合上述实验可知，ReLU的稀疏性与网络性能之间并不存在绝对正负比关系。\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/7.jpg)\n\n**PReLU**\n\nPReLU [10]是ReLU 和 LReLU的改进版本，具有非饱和性：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/8.jpg)\n\n与LReLU相比，PReLU中的负半轴斜率a可学习而非固定。原文献建议初始化a为0.25，不采用正则。个人认为，是否采用正则应当视具体的数据库和网络，通常情况下使用正则能够带来性能提升。\n\n虽然PReLU 引入了额外的参数，但基本不需要担心过拟合。例如，在上述cifar10+NIN实验中， PReLU比ReLU和ELU多引入了参数，但也展现了更优秀的性能。所以实验中若发现网络性能不好，建议从其他角度寻找原因。\n\n与ReLU相比，PReLU收敛速度更快。因为PReLU的输出更接近0均值，使得SGD更接近natural gradient。证明过程参见原文[10]。\n\n此外，作者在ResNet 中采用ReLU，而没有采用新的PReLU。这里给出个人浅见，不一定正确，仅供参考。首先，在上述LReLU实验中，负半轴斜率对性能的影响表现出一致性。对PReLU采用正则将激活值推向0也能够带来性能提升。这或许表明，小尺度或稀疏激活值对深度网络的影响更大。其次，ResNet中包含单位变换和残差两个分支。残差分支用于学习对单位变换的扰动。如果单位变换是最优解，那么残差分支的扰动应该越小越好。这种假设下，小尺度或稀疏激活值对深度网络的影响更大。此时，ReLU或许是比PReLU更好的选择。\n\n**RReLU**\n\n数学形式与PReLU类似，但RReLU[9]是一种非确定性激活函数，其参数是随机的。这种随机性类似于一种噪声，能够在一定程度上起到正则效果。作者在cifar10/100上观察到了性能提升。\n\n**Maxout**\n\nMaxout[13]是ReLU的推广，其发生饱和是一个零测集事件（measure zero event）。正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/9.jpg)\n\nMaxout网络能够近似任意连续函数，且当w2,b2,…,wn,bn为0时，退化为ReLU。 其实，Maxout的思想在视觉领域存在已久。例如，在HOG特征里有这么一个过程：计算三个通道的梯度强度，然后在每一个像素位置上，仅取三个通道中梯度强度最大的数值，最终形成一个通道。这其实就是Maxout的一种特例。\n\nMaxout能够缓解梯度消失，同时又规避了ReLU神经元死亡的缺点，但增加了参数和计算量。\n\n**ELU**\n\nELU[7]融合了sigmoid和ReLU，具有左侧软饱性。其正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/10.jpg)\n\n右侧线性部分使得ELU能够缓解梯度消失，而左侧软饱能够让ELU对输入变化或噪声更鲁棒。ELU的输出均值接近于零，所以收敛速度更快。经本文作者实验，ELU的收敛性质的确优于ReLU和PReLU。在cifar10上，ELU 网络的loss 降低速度更快；在 ImageNet上，不加 Batch Normalization 30 层以上的 ReLU 网络会无法收敛，PReLU网络在MSRA的Fan-in （caffe ）初始化下会发散，而 ELU 网络在Fan-in/Fan-out下都能收敛 。实验代码见https://github.com/Coldmooon/Code-for-MPELU/。\n\n论文的另一个重要贡献是分析了Bias shift 现象与激活值的关系，证明了降低Bias shift 等价于把激活值的均值推向0。\n\n**Noisy Activation Functions**\n\nengio教授在ICML 2016 提出了一种激活策略[1]，可用于多种软饱和激活函数，例如 sigmoid和 tanh。\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/11.jpg)\n\n当激活函数发生饱和时， 网络参数还能够在两种动力下继续更新：正则项梯度和噪声梯度。引入适当的噪声能够扩大SGD的参数搜索范围，从而有机会跳出饱和区。在激活函数中引入噪声的更早工作可追溯到[5]，但文献[5]的工作并不考虑噪声引入的时间和大小。本篇的特点在于，只在饱和区才引入噪声，且噪声量与饱和程度相关——原式与泰勒展开式一次项之差 δ。算法1中g表示sigmoid，用于归一化 δ。注意，ReLU的 δ恒为0，无法直接加噪声，所以作者把噪声加在了输入上。\n\n**CReLU**\n\nCReLU [14]是Wenling Shang 发表在 ICML 2016的工作，本篇同样提出了一种激活策略:\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/12.jpg)\n\n其中，[] 表示 ReLU（其他亦可）。\n\n作者在观察第一层滤波器（filter）时发现，滤波器相位具有成对现象（pair-grouping phenomenon）。这一发现揭示了网络的底层学到了一些冗余滤波器来提取输入的正负相位信息的可能性。因此可以考虑采用适当的操作移除这些冗余滤波器。对此，作者提出了CReLU，将激活函数的输入额外做一次取反，等价于将输入相位旋转180°。这种策略可以看作在网络中加入相位的先验。实验在cifar10上观察到能以更少的参数获得性能提升。\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/13.jpg)\n\n使用CReLU时，要有意识的将滤波器数量减半，否则， 网络参数变为2倍。\n\n**MPELU**\n\nMPELU[8]是我们组的工作，将分段线性与ELU统一到了一种形式下。在NIN+CIFAR10，本文作者发现ELU与LReLU性能一致，而与PReLU差距较大。经过分析，ELU泰勒展开的一次项就是LReLU。当在ELU前加入BN让输入集中在0均值附近， 则ELU与LReLU之差——泰勒展开高次项会变小，粗略估计，约55.57%的激活值误差小于0.01。因此，受PReLU启发，令α可学习能够提高性能。此外，引入参数β能够进一步控制ELU的函数形状。正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/14.jpg)\n\nα 和 β可以使用正则。α, β 固定为1时，MPELU 退化为 ELU； β 固定为很小的值时，MPELU 近似为 PReLU；当α=0，MPELU 等价于 ReLU。\n\nMPELU 的优势在于同时具备 ReLU、PReLU和 ELU的优点。首先，MPELU具备ELU的收敛性质，能够在无 Batch Normalization 的情况下让几十层网络收敛。其次，作为一般化形式， MPELU较三者的推广能力更强。简言之，MPELU = max(ReLU, PReLU, ELU)。\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/15.jpg)\n\n当前对ELU网络普遍采用的初始化方法是 MSRA。这在实际中是可行的，只是不具备理论解释性。我们的工作利用泰勒公式和MSRA的推导过程，为ELU网络初始化提供了理论解释。此外，Dmytro 提出了 LSUV[15]，理论上可以用于 ELU/MPELU 的初始化。但在30/52层ELU网络上，发现 LSUV 会导致ELU网络在几次迭代之内发散，网络文件见https://github.com/Coldmooon/Code-for-MPELU/。\n\n### 总结\n\n深度学习的快速发展，催生了形式各异的激活函数。面对琳琅满目的成果，如何做出选择目前尚未有统一定论，仍需依靠实验指导。一般来说，在分类问题上建议首先尝试 ReLU，其次ELU，这是两类不引入额外参数的激活函数。然后可考虑使用具备学习能力的PReLU和本文作者提出的MPELU，并使用正则化技术，例如应该考虑在网络中增加Batch Normalization层。\n\n本文围绕深度卷积神经网络结构，对十余种激活函数进行了总结，相关代码可在作者的github主页上下载：https://github.com/Coldmooon/Code-for-MPELU/。个人浅见如有疏漏之处，请诸位读者不吝斧正。\n\n### 致谢\n\n这是一次严肃又愉快的写作过程，本文作者在撰稿过程中得到了两位审稿人的建设性意见，改善了文章的可读性，并提示了若干重要的引证文献，在此特表感谢！\n\n### 参考文献\n\n1. Gulcehre, C., et al., Noisy Activation Functions, in ICML 2016. 2016.\n2. Glorot, X. and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. AISTATS 2010.\n3. LeCun, Y., et al., Backpropagation applied to handwritten zip code recognition. Neural computation, 1989. 1(4): p. 541-551.\n4. Amari, S.-I., Natural gradient works efficiently in learning. Neural computation, 1998. 10(2): p. 251-276.\n5. Nair, V. and G.E. Hinton. Rectified linear units improve Restricted Boltzmann machines. ICML 2010.\n6. Glorot, X., A. Bordes, and Y. Bengio. Deep Sparse Rectifier Neural Networks.AISTATS 2011.\n7. Djork-Arné Clevert, T.U., Sepp Hochreiter. Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs). ICLR 2016.\n8. Li, Y., et al., Improving Deep Neural Network with Multiple Parametric Exponential Linear Units. arXiv preprint arXiv:1606.00305, 2016.\n9. Xu, B., et al. Empirical Evaluation of Rectified Activations in Convolutional Network. ICML Deep Learning Workshop 2015.\n10. He, K., et al. Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification. ICCV 2015.\n11. He, K. and J. Sun Convolutional Neural Networks at Constrained Time Cost. CVPR 2015.\n12. Maas, A.L., Awni Y. Hannun, and Andrew Y. Ng. Rectifier nonlinearities improve neural network acoustic models. in ICML 2013.\n13. Goodfellow, I.J., et al. Maxout Networks.  ICML 2013..\n14. Shang, W., et al., Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units.ICML 2016.\n15. Mishkin, D. and J. Matas All you need is a good init. ICLR 2016.\n\n### 关于作者\n\n李扬，北京邮电大学电子工程学院通信与网络中心实验室博士生，导师范春晓教授。本科毕业于合肥工业大学光信息科学与技术专业，硕士师从北京邮电大学杨义先教授学习并从事信息安全项目研发。2015年转向深度学习领域，目前专注于深度学习及其在目标检测的应用。\n\n---\n\n* 原文链接：[深度学习中的激活函数导引](http://mp.weixin.qq.com/s?src=3&timestamp=1474434369&ver=1&signature=H36Q3gNgtCqDZLQEQ3aTx9evHu1fKDFx7LCR*LcRieFfHes3XFUZg8GWgpz-RnxEfnw*KF-WQwRpDpzuYgepbW9yM4VOifeaHoqs4PHxzE-9pkI0pYNMniqgNSdKZp-AdP3EbAROmFXlVZR7MZ*28kP8qJCraKtzfatkP62PatY=)\n","tags":["Activation-Function"],"categories":["Deep-Learning"]},{"title":"分布式队列编程：模型、实战","url":"%2F2016%2F2016-07-29-distributed-queue-based-programming%2F","content":"\n\n## 介绍\n\n作为一种基础的抽象数据结构，队列被广泛应用在各类编程中。大数据时代对跨进程、跨机器的通讯提出了更高的要求，和以往相比，分布式队列编程的运用几乎已无处不在。但是，这种常见的基础性的事物往往容易被忽视，使用者往往会忽视两点：\n\n* 使用分布式队列的时候，没有意识到它是队列。\n\n* 有具体需求的时候，忘记了分布式队列的存在。\n\n文章首先从最基础的需求出发，详细剖析分布式队列编程模型的需求来源、定义、结构以及其变化多样性。通过这一部分的讲解，作者期望能在两方面帮助读者：一方面，提供一个系统性的思考方法，使读者能够将具体需求关联到分布式队列编程模型，具备进行分布式队列架构的能力；另一方面，通过全方位的讲解，让读者能够快速识别工作中碰到的各种分布式队列编程模型。\n\n文章的第二部分实战篇。根据作者在新美大实际工作经验，给出了队列式编程在分布式环境下的一些具体应用。这些例子的基础模型并非首次出现在互联网的文档中，但是所有的例子都是按照挑战、构思、架构三个步骤进行讲解的。这种讲解方式能给读者一个“从需求出发去构架分布式队列编程”的旅程。\n\n## 分布式队列编程模型\n\n模型篇从基础的需求出发，去思考何时以及如何使用分布式队列编程模型。建模环节非常重要，因为大部分中高级工程师面临的都是具体的需求，接到需求后的第一个步骤就是建模。通过本篇的讲解，希望读者能够建立起从需求到分布式队列编程模型之间的桥梁。\n\n### 何时选择分布式队列\n\n通讯是人们最基本的需求，同样也是计算机最基本的需求。对于工程师而言，在编程和技术选型的时候，更容易进入大脑的概念是RPC、RESTful、Ajax、Kafka。在这些具体的概念后面，最本质的东西是“通讯”。所以，大部分建模和架构都需要从“通讯”这个基本概念开始。当确定系统之间有通讯需求的时候，工程师们需要做很多的决策和平衡，这直接影响工程师们是否会选择分布式队列编程模型作为架构。从这个角度出发，影响建模的因素有四个：When、Who、Where、How。\n\n#### When：同步VS异步\n\n通讯的一个基本问题是：发出去的消息什么时候需要被接收到？这个问题引出了两个基础概念：“同步通讯”和“异步通讯”。根据理论抽象模型，同步通讯和异步通讯最本质的差别来自于时钟机制的有无。同步通讯的双方需要一个校准的时钟，异步通讯的双方不需要时钟。现实的情况是，没有完全校准的时钟，所以没有绝对的同步通讯。同样，绝对异步通讯意味着无法控制一个发出去的消息被接收到的时间点，无期限的等待一个消息显然毫无实际意义。所以，实际编程中所有的通讯既不是“同步通讯”也不是“异步通讯”；或者说，既是“同步通讯”也是“异步通讯”。特别是对于应用层的通讯，其底层架构可能既包含“同步机制”也包含“异步机制”。判断“同步”和“异步”消息的标准问题太深，而不适合继续展开。作者这里给一些启发式的建议：\n\n* 发出去的消息是否需要确认，如果不需要确认，更像是异步通讯，这种通讯有时候也称为单向通讯（One-Way Communication）。\n\n* 如果需要确认，可以根据需要确认的时间长短进行判断。时间长的更像是异步通讯，时间短的更像是同步通讯。当然时间长短的概念是纯粹的主观概念，不是客观标准。\n\n* 发出去的消息是否阻塞下一个指令的执行，如果阻塞，更像是同步，否则，更像是异步。\n\n无论如何，工程师们不能生活在混沌之中，不做决定往往是最坏的决定。当分析一个通讯需求或者进行通讯构架的时候，工程师们被迫作出“同步”还是“异步”的决定。当决策的结论是“异步通讯”的时候，分布式队列编程模型就是一个备选项。\n\n#### Who：发送者接收者解耦\n\n在进行通讯需求分析的时候，需要回答的另外一个基本问题是：消息的发送方是否关心谁来接收消息，或者反过来，消息接收方是否关心谁来发送消息。如果工程师的结论是：消息的发送方和接收方不关心对方是谁、以及在哪里，分布式队列编程模型就是一个备选项。因为在这种场景下，分布式队列架构所带来的解耦能给系统架构带来这些好处：\n\n* 无论是发送方还是接收方，只需要跟消息中间件通讯，接口统一。统一意味着降低开发成本。\n\n* 在不影响性能的前提下，同一套消息中间件部署，可以被不同业务共享。共享意味着降低运维成本。\n\n* 发送方或者接收方单方面的部署拓扑的变化不影响对应的另一方。解藕意味着灵活和可扩展。\n\n#### Where：消息暂存机制\n\n在进行通讯发送方设计的时候，令工程师们苦恼的问题是：如果消息无法被迅速处理掉而产生堆积怎么办、能否被直接抛弃？如果根据需求分析，确认存在消息积存，并且消息不应该被抛弃，就应该考虑分布式队列编程模型构架，因为队列可以暂存消息。\n\n#### How：如何传递\n\n对通讯需求进行架构，一系列的基础挑战会迎面而来，这包括：\n\n* 可用性，如何保障通讯的高可用。\n\n* 可靠性，如何保证消息被可靠地传递。\n\n* 持久化，如何保证消息不会丢失。\n\n* 吞吐量和响应时间。\n\n* 跨平台兼容性。\n   除非工程师对造轮子有足够的兴趣，并且有充足的时间，采用一个满足各项指标的分布式队列编程模型就是一个简单的选择。\n\n### 分布式队列编程定义\n\n很难给出分布式队列编程模型的精确定义，由于本文偏重于应用，作者并不打算完全参照某个标准的模型。总体而言：分布式队列编程模型包含三类角色：发送者（Sender）、分布式队列（Queue）、接收者（Receiver）。发送者和接收者分别指的是生产消息和接收消息的应用程序或服务。\n\n需要重点明确的概念是分布式队列，它是提供以下功能的应用程序或服务：1. 接收“发送者”产生的消息实体；2. 传输、暂存该实体；3. 为“接收者”提供读取该消息实体的功能。特定的场景下，它当然可以是Kafka、RabbitMQ等消息中间件。但它的展现形式并不限于此，例如：\n\n* 队列可以是一张数据库的表，发送者将消息写入表，接收者从数据表里读消息。\n\n* 如果一个程序把数据写入Redis等内存Cache里面，另一个程序从Cache里面读取，缓存在这里就是一种分布式队列。\n\n* 流式编程里面的的数据流传输也是一种队列。\n\n* 典型的MVC（Model–view–controller）设计模式里面，如果Model的变化需要导致View的变化，也可以通过队列进行传输。这里的分布式队列可以是数据库，也可以是某台服务器上的一块内存。\n\n### 抽象模型\n\n最基础的分布式队列编程抽象模型是点对点模型，其他抽象构架模型居于改基本模型上各角色的数量和交互变化所导致的不同拓扑图。具体而言，不同数量的发送者、分布式队列以及接收者组合形成了不同的分布式队列编程模型。记住并理解典型的抽象模型结构对需求分析和建模而言至关重要，同时也会有助于学习和深入理解开源框架以及别人的代码。\n\n#### 点对点模型（Point-to-point）\n\n基础模型中，只有一个发送者、一个接收者和一个分布式队列。如下图所示：\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/point2point.png)\n\n#### 生产者消费者模型（Producer–consumer）\n\n如果发送者和接收者都可以有多个部署实例，甚至不同的类型；但是共用同一个队列，这就变成了标准的生产者消费者模型。在该模型，三个角色一般称之为生产者（Producer）、分布式队列（Queue）、消费者（Consumer）。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/producer-consumer.png)\n\n#### 发布订阅模型（PubSub）\n\n如果只有一类发送者，发送者将产生的消息实体按照不同的主题（Topic）分发到不同的逻辑队列。每种主题队列对应于一类接收者。这就变成了典型的发布订阅模型。在该模型，三个角色一般称之为发布者（Publisher），分布式队列（Queue），订阅者（Subscriber）。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/pubsub.png)\n\n#### MVC模型\n\n如果发送者和接收者存在于同一个实体中，但是共享一个分布式队列。这就很像经典的MVC模型。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/mvc.png)\n\n### 编程模型\n\n为了让读者更好地理解分布式队列编程模式概念，这里将其与一些容易混淆的概念做一些对比 。\n\n#### 分布式队列模型编程和异步编程\n\n分布式队列编程模型的通讯机制一般是采用异步机制，但是它并不等同于异步编程。\n\n首先，并非所有的异步编程都需要引入队列的概念，例如：大部分的操作系统异步I/O操作都是通过硬件中断（ Hardware Interrupts）来实现的。\n\n其次，异步编程并不一定需要跨进程，所以其应用场景并不一定是分布式环境。\n\n最后，分布式队列编程模型强调发送者、接收者和分布式队列这三个角色共同组成的架构。这三种角色与异步编程没有太多关联。\n\n#### 分布式队列模式编程和流式编程\n\n随着Spark Streaming，Apache Storm等流式框架的广泛应用，流式编程成了当前非常流行的编程模式。但是本文所阐述的分布式队列编程模型和流式编程并非同一概念。\n\n首先，本文的队列编程模式不依赖于任何框架，而流式编程是在具体的流式框架内的编程。\n\n其次，分布式队列编程模型是一个需求解决方案，关注如何根据实际需求进行分布式队列编程建模。流式框架里的数据流一般都通过队列传递，不过，流式编程的关注点比较聚焦，它关注如何从流式框架里获取消息流，进行map、reduce、 join等转型（Transformation）操作、生成新的数据流，最终进行汇总、统计。\n\n## 分布式队列编程实战篇\n\n这里所有的项目都是作者在新美大工作的真实案例。实战篇的关注点是训练建模思路，所以这些例子都按照挑战、构思、架构三个步骤进行讲解。受限于保密性要求，有些细节并未给出，但这些细节并不影响讲解的完整性。另一方面，特别具体的需求容易让人费解，为了使讲解更加顺畅，作者也会采用一些更通俗易懂的例子。通过本篇的讲解，希望和读者一起去实践“如何从需求出发去构架分布式队列编程模型”。\n\n需要声明的是，这里的解决方案并不是所处场景的最优方案。但是，任何一个稍微复杂的问题，都没有最优解决方案，更谈不上唯一的解决方案。实际上，工程师每天所追寻的只是在满足一定约束条件下的可行方案。当然不同的约束会导致不同的方案，约束的松弛度决定了工程师的可选方案的宽广度。\n\n### 信息采集处理\n\n信息采集处理应用广泛，例如：广告计费、用户行为收集等。作者碰到的具体项目是为广告系统设计一套高可用的采集计费系统。\n\n典型的广告CPC、CPM计费原理是：收集用户在客户端或者网页上的点击和浏览行为，按照点击和浏览进行计费。计费业务有如下典型特征：\n\n* 采集者和处理者解耦，采集发生在客户端，而计费发生在服务端。\n\n* 计费与钱息息相关。\n\n* 重复计费意味着灾难。\n\n* 计费是动态实时行为，需要接受预算约束，如果消耗超过预算，则广告投放需要停止。\n\n* 用户的浏览和点击量非常大。\n\n#### 挑战\n\n计费业务的典型特征给我们带来了如下挑战：\n\n* 高吞吐量－－广告的浏览和点击量非常巨大，我们需要设计一个高吞吐量的采集架构。\n\n* 高可用性－－计费信息的丢失意味着直接的金钱损失。任何处理服务器的崩溃不应该导致系统不可用。\n\n* 高一致性要求－－计费是一个实时动态处理过程，但要受到预算的约束。收集到的浏览和点击行为如果不能快速处理，可能会导致预算花超，或者点击率预估不准确。所以采集到的信息应该在最短的时间内传输到计费中心进行计费。\n\n* 完整性约束－－这包括反作弊规则，单个用户行为不能重复计费等。这要求计费是一个集中行为而非分布式行为。\n\n* 持久化要求－－计费信息需要持久化，避免因为机器崩溃而导致收集到的数据产生丢失。\n\n#### 构思\n\n采集的高可用性意味着我们需要多台服务器同时采集，为了避免单IDC故障，采集服务器需要部署在多IDC里面。\n\n实现一个高可用、高吞吐量、高一致性的信息传递系统显然是一个挑战，为了控制项目开发成本，采用开源的消息中间件进行消息传输就成了必然选择。\n\n完整性约束要求集中进行计费，所以计费系统发生在核心IDC。\n\n计费服务并不关心采集点在哪里，采集服务也并不关心谁进行计费。\n\n根据以上构思，我们认为采集计费符合典型的“生产者消费者模型”。\n\n架构\n\n采集计费系统架构图如下：\n\n* 用户点击浏览收集服务（Click/View Collector）作为生产者部署在多个机房里，以提高收集服务可用性。\n\n* 每个机房里采集到的数据通过消息队列中间件发送到核心机房IDC_Master。\n\n* Billing服务作为消费者部署在核心机房集中计费。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/infomation-collector.png)\n\n采用此架构，我们可以在如下方面做进一步优化：\n\n* 提高可扩展性，如果一个Billing部署实例在性能上无法满足要求，可以对采集的数据进行主题分区（Topic Partition）计费，即采用发布订阅模式以提高可扩展性（Scalability）。\n\n* 全局排重和反作弊。采用集中计费架构解决了点击浏览排重的问题，另一方面，这也给反作弊提供了全局信息。\n\n* 提高计费系统的可用性。采用下文单例服务优化策略，在保障计费系统集中性的同时，提高计费系统可用性。\n\n### 分布式缓存更新（Distributed Cache Replacement）\n\n缓存是一个非常宽泛的概念，几乎存在于系统各个层级。典型的缓存访问流程如下：\n\n* 接收到请求后，先读取缓存，如果命中则返回结果。\n\n* 如果缓存不命中，读取DB或其它持久层服务，更新缓存并返回结果。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/cache-replacement.png)\n\n对于已经存入缓存的数据，其更新时机和更新频率是一个经典问题，即缓存更新机制（Cache Replacement Algorithms ）。典型的缓存更新机制包括：近期最少使用算法（LRU）、最不经常使用算法（LFU）。这两种缓存更新机制的典型实现是：启动一个后台进程，定期清理最近没有使用的，或者在一段时间内最少使用的数据。由于存在缓存驱逐机制，当一个请求在没有命中缓存时，业务层需要从持久层中获取信息并更新缓存，提高一致性。\n\n#### 挑战\n\n分布式缓存给缓存更新机制带来了新的问题：\n\n* 数据一致性低。分布式缓存中键值数量巨大，从而导致LRU或者LFU算法更新周期很长。在分布式缓存中，拿LRU算法举例，其典型做法是为每个Key值设置一个生存时间（TTL），生存时间到期后将该键值从缓存中驱逐除去。考虑到分布式缓存中庞大的键值数量，生存时间往往会设置的比较长，这就导致缓存和持久层数据不一致时间很长。如果生存时间设置过短，大量请求无法命中缓存被迫读取持久层，系统响应时间会急剧恶化。\n\n* 新数据不可用。在很多场景下，由于分布式缓存和持久层的访问性能相差太大，在缓存不命中的情况下，一些应用层服务不会尝试读取持久层，而直接返回空结果。漫长的缓存更新周期意味着新数据的可用性就被牺牲了。从统计的角度来讲，新键值需要等待半个更新周期才会可用。\n\n#### 构思\n\n根据上面的分析，分布式缓存需要解决的问题是：在保证读取性能的前提下，尽可能地提高老数据的一致性和新数据的可用性。如果仍然假定最近被访问的键值最有可能被再次访问（这是LRU或者LFU成立的前提），键值每次被访问后触发一次异步更新就是提高可用性和一致性最早的时机。无论是高性能要求还是业务解耦都要求缓存读取和缓存更新分开，所以我们应该构建一个单独的集中的缓存更新服务。集中进行缓存更新的另外一个好处来自于频率控制。由于在一段时间内，很多类型访问键值的数量满足高斯分布，短时间内重复对同一个键值进行更新Cache并不会带来明显的好处，甚至造成缓存性能的下降。通过控制同一键值的更新频率可以大大缓解该问题，同时有利于提高整体数据的一致性，参见“排重优化”。\n\n综上所述，业务访问方需要把请求键值快速传输给缓存更新方，它们之间不关心对方的业务。要快速、高性能地实现大量请求键值消息的传输，高性能分布式消息中间件就是一个可选项。这三方一起组成了一个典型的分布式队列编程模型。\n\n#### 架构\n\n如下图，所有的业务请求方作为生产者，在返回业务代码处理之前将请求键值写入高性能队列。Cache Updater作为消费者从队列中读取请求键值，将持久层中数据更新到缓存中。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/distributed-cache-replacement.png)\n\n采用此架构，我们可以在如下方面做进一步优化：\n\n* 提高可扩展性，如果一个Cache Updater在性能上无法满足要求，可以对键值进行主题分区（Topic Partition）进行并行缓存更新，即采用发布订阅模式以提高可扩展性（Scalability）。\n\n* 更新频率控制。缓存更新都集中处理，对于发布订阅模式，同一类主题（Topic）的键值集中处理。Cache Updater可以控制对同一键值的在短期内的更新频率（参见下文排重优化）。\n\n### 后台任务处理\n\n典型的后台任务处理应用包括工单处理、火车票预订系统、机票选座等。我们所面对的问题是为运营人员创建工单。一次可以为多个运营人员创建多个工单。这个应用场景和火车票购买非常类似。工单相对来说更加抽象，所以，下文会结合火车票购买和运营人员工单分配这两种场景同时讲解。典型的工单创建要经历两个阶段：数据筛选阶段、工单创建阶段。例如，在火车票预订场景，数据筛选阶段用户选择特定时间、特定类型的火车，而在工单创建阶段，用户下单购买火车票。\n\n#### 挑战\n\n工单创建往往会面临如下挑战：\n\n* 数据一致性问题。以火车票预订为例，用户筛选火车票和最终购买之间往往有一定的时延，意味着两个操作之间数据是不一致的。在筛选阶段，工程师们需决定是否进行车票锁定，如果不锁定，则无法保证出票成功。反之，如果在筛选地时候锁定车票，则会大大降低系统效率和出票吞吐量。\n\n* 约束问题。工单创建需要满足很多约束，主要包含两种类型：动态约束，与操作者的操作行为有关，例如购买几张火车票的决定往往发生在筛选最后阶段。隐性约束，这种约束很难通过界面进行展示，例如一个用户购买了5张火车票，这些票应该是在同一个车厢的临近位置。\n\n* 优化问题。工单创建往往是约束下的优化，这是典型的统筹优化问题，而统筹优化往往需要比较长的时间。\n\n* 响应时间问题。对于多任务工单，一个请求意味着多个任务产生。这些任务的创建往往需要遵循事务性原则，即All or Nothing。在数据层面，这意味着工单之间需要满足串行化需求（Serializability）。大数据量的串行化往往意味着锁冲突延迟甚至失败。无论是延迟机制所导致的长时延，还是高创建失败率，都会大大伤害用户体验。\n\n#### 构思\n\n如果将用户筛选的最终规则做为消息存储下来，并发送给工单创建系统。此时，工单创建系统将具备创建工单所需的全局信息，具备在满足各种约束的条件下进行统筹优化的能力。如果工单创建阶段采用单实例部署，就可以避免数据锁定问题，同时也意味着没有锁冲突，所以也不会有死锁或任务延迟问题。\n\n居于以上思路，在多工单处理系统的模型中，筛选阶段的规则创建系统将充当生产者角色，工单创建系统将充当消费者角色，筛选规则将作为消息在两者之间进行传递。这就是典型的分布式队列编程架构。根据工单创建量的不同，可以采用数据库或开源的分布式消息中间件作为分布式队列。\n\n#### 架构\n\n该架构流程如下图：\n\n* 用户首选进行规则创建，这个过程主要是一些搜索筛选操作；\n\n* 用户点击工单创建，TicketRule Generator将把所有的筛选性组装成规则消息并发送到队列里面去；\n\n* Ticket Generator作为一个消费者，实时从队列中读取工单创建请求，开始真正创建工单。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/ticket-generation.png)\n\n采用该架构，我们在数据锁定、运筹优化、原子性问题都能得到比较好成果：\n\n* 数据锁定推迟到工单创建阶段，可以减少数据锁定范围，最大程度的降低工单创建对其他在线操作的影响范围。\n\n* 如果需要进行统筹优化，可以将Ticket Generator以单例模式进行部署（参见单例服务优化）。这样，Ticket Generator可以读取一段时间内的工单请求，进行全局优化。例如，在我们的项目中，在某种条件下，运营人员需要满足分级公平原则，即相同级别的运营人员的工单数量应该接近，不同级别的运营人员工单数量应该有所区分。如果不集中进行统筹优化，实现这种优化规则将会很困难。\n\n* 保障了约束完整性。例如，在我们的场景里面，每个运营人员每天能够处理的工单是有数量限制的，如果采用并行处理的方式，这种完整性约束将会很难实施。\n\n## 预告\n\n下周我们会推出优化篇，重点阐述在工程师在运用分布式队列编程构架的时候，在生产者、分布式队列以及消费者这三个环节的注意点以及优化建议，欢迎关注！\n\n## 参考资料\n\n[1] RabbitMQ, [Highly Available Queues](https://www.rabbitmq.com/ha.html).\n[2] IBM Knowledge Center, [Introduction to message queuing](https://www.ibm.com/support/knowledgecenter/SSFKSJ_8.0.0/com.ibm.mq.pro.doc/q002620_.htm).\n[3] Wikipedia, [Serializability](https://en.wikipedia.org/wiki/Serializability).\n[4] Hadoop, [ZooKeeper Recipes and Solutions](https://zookeeper.apache.org/doc/trunk/recipes.html#sc_leaderElection).\n[5] [Apache Kafka](http://kafka.apache.org/documentation.html#introduction).\n[6] Lamport L, [Paxos Made Simple](http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf).\n\n---\n\n* 原文链接：[分布式队列编程：模型、实战](http://tech.meituan.com/distributed_queue_based_programming.html)\n","tags":["Distributed"],"categories":["Distributed"]},{"title":"Approaching (Almost) Any Machine Learning Problem","url":"%2F2016%2F2016-07-18-approaching-almost-any-machine-learning-problem%2F","content":"\nAn average data scientist deals with loads of data daily. Some say over 60-70% time is spent in data cleaning, munging and bringing data to a suitable format such that machine learning models can be applied on that data. This post focuses on the second part, i.e., applying machine learning models, including the preprocessing steps. The pipelines discussed in this post come as a result of over a hundred machine learning competitions that I’ve taken part in. It must be noted that the discussion here is very general but very useful and there can also be very complicated methods which exist and are practised by professionals.\n\nWe will be using python!\n\n# Data\n\nBefore applying the machine learning models, the data must be converted to a tabular form. This whole process is the most time consuming and difficult process and is depicted in the figure below.\n\n![abhishek_1](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_1.png)\n\nThe machine learning models are then applied to the tabular data. Tabular data is most common way of representing data in machine learning or data mining. We have a data table, rows with different samples of the data or X and labels, y. The labels can be single column or multi-column, depending on the type of problem. We will denote data by X and labels by y.\n\n# Types of labels\n\nThe labels define the problem and can be of different types, such as:\n\n*   Single column, binary values (classification problem, one sample belongs to one class only and there are only two classes)\n*   Single column, real values (regression problem, prediction of only one value)\n*   Multiple column, binary values (classification problem, one sample belongs to one class, but there are more than two classes)\n*   Multiple column, real values (regression problem, prediction of multiple values)\n*   And multilabel (classification problem, one sample can belong to several classes)\n\n# Evaluation Metrics\n\nFor any kind of machine learning problem, we must know how we are going to evaluate our results, or what the evaluation metric or objective is. For example in case of a skewed binary classification problem we generally choose area under the receiver operating characteristic curve (ROC AUC or simply AUC). In case of multi-label or multi-class classification problems, we generally choose categorical cross-entropy or multiclass log loss and mean squared error in case of regression problems.\n\nI won’t go into details of the different evaluation metrics as we can have many different types, depending on the problem.\n\n# The Libraries\n\nTo start with the machine learning libraries, install the basic and most important ones first, for example, numpy and scipy.\n\n*   To see and do operations on data: pandas ([http://pandas.pydata.org/](http://pandas.pydata.org/))\n*   For all kinds of machine learning models: scikit-learn ([http://scikit-learn.org/stable/](http://scikit-learn.org/stable/))\n*   The best gradient boosting library: xgboost ([https://github.com/dmlc/xgboost](https://github.com/dmlc/xgboost))\n*   For neural networks: keras ([http://keras.io/](http://keras.io/))\n*   For plotting data: matplotlib ([http://matplotlib.org/](http://matplotlib.org/))\n*   To monitor progress: tqdm ([https://pypi.python.org/pypi/tqdm](https://pypi.python.org/pypi/tqdm))\n\nI don’t use Anaconda ([https://www.continuum.io/downloads](https://www.continuum.io/downloads)). It’s easy and does everything for you, but I want more freedom. The choice is yours. 🙂\n\n# The Machine Learning Framework\n\nIn 2015, I came up with a framework for automatic machine learning which is still under development and will be released soon. For this post, the same framework will be the basis. The framework is shown in the figure below:\n\n![Figure from: A. Thakur and A. Krohn-Grimberghe, AutoCompete: A Framework for Machine Learning Competitions, AutoML Workshop, International Conference on Machine Learning 2015.](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_2.png)\n\nFigure from: A. Thakur and A. Krohn-Grimberghe, AutoCompete: A Framework for Machine Learning Competitions, AutoML Workshop, International Conference on Machine Learning 2015.\n\nIn the framework shown above, the pink lines represent the most common paths followed. After we have extracted and reduced the data to a tabular format, we can go ahead with building machine learning models.\n\nThe very first step is identification of the problem. This can be done by looking at the labels. One must know if the problem is a binary classification, a multi-class or multi-label classification or a regression problem. After we have identified the problem, we split the data into two different parts, a training set and a validation set as depicted in the figure below.\n\n![abhishek_3](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_3.png)\n\nThe splitting of data into training and validation sets “must” be done according to labels. In case of any kind of classification problem, use stratified splitting. In python, you can do this using scikit-learn very easily.\n\n![abhishek_4](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_4.png)\n\nIn case of regression task, a simple K-Fold splitting should suffice. There are, however, some complex methods which tend to keep the distribution of labels same for both training and validation set and this is left as an exercise for the reader.\n\n![abhishek_5](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_5.png)\n\nI have chosen the eval_size or the size of the validation set as 10% of the full data in the examples above, but one can choose this value according to the size of the data they have.\n\nAfter the splitting of the data is done, leave this data out and don’t touch it. Any operations that are applied on training set must be saved and then applied to the validation set. Validation set, in any case, should not be joined with the training set. Doing so will result in very good evaluation scores and make the user happy but instead he/she will be building a useless model with very high overfitting.\n\nNext step is identification of different variables in the data. There are usually three types of variables we deal with. Namely, numerical variables, categorical variables and variables with text inside them. Let’s take example of the popular Titanic dataset ([https://www.kaggle.com/c/titanic/data](https://www.kaggle.com/c/titanic/data)).\n\n![abhishek_6](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_6.png)\n\nHere, survival is the label. We have already separated labels from the training data in the previous step. Then, we have pclass, sex, embarked. These variables have different levels and thus they are categorical variables. Variables like age, sibsp, parch, etc are numerical variables. Name is a variable with text data but I don’t think it’s a useful variable to predict survival.\n\nSeparate out the numerical variables first. These variables don’t need any kind of processing and thus we can start applying normalization and machine learning models to these variables.\n\nThere are two ways in which we can handle categorical data:\n\n*   Convert the categorical data to labels\n\n![abhishek_7](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_7.png)\n\n*   Convert the labels to binary variables (one-hot encoding)\n\n![abhishek_8](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_8.png)\n\nPlease remember to convert categories to numbers first using LabelEncoder before applying OneHotEncoder on it.\n\nSince, the Titanic data doesn’t have good example of text variables, let’s formulate a general rule on handling text variables. We can combine all the text variables into one and then use some algorithms which work on text data and convert it to numbers.\n\nThe text variables can be joined as follows:\n\n![abhishek_9](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_9.png)\n\nWe can then use CountVectorizer or TfidfVectorizer on it:\n\n![abhishek_10](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_10.png)\n\nor,\n\n![abhishek_11](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_11.png)\n\nThe TfidfVectorizer performs better than the counts most of the time and I have seen that the following parameters for TfidfVectorizer work almost all the time.\n\n![abhishek_12](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_12.png)\n\nIf you are applying these vectorizers only on the training set, make sure to dump it to hard drive so that you can use it later on the validation set.\n\n![abhishek_13](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_13.png)\n\nNext, we come to the stacker module. Stacker module is not a model stacker but a feature stacker. The different features after the processing steps described above can be combined using the stacker module.\n\n![abhishek_14](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_14.png)\n\nYou can horizontally stack all the features before putting them through further processing by using numpy hstack or sparse hstack depending on whether you have dense or sparse features.\n\n![abhishek_15](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_15.png)\n\nAnd can also be achieved by FeatureUnion module in case there are other processing steps such as pca or feature selection (we will visit decomposition and feature selection later in this post).\n\n![abhishek_16](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_16.png)\n\nOnce, we have stacked the features together, we can start applying machine learning models. At this stage only models you should go for should be ensemble tree based models. These models include:\n\n*   RandomForestClassifier\n*   RandomForestRegressor\n*   ExtraTreesClassifier\n*   ExtraTreesRegressor\n*   XGBClassifier\n*   XGBRegressor\n\nWe cannot apply linear models to the above features since they are not normalized. To use linear models, one can use Normalizer or StandardScaler from scikit-learn.\n\nThese normalization methods work only on dense features and don’t give very good results if applied on sparse features. Yes, one can apply StandardScaler on sparse matrices without using the mean (parameter: with_mean=False).\n\nIf the above steps give a “good” model, we can go for optimization of hyperparameters and in case it doesn’t we can go for the following steps and improve our model.\n\nThe next steps include decomposition methods:\n\n![abhishek_17](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_17.png)\n\nFor the sake of simplicity, we will leave out LDA and QDA transformations. For high dimensional data, generally PCA is used decompose the data. For images start with 10-15 components and increase this number as long as the quality of result improves substantially. For other type of data, we select 50-60 components initially (we tend to avoid PCA as long as we can deal with the numerical data as it is).\n\n![abhishek_18](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_18.png)\n\nFor text data, after conversion of text to sparse matrix, go for Singular Value Decomposition (SVD). A variation of SVD called TruncatedSVD can be found in scikit-learn.\n\n![abhishek_decomp](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_decomp.png)\n\nThe number of SVD components that generally work for TF-IDF or counts are between 120-200. Any number above this might improve the performance but not substantially and comes at the cost of computing power.\n\nAfter evaluating further performance of the models, we move to scaling of the datasets, so that we can evaluate linear models too. The normalized or scaled features can then be sent to the machine learning models or feature selection modules.\n\n![abhishek_19](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_19.png)\n\nThere are multiple ways in which feature selection can be achieved. One of the most common way is greedy feature selection (forward or backward). In greedy feature selection we choose one feature, train a model and evaluate the performance of the model on a fixed evaluation metric. We keep adding and removing features one-by-one and record performance of the model at every step. We then select the features which have the best evaluation score. One implementation of greedy feature selection with AUC as evaluation metric can be found here: [https://github.com/abhishekkrthakur/greedyFeatureSelection](https://github.com/abhishekkrthakur/greedyFeatureSelection). It must be noted that this implementation is not perfect and must be changed/modified according to the requirements.\n\nOther faster methods of feature selection include selecting best features from a model. We can either look at coefficients of a logit model or we can train a random forest to select best features and then use them later with other machine learning models.\n\n![abhishek_20](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_20.png)\n\nRemember to keep low number of estimators and minimal optimization of hyper parameters so that you don’t overfit.\n\nThe feature selection can also be achieved using Gradient Boosting Machines. It is good if we use xgboost instead of the implementation of GBM in scikit-learn since xgboost is much faster and more scalable.\n\n![abhishek_21](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_21.png)\n\nWe can also do feature selection of sparse datasets using RandomForestClassifier / RandomForestRegressor and xgboost.\n\nAnother popular method for feature selection from positive sparse datasets is chi-2 based feature selection and we also have that implemented in scikit-learn.\n\n![abhishek_22](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_22.png)\n\nHere, we use chi2 in conjunction with SelectKBest to select 20 features from the data. This also becomes a hyperparameter we want to optimize to improve the result of our machine learning models.\n\nDon’t forget to dump any kinds of transformers you use at all the steps. You will need them to evaluate performance on the validation set.\n\nNext (or intermediate) major step is model selection + hyperparameter optimization.\n\n![abhishek_23](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_23.png)\n\nWe generally use the following algorithms in the process of selecting a machine learning model:\n\n*   **Classification**:\n\n  *  Random Forest\n  *  GBM\n  *  Logistic Regression\n  *  Naive Bayes\n  *  Support Vector Machines\n  *  k-Nearest Neighbors\n\n*   **Regression**\n\n  *  Random Forest\n  *  GBM\n  *  Linear Regression\n  *  Ridge\n  *  Lasso\n  *  SVR\n\nWhich parameters should I optimize? How do I choose parameters closest to the best ones? These are a couple of questions people come up with most of the time. One cannot get answers to these questions without experience with different models + parameters on a large number of datasets. Also people who have experience are not willing to share their secrets. Luckily, I have quite a bit of experience too and I’m willing to give away some of the stuff.\n\nLet’s break down the hyperparameters, model wise:\n\n![abhishek_24](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_24.png)\n\nRS* = Cannot say about proper values, go for Random Search in these hyperparameters.\n\nIn my opinion, and strictly my opinion, the above models will out-perform any others and we don’t need to evaluate any other models.\n\nOnce again, remember to save the transformers:\n\n![abhishek_25](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_25.png)\n\nAnd apply them on validation set separately:\n\n![abhishek_26](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_26.png)\n\nThe above rules and the framework has performed very well in most of the datasets I have dealt with. Of course, it has also failed for very complicated tasks. Nothing is perfect and we keep on improving on what we learn. Just like in machine learning.\n\nGet in touch with me with any doubts: abhishek4 [at] gmail [dot] com\n\n# Bio\n\n![Abhishek Thakur](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek.png)\n\n[Abhishek Thakur](https://www.kaggle.com/abhishek), competitions grandmaster.\n**[Abhishek Thakur](https://www.kaggle.com/abhishek)** works as a Senior Data Scientist on the Data Science team at [Searchmetrics Inc](http://www.searchmetrics.com/). At Searchmetrics, Abhishek works on some of the most interesting data driven studies, applied machine learning algorithms and deriving insights from huge amount of data which require a lot of data munging, cleaning, feature engineering and building and optimization of machine learning models.\n\nIn his free time, he likes to take part in machine learning competitions and has taken part in over 100 competitions. His research interests include automatic machine learning, deep learning, hyperparameter optimization, computer vision, image analysis and retrieval and pattern recognition.\n\n---\n\n* Author: [Abhishek Thakur](https://www.linkedin.com/in/abhisvnit/)\n* Link: [Approaching (Almost) Any Machine Learning Problem](https://www.linkedin.com/pulse/approaching-almost-any-machine-learning-problem-abhishek-thakur)\n","tags":["Machine-Learning"],"categories":["Machine-Learning"]},{"title":"消息队列设计精要","url":"%2F2016%2F2016-07-01-mq-design%2F","content":"\n\n消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。\n\n当今市面上有很多主流的消息中间件，如老牌的ActiveMQ、RabbitMQ，炙手可热的Kafka，阿里巴巴自主开发的Notify、MetaQ、RocketMQ等。\n\n本文不会一一介绍这些消息队列的所有特性，而是探讨一下自主开发设计一个消息队列时，你需要思考和设计的重要方面。过程中我们会参考这些成熟消息队列的很多重要思想。\n\n本文首先会阐述什么时候你需要一个消息队列，然后以Push模型为主，从零开始分析设计一个消息队列时需要考虑到的问题，如RPC、高可用、顺序和重复消息、可靠投递、消费关系解析等。\n\n也会分析以Kafka为代表的pull模型所具备的优点。最后是一些高级主题，如用批量/异步提高性能、pull模型的系统设计理念、存储子系统的设计、流量控制的设计、公平调度的实现等。其中最后四个方面会放在下篇讲解。\n\n# 何时需要消息队列\n\n当你需要使用消息队列时，首先需要考虑它的必要性。可以使用mq的场景有很多，最常用的几种，是做业务解耦/最终一致性/广播/错峰流控等。反之，如果需要强一致性，关注业务逻辑的处理结果，则RPC显得更为合适。\n\n## 解耦\n\n解耦是消息队列要解决的最本质问题。所谓解耦，简单点讲就是一个事务，只关心核心的流程。而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。换句话说，基于消息的模型，关心的是“通知”，而非“处理”。\n\n比如在美团旅游，我们有一个产品中心，产品中心上游对接的是主站、移动后台、旅游供应链等各个数据源；下游对接的是筛选系统、API系统等展示系统。当上游的数据发生变更的时候，如果不使用消息系统，势必要调用我们的接口来更新数据，就特别依赖产品中心接口的稳定性和处理能力。但其实，作为旅游的产品中心，也许只有对于旅游自建供应链，产品中心更新成功才是他们关心的事情。而对于团购等外部系统，产品中心更新成功也好、失败也罢，并不是他们的职责所在。他们只需要保证在信息变更的时候通知到我们就好了。\n\n而我们的下游，可能有更新索引、刷新缓存等一系列需求。对于产品中心来说，这也不是我们的职责所在。说白了，如果他们定时来拉取数据，也能保证数据的更新，只是实时性没有那么强。但使用接口方式去更新他们的数据，显然对于产品中心来说太过于“重量级”了，只需要发布一个产品ID变更的通知，由下游系统来处理，可能更为合理。\n\n再举一个例子，对于我们的订单系统，订单最终支付成功之后可能需要给用户发送短信积分什么的，但其实这已经不是我们系统的核心流程了。如果外部系统速度偏慢（比如短信网关速度不好），那么主流程的时间会加长很多，用户肯定不希望点击支付过好几分钟才看到结果。那么我们只需要通知短信系统“我们支付成功了”，不一定非要等待它处理完成。\n\n## 最终一致性\n\n最终一致性指的是两个系统的状态保持一致，要么都成功，要么都失败。当然有个时间限制，理论上越快越好，但实际上在各种异常的情况下，可能会有一定延迟达到最终一致状态，但最后两个系统的状态是一样的。\n\n业界有一些为“最终一致性”而生的消息队列，如Notify（阿里）、QMQ（去哪儿）等，其设计初衷，就是为了交易系统中的高可靠通知。\n\n以一个银行的转账过程来理解最终一致性，转账的需求很简单，如果A系统扣钱成功，则B系统加钱一定成功。反之则一起回滚，像什么都没发生一样。\n\n然而，这个过程中存在很多可能的意外：\n\n1.  A扣钱成功，调用B加钱接口失败。\n2.  A扣钱成功，调用B加钱接口虽然成功，但获取最终结果时网络异常引起超时。\n3.  A扣钱成功，B加钱失败，A想回滚扣的钱，但A机器down机。\n\n可见，想把这件看似简单的事真正做成，真的不那么容易。所有跨VM的一致性问题，从技术的角度讲通用的解决方案是：\n\n1.  强一致性，分布式事务，但落地太难且成本太高，后文会具体提到。\n2.  最终一致性，主要是用“记录”和“补偿”的方式。在做所有的不确定的事情之前，先把事情记录下来，然后去做不确定的事情，结果可能是：成功、失败或是不确定，“不确定”（例如超时等）可以等价为失败。成功就可以把记录的东西清理掉了，对于失败和不确定，可以依靠定时任务等方式把所有失败的事情重新搞一遍，直到成功为止。\n   回到刚才的例子，系统在A扣钱成功的情况下，把要给B“通知”这件事记录在库里（为了保证最高的可靠性可以把通知B系统加钱和扣钱成功这两件事维护在一个本地事务里），通知成功则删除这条记录，通知失败或不确定则依靠定时任务补偿性地通知我们，直到我们把状态更新成正确的为止。\n   整个这个模型依然可以基于RPC来做，但可以抽象成一个统一的模型，基于消息队列来做一个“企业总线”。\n   具体来说，本地事务维护业务变化和通知消息，一起落地（失败则一起回滚），然后RPC到达broker，在broker成功落地后，RPC返回成功，本地消息可以删除。否则本地消息一直靠定时任务轮询不断重发，这样就保证了消息可靠落地broker。\n   broker往consumer发送消息的过程类似，一直发送消息，直到consumer发送消费成功确认。\n   我们先不理会重复消息的问题，通过两次消息落地加补偿，下游是一定可以收到消息的。然后依赖状态机版本号等方式做判重，更新自己的业务，就实现了最终一致性。\n\n最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。另外，所有不保证100%不丢消息的消息队列，理论上无法实现最终一致性。好吧，应该说理论上的100%，排除系统严重故障和bug。\n\n像Kafka一类的设计，在设计层面上就有丢消息的可能（比如定时刷盘，如果掉电就会丢消息）。哪怕只丢千分之一的消息，业务也必须用其他的手段来保证结果正确。\n\n## 广播\n\n消息队列的基本功能之一是进行广播。如果没有消息队列，每当一个新的业务方接入，我们都要联调一次新接口。有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。\n\n比如本文开始提到的产品中心发布产品变更的消息，以及景点库很多去重更新的消息，可能“关心”方有很多个，但产品中心和景点库只需要发布变更消息即可，谁关心谁接入。\n\n## 错峰与流控\n\n试想上下游对于事情的处理能力是不同的。比如，Web前端每秒承受上千万的请求，并不是什么神奇的事情，只需要加多一点机器，再搭建一些LVS负载均衡设备和Nginx等即可。但数据库的处理能力却十分有限，即使使用SSD加分库分表，单机的处理能力仍然在万级。由于成本的考虑，我们不能奢求数据库的机器数量追上前端。\n\n这种问题同样存在于系统和系统之间，如短信系统可能由于短板效应，速度卡在网关上（每秒几百次请求），跟前端的并发量不是一个数量级。但用户晚上个半分钟左右收到短信，一般是不会有太大问题的。如果没有消息队列，两个系统之间通过协商、滑动窗口等复杂的方案也不是说不能实现。但系统复杂性指数级增长，势必在上游或者下游做存储，并且要处理定时、拥塞等一系列问题。而且每当有处理能力有差距的时候，都需要单独开发一套逻辑来维护这套逻辑。所以，利用中间系统转储两个系统的通信内容，并在下游系统有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式。\n\n总而言之，消息队列不是万能的。对于需要强事务保证而且延迟敏感的，RPC是优于消息队列的。\n\n对于一些无关痛痒，或者对于别人非常重要但是对于自己不是那么关心的事情，可以利用消息队列去做。\n\n支持最终一致性的消息队列，能够用来处理延迟不那么敏感的“分布式事务”场景，而且相对于笨重的分布式事务，可能是更优的处理方式。\n\n当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”。在下游有能力处理的时候，再进行分发。\n\n如果下游有很多系统关心你的系统发出的通知的时候，果断地使用消息队列吧。\n\n# 如何设计一个消息队列\n\n## 综述\n\n我们现在明确了消息队列的使用场景，下一步就是如何设计实现一个消息队列了。\n\n![](/assets/images/2016/07/01/mq-design/mq-design.png)\n\n基于消息的系统模型，不一定需要broker(消息队列服务端)。市面上的的Akka（actor模型）、ZeroMQ等，其实都是基于消息的系统设计范式，但是没有broker。\n\n我们之所以要设计一个消息队列，并且配备broker，无外乎要做两件事情：\n\n1.  消息的转储，在更合适的时间点投递，或者通过一系列手段辅助消息最终能送达消费机。\n2.  规范一种范式和通用的模式，以满足解耦、最终一致性、错峰等需求。\n   掰开了揉碎了看，最简单的消息队列可以做成一个消息转发器，把一次RPC做成两次RPC。发送者把消息投递到服务端（以下简称broker），服务端再将消息转发一手到接收端，就是这么简单。\n\n一般来讲，设计消息队列的整体思路是先build一个整体的数据流,例如producer发送给broker,broker发送给consumer,consumer回复消费确认，broker删除/备份消息等。\n\n利用RPC将数据流串起来。然后考虑RPC的高可用性，尽量做到无状态，方便水平扩展。\n\n之后考虑如何承载消息堆积，然后在合适的时机投递消息，而处理堆积的最佳方式，就是存储，存储的选型需要综合考虑性能/可靠性和开发维护成本等诸多因素。\n\n为了实现广播功能，我们必须要维护消费关系，可以利用zk/config server等保存消费关系。\n\n在完成了上述几个功能后，消息队列基本就实现了。然后我们可以考虑一些高级特性，如可靠投递，事务特性，性能优化等。\n\n下面我们会以设计消息队列时重点考虑的模块为主线，穿插灌输一些消息队列的特性实现方法，来具体分析设计实现一个消息队列时的方方面面。\n\n## 实现队列基本功能\n\n### RPC通信协议\n\n刚才讲到，所谓消息队列，无外乎两次RPC加一次转储，当然需要消费端最终做消费确认的情况是三次RPC。既然是RPC，就必然牵扯出一系列话题，什么负载均衡啊、服务发现啊、通信协议啊、序列化协议啊，等等。在这一块，我的强烈建议是不要重复造轮子。利用公司现有的RPC框架：Thrift也好，Dubbo也好，或者是其他自定义的框架也好。因为消息队列的RPC，和普通的RPC没有本质区别。当然了，自主利用Memchached或者Redis协议重新写一套RPC框架并非不可（如MetaQ使用了自己封装的Gecko NIO框架，卡夫卡也用了类似的协议）。但实现成本和难度无疑倍增。排除对效率的极端要求，都可以使用现成的RPC框架。\n\n简单来讲，服务端提供两个RPC服务，一个用来接收消息，一个用来确认消息收到。并且做到不管哪个server收到消息和确认消息，结果一致即可。当然这中间可能还涉及跨IDC的服务的问题。这里和RPC的原则是一致的，尽量优先选择本机房投递。你可能会问，如果producer和consumer本身就在两个机房了，怎么办？首先，broker必须保证感知的到所有consumer的存在。其次，producer尽量选择就近的机房就好了。\n\n### 高可用\n\n其实所有的高可用，是依赖于RPC和存储的高可用来做的。先来看RPC的高可用，美团的基于MTThrift的RPC框架，阿里的Dubbo等，其本身就具有服务自动发现，负载均衡等功能。而消息队列的高可用，只要保证broker接受消息和确认消息的接口是幂等的，并且consumer的几台机器处理消息是幂等的，这样就把消息队列的可用性，转交给RPC框架来处理了。\n\n那么怎么保证幂等呢？最简单的方式莫过于共享存储。broker多机器共享一个DB或者一个分布式文件/kv系统，则处理消息自然是幂等的。就算有单点故障，其他节点可以立刻顶上。另外failover可以依赖定时任务的补偿，这是消息队列本身天然就可以支持的功能。存储系统本身的可用性我们不需要操太多心，放心大胆的交给DBA们吧！\n\n对于不共享存储的队列，如Kafka使用分区加主备模式，就略微麻烦一些。需要保证每一个分区内的高可用性，也就是每一个分区至少要有一个主备且需要做数据的同步，关于这块HA的细节，可以参考下篇pull模型消息系统设计。\n\n### 服务端承载消息堆积的能力\n\n消息到达服务端如果不经过任何处理就到接收者了，broker就失去了它的意义。为了满足我们错峰/流控/最终可达等一系列需求，把消息存储下来，然后选择时机投递就显得是顺理成章的了。\n\n只是这个存储可以做成很多方式。比如存储在内存里，存储在分布式KV里，存储在磁盘里，存储在数据库里等等。但归结起来，主要有持久化和非持久化两种。\n\n持久化的形式能更大程度地保证消息的可靠性（如断电等不可抗外力），并且理论上能承载更大限度的消息堆积（外存的空间远大于内存）。\n\n但并不是每种消息都需要持久化存储。很多消息对于投递性能的要求大于可靠性的要求，且数量极大（如日志）。这时候，消息不落地直接暂存内存，尝试几次failover，最终投递出去也未尝不可。\n\n市面上的消息队列普遍两种形式都支持。当然具体的场景还要具体结合公司的业务来看。\n\n### 存储子系统的选择\n\n我们来看看如果需要数据落地的情况下各种存储子系统的选择。理论上，从速度来看，文件系统&gt;分布式KV（持久化）&gt;分布式文件系统&gt;数据库，而可靠性却截然相反。还是要从支持的业务场景出发作出最合理的选择，如果你们的消息队列是用来支持支付/交易等对可靠性要求非常高，但对性能和量的要求没有这么高，而且没有时间精力专门做文件存储系统的研究，DB是最好的选择。\n\n但是DB受制于IOPS，如果要求单broker 5位数以上的QPS性能，基于文件的存储是比较好的解决方案。整体上可以采用数据文件+索引文件的方式处理，具体这块的设计比较复杂，可以参考下篇的存储子系统设计。\n\n分布式KV（如MongoDB，HBase）等，或者持久化的Redis，由于其编程接口较友好，性能也比较可观，如果在可靠性要求不是那么高的场景，也不失为一个不错的选择。\n\n### 消费关系解析\n\n现在我们的消息队列初步具备了转储消息的能力。下面一个重要的事情就是解析发送接收关系，进行正确的消息投递了。\n\n市面上的消息队列定义了一堆让人晕头转向的名词，如JMS 规范中的Topic/Queue，Kafka里面的Topic/Partition/ConsumerGroup，RabbitMQ里面的Exchange等等。抛开现象看本质，无外乎是单播与广播的区别。所谓单播，就是点到点；而广播，是一点对多点。当然，对于互联网的大部分应用来说，组间广播、组内单播是最常见的情形。\n\n消息需要通知到多个业务集群，而一个业务集群内有很多台机器，只要一台机器消费这个消息就可以了。\n\n当然这不是绝对的，很多时候组内的广播也是有适用场景的，如本地缓存的更新等等。另外，消费关系除了组内组间，可能会有多级树状关系。这种情况太过于复杂，一般不列入考虑范围。所以，一般比较通用的设计是支持组间广播，不同的组注册不同的订阅。组内的不同机器，如果注册一个相同的ID，则单播；如果注册不同的ID(如IP地址+端口)，则广播。\n\n至于广播关系的维护，一般由于消息队列本身都是集群，所以都维护在公共存储上，如config server、zookeeper等。维护广播关系所要做的事情基本是一致的:\n\n1.  发送关系的维护。\n2.  发送关系变更时的通知。\n\n## 队列高级特性设计\n\n上面都是些消息队列基本功能的实现，下面来看一些关于消息队列特性相关的内容，不管可靠投递/消息丢失与重复以及事务乃至于性能，不是每个消息队列都会照顾到，所以要依照业务的需求，来仔细衡量各种特性实现的成本，利弊，最终做出最为合理的设计。\n\n### 可靠投递（最终一致性）\n\n这是个激动人心的话题，完全不丢消息，究竟可不可能？答案是，完全可能，前提是消息可能会重复，并且，在异常情况下，要接受消息的延迟。\n\n方案说简单也简单，就是每当要发生不可靠的事情（RPC等）之前，先将消息落地，然后发送。当失败或者不知道成功失败（比如超时）时，消息状态是待发送，定时任务不停轮询所有待发送消息，最终一定可以送达。\n\n具体来说：\n\n1.  producer往broker发送消息之前，需要做一次落地。\n2.  请求到server后，server确保数据落地后再告诉客户端发送成功。\n3.  支持广播的消息队列需要对每个待发送的endpoint，持久化一个发送状态，直到所有endpoint状态都OK才可删除消息。\n\n对于各种不确定（超时、down机、消息没有送达、送达后数据没落地、数据落地了回复没收到），其实对于发送方来说，都是一件事情，就是消息没有送达。\n\n重推消息所面临的问题就是消息重复。重复和丢失就像两个噩梦，你必须要面对一个。好在消息重复还有处理的机会，消息丢失再想找回就难了。\n\nAnyway，作为一个成熟的消息队列，应该尽量在各个环节减少重复投递的可能性，不能因为重复有解决方案就放纵的乱投递。\n\n最后说一句，不是所有的系统都要求最终一致性或者可靠投递，比如一个论坛系统、一个招聘系统。一个重复的简历或话题被发布，可能比丢失了一个发布显得更让用户无法接受。不断重复一句话，任何基础组件要服务于业务场景。\n\n#### 消费确认\n\n当broker把消息投递给消费者后，消费者可以立即响应我收到了这个消息。但收到了这个消息只是第一步，我能不能处理这个消息却不一定。或许因为消费能力的问题，系统的负荷已经不能处理这个消息；或者是刚才状态机里面提到的消息不是我想要接收的消息，主动要求重发。\n\n把消息的送达和消息的处理分开，这样才真正的实现了消息队列的本质-解耦。所以，允许消费者主动进行消费确认是必要的。当然，对于没有特殊逻辑的消息，默认Auto Ack也是可以的，但一定要允许消费方主动ack。\n\n对于正确消费ack的，没什么特殊的。但是对于reject和error，需要特别说明。reject这件事情，往往业务方是无法感知到的，系统的流量和健康状况的评估，以及处理能力的评估是一件非常复杂的事情。举个极端的例子，收到一个消息开始build索引，可能这个消息要处理半个小时，但消息量却是非常的小。所以reject这块建议做成滑动窗口/线程池类似的模型来控制，\n\n消费能力不匹配的时候，直接拒绝，过一段时间重发，减少业务的负担。\n\n但业务出错这件事情是只有业务方自己知道的，就像上文提到的状态机等等。这时应该允许业务方主动ack error，并可以与broker约定下次投递的时间。\n\n#### 重复消息和顺序消息\n\n上文谈到重复消息是不可能100%避免的，除非可以允许丢失，那么，顺序消息能否100%满足呢? 答案是可以，但条件更为苛刻：\n\n1.  允许消息丢失。\n2.  从发送方到服务方到接受者都是单点单线程。\n\n所以绝对的顺序消息基本上是不能实现的，当然在METAQ/Kafka等pull模型的消息队列中，单线程生产/消费，排除消息丢失，也是一种顺序消息的解决方案。\n\n一般来讲，一个主流消息队列的设计范式里，应该是不丢消息的前提下，尽量减少重复消息，不保证消息的投递顺序。\n\n谈到重复消息，主要是两个话题：\n\n1.  如何鉴别消息重复，并幂等的处理重复消息。\n2.  一个消息队列如何尽量减少重复消息的投递。\n\n先来看看第一个话题，每一个消息应该有它的唯一身份。不管是业务方自定义的，还是根据IP/PID/时间戳生成的MessageId，如果有地方记录这个MessageId，消息到来是能够进行比对就\n\n能完成重复的鉴定。数据库的唯一键/bloom filter/分布式KV中的key，都是不错的选择。由于消息不能被永久存储，所以理论上都存在消息从持久化存储移除的瞬间上游还在投递的可能（上游因种种原因投递失败，不停重试，都到了下游清理消息的时间）。这种事情都是异常情况下才会发生的，毕竟是小众情况。两分钟消息都还没送达，多送一次又能怎样呢？幂等的处理消息是一门艺术，因为种种原因重复消息或者错乱的消息还是来到了，说两种通用的解决方案：\n\n1.  版本号。\n2.  状态机。\n\n##### 版本号\n\n举个简单的例子，一个产品的状态有上线/下线状态。如果消息1是下线，消息2是上线。不巧消息1判重失败，被投递了两次，且第二次发生在2之后，如果不做重复性判断，显然最终状态是错误的。\n\n但是，如果每个消息自带一个版本号。上游发送的时候，标记消息1版本号是1，消息2版本号是2。如果再发送下线消息，则版本号标记为3。下游对于每次消息的处理，同时维护一个版本号。\n\n每次只接受比当前版本号大的消息。初始版本为0，当消息1到达时，将版本号更新为1。消息2到来时，因为版本号&gt;1.可以接收，同时更新版本号为2.当另一条下线消息到来时，如果版本号是3.则是真实的下线消息。如果是1，则是重复投递的消息。\n\n如果业务方只关心消息重复不重复，那么问题就已经解决了。但很多时候另一个头疼的问题来了，就是消息顺序如果和想象的顺序不一致。比如应该的顺序是12，到来的顺序是21。则最后会发生状态错误。\n\n参考TCP/IP协议，如果想让乱序的消息最后能够正确的被组织，那么就应该只接收比当前版本号大一的消息。并且在一个session周期内要一直保存各个消息的版本号。\n\n如果到来的顺序是21，则先把2存起来，待1到来后，先处理1，再处理2，这样重复性和顺序性要求就都达到了。\n\n##### 状态机\n\n基于版本号来处理重复和顺序消息听起来是个不错的主意，但凡事总有瑕疵。使用版本号的最大问题是：\n\n1.  对发送方必须要求消息带业务版本号。\n2.  下游必须存储消息的版本号，对于要严格保证顺序的。\n\n还不能只存储最新的版本号的消息，要把乱序到来的消息都存储起来。而且必须要对此做出处理。试想一个永不过期的&quot;session&quot;，比如一个物品的状态，会不停流转于上下线。那么中间环节的所有存储\n\n就必须保留，直到在某个版本号之前的版本一个不丢的到来，成本太高。\n\n就刚才的场景看，如果消息没有版本号，该怎么解决呢？业务方只需要自己维护一个状态机，定义各种状态的流转关系。例如，&quot;下线&quot;状态只允许接收&quot;上线&quot;消息，“上线”状态只能接收“下线消息”，如果上线收到上线消息，或者下线收到下线消息，在消息不丢失和上游业务正确的前提下。要么是消息发重了，要么是顺序到达反了。这时消费者只需要把“我不能处理这个消息”告诉投递者，要求投递者过一段时间重发即可。而且重发一定要有次数限制，比如5次，避免死循环，就解决了。\n\n举例子说明，假设产品本身状态是下线，1是上线消息，2是下线消息，3是上线消息，正常情况下，消息应该的到来顺序是123，但实际情况下收到的消息状态变成了3123。\n\n那么下游收到3消息的时候，判断状态机流转是下线-&gt;上线，可以接收消息。然后收到消息1，发现是上线-&gt;上线，拒绝接收，要求重发。然后收到消息2，状态是上线-&gt;下线，于是接收这个消息。\n\n此时无论重发的消息1或者3到来，还是可以接收。另外的重发，在一定次数拒绝后停止重发，业务正确。\n\n#### 中间件对于重复消息的处理\n\n回归到消息队列的话题来讲。上述通用的版本号/状态机/ID判重解决方案里，哪些是消息队列该做的、哪些是消息队列不该做业务方处理的呢？其实这里没有一个完全严格的定义，但回到我们的出发点，我们保证不丢失消息的情况下尽量少重复消息，消费顺序不保证。那么重复消息下和乱序消息下业务的正确，应该是由消费方保证的，我们要做的是减少消息发送的重复。\n\n我们无法定义业务方的业务版本号/状态机，如果API里强制需要指定版本号，则显得过于绑架客户了。况且，在消费方维护这么多状态，就涉及到一个消费方的消息落地/多机间的同步消费状态问题，复杂度指数级上升，而且只能解决部分问题。\n\n减少重复消息的关键步骤：\n\n1.  broker记录MessageId，直到投递成功后清除，重复的ID到来不做处理，这样只要发送者在清除周期内能够感知到消息投递成功，就基本不会在server端产生重复消息。\n2.  对于server投递到consumer的消息，由于不确定对端是在处理过程中还是消息发送丢失的情况下，有必要记录下投递的IP地址。决定重发之前询问这个IP，消息处理成功了吗？如果询问无果，再重发。\n\n### 事务\n\n持久性是事务的一个特性，然而只满足持久性却不一定能满足事务的特性。还是拿扣钱/加钱的例子讲。满足事务的一致性特征，则必须要么都不进行，要么都能成功。\n\n解决方案从大方向上有两种：\n\n1.  两阶段提交，分布式事务。\n2.  本地事务，本地落地，补偿发送。\n\n分布式事务存在的最大问题是成本太高，两阶段提交协议，对于仲裁down机或者单点故障，几乎是一个无解的黑洞。对于交易密集型或者I/O密集型的应用，没有办法承受这么高的网络延迟，系统复杂性。\n\n并且成熟的分布式事务一定构建与比较靠谱的商用DB和商用中间件上，成本也太高。\n\n那如何使用本地事务解决分布式事务的问题呢？以本地和业务在一个数据库实例中建表为例子，与扣钱的业务操作同一个事务里，将消息插入本地数据库。如果消息入库失败，则业务回滚；如果消息入库成功，事务提交。\n\n然后发送消息（注意这里可以实时发送，不需要等定时任务检出，以提高消息实时性）。以后的问题就是前文的最终一致性问题所提到的了，只要消息没有发送成功，就一直靠定时任务重试。\n\n这里有一个关键的点，本地事务做的，是业务落地和消息落地的事务，而不是业务落地和RPC成功的事务。这里很多人容易混淆，如果是后者，无疑是事务嵌套RPC，是大忌，会有长事务死锁等各种风险。\n\n而消息只要成功落地，很大程度上就没有丢失的风险（磁盘物理损坏除外）。而消息只要投递到服务端确认后本地才做删除，就完成了producer-&gt;broker的可靠投递，并且当消息存储异常时，业务也是可以回滚的。\n\n本地事务存在两个最大的使用障碍：\n\n1.  配置较为复杂，“绑架”业务方，必须本地数据库实例提供一个库表。\n2.  对于消息延迟高敏感的业务不适用。\n\n话说回来，不是每个业务都需要强事务的。扣钱和加钱需要事务保证，但下单和生成短信却不需要事务，不能因为要求发短信的消息存储投递失败而要求下单业务回滚。所以，一个完整的消息队列应该定义清楚自己可以投递的消息类型，如事务型消息，本地非持久型消息，以及服务端不落地的非可靠消息等。对不同的业务场景做不同的选择。另外事务的使用应该尽量低成本、透明化，可以依托于现有的成熟框架，如Spring的声明式事务做扩展。业务方只需要使用@Transactional标签即可。\n\n### 性能相关\n\n#### 异步/同步\n\n首先澄清一个概念，异步，同步和oneway是三件事。异步，归根结底你还是需要关心结果的，但可能不是当时的时间点关心，可以用轮询或者回调等方式处理结果；同步是需要当时关心的结果的；而oneway是发出去就不管死活的方式，这种对于某些完全对可靠性没有要求的场景还是适用的，但不是我们重点讨论的范畴。\n\n回归来看，任何的RPC都是存在客户端异步与服务端异步的，而且是可以任意组合的：客户端同步对服务端异步，客户端异步对服务端异步，客户端同步对服务端同步，客户端异步对服务端同步。\n\n对于客户端来说，同步与异步主要是拿到一个Result，还是Future<Result>(Listenable)的区别。实现方式可以是线程池，NIO或者其他事件机制，这里先不展开讲。\n\n服务端异步可能稍微难理解一点，这个是需要RPC协议支持的。参考servlet 3.0规范，服务端可以吐一个future给客户端，并且在future done的时候通知客户端。\n\n整个过程可以参考下面的代码：\n\n客户端同步服务端异步。\n\n```java\nFuture<Result> future = request(server);//server立刻返回future\nsynchronized(future){\n    while(!future.isDone()){\n       future.wait();//server处理结束后会notify这个future，并修改isdone标志\n    }\n}\nreturn future.get();\n\n//客户端同步服务端同步。\n\nResult result = request(server);\n\n//客户端异步服务端同步(这里用线程池的方式)。\n\nFuture<Result> future = executor.submit(new Callable(){public void call&lt;Result&gt;(){\n    result = request(server);\n}})\nreturn future;\n\n//客户端异步服务端异步。\n\nFuture<Result> future = request(server);//server立刻返回future\n\nreturn future\n```\n\n上面说了这么多，其实是想让大家脱离两个误区：\n\n1.  RPC只有客户端能做异步，服务端不能。\n2.  异步只能通过线程池。\n\n那么，服务端使用异步最大的好处是什么呢？说到底，是解放了线程和I/O。试想服务端有一堆I/O等待处理，如果每个请求都需要同步响应，每条消息都需要结果立刻返回，那么就几乎没法做I/O合并\n\n（当然接口可以设计成batch的，但可能batch发过来的仍然数量较少）。而如果用异步的方式返回给客户端future，就可以有机会进行I/O的合并，把几个批次发过来的消息一起落地（这种合并对于MySQL等允许batch insert的数据库效果尤其明显），并且彻底释放了线程。不至于说来多少请求开多少线程，能够支持的并发量直线提高。\n\n来看第二个误区，返回future的方式不一定只有线程池。换句话说，可以在线程池里面进行同步操作，也可以进行异步操作，也可以不使用线程池使用异步操作（NIO、事件）。\n\n回到消息队列的议题上，我们当然不希望消息的发送阻塞主流程（前面提到了，server端如果使用异步模型，则可能因消息合并带来一定程度上的消息延迟），所以可以先使用线程池提交一个发送请求，主流程继续往下走。\n\n但是线程池中的请求关心结果吗？Of course，必须等待服务端消息成功落地，才算是消息发送成功。所以这里的模型，准确地说事客户端半同步半异步（使用线程池不阻塞主流程，但线程池中的任务需要等待server端的返回），server端是纯异步。客户端的线程池wait在server端吐回的future上，直到server端处理完毕，才解除阻塞继续进行。\n\n总结一句，同步能够保证结果，异步能够保证效率，要合理的结合才能做到最好的效率。\n\n#### 批量\n\n谈到批量就不得不提生产者消费者模型。但生产者消费者模型中最大的痛点是：消费者到底应该何时进行消费。大处着眼来看，消费动作都是事件驱动的。主要事件包括：\n\n1.  攒够了一定数量。\n2.  到达了一定时间。\n3.  队列里有新的数据到来。\n\n对于及时性要求高的数据，可用采用方式3来完成，比如客户端向服务端投递数据。只要队列有数据，就把队列中的所有数据刷出，否则将自己挂起，等待新数据的到来。\n在第一次把队列数据往外刷的过程中，又积攒了一部分数据，第二次又可以形成一个批量。伪代码如下:\n\n```java\nExecutor executor = Executors.newFixedThreadPool(4);\nfinal BlockingQueue<Message> queue = new ArrayBlockingQueue<>();\nprivate Runnable task = new Runnable({//这里由于共享队列，Runnable可以复用，故做成全局的\n    public void run(){\n        List&lt;Message&gt; messages  = new ArrayList&lt;&gt;(20);\n        queue.drainTo(messages，20);\n        doSend(messages);//阻塞，在这个过程中会有新的消息到来，如果4个线程都占满，队列就有机会囤新的消息\n    }\n});\npublic void send(Message message){\n    queue.offer(message);\n    executor.submit(task)\n}\n```\n\n这种方式是消息延迟和批量的一个比较好的平衡，但优先响应低延迟。延迟的最高程度由上一次发送的等待时间决定。但可能造成的问题是发送过快的话批量的大小不够满足性能的极致。\n\n```java\nExecutor executor = Executors.newFixedThreadPool(4);\nfinal BlockingQueue<Message> queue = new ArrayBlockingQueue&lt;&gt;();\nvolatile long last = System.currentMills();\nExecutors.newSingleThreadScheduledExecutor().submit(new Runnable(){\n    flush();\n}，500，500，TimeUnits.MILLS);\nprivate Runnable task = new Runnable({//这里由于共享队列，Runnable可以复用，顾做成全局的。\n    public void run(){\n        List&lt;Message&gt; messages  = new ArrayList&lt;&gt;(20);\n        queue.drainTo(messages，20);\n        doSend(messages);//阻塞，在这个过程中会有新的消息到来，如果4个线程都占满，队列就有机会屯新的消息。\n    }\n});\npublic void send(Message message){\n    last = System.currentMills();\n    queue.offer(message);\n    flush();\n}\nprivate void flush(){\n    if(queue.size&gt;200||System.currentMills()-last&gt;200){\n        executor.submit(task)\n    }\n}\n```\n\n相反对于可以用适量的延迟来换取高性能的场景来说，用定时/定量二选一的方式可能会更为理想，既到达一定数量才发送，但如果数量一直达不到，也不能干等，有一个时间上限。\n\n具体说来，在上文的submit之前，多判断一个时间和数量，并且Runnable内部维护一个定时器，避免没有新任务到来时旧的任务永远没有机会触发发送条件。对于server端的数据落地，使用这种方式就非常方便。\n\n最后啰嗦几句，曾经有人问我，为什么网络请求小包合并成大包会提高性能？主要原因有两个：\n\n1.  减少无谓的请求头，如果你每个请求只有几字节，而头却有几十字节，无疑效率非常低下。\n2.  减少回复的ack包个数。把请求合并后，ack包数量必然减少，确认和重发的成本就会降低。\n\n## push还是pull\n\n上文提到的消息队列，大多是针对push模型的设计。现在市面上有很多经典的也比较成熟的pull模型的消息队列，如Kafka、MetaQ等。这跟JMS中传统的push方式有很大的区别，可谓另辟蹊径。\n\n我们简要分析下push和pull模型各自存在的利弊。\n\n### 慢消费\n\n慢消费无疑是push模型最大的致命伤，穿成流水线来看，如果消费者的速度比发送者的速度慢很多，势必造成消息在broker的堆积。假设这些消息都是有用的无法丢弃的，消息就要一直在broker端保存。当然这还不是最致命的，最致命的是broker给consumer推送一堆consumer无法处理的消息，consumer不是reject就是error，然后来回踢皮球。\n\n反观pull模式，consumer可以按需消费，不用担心自己处理不了的消息来骚扰自己，而broker堆积消息也会相对简单，无需记录每一个要发送消息的状态，只需要维护所有消息的队列和偏移量就可以了。所以对于建立索引等慢消费，消息量有限且到来的速度不均匀的情况，pull模式比较合适。\n\n### 消息延迟与忙等\n\n这是pull模式最大的短板。由于主动权在消费方，消费方无法准确地决定何时去拉取最新的消息。如果一次pull取到消息了还可以继续去pull，如果没有pull取到则需要等待一段时间重新pull。\n\n但等待多久就很难判定了。你可能会说，我可以有xx动态pull取时间调整算法，但问题的本质在于，有没有消息到来这件事情决定权不在消费方。也许1分钟内连续来了1000条消息，然后半个小时没有新消息产生，\n\n可能你的算法算出下次最有可能到来的时间点是31分钟之后，或者60分钟之后，结果下条消息10分钟后到了，是不是很让人沮丧？\n\n当然也不是说延迟就没有解决方案了，业界较成熟的做法是从短时间开始（不会对broker有太大负担），然后指数级增长等待。比如开始等5ms，然后10ms，然后20ms，然后40ms……直到有消息到来，然后再回到5ms。\n\n即使这样，依然存在延迟问题：假设40ms到80ms之间的50ms消息到来，消息就延迟了30ms，而且对于半个小时来一次的消息，这些开销就是白白浪费的。\n\n在阿里的RocketMq里，有一种优化的做法-长轮询，来平衡推拉模型各自的缺点。基本思路是:消费者如果尝试拉取失败，不是直接return,而是把连接挂在那里wait,服务端如果有新的消息到来，把连接notify起来，这也是不错的思路。但海量的长连接block对系统的开销还是不容小觑的，还是要合理的评估时间间隔，给wait加一个时间上限比较好~\n\n### 顺序消息\n\n如果push模式的消息队列，支持分区，单分区只支持一个消费者消费，并且消费者只有确认一个消息消费后才能push送另外一个消息，还要发送者保证全局顺序唯一，听起来也能做顺序消息，但成本太高了，尤其是必须每个消息消费确认后才能发下一条消息，这对于本身堆积能力和慢消费就是瓶颈的push模式的消息队列，简直是一场灾难。\n\n反观pull模式，如果想做到全局顺序消息，就相对容易很多：\n\n1.  producer对应partition，并且单线程。\n2.  consumer对应partition，消费确认（或批量确认），继续消费即可。\n\n所以对于日志push送这种最好全局有序，但允许出现小误差的场景，pull模式非常合适。如果你不想看到通篇乱套的日志~~\n\nAnyway，需要顺序消息的场景还是比较有限的而且成本太高，请慎重考虑。\n\n# 总结\n\n本文从为何使用消息队列开始讲起，然后主要介绍了如何从零开始设计一个消息队列，包括RPC、事务、最终一致性、广播、消息确认等关键问题。并对消息队列的push、pull模型做了简要分析，最后从批量和异步角度，分析了消息队列性能优化的思路。下篇会着重介绍一些高级话题，如存储系统的设计、流控和错峰的设计、公平调度等。希望通过这些，让大家对消息队列有个提纲挈领的整体认识，并给自主开发消息队列提供思路。另外，本文主要是源自自己在开发消息队列中的思考和读源码时的体会，比较不&quot;官方&quot;，也难免会存在一些漏洞，欢迎大家多多交流。\n\n后续我们还会推出消息队列设计高级篇，内容会涵盖以下方面：\n\n> *   pull模型消息系统设计理念\n> *   存储子系统设计\n> *   流量控制\n> *   公平调度\n\n敬请期待哦~\n\n---\n\n* 原文链接：[消息队列设计精要](http://succinct.cs.berkeley.edu/wp/wordpress/?page_id=127)\n","tags":["MQ"],"categories":["MQ"]},{"title":"深入理解 Spring 事务原理","url":"%2F2016%2F2016-06-30-spring-transactions%2F","content":"\n## 一、事务的基本原理\n\nSpring事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，spring是无法提供事务功能的。对于纯JDBC操作数据库，想要用到事务，可以按照以下步骤进行：\n\n1.  获取连接 Connection con = DriverManager.getConnection()\n2.  开启事务 con.setAutoCommit(true/false);\n3.  执行 CRUD\n4.  提交事务/回滚事务 con.commit() / con.rollback();\n5.  关闭连接 conn.close();\n\n使用 Spring 的事务管理功能后，我们可以不再写步骤 2 和 4 的代码，而是由 Spirng 自动完成。 那么 Spring 是如何在我们书写的 CRUD 之前和之后开启事务和关闭事务的呢？解决这个问题，也就可以从整体上理解 Spring 的事务管理实现原理了。下面简单地介绍下，注解方式为例子：\n\n1.  配置文件开启注解驱动，在相关的类和方法上通过注解@Transactional标识。\n2.  spring 在启动的时候会去解析生成相关的bean，这时候会查看拥有相关注解的类和方法，并且为这些类和方法生成代理，并根据@Transaction的相关参数进行相关配置注入，这样就在代理中为我们把相关的事务处理掉了（开启正常提交事务，异常回滚事务）。\n3.  真正的数据库层的事务提交和回滚是通过binlog或者redo log实现的。\n\n## 二、Spring 事务的传播属性\n\n所谓spring事务的传播属性，就是定义在存在多个事务同时存在的时候，spring应该如何处理这些事务的行为。这些属性在TransactionDefinition中定义，具体常量的解释见下表：\n\n| 常量名称 | 常量解释 |\n| ------- | ------- |\n| PROPAGATION_REQUIRED | 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择，也是 Spring 默认的事务的传播。 |\n| PROPAGATION_REQUIRES_NEW | 新建事务，如果当前存在事务，把当前事务挂起。新建的事务将和被挂起的事务没有任何关系，是两个独立的事务，外层事务失败回滚之后，不能回滚内层事务执行的结果，内层事务失败抛出异常，外层事务捕获，也可以不处理回滚操作。 |\n| PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 |\n| PROPAGATION_MANDATORY | 支持当前事务，如果当前没有事务，就抛出异常。 |\n| PROPAGATION_NOT_SUPPORTED | 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 |\n| PROPAGATION_NEVER | 以非事务方式执行，如果当前存在事务，则抛出异常。 |\n| PROPAGATION_NESTED | 如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务，则按REQUIRED属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager事务管理器起效。 |\n\n## 三、数据库隔离级别\n\n| 隔离级别 | 隔离级别的值 | 导致的问题 |\n| ------- | ---------- | --------- |\n| Read-Uncommitted | 0 | 导致脏读 |\n| Read-Committed | 1 | 避免脏读，允许不可重复读和幻读 |\n| Repeatable-Read | 2 | 避免脏读，不可重复读，允许幻读 |\n| Serializable | 3 | 串行化读，事务只能一个一个执行，避免了脏读、不可重复读、幻读。执行效率慢，使用时慎重 |\n\n脏读：一事务对数据进行了增删改，但未提交，另一事务可以读取到未提交的数据。如果第一个事务这时候回滚了，那么第二个事务就读到了脏数据。\n\n不可重复读：一个事务中发生了两次读操作，第一次读操作和第二次操作之间，另外一个事务对数据进行了修改，这时候两次读取的数据是不一致的。\n\n幻读：第一个事务对一定范围的数据进行批量修改，第二个事务在这个范围增加一条数据，这时候第一个事务就会丢失对新增数据的修改。\n\n**总结：**\n\n隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。\n\n大多数的数据库默认隔离级别为 Read Commited，比如 SqlServer、Oracle\n\n少数数据库默认隔离级别为：Repeatable Read 比如： MySQL InnoDB\n\n## 四、Spring中的隔离级别\n\n| 常量 | 解释 |\n| --- | --- |\n| ISOLATION_DEFAULT | 这是个 PlatfromTransactionManager 默认的隔离级别，使用数据库默认的事务隔离级别。另外四个与 JDBC 的隔离级别相对应。 |\n| ISOLATION_READ_UNCOMMITTED | 这是事务最低的隔离级别，它充许另外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻像读。 |\n| ISOLATION_READ_COMMITTED | 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。 |\n| ISOLATION_REPEATABLE_READ | 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读。 |\n| ISOLATION_SERIALIZABLE | 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。 |\n\n## 五、事务的嵌套\n\n通过上面的理论知识的铺垫，我们大致知道了数据库事务和spring事务的一些属性和特点，接下来我们通过分析一些嵌套事务的场景，来深入理解spring事务传播的机制。\n\n假设外层事务 Service A 的 Method A() 调用 内层Service B 的 Method B()\n\n**PROPAGATION_REQUIRED(spring 默认)**\n\n如果ServiceB.methodB() 的事务级别定义为 PROPAGATION_REQUIRED，那么执行 ServiceA.methodA() 的时候spring已经起了事务，这时调用 ServiceB.methodB()，ServiceB.methodB() 看到自己已经运行在 ServiceA.methodA() 的事务内部，就不再起新的事务。\n\n假如 ServiceB.methodB() 运行的时候发现自己没有在事务中，他就会为自己分配一个事务。\n\n这样，在 ServiceA.methodA() 或者在 ServiceB.methodB() 内的任何地方出现异常，事务都会被回滚。\n\n**PROPAGATION_REQUIRES_NEW**\n\n比如我们设计 ServiceA.methodA() 的事务级别为 PROPAGATION_REQUIRED，ServiceB.methodB() 的事务级别为 PROPAGATION_REQUIRES_NEW。\n\n那么当执行到 ServiceB.methodB() 的时候，ServiceA.methodA() 所在的事务就会挂起，ServiceB.methodB() 会起一个新的事务，等待 ServiceB.methodB() 的事务完成以后，它才继续执行。\n\n他与 PROPAGATION_REQUIRED 的事务区别在于事务的回滚程度了。因为 ServiceB.methodB() 是新起一个事务，那么就是存在两个不同的事务。如果 ServiceB.methodB() 已经提交，那么 ServiceA.methodA() 失败回滚，ServiceB.methodB() 是不会回滚的。如果 ServiceB.methodB() 失败回滚，如果他抛出的异常被 ServiceA.methodA() 捕获，ServiceA.methodA() 事务仍然可能提交(主要看B抛出的异常是不是A会回滚的异常)。\n\n**PROPAGATION_SUPPORTS**\n\n假设ServiceB.methodB() 的事务级别为 PROPAGATION_SUPPORTS，那么当执行到ServiceB.methodB()时，如果发现ServiceA.methodA()已经开启了一个事务，则加入当前的事务，如果发现ServiceA.methodA()没有开启事务，则自己也不开启事务。这种时候，内部方法的事务性完全依赖于最外层的事务。\n\n**PROPAGATION_NESTED**\n\n现在的情况就变得比较复杂了, ServiceB.methodB() 的事务属性被配置为 PROPAGATION_NESTED, 此时两者之间又将如何协作呢? ServiceB#methodB 如果 rollback, 那么内部事务(即 ServiceB#methodB) 将回滚到它执行前的 SavePoint 而外部事务(即 ServiceA#methodA) 可以有以下两种处理方式:\n\na、捕获异常，执行异常分支逻辑\n\n```java\nvoid methodA() { \n        try { \n            ServiceB.methodB(); \n        } catch (SomeException) { \n            // 执行其他业务, 如 ServiceC.methodC(); \n        } \n    }\n```\n\n这种方式也是嵌套事务最有价值的地方, 它起到了分支执行的效果, 如果 ServiceB.methodB 失败, 那么执行 ServiceC.methodC(), 而 ServiceB.methodB 已经回滚到它执行之前的 SavePoint, 所以不会产生脏数据(相当于此方法从未执行过), 这种特性可以用在某些特殊的业务中, 而 PROPAGATION_REQUIRED 和 PROPAGATION_REQUIRES_NEW 都没有办法做到这一点。\n\nb、 外部事务回滚/提交 代码不做任何修改, 那么如果内部事务(ServiceB#methodB) rollback, 那么首先 ServiceB.methodB 回滚到它执行之前的 SavePoint(在任何情况下都会如此), 外部事务(即 ServiceA#methodA) 将根据具体的配置决定自己是 commit 还是 rollback\n\n另外三种事务传播属性基本用不到，在此不做分析。\n\n## 六、总结\n\n对于项目中需要使用到事务的地方，我建议开发者还是使用spring的TransactionCallback接口来实现事务，不要盲目使用spring事务注解，如果一定要使用注解，那么一定要对spring事务的传播机制和隔离级别有个详细的了解，否则很可能发生意想不到的效果。\n\n---\n\n* Author: 吴极心\n* Source: [码农网](http://www.codeceo.com)\n* Link: [深入理解 Spring 事务原理](http://www.codeceo.com/article/spring-transactions.html)\n","tags":["Transactions"],"categories":["Spring"]},{"title":"基于HBase的海量GIS数据分布式处理实践","url":"%2F2016%2F2016-05-31-distributed-processing-practice-of-the-massive-gis-data-based-on-hbase%2F","content":"\n### *Distributed processing practice of the massive GIS data based on HBase*\n\n李雪梅1，邢俊峰1，刘大伟1，王海洋1,2，刘玮1,2\n\n*LI Xuemei1, XING Junfeng1, LIU Dawei1, WANG Haiyang1,2, LIU Wei1,2*\n\n1.烟台中科网络技术研究所，山东 烟台 264003；\n\n*1.Institute of Network Technology, ICT(YANTAI), Yantai 264003, China*\n\n2.中国科学院计算技术研究所，北京 100080\n\n*2.Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100080, China*\n\n**摘要** 设计了一种基于分布式数据库HBase的GIS数据管理系统。系统优化了栅格数据的生成和存储过程，将海量 栅格数据直接写入HBase存储、索引。同时，针对矢量空间数据的存储、索引与检索，提出了一种新的rowkey 设计，既考虑经纬度，又考虑空间数据类型和属性，使得在按空间位置检索矢量地理信息时，能通过HBase的 rowkey迅速定位需要返回的数据。在HBase的集群环境上用真实GIS数据对上述方法进行了验证，结果表明， 提出的系统具有较高的海量数据存储和检索性能，实现了海量地理信息数据的高效存储和实时高速检索。\t\n\n*__Abstract__：Based on the distributed database HBase, a kind of GIS data management system was designed. The system optimized the generated and stored procedures of raster data, which could be directly written into the storage and indexing of the HBase. At the same time, in view of the storing, indexing and retrieval of the vector spatial data, a new design for rowkey was proposed that considering both the latitude and longitude, and the spatial data types and attributes. So that the data needed to be returned could be quickly located by rowkey of the HBase, when retrieving vector geographic information according to the spatial location. The above methods had been verified on the HBase cluster environment with real GIS data. The results show that the proposed system has high performance for storage and retrieval of mass data, and realizes the efficient storage and real-time high-speed retrieval of the vast geographic information data.*\n\n**关键词**: 大数据, HBase, 栅格数据, 矢量数据, rowkey \n\n*__Key words__： big data; HBase; raster data; \tvector data; rowkey*\n\n### 资源\n\n[基于HBase的海量GIS数据分布式处理实践.pdf](/assets/images/2016/05/31/distributed-processing-practice-of-the-massive-gis-data-based-on-hbase/基于HBase的海量GIS数据分布式处理实践.pdf)\n\n---\n\n* 原文链接：[基于HBase的海量GIS数据分布式处理实践](http://www.j-bigdataresearch.com.cn/CN/10.11959/j.issn.2096-0271.2016032)\n","tags":["GIS"],"categories":["HBase"]},{"title":"Java 性能测试的四项原则","url":"%2F2016%2F2016-05-23-java-performance-testing%2F","content":"\n## 引言\n\n计算机软件作为人类智慧的结晶，帮助我们在这个日新月异的社会中完成了大量工作。我们的日常生活中已经离不开软件，玲琅满目的软件已经渗透到了我们生活的各个角落，令我们目不暇接。我们都希望软件变得更好，运行处理的速度更快，在当今硬件性能突飞猛进的变革中，软件性能的提升也是一个永不落伍的话题。软件性能测试的实质，是从哲学的角度看问题，找出其内在联系，因果关系，形式内容关系，重叠关系等等。假如这些关系我们在分析过程中理清了，那么性能测试问题就会变得迎刃而解。\n\n在软件开发过程中，性能测试往往在开发前期容易被忽略。直到有一天问题暴露后，开发人员被迫的直面这个问题，大多数情况下，这是令开发人员感觉到非常痛苦事情。所以在软件开发前期以及开发过程中性能测试的考量是必要的，那么具备相应理论知识和实践方法也是一个优秀工程师所应当具备的素养，这里我们概括有四项原则，这些原则可以帮助开发人员丰富、充实测试理论，系统的开展性能测试工作，从而获得更有价值的结果。\n\n## 实际项目中的性能测试才有意义\n\n第一个原则就是性能测试只有在实际项目中实施才是有意义的，这样才使得测试工作具有针对性，而且目标会更加明确。这个原则中有三个类别的基准可以指导开发人员度量性能测试的结果，但是每一种方法都有它的优点和劣势，我们将结合实际例子，来总结阐述。\n\n* 微观基准，可以理解为在某一个方法或某一个组件中进行的单元性能测试。比如检测一个线程同步和一个非线程同步的方法运行时所需要的时间。或者对比创建一个单独线程和使用一个线程池的性能开销。或者对比执行一个算法中的某一个迭代过程所需要的时间。当我们遇到这些情况时，我们常常会选择做一个方法层面的性能测试。这些情况的性能测试，都可以尝试使用微观基准的方法进行性能测试。微观基准看似编写起来简单快捷，但是编写能够准确反映性能问题的代码并非一件易事。接下来通过例子让我们从代码中发现一些问题。这是一个单线程的程序片段，通过计算 50 次循环迭代来检测执行方法所耗费的时间体现性能差异：\n\n```java\npublic void doTest() {\n double l;\n long then = System.currentTimeMillis();\n int nLoops = 50;\n for (int i = 0; i < nLoops; i++) {\n l = compute(50);\n }\n long now = System.currentTimeMillis();\n System.out.println(\"Elapsed time:\" + (now - then));\n }\n\n private double compute(int n){\n if (n < 0)\n throw new IllegalArgumentException(\"Must be > 0\");\n if (n == 0)\n return 0d;\n if (n == 1)\n return 1d;\n double d = compute(n - 2) + compute(n - 1);\n if (Double.isInfinite(d))\n throw new ArithmeticException(\"Overflow\");\n return d;\n}\n```\n执行这段代码我们会发现一个问题，那就是执行时间只有短短的几秒。难道果真是程序性能很高？答案并非如此，其实在整个执行过程中 compute 计算方法并没有调用而是被编译器自动忽略了。那么解决这个问题的办法是将 double 类型的“l”换成 volatile 实例变量。这样能够确保每一个计算后所得到的结果是可以被记录下来，用 volatile 修饰的变量，线程在每次使用变量的时候，都会读取变量修改后的最后的值。\n\n要特别值得注意的是，当考虑为多线程写一个微基准性能测试用例时，假如几个线程同时执行一小段业务逻辑代码，这可能会引发潜在的线程同步所带来的性能开销和瓶颈。此时微观微基准测试的结果往往引导开发人员为了保持同步进行不断的优化，这样会浪费很多时间，对于解决更紧迫的性能问题，这样做就显得得不偿失。\n\n我们再试想这样一个例子，微基准测试两个线程调用同步方法的情况，因为基准代码很小，那么测试用例大部分时间将消耗在同步过程中。即使微基准测试在整体的同步过程中只占 50%，那么两个线程尝试执行同步方法的几率也是相当高的。基准运行将会非常缓慢，添加额外的线程会造成更大的性能问题。\n\n基于微观基准的测试过程中，是不能含有额外的对性能产生影响的操作，我们知道执行 compute(1000) 和 compute(1) 在性能上是有很大差异的，假如我们的目标是对比两个不同实现方法之间的性能差异，那么就应当考虑一系列的输入测试值作为前提，传递给测试目标，参数就需要多样化。这里以我们的经验解决的办法就是使用随机值：\n\n```java\nfor (int i = 0; i < nLoops; i++) {\n l = compute(random.nextInt());\n }\n```\n\n现在，产生随机数的时间也包含在了整个循环执行过程中，因此测试结果中包含了随机数生成所需要的时间，这并不能客观的体现 compute 方法真实的性能。所以在构建微观基准时，输入的测试值必须是预先准备好的，且不会对性能测试产生额外的影响。正确的做法如下：\n\n```java\npublic void doTest() {\n double l;\n int nLoops = 10;\n Random random = new Random();\n int[] input = new int[nLoops];\n for (int i = 0; i < nLoops; i++) {\n input[i] = random.nextInt();\n }\n long then = System.currentTimeMillis();\n for (int i = 0; i < nLoops; i++) {\n try {\n l = compute(input[i]);\n } catch (IllegalArgumentException iae) {\n\n }\n\n }\n long now = System.currentTimeMillis();\n System.out.println(\"Elapsed time:\" + (now - then));\n}\n```\n\n微观基准中输入的测试值必须是符合业务逻辑的。所有的输入的值并不一定会被代码用到，实际的业务可能对输入的数据有特定的要求，不合理的输入值可能导致代码在执行过程中就抛出异常而中断，从而使得我们难以判断代码执行的效率。所以在准备测试数据的时候应当考虑到输入数据的有效性，保证代码执行的完整性。比如下面的例子输入的参数如果是大于 1476 ，执行会立即中断，从而影响了真实性能结果的产生。\n\n```java\npublic double ImplSlow(int n) {\n if (n < 0) throw new IllegalArgumentException(\"Must be > 0\");\n if (n > 1476) throw new ArithmeticException(\"Must be < 1476\");\n return verySlowImpl(n);\n}\n```\n\n通常情况下，对参与到实际业务计算的值提前检测对提升性能是有帮助的，但是假如用户大多数输入的值是合理的，那么提前检查数据的有效性就显得冗余了。所以编写核心逻辑代码的时候，我们建议只针对一般情况做处理，保证执行的效率的高效性。假设访问一个 collection 对象时，每一次能够节省几毫秒的话，那么在多次的访问情况下就会对性能的提升产生重大的意义。\n\n```java\npublic class Test1 {\n\n private volatile double l;\n private int nLoops;\n private int[] input;\n \n \n private Test1(int n) {\n nLoops = n;\n input = new int[nLoops];\n Random random = new Random();\n for (int i = 0; i < nLoops; i++) {\n input[i] = random.nextInt(50);\n }\n }\n\n public void doTest(boolean isWarmup) {\n long then = System.currentTimeMillis();\n\n for (int i = 0; i < nLoops; i++) {\n try {\n l = compute(input[i]);\n } catch (IllegalArgumentException iae) {\n }\n if (!isWarmup) {\n long now = System.currentTimeMillis();\n System.out.println(\"Elapsed time:\" + (now - then));\n }\n }\n\n }\n\n private double compute(int n) {\n if (n < 0)\n throw new IllegalArgumentException(\"Must be > 0\");\n if (n == 0)\n return 0d;\n if (n == 1)\n return 1d;\n double d = compute(n - 2) + compute(n - 1);\n if (Double.isInfinite(d))\n throw new ArithmeticException(\"Overflow\");\n return d;\n }\n\n public static void main(String[] args) {\n // TODO Auto-generated method stub\n Test1 test1 = new Test1(Integer.parseInt(\"10\");));\n test1.doTest(true);\n test1.doTest(false);\n }\n\n}\n```\n\n总得说来，微观基准作用是有限的，在频繁调用的方法中使用微观基准的度量方法会帮助我们检测代码的性能，如果用在不会被频繁调用的方法中是不合适的，应当考虑其它方法。\n\n* 宏观基准，当我们测量应用程序性能时，应当纵览整个系统，影响应用程序性能的原因可能是多方面的，不能片面的认为性能瓶颈只会在程序本身上。通过下面这个例子我们将探讨离开宏观基准的性能测试是不可能找到影响应用程序性能真正的瓶颈。\n\n![](/assets/images/2016/05/23/java-performance-testing/img001.png)\n\n上图数据来自客户实体，触发应用程序的核心业务计算方法，该方法从数据库加载数据，并传导给核心业务中的计算方法，得到结果保存到数据库，最终响应客户的请求。每个图形中的数字分别代表了这个模块所能处理客户请求的数量。核心业务模块的优化多数情况是受限于业务的要求。假设我们优化这些核心模块，使其可以处理 200 RPS 时，我们发现加载数据的模块依然只能处理 100 RPS，也就是说整个系统的吞吐能力其实仍然为 100 RPS，最终对应用程序整体的性能提升是没有任何帮助的。从这个例子我们得知，我们花费再多的精力在核心业务上的优化意义并不大，我们应当从整体运行情况来看，发现真正影响性能的瓶颈来解决问题，这就是宏观基准原则的意义。\n\n* 折衷基准，相比微观基准和宏观基准，一个单独功能模块的性能测试，或者一系列特定操作的性能测试被称为折衷基准。它是介于微观基准和宏观基准之间的折衷方案。基于微观基准测试的正确性是较难把握的，性能瓶颈的判断绝不能仅仅依赖于此。如果我们要使用微观基准作为性能的测量方法，那么不妨在此之前先尝试基于宏观基准的测试。它可以帮助我们了解系统以及代码是如何工作的，从而形成一个系统整体逻辑结构图。接下来可以考虑基于折衷基准的测试，来真正发现潜在的性能瓶颈。需要明确的是折衷基准的测试方法并不是完整应用程序测试的替代方法，更多情况下我们认为它更适用于一个功能模块的自动测试。\n\n## 批量，吞吐量和响应时间的测量方法\n\n性能测试中的第二个重要的原则是引入多样的测量方法来分析程序的性能。\n\n* 批量执行所用时间的测量方法（耗时法），这是种简单而快速有效的方法，通过测量完成特定任务所消耗的时间来测量整体性能。但是需要特别注意，假如所测试的应用程序中使用缓存数据技术来为了获得更好的性能表现时，多次循环使用该方法可能无法完全反应性能问题。那么可以尝试在初始状态开始时应用耗时法做一次性能的评估，然后当缓存建立后，再次尝试此方法。\n\n* 吞吐量的测量方法，在一段时间内考察完成任务的数量的能力，被称为吞吐量测量方法。在测试客户服务器的应用程序时，吞吐量的测量意味着客户端发送请求到服务器是没有任何延迟的，当客户端接收到响应后，应当立即发出新的请求，直到最终结束，统计客户端完成任务的总数。这种相对理想的测试方法通常称之为“Zero-think-time”。可是通常情况下，客户端可能会有多个线程做同一件事情，吞吐量则意味着每秒钟内所有客户端的操作数，而不是测量的某一个时段内的所有操作总数。这种测量经常称为每秒事务/(TPS)，每秒请求 (RPS)，或每秒操作数 (OPS)。\n\n测试所有基于客户端和服务器端应用程序都存在一种风险，客户端不能以足够快的速度发送数据到服务器端，这种情况的发生可能是由于客户端此时没有足够的 CPU 资源去运行需要数量的线程，或者客户端必须耗用更长的时间来处理当前的请求。这种情况下，实际上测量的是客户端的性能，而非服务器的性能，与吞吐量测量方法是背道而驰的。其实这种风险是由每个客户端线程处理任务的数量和硬件配置决定的。“Zero-think-time”在吞吐量测试中可能经常会遇见以上的情况，由于每个客户端线程都需要处理大量的任务，因此吞吐量测试通常被应用于较少的客户端线程程序。吞吐量测量方法也同样适应用于带有缓存技术的应用程序，尤其是当测试的数据是一个并不固定的情况下。\n\n* 响应时间的测量方法，响应时间的测量方法是指客户端发出一个请求后直到接收到服务器的响应返回后的时间消耗。响应时间测量方法不同于吞吐量测量方法，在响应时间测试过程中，客户端线程可能会在操作的过程中某一时刻休眠，这就引出“think- time”这个关键词，当“think- time”被引入到测试过程中，也就是意味着待处理任务量是固定的，测量的是服务器响应请求的速率是怎样的。大多数情况下，响应时间的测量方法用来模拟用户真实操作，从而测量应用程序的性能。\n\n## 多变性\n\n性能测试的第三个原则是理解测试结果如何随时间改变，即使每一次测试使用同样的数据，可能获得的结果也是不同的。一些客观因素，比如后台运行的进程，网络的负载情况，这些都可能带来测试结果的不同，所以在测试过程中存在着一些随机性的因素。这就产生了一个问题： 当比较两次运行得到的测试结果时，它们之间的差异是由回归测试产生的，还是是随机变化而导致的呢？\n\n我们不能简单的通过测量多次运行回归测试的平均结果来评判性能的差异。这时我们可以使用统计分析的方法，假设两种情况的平均值是一样的，然后通过概率来判断这样的假设是成立的。如果假设不成立，那么就说明有很高的概率证明平均数存在差异。\n\n在回归测试中原始代码被视为基线，新增加的代码称为样本。三次运行基线和样本，产生时间如表 1：\n\n**表 1. 三次运行基线和样本结果**\n| 次数 | 基准 | 样本 |\n| ---- | ---- | ---- |\n| 1 | 1.0 | 0.5 |\n| 2 | 0.8 | 1.25 |\n| 3 | 1.2 | 0.5 |\n| 平均 | 1 | 0.75 |\n\n看起来样本的平均值显示有 25%的提升，可事实证明样本和基线有相同性能的概率是 43%。也就是说 57%的概率存在性能上的不同。43%是基于 T 检验所得到的结果，T 检验主要用于样本含量较小（例如 n<30），总体标准差σ未知的正态分布资料。t 检验是用 t 分布理论来推论差异发生的概率，从而比较两个平均数的差异是否显著。它与 z 检验、卡方检验并列。现在的 T 检验结果告诉我们这样一个信息:：57%概率显示样本和基线存在性能差异，差异最大值是 25%。也可以理解为性能差有 57%的置信度向理想发现发展，结果有 25%的改善。\n\n在考量回归测试的结果时，离开了统计分析的方法，而只关注平均值来做出判断，含糊的理解这些数字的含义是不可取的。性能工程师的工作是看数据，理解这些概率，基于所有可用的数据确定在何处花时间。\n\n## 尽早测试，经常测试\n\n第四个原则就是工程师应该视性能测试是整个开发过程必要的部分，尽早进行性能测试，经常进行性能的测试，是一个好的工程师应该做到的。在代码提交到代码库之前，就应当做性能测试，因为性能问题也会导致回归测试失败。所以提早发现问题会提高整个项目的质量，减小交付的风险性。\n\n在一个典型的项目开发周期过程中，项目计划常常是建立一个功能提交的时间表，所有功能的开发必须要在某一个时间点全部提交到代码库中，在项目发布之前，所有的精力都致力于解决功能上的 Bug，那么很有可能在这个过程中发现性能问题，这会导致两个问题产生：\n\n* 开发人员在时间的约束下不得不提交代码以满足时间表，一旦发现出严重的性能问题他们会非常畏惧，所以开发人员在测试开始的早期解决性能问题能够产生 1%的回归测试代价，而如果开发人员一直在等待晚上的冻结功能开发的时候才开始检查代码将会导致 20%的回归测试的代价。\n* 任何为解决性能做出的修改都有可能带来巨大的成本，有时不仅仅是代码的修改，更有可能是软件架构的修改。所以最好在软件设计之时就充分的考虑到未来可能带来的性能问题。\n\n尽早测试性能有以下四点可作为指导：\n\n* 提早准备测试用户以及测试环境的设计和创建；\n* 性能测试应该考虑尽量用脚本来完成；\n* 通过性能监控工具尽量收集有可能得到的运行信息，为将来分析提供便利；\n* 一定要在一个能真实模拟多数用户的机器环境下进行性能测试。\n\n## 总结\n\n最后，基于我们讲过的方法作为基础，构建一个自动化的测试系统来收集测试过程中产生的各种信息，能够很好的帮助我们分析发现性能瓶颈。\n\n---\n\n* Author: 李伟军，杨翔宇，宋翰瀛\n* Source: [IBM Developerworks](https://www.ibm.com/developerworks/cn/)\n* Link: [Java 性能测试的四项原则](https://www.ibm.com/developerworks/cn/java/j-lo-java-performance-testing/index.html)","tags":["Test"],"categories":["Java"]},{"title":"Evaluation of Deep Learning Toolkits","url":"%2F2016%2F2016-05-12-evaluation-deep-learning-toolkits%2F","content":"\n**Abstract.** In this study, I evaluate some popular deep learning toolkits. The candidates are listed in alphabetical order: [Caffe](https://github.com/BVLC/caffe), [CNTK](https://cntk.codeplex.com/), [TensorFlow](https://github.com/tensorflow/tensorflow), [Theano](https://github.com/Theano/Theano), and [Torch](https://github.com/torch/torch7). This is a dynamic document and the evaluation, to the best of my knowledge, is based on the current state of their code.\n\nI also provide ratings in some areas because for a lot of people, ratings are useful. However, keep in mind that ratings are inherently subjective [1].\n\nIf you find something wrong or inadequate, please help improve by filing an issue.\n\n**Table of contents**\n\n1. [Modeling Capability](#modeling-capability)\n- [Interfaces](#interfaces)\n- [Model Deployment](#model-deployment)\n- [Performance](#performance)\n- [Architecture](#architecture)\n- [Ecosystem](#ecosystem)\n- [Cross-platform](#cross-platform) \n\n___\n\n## Modeling Capability\nIn this section, we evaluate each toolkit's ability to train common and state-of-the-art networks <u>without writing too much code</u>. Some of these networks are:\n\n- ConvNets: AlexNet, OxfordNet, GoogleNet\n- RecurrentNets: plain RNN, LSTM/GRU, bidirectional RNN\n- Sequential modeling with attention.\n\nIn addition, we also evaluate the flexibility to create a new type of model.\n\n#### Caffe <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_3_stars.png\">\nCaffe is perhaps the first mainstream industry-grade deep learning toolkit, started in late 2013, due to its excellent convnet implementation (at the time). It is still the most popular toolkit within the computer vision community, with many extensions being actively added. \n\nHowever, its support for recurrent networks and language modeling in general is poor, due to its legacy architecture, which's limitations are detailed in the [architecture section](#architecture).\n\n#### CNTK <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_2_stars.png\">\nCNTK is a deep learning system started by the speech people who [started the deep learning craze](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.185.1908&rep=rep1&type=pdf) and grown into a more general platform-independent deep learning system. It is better known in the speech community than in the general deep learning community.\n\nIn CNTK (as in TensorFlow and Theano), a network is specified as a symbolic graph of vector operations, such as matrix add/multiply or convolution. A layer is just a composition of those operations. The fine granularity of the building blocks (operations) allows users to invent new complex layer types without implementing them in a low-level language (as in Caffe).\n\nAs of today, CNTK is not usable for a variety of tasks such as sequence-2-sequence.\n\n\n#### TensorFlow <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_4_and_a_half_stars.png\">\n**State-of-the-art models**\n\n- RNN API and implementation are suboptimal. The team also commented about it [here](https://github.com/tensorflow/tensorflow/issues/7) and [here](https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!msg/discuss/B8HyI0tVtPY/aR43OIuUAwAJ).\n- Bidirectional RNN [not available yet](https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!msg/discuss/lwgaL7WEuW4/UXaL4bYkAgAJ)\n- No 3D convolution, which is useful for video recognition\n\n**New models**\nSince TF uses symbolic graph of vector operations approach, specifying a new network is fairly easy. Although it doesn't support symbolic loop yet (at least not well tested/documented, as of 05/2016), RNNs can be made easy and efficient using the [bucketing trick](https://www.tensorflow.org/versions/r0.8/tutorials/seq2seq/index.html#bucketing-and-padding).\n\nHowever, TF has a major weakness in terms of modeling flexibility. Every computational flow has be constructed as a static graph. That makes some computations difficult, such as [beam search](https://github.com/tensorflow/tensorflow/issues/654) (which is used frequently in sequence prediction tasks). \n\n\n#### Theano <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_4_and_a_half_stars.png\">\n**State-of-the-art models.** Theano has implementation for most state-of-the-art networks, either in the form of a higher-level framework (e.g. [Blocks](https://github.com/mila-udem/blocks), [Keras](https://github.com/fchollet/keras), etc.) or in pure Theano.\n\n**New models.** Theano pioneered the trend of using symbolic graph for programming a network. Theano's symbolic API supports looping control, so-called [scan](http://deeplearning.net/software/theano/tutorial/loop.html), which makes implementing RNNs easy and efficient. Users don't always have to define a new model at the tensor operations level. There are a few higher-level frameworks, mentioned above, which make model definition and training simpler.\n\n#### Torch <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_5_stars.png\">\n**State-of-the-art models**\n\n- Excellent for conv nets. It's worth noting that temporal convolution can be done in TensorFlow/Theano via `conv2d` but that's a trick. The native interface for temporal convolution  in Torch makes it slightly more intuitive to use. \n- Rich set of RNNs available through a [non-official extension](https://github.com/Element-Research/rnn) [2]\n\n**New models.** In Torch, there are multiple ways (stack of layers or graph of layers) to define a network but essentially, a network is defined as a graph of layers. Because of this coarser granularity, Torch is sometimes considered less flexible because for new layer types, users have to implement the full forward, backward, and gradient input update.\n\nHowever, unlike Caffe, defining a new layer in Torch is much easier because you don't have to program in C++. Plus, in Torch, the difference between new layer definition and network definition is minimal. In Caffe, layers are defined in C++ while networks are defined via `Protobuf`.\n\nTorch is more flexible than TensorFlow and Theano in that it is imperative while TF/Theano are declarative (i.e. one has to declare a computational graph). That makes some operations, e.g. beam search, much easier to do in Torch.\n\n---\n<center>\n<img src=\"http://i.snag.gy/0loNv.jpg\" height=\"450\">  <img src=\"https://camo.githubusercontent.com/49ac7d0f42e99d979c80a10d0ffd125f4b3df0ea/68747470733a2f2f7261772e6769746875622e636f6d2f6b6f7261796b762f746f7263682d6e6e67726170682f6d61737465722f646f632f6d6c70335f666f72776172642e706e67\" height=\"450\"><br>\n<i>Left: graph model of CNTK/Theano/TensorFlow; Right: graph model of Caffe/Torch</i>\n</center>\n\n\n## Interfaces\n\n#### Caffe <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_3_stars.png\">\nCaffe has `pycaffe` interface but that's a mere secondary alternative to the command line interface. The model has to be defined in protobuf (usually with a plain text editor), even if you use `pycaffe`.\n\n#### CNTK <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_2_and_a_half_stars.png\">\nThe way to use CNTK, similar to Caffe, is to specify a config file and run command line. CNTK is slightly worse than Caffe because there's no Python or any other high-level language interface.\n\n\n#### TensorFlow <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_4_and_a_half_stars.png\">\nTF supports two interfaces: Python and C++. This means that you can do experiments in a rich, high-level environment and deploy your model in an environment that requires native code or low latency.  \n\nIt would be perfect if TF supports `F#` or `TypeScript`. The lack of static type in Python is just ... painful :).\n\n#### Theano <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_4_stars.png\">\nPython\n\n#### Torch <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_4_stars.png\">\nTorch runs on LuaJIT, which is amazingly fast (comparable with industrial languages such as C++/C#/Java). Hence developers don't have to think about symbolic programming, which can be limited. They can just write all kinds of computations without worrying about performance penalty.\n\nHowever, let's face it, Lua is not yet a mainstream language.\n\n## Model Deployment\nHow easy to deploy a new model?\n\n#### Caffe <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_5_stars.png\">\nCaffe is C++ based, which can be compiled on a variety of devices. It is cross-platform (windows port is available and maintained [here](https://github.com/MSRDL/caffe)). Which makes Caffe the best choice with respect deployment.\n\n#### CNTK <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_4_and_a_half_stars.png\">\nLike Caffe, CNTK is also C++ based and is cross-platform. Hence, deployment should be easy in most cases. However, to my understanding, it doesn't work on ARM architecture, which limits its its capability on mobile devices. \n\n#### TensorFlow <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_4_and_a_half_stars.png\">\nTF supports C++ interface and the library can be compiled/optimized on ARM architectures because it uses [Eigen](http://eigen.tuxfamily.org) (instead of a BLAS library). This means that you can deploy your trained models on a variety of devices (servers or mobile devices) without having to implement a separate model decoder or load Python/LuaJIT interpreter [3].\n\nTF doesn't work on Windows yet so TF models can't be deployed on Windows devices though.\n\n#### Theano <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_3_stars.png\">\nThe lack of low-level interface and the inefficiency of Python interpreter makes Theano less attractive for industrial users. For a large model, the overhead of Python isn’t too bad but the dogma is still there.\n\nThe cross-platform nature (mentioned below) enables a Theano model to be deployed in a Windows environment. Which helps it gain some points.\n\n#### Torch <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_3_stars.png\">\nTorch require LuaJIT to run models. This makes it less attractive than bare bone C++ support of Caffe/CNTK/TF. It’s not just the performance overhead, which is minimal. The bigger problem is integration, at API level, with a larger production pipeline.\n\n\n## Performance\n### Single-GPU\nAll of these toolkits call cuDNN so as long as there’s no major computations or memory allocations at the outer level, they should perform similarly.\n\nSoumith@FB has done some [benchmarking for ConvNets](https://github.com/soumith/convnet-benchmarks). Deep Learning is not just about feedforward convnets, not just about ImageNet, and certainly not just about a few passes over the network. However, Soumith’s benchmark is the only notable one as of today. So we will base the Single-GPU performance rating based on his benchmark.\n\n#### TensorFlow and Torch <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_5_stars.png\">\n\nTensorFlow used to be slow when it first came out but as of 05/2016, it has reached the ballpark of other frameworks in terms of ConvNet speed. This is not surprising because every framework nowadays calls CuDNN for the actual computations.\n\nHere's my latest micro benchmark of TensorFlow 0.8 vs before. The measurement is latency, in milliseconds, for one full minibatch forward-backward pass on a single Titan X GPU. \n\n| Network | TF 0.6 [[ref](https://github.com/soumith/convnet-benchmarks/blob/efb3d9321d14856f49951980dbea2f554190161a/README.md)]                                                                     | TF 0.8 [my run] | Torch FP32 [my run] |\n|:------------------------:|:-----------------------------------------------------------------------------------------------------------:| ----------:| ------------:|\n| AlexNet      | 292  | 97  |  81  |\n| Inception v1 | 1237 | 518 |  470 |\n\n\n#### Theano <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_3_stars.png\">\nOn big networks, Theano’s performance is on par with Torch7, according to [this benchmark](http://arxiv.org/pdf/1211.5590v1.pdf). The main issue of Theano is startup time, which is terrible, because Theano has to compile C/CUDA code to binary. We don’t always train big models. In fact, DL researchers often spend more time debugging than training big models. TensorFlow doesn’t have this problem. It simply maps the symbolic tensor operations to the already-compiled corresponding function calls.\n\nEven `import theano` takes time because this `import` apparently does a lot of stuffs. Also, after `import Theano`, you are stuck with a pre-configured device (e.g. `GPU0`).\n\n### Multi-GPU\nTBD \n\n## Architecture\nDeveloper Zone\n\n#### Caffe <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_3_stars.png\">\nCaffe's architecture was considered excellent when it was born but in the modern standard, it is considered average. The main pain points of Caffe are its layer-wise design in C++ and the protobuf interface for model definition.\n\n**Layer-wise design.** The building block of a network in Caffe is layer. \n- For new layer types, you have to define the full forward, backward, and gradient update. You can see an  already [long-list of layers implemented in (official) caffe](https://github.com/BVLC/caffe/tree/master/src/caffe/layers).\n- What's worse is that if you want to support both CPU and GPU, you need to implement extra functions, e.g. [`Forward_gpu` and `Backward_gpu`](https://github.com/BVLC/caffe/blob/master/src/caffe/layers/cudnn_conv_layer.cu).\n- Worse, you need to assign an int id to your layer type and add that to the [proto file](https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto#L1046). If your pull request is not merged early, you may need to change the id because someone else already claims that.\n\n**Protobuf.** Caffe has `pycaffe` interface but that's a mere replacement of the command line interface. The model has to be defined in protobuf (usually with a plain text editor), even if you use `pycaffe`.\n\n[*Copied from [my own answer on Quora](https://www.quora.com/How-is-TensorFlow-architected-differently-from-Caffe)*]\n \n### CNTK\nTo be updated ...\n\n#### TensorFlow <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_5_stars.png\">\nTF has a clean, modular architecture with multiple frontends and execution platforms. Details are in the [white paper](http://download.tensorflow.org/paper/whitepaper2015.pdf).\n\n<img src=\"http://i.snag.gy/sJlZe.jpg\" width=\"500\">\n\n#### Theano <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_3_stars.png\">\nThe architecture is fairly hacky: the whole code base is Python where C/CUDA code is packaged as Python string. This makes it hard to navigate, debug, refactor, and hence contribute as developers.\n\n#### Torch <img src=\"http://www.wpclipart.com/signs_symbol/stars/5_star_rating_system/.cache/5_Star_Rating_System_5_stars.png\">\nTorch7 and nn libraries are also well-designed with clean, modular interfaces.\n\n## Ecosystem\n- Caffe and CNTK: C++\n- TensorFlow: Python and C++\n- Theano: Python\n- Torch: Lua is not a mainstream language and hence libraries built for it are not as rich as ones built for Python.\n\n\n## Cross-platform\nCaffe, CNTK, and Theano work on all OSes. TensorFlow and Torch do not work on Windows and there's no known plan to port from either camp.\n\n<br>\n___ \n\n**Footnotes**\n\n[1] Note that I don’t aggregate ratings because different users/developers have different priorities.\n\n[2] Disclaimer: I haven’t analyzed this extension carefully.\n\n[3] See my [blog post](http://www.kentran.net/2014/12/challenges-in-machine-learning-practice.html) for why this is desirable.\n\n---\n\n* 原文链接：[Evaluation of Deep Learning Frameworks](https://github.com/zer0n/deepframeworks)\n","tags":["Toolkits"],"categories":["Deep-Learning"]},{"title":"Tuning G1GC For Your HBase Cluster","url":"%2F2016%2F2016-05-10-g1gc-tuning-your-hbase-cluster%2F","content":"\nHBase is the big data store of choice for engineering at HubSpot. It’s a complicated data store with a multitude of levers and knobs that can be adjusted to tune performance. We’ve put a lot of effort into optimizing the performance and stability of our HBase clusters, and recently discovered that suboptimal G1GC tuning was playing a big part in issues we were seeing, especially with stability.\n\nEach of our HBase clusters is made up of 6 to 40 AWS d2.8xlarge instances serving terabytes of data. Individual instances handle sustained loads over 50k ops/sec with peaks well beyond that. This post will cover the efforts undertaken to iron out G1GC-related performance issues in these clusters. If you haven't already, we suggest getting familiar with the [characteristics, quirks, and terminology of G1GC](http://product.hubspot.com/blog/g1gc-fundamentals-lessons-from-taming-garbage-collection) first.\n\nWe first discovered that G1GC might be a source of pain while investigating frequent\n\n```\n“...FSHLog: Slow sync cost: ### ms...”\n```\n\nmessages in our RegionServer logs. Their occurrence correlated very closely to GC pauses, so we dug further into RegionServer GC. We discovered three issues related to GC:\n\n* One cluster was losing nodes regularly due to long GC pauses.\n* The overall GC time was between 15-25% during peak hours.\n* Individual GC events were frequently above 500ms, with many over 1s.\n\nBelow are the 7 tuning iterations we tried in order to solve these issues, and how each one played out. As a result, we developed a step-by-step summary for tuning HBase clusters that you can find and follow here.\n\n### Original GC Tuning State\n\nThe original JVM tuning was based on [an Intel blog post](https://software.intel.com/en-us/blogs/2014/06/18/part-1-tuning-java-garbage-collection-for-hbase), and over time morphed into the following configuration just prior to our major tuning effort.\n\n| Xmx32g -Xms32g | 32 GB heap, initial and max should be the same |\n| XX:G1NewSizePercent= 3-9 | Minimum size for Eden each epoch, differs by cluster |\n| XX:MaxGCPauseMillis=50 | Optimistic target, most clusters take  100+ ms |\n| XX:-OmitStackTraceInFastThrow | Better stack traces in some circumstances, traded for a bit more  CPU usage |\n| XX:+ParallelRefProcEnabled | Helps keep a lid on [reference processing time](http://www.infoq.com/articles/tuning-tips-G1-GC) issues were were seeing |\n| XX:+PerfDisableSharedMem | Alleged to protect against [bizarre linux issue](http://www.evanjones.ca/jvm-mmap-pause.html) |\n| XX:-ResizePLAB | Alleged to save some CPU cycles in between GC epochs |\n\nGC logging verbosity as shown below was cranked up to a high enough level of detail for our homegrown [gc_log_visualizer](https://github.com/HubSpot/gc_log_visualizer) script. The majority of graphs in this document were created with gc_log_visualizer, while others were snapshotted from SignalFX data collected through our [CollectD GC metrics plugin](https://github.com/HubSpot/collectd-gcmetrics).\n\nOur GC logging params:\n\n```\n-verbosegc -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintAdaptiveSizePolicy -XX:+PrintGCDetails -XX:+PrintGCApplicationStoppedTime -XX:+PrintTenuringDistribution\n```\n\n#### Starting Point: Heap Sizes and Overall Time Spent in GC\n\nWith the highly detailed GC logs came the following chart of heap state. Eden size is in red and stays put at its minimum (`G1NewSizePercent`), 9% of total heap. Tenured size, or Working set + waste, floats in a narrow band between 18-20gb. With Eden a flat line, the total heap line will mirror the Tenured line, just 9% higher.\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC1-1.png)\n\nThe black horizontal line just under 15GB marks the `InitiatingHeapOccupancyPercent` (aka “IHOP”), at its default setting of 45%. The purple squares are the amount of Tenured space reclaimable at the start of a mixed GC event. The floor of the band of purple squares is 5% of heap, the value of `G1HeapWastePercent`.\n\nThe next graph shows a red “+” on each minute boundary and stands for the total percent of wall time the JVM was in STW and doing no useful work. The overall time spent in GC for this HBase instance for this time period is 15-25%. For reference, an application tier server spending 20%+ time in GC is considered stuck in “GC Hell” and in desperate need of tuning.\n\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC2-1.png)\n\n### Tuning #1 Goal: Lower Total Time in GC - Action: Raise IHOP\n\nOne aspect that stands out clearly in the previous graph of heap sizes is that the working set is well above the IHOP. Tenured being higher than IHOP generally results in an overabundance of MPCMC runs (wastes CPU) and consequently an overabundance of Mixed GC cycles resulting in a higher ratio of expensive GC events vs cheap GC events. By moving IHOP a bit higher than Tenured, we expect fewer Mixed GC events to reclaim larger amounts of space, which should translate to less overall time spent in STW.\n\nRaising the IHOP value on an hbase instance, the following before/after (above/below) graphs show that indeed the frequency of Mixed GC events drops dramatically while the reclaimable amount rises.\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC3-1.png)\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1Gc4-1.png)\n\nConsidering that at least half of Mixed GC events on this instance took 200-400ms, we expected the reduced amount of Mixed GC events to outweigh any increase in individual Mixed GC times, such that overall GC time would drop. That expectation held true, as overall time spent in GC dropped from 4-12% to 1-8%.\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC5-1.png)\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC6-1.png)\n\nThe following graphs show before/after on the STW times for all Mixed GC events. Note the drastic drop in frequency while individual STW times don't seem to change.\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC7-1.png)\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC8.png)\n\n#### Result: Success\n\nThis test was considered successful. We made the change across all HBase clusters to use a significantly larger IHOP value than the default of 45%.\n\n### Tuning #2 Goal: Lower Total Time in GC - Action: Increase Eden\n\nFixing the IHOP value to be higher than working set was basically fixing a misconfiguration. There was very little doubt that nonstop MPCMC + Mixed GC events was an inefficient behavior. Increasing Eden size, on the other hand, had a real possibility of increasing all STW times, both Minor and Mixed. GC times are driven by the amount of data being copied (surviving) from one epoch to the next, and databases like HBase are expected to have very large caches. A 10+ GB cache could very well have high churn and thus high object survival rates.\n\nThe effective Eden size for our HBase clusters is driven by the minimum Eden value `G1NewSizePercent` because the `MaxGCPauseMillis` target of 50ms is never met.\n\nFor this test, we raised Eden from 9% to 20% through `G1NewSizePercent`.\n\n#### Effects on Overall GC Time\n\nLooking at the following graphs, we see that overall time spent in GC may have dropped a little for this one hour time window from one day to the next.\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC9.png)\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC10.png)\n\n#### Individual STW times\n\nLooking at the STW times for just the Minor GC events there is a noticeable jump in the floor of STW times.\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC11.png)\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC12.png)\n\n#### To-space Exhaustion Danger\n\nAs mentioned in the [G1GC Foundational blog post](http://product.hubspot.com/g1gc-fundamentals-lessons-from-taming-garbage-collection?hs_preview=zL3BfQaN-4049945892), `G1ReservePercent` is ignored when the minimum end of the Eden range is used. The working set on a few of our HBase clusters is in the 70-75% range, which combined with a min Eden of 20% would leave only 5-10% of heap free for emergency circumstances. The downside of running out of free space, thus triggering To-space Exhaustion, is a 20+ sec GC pause and the effective death of the HBase instance. While the instance would recover, the other HBase instances in the cluster would consider it long dead before the GC pause completed.\n\n#### Result: Failure\n\nThe overall time spent in GC did drop a little as theoretically expected, unfortunately the low end of Minor GC stw times increased by a similar percent. In addition, the risk for To-space exhaustion increased. The approach of increasing `G1NewSizePercent` to reduce overall time spent in GC didn't look promising and was not rolled out to any clusters.\n\n### Tuning #3 Goal: Reduce Individual STW Durations - Action: SurvivorRatio & MaxTenuringThreshold\n\nIn the previous tuning approach, we found that STW times increased as Eden size increased. We took some time to dig a little deeper into Survivor space to determine if there was any To-space overflow or if objects could be promoted faster to reduce the amount of object copying being done. To collect the Survivor space tenuring distribution data in the GC logs we enabled `-XX:+PrintTenuringDistribution` and restarted a few select instances.\n\nTo-space overflow is the phenomenon where the Survivor To space isn't large enough to fit all the live data in Eden at the end of an epoch. Any data collected after Survivor To is full is added to Free regions, which are then added to Tenured. If this overflow is transient data, putting it in Tenured is inefficient as it will be expensive to clean out. If that was the case, we'd need to increase `SurvivorRatio`.\n\nOn the other hand, consider a use case where any object that survives two epochs will also survive ten epochs. In that case, by ensuring that any object that survives a second epoch is immediately promoted to Tenured, we would see a performance improvement since we wouldn’t be copying it around in the GC events that followed.\n\nHere’s some data collected from the `PrintTenuringDistribution` parameter:\n\n```\nDesired survivor size 192937984 bytes, new threshold 2 (max 15)\n\n- age 1: 152368032 bytes, 152368032 total\n\n- age 2: 147385840 bytes, 299753872 total\n\n[Eden: 2656.0M(2656.0M)->0.0B(2624.0M) Survivors: 288.0M->320.0M Heap: 25.5G(32.0G)->23.1G(32.0G)]\n```\n\nAn Eden size of 2656 MB with `SurvivorRatio=8` (default) yields a 2656/8 = 332 MB survivor space. In the example entries we see enough room to hold two ages of survivor objects. The second age here is 5mb smaller than the first age, indicating that in the interval between GC events, only 5/152 = 3.3% of the data was transient. We can reasonably assume the other 97% of the data is some kind of caching. By setting `-XX:MaxTenuringThreshold=1`, we optimize for the 97% of cached data to be promoted to Tenured after surviving its second epoch and hopefully shave a few ms of object copy time off each GC event.\n\n#### Result: Theoretical Success\n\nUnfortunately we don't have any nice graphs available to show these effects in isolation. We consider the theory sound and rolled out -XX:MaxTenuringThreshold=1 to all our clusters.\n\n### Tuning #4 Goal: Eliminate Long STW Events - Action: G1MixedGCCountTarget & G1HeapWastePercent\n\nNext, we wanted to see what we could do about eliminating the high end of Mixed GC pauses. Looking at a 5 minute interval of our Mixed GC STW times, we saw a pattern of sharply increasing pauses across each cycle of 6 mixed GCs:\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC13.png)\n\nThat in and of itself should not be considered unusual, after all that behavior is how the G1GC algorithm got it's name. Each Mixed GC event will evacuate `1/G1MixedGCCountTarget` of the high-waste regions (regions with the most non-live data). Since it prioritizes regions with the most garbage, each successive Mixed GC event will be evicting regions with more and more live objects. The chart shows the performance effects of clearing out regions with more and more live data: the Mixed event times start at 100ms at the beginning of a mixed GC cycle and range upwards past 600ms by the end.\n\nIn our case, we were seeing occasional pauses at the end of some cycles that were several seconds long. Even though they were rare enough that our average pause time was reasonable, pauses that long are still a serious concern.\n\nTwo levers in combination can be used together to lessen the “scraping the bottom of the barrel” effect of cleaning up regions with a lot of live data:\n\n`G1HeapWastePercent`: default (5) → 10. Allow twice as much wasted space in Tenured. Having 5% waste resulted in 6 of the 8 potential Mixed GC events occurring in each Mixed GC cycle. Bumping to 10% waste should chop off 1-2 more of the most expensive events of the Mixed GC cycle.\n\n`G1MixedGCCountTarget`: default (8) → 16. Double the target number of Mixed GC events each Mixed GC cycle, but halve the work done by each GC event. Though it’s an increase to the number of GC events that are Mixed GC events, STW times of individual Mixed events should drop noticeably.\n\nIn combination, we expected doubling the target count to drop the average Mixed GC time, and increasing the allowable waste to eliminate the most expensive Mixed GC time. There should be some synergy, as more heap waste should also mean regions are on average slightly less live when collected.\n\nWaste heap values of 10% and 15% were both examined in a test environment. (Don’t be alarmed by the high average pause times--this test environment was running under heavy load, on less capable hardware than our production servers.)\n\nAbove: 10% heap waste; below: 15% heap waste:\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC14.png)\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC15.png)\n\nThe results are very similar. 15% performed slightly better, but in the end we decided that 15% waste was unnecessarily much. 10% was enough to clear out the \"scraping the bottom of the barrel\" effect such that the 1+ sec Mixed GC STW times all but disappeared in production.\n\n#### Result: Success\n\nDoubling `G1MixedGCCountTarget` from 8 to 16 and `G1HeapWastePercent` from 5 to 10 succeeded in eliminating the frequent 1s+ Mixed GC STW times. We kept these changes and rolled them out across all our clusters.\n\n### Tuning #5 Goal: Stop Losing Nodes: Heap Size and HBase Configs\n\nWhile running load tests to gauge the effects of the parameters above, we also began to dig into what looked like evidence of memory leaks in a production cluster. In the following graph we see the heap usage slowly grow over time until To-space Exhaustion, triggering a Full GC with a long enough pause to get the HBase instance booted from the cluster and killed:\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC16.png)\n\nWe've got several HBase clusters, and only one cluster occasionally showed this type of behavior.  If this issue were a memory leak, we'd expect the issue to arise more broadly, so it looks like HBase is using more memory in this cluster than we expected. To understand why, we looked into the heap breakdown of our RegionServers. The vast majority of an HBase RegionServer’s Tenured space is allocated to three main areas:\n\n* __Memstore__: region server’s write cache; default configuration caps this at 40% of heap.\n* __Block Cache__: region server’s read cache; default config caps at 40% of heap.\n* __Overhead__: the vast majority of HBase’s in-memory overhead is contained in a “static index”. The size of this index isn’t capped or configurable, but HBase assumes this won’t be an issue since the combined cap for memstore and block cache can’t exceed 80%.\n\nWe have metrics for the size of each of these, from the RegionServer’s JMX stats: “memStoreSize,” “blockCacheSize,” and “staticIndexSize.” The stats from our clusters show that HBase will use basically all of the block cache capacity you give it, but memstore and static index sizes depend on cluster usage and tables. Memstore fluctuates over time, while static index size depends on the RegionServer’s StoreFile count and average row key size.\n\nIt turned out, for the cluster in question, that the HBase caches and overhead combined were actually using more space than our JVM was tuned to handle. Not only were memstore and block cache close to capacity—12 GB block cache, memstore rising past 10GB—but the static index size was unexpectedly large, at 6 GB. Combined, this put desired Tenured space at 28+ GB, while our IHOP was set at 24 GB, so the upward trend of our Tenured space was just the legitimate memory usage of the RegionServer.\n\nWith this in mind, we judged the maximum expected heap use for each cluster’s RegionServers by looking at the cluster maximum memstore size, block cache size, and static index size over the previous month, and assuming max expected usage to be 110% of each value. We then used that number to set the block cache and memstore size caps (`hfile.block.cache.size` & `hbase.regionserver.global.memstore.size`) in our HBase configs.\n\nThe fourth component of Tenured space is the heap waste, in our case 10% of the heap size. We could now confidently tune our IHOP threshold by summing the max expected memstore, block cache, static index size, 10% heap for heap waste, and finally 10% more heap as a buffer to avoid constant mixed GCs when working set is maxed (as described in Tuning #1).\n\nHowever, before we went ahead and blindly set this value, we had to consider the uses of heap other than Tenured space. Eden requires a certain amount of heap (determined by `G1NewSizePercent`), and a certain amount (default 10%) is Reserved free space. IHOP + Eden + Reserved must be ≤ 100% in order for a tuning to make sense; in cases where our now-precisely-calculated IHOP was too large for this to be possible, we had to expand our RegionServer heaps. To determine minimum acceptable heap size, assuming 10% Reserved space, we used this formula:\n\n```\nHeap ≥ (M + B + O + E) ÷ 0.7\n\nM = max expected memstore size\nB = max expected block cache size\nO = max expected overhead (static index)\nE = minimum Eden size\n```\n\nWhen those four components add up to ≤ 70% of the heap, then there will be enough room for 10% Reserved space, 10% heap waste, and 10% buffer between max working set and IHOP.\n\n#### Result: Success\n\nWe reviewed memory usage of each of our clusters and calculated correct heap sizes and IHOP thresholds for each. Rolling out these changes immediately ended the To-space Exhaustion events we were seeing on the problematic cluster.\n\n### Tuning #6 Goal: Eliminate Long STW Events - Action: Increase G1 Region Size\n\nWe’d rolled out HBase block cache & memstore config changes, changes to `G1HeapWastePercent` and `G1MixedGCCountTarget`, and an increase in heap size on a couple clusters (32 GB → 40+ GB) to accommodate larger IHOP. In general things were smooth, but there were still occasional Mixed GC events taking longer than we were comfortable with, especially on the clusters whose heap had increased. Using gc_log_visualizer, we looked into what phase of Mixed GC was the most volatile and noticed that Scan RS times correlated:\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC17.png)\n\nA few Google searches indicated that Scan RS time output in the GC logs is the time taken examining all the regions referencing the tenured regions being collected. In our most recent tuning changes, heap size had been bumped up, however the `G1HeapRegionSize` remained fixed at 16 MB. Increasing the `G1HeapRegionSize` to 32 MB eliminated those high scan times:\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC18.png)\n\n#### Result: Success\n\nHalving the G1 region count cleared out the high volatility in Scan RS times. According to G1GC documentation, the ideal region count is 2048, so 16 MB regions were perfect for a 32 GB heap. However, this tuning case led us to believe that for HBase heaps without a clear choice of region size, in our case 40+ GB, it’s much better to err on the side of fewer, larger regions.\n\n### Tuning #7 Goal: Preventing RegionServer To-space Exhaustion - Action: Extra Heap as Buffer\n\nAt this point, our RegionServers were tuned and running much shorter and less frequent GC Events. IHOP rested above Tenured while Tenured + Eden remained under the target of 90% total heap. Yet once in awhile, a RegionServer would still die from a To-space exhaustion triggered Full GC event as shown in the following graph.\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC19.png)\n\nIt looks like we did everything right—there’s lot’s of reclaimable space and Tenured space drops well below IHOP with each Mixed GC. But right at the end, heap usage spikes up and we hit To-space Exhaustion. And while it’s likely the HBase client whose requests caused this problem could be improved to avoid this*, we can’t rely on our various HBase clients to behave perfectly all the time.\n\nIn the scenario above, very bursty traffic caused Tenured space to fill up the heap before the MPCMC could complete and enable a Mixed GC run. To tune around this, we simply added heap space**, while adjusting IHOP and `G1NewSizePercent` down to keep them at the same GB values they had been at before. By doing this we increased the buffer of free space in the heap above our original 10% default, for additional protection against spikes in memory usage.\n\n#### Result: Success\n\nIncreasing heap buffer space on clusters whose HBase clients are known to be occasionally bursty has all but eliminated Full GC events on our RegionServers.\n\n#### Notes:\n\nBlock cache churn correlates very closely with time spent in Mixed GC events on our clusters (see chart below). A high volume of Get and Scan requests with caching enabled unnecessarily (e.g. requested data isn’t expected to be in cache and isn’t expected to be requested again soon) will increase cache churn as data is evicted from cache to make room for the Get/Scan results. This will raise the RegionServer’s time in GC and could contribute to instability as described in this section.\n\nChart: % time in Mixed GC is in yellow (left axis); MB/sec cache churn is in blue (right axis):\n\n![](/assets/images/2016/05/10/g1gc-tuning-your-hbase-cluster/G1GC20.png)\n\nAnother potential way to tune around this issue is by increasing `ConcGCThreads` (default is `1/4 ParallelGCThreads`). `ConcGCThreads` is the number of threads used to do the MPCMC, so increasing it could mean the MPCMC finishes sooner and the RegionServer can start a Mixed GC before Tenured space fills the heap. At HubSpot we’ve been satisfied with the results of increasing our heap size and haven’t tried experimenting with this value.\n\n### Overall Results: Goals Achieved!\n\nAfter these cycles of debugging and tuning G1GC for our HBase clusters, we’ve improved performance in all the areas we were seeing problems originally:\n\n* __Stability__: no more To-space Exhaustion events causing Full GCs.\n* __99th percentile performance__: greatly reduced frequency of long STW times.\n* __Avg. performance__: overall time spent in GC STW significantly reduced.\n\n### Summary: How to Tune Your HBase Cluster\n\nBased on our findings, here’s how we recommend you tune G1GC for your HBase cluster(s):\n\n#### Before you start: GC & HBase monitoring\n\n* Track block cache, memstore & static index size metrics for your clusters in whatever tool you use for charts and monitoring, if you don’t already. These are found in the RegionServer JMX metrics:\n  * “memStoreSize”\n  * “blockCacheSize”\n  * “staticIndexSize”\n* You can use our [collectd plugin](https://github.com/HubSpot/collectd-gcmetrics) to track G1GC performance over time, and our [gc_log_visualizer](https://github.com/HubSpot/gc_log_visualizer) for insight on specific GC logs. In order to use these you’ll have to log GC details on your RegionServers:\n  * -Xloggc:$GC_LOG_PATH\n  * -verbosegc\n  * -XX:+PrintGC\n  * -XX:+PrintGCDateStamps\n  * -XX:+PrintAdaptiveSizePolicy\n  * -XX:+PrintGCDetails\n  * -XX:+PrintGCApplicationStoppedTime\n  * -XX:+PrintTenuringDistribution\n  * Also recommended is some kind of GC log rotation, e.g.:\n    * -XX:+UseGCLogFileRotation\n    * -XX:NumberOfGCLogFiles=5\n    * -XX:GCLogFileSize=20M\n\n#### Step 0: Recommended Defaults\n\n* We recommend the following JVM parameters and values as defaults for your HBase RegionServers (as explained in [Original GC Tuning State](http://product.hubspot.com/blog/g1gc-tuning-your-hbase-cluster#OriginalGCTuning)):\n  * -XX:+UseG1GC\n  * -XX:+UnlockExperimentalVMOptions\n  * -XX:MaxGCPauseMillis=50\n    This value is intentionally very low and doesn’t actually represent a pause time upper bound. We recommend keeping it low to pin Eden to the low end of its range (see Tuning #2).\n  * -XX:-OmitStackTraceInFastThrow\n  * -XX:ParallelGCThreads=8+(logical processors-8)(5/8)\n  * -XX:+ParallelRefProcEnabled\n  * -XX:+PerfDisableSharedMem\n  * -XX:-ResizePLAB\n\n#### Step 1: Determine maximum expected HBase usage\n\n* As discussed in the Tuning #5 section, before you can properly tune your cluster you need to know your max expected block cache, memstore, and static index usage.\n  * Using the RegionServer JMX metrics mentioned above, look for the maximum value of each metric across the cluster:\n    * Maximum block cache size.\n    * Maximum memstore size.\n    * Maximum static index size.\n  * Scale each maximum by 110%, to accommodate even for slight increase in max usage. This is your **usage cap** for that metric: e.g. a 10 GB max recorded memstore → 11 GB **memstore cap**.\n    * Ideally, you’ll have these metrics tracked for the past week or month, and you can find the maximum values over that time. If not, be more generous than 110% when calculating memstore and static index caps. Memstore size especially can vary widely over time.\n\n#### Step 2: Set Heap size, IHOP, and Eden size\n\n* Start with Eden size relatively low: 8% of heap is a good initial value if you’re not sure.\n  * -XX:G1NewSizePercent=8\n  * See Tuning #2 for more about Eden sizing.\n    * Increasing Eden size will increase individual GC pauses, but slightly reduce overall % time spent in GC.\n    * Decreasing Eden size will have the opposite effect: shorter pauses, slightly more overall time in GC.\n* Determine necessary heap size, using Eden size and usage caps from Step 1:\n  * From Tuning #5: Heap ≥ (M + B + O + E) ÷ 0.7\n    * M = memstore cap, GB\n    * B = block cache cap, GB\n    * O = static index cap, GB\n    * E = Eden size, GB\n  * Set JVM args for fixed heap size based on the calculated value, e.g:\n    * -Xms40960m -Xmx40960m\n* Set IHOP in the JVM, based on usage caps and heap size:\n  * IHOP = (memstore cap’s % heap + block cache cap’s % heap + overhead cap’s % heap + 20)\n  * -XX:InitiatingHeapOccupancyPercent=IHOP\n\n#### Step 3: Adjust HBase configs based on usage caps\n\n* Set block cache cap and memstore cap ratios in HBase configs, based on usage caps and total heap size. In hbase-site.xml:\n  * `hfile.block.cache.size` → block cache cap ÷ heap size\n  * `hbase.regionserver.global.memstore.size` → memstore cap ÷ heap size\n\n#### Step 4: Adjust additional recommended JVM flags for GC performance\n\n* From Tuning #3:\n  * -XX:MaxTenuringThreshold=1\n* From Tuning #4:\n  * -XX:G1HeapWastePercent=10\n  * -XX:G1MixedGCCountTarget=16\n* From Tuning #6:\n  * -XX:G1HeapRegionSize=#M\n  * `#` must be a power of 2, in range [1..32].\n  * Ideally, # is such that: heap size ÷ # MB = 2048 regions.\n  * If your heap size doesn’t provide a clear choice for region size, err on the side of fewer, larger regions. Larger regions reduce GC pause time volatility.\n\n#### Step 5: Run it!\n\n* Restart your RegionServers with these settings and see how they look.\n  * Remember that you can adjust Eden size as described above, to optimize either for shorter individual GCs or for less overall time in GC. If you do, make sure to maintain Eden + IHOP ≤ 90%.\n  * If your HBase clients can have very bursty traffic, consider adding heap space outside of IHOP and Eden (so that IHOP + Eden adds up to 80%, for example).\n    * Remember to update % and ratio configs along with the new heap size.\n    * Details and further suggestions about this found in Tuning #7.\n\n### Further reference:\n\n* [G1GC Fundamentals (HubSpot blog)](http://product.hubspot.com/blog/g1gc-fundamentals-lessons-from-taming-garbage-collection)\n* [Understanding G1GC Logs (Oracle blog)](https://blogs.oracle.com/poonam/entry/understanding_g1_gc_logs)\n* [Tuning HBase Garbage Collection (Intel blog)](https://software.intel.com/en-us/blogs/2014/06/18/part-1-tuning-java-garbage-collection-for-hbase)\n\nThis blog post was co-authored by Staff Software Engineer Eric Abbott. \n\n---\n\n* 原文链接：[Tuning G1GC For Your HBase Cluster](http://product.hubspot.com/blog/g1gc-tuning-your-hbase-cluster)\n","tags":["Tuning"],"categories":["HBase"]},{"title":"Hadoop Raid - 实战经验总结","url":"%2F2016%2F2016-03-10-hadoop-raid%2F","content":"\n### 介绍\n\n分布式文件系统用于解决海量数据存储的问题，腾讯大数据采用HDFS（Hadoop分布式文件系统）作为数据存储的基础设施，并在其上构建如Hive、HBase、Spark等计算服务。\n\nHDFS块存储采用三副本策略来保证数据可靠性，随着数据量的不断增长，三副本策略为可靠性牺牲的存储空间也越来越大。如何在不降低数据可靠性的基础上，进一步降低存储空间成本，成为腾讯大数据迫切需要解决的问题。\n\n我们对facebook版本的hadoop raid分析发现，还有很多细节需要优化改进，本文就hadoop raid存在的问题进行探讨，并对一些可以改进的地方给出思路。\n\n首先介绍一下hadoop raid的原理和架构：\n\n![](/assets/images/2016/03/10/hadoop-raid/001.jpg)\n\n### 原理分析\n\nHDFS Raid以文件为单位计算校验，并将计算出来的校验block存储为一个HDFS文件。HDFS Raid支持XOR和RS两种编码方式，其中XOR以位异或生成校验信息；而RS又称里所码，即Reed-solomon codes，是一种纠错能力很强的信道编码，被广泛应用在CD、DVD和蓝光光盘的数据纠错当中。\n\nHDFS为每个block创建3个副本，可以容忍2个block丢失，因此存储空间为数据量的3倍。而采用RS编码，如按条带（Stripe length）和校验块（Parity block）个数比例为10,4计算，则只需要1.4倍的存储开销，就可以容忍同一条带内任意4个block丢失，即存储量可以节省16/30。\n\n### Hadoop Raid架构\n\n![](/assets/images/2016/03/10/hadoop-raid/002.jpg)\n\n### DRFS\n\n* DRFS：应用Raid方案后的HDFS\n* RaidNode：根据配置路径，对需要Raid的文件（source file），从HDFS DataNode中读取对应的数据块，计算出校验块文件（parity file，所有校验块组成一个HDFS文件），并将parity file存储在HDFS中；RaidNode周期性的检查源文件及校验块文件对应的block数据是否丢失，如有丢失，则重新计算以恢复丢失的block\n* Raid File System：提供访问DRFS的HDFS客户端，其在HDFS Client接口上进行封装，当读取已丢失或损坏的block时，通过对应的校验块计算恢复的block数据返回给应用，恢复过程对应用是透明的\n* RaidShell：DRFS管理工具，可手工触发生成parity file、恢复丢失block等\n\n**问题与优化**\n\n#### 问题1 集群压力增加\n\n集群压力增加表现为NameNode元数据增多、访问量增加、Raid和数据恢复时集群网络及IO负载增加几个方面，具体如下：\n\n其一，raid过程中会生成校验文件以及目录结构，导致元数据增加。如下图所示，对于每一个原始文件，都会在目标目录生成一个对应的检验文件，造成元数据量double。由于校验文件读操作远大于删除等更新操作，解决方案为对校验文件做har打包，将目录打包成一个har文件，以节省元数据量。\n\n![](/assets/images/2016/03/10/hadoop-raid/003.jpg)\n\n其二，RaidNode周期性的访问NameNode，查询哪些文件需要做raid、是否存在废弃的parity file（源文件被删除，则对应的parity file已经无效了，需要清理掉）、是否存在Missing Block等，这些操作都对NameNode产生一定压力。解决方案为调整RaidNode访问NameNode的频率，控制在可接受的范围。\n\n其三，做Raid生成校验文件及恢复丢失的block时，需要读取相同stripe的多个block数据，导致集群内网络及IO负载增加。解决方案为选择空闲时段进行操作，减少对现网生产环境的影响。\n\n其四，Raid完成后，源文件block副本数减少，job本地化概率减小，同时增加了网络流量和job的执行时间。为减少影响，只对访问频率较低的冷数据做Raid，而冷数据的判定，则需要从数据生成时间、访问时间、访问次数综合考虑。\n\n#### 问题2 集群性能下降\n\n性能下降则包括块删除速度变慢、读取频繁移动的块速度变慢，具体如下：\n\n其一，NameNode应用Raid块放置策略，删除block需要考虑相同stripe的其他block的位置情况，以保证同一DataNode上不会存储该stripe的多个block，避免由于该DataNode故障缺失过多的块，造成数据无法恢复的风险。另外，在集群启动时，NameNode要重建元数据信息，同时对比block的实际副本数和配置值，用以删除和增加block；由于Raid块放置策略的引入，每个block的增加和删除都需要考虑相同stripe的其他block位置信息，这一过程非常耗时，导致NameNode启动变慢很多。\n\n解决方案是，在启动时使用默认的块放置策略，保持启动过程同原有流程相同，待启动完成，再修改为Raid块放置策略，动态刷新到NameNode生效。\n\n![](/assets/images/2016/03/10/hadoop-raid/004.png)\n\n其二，RaidNode周期性的扫描原始文件和检验文件，如发现同一DataNode上存储该stripe内的过多block，则将超出来的block迁移到其他DataNode上。RaidNode的检查周期默认值为10分钟，然而块移动过程NameNode并不会及时清掉block同移出DataNode的映射关系，而要等到下次DataNode块上报，块上报的周期比较长，一般2个小时。这样在下次块上报之前，NameNode中block映射的DataNode会不断累积，直至遍布整个集群。客户端读取这个block数据就会因很多DataNode上并不存在块文件而重试，导致性能下降。解决方案为调整RaidNode扫描周期，要大于DataNode的块上报周期，期间NameNode来修正block和DataNode的映射关系。\n\n![](/assets/images/2016/03/10/hadoop-raid/005.png)\n\n#### 问题3 数据安全性问题\n\n表现在rebalance不理解raid概念：\n\nRebalance不理解raid的条带的概念，将block在集群中重新移动后，可能会导致相同stripe的多个block保存在相同的DataNode上，存在丢块的风险。解决方案为NameNode增加RPC接口，查询block所属文件，进而结合raid块放置策略，将stripe的多个block分散得更散。\n\n#### 问题4 Raid过程Job数据倾斜\n\nRaidNode提交job对多个源文件做raid，理想效果如图(a)，多个文件平均分配到每个map中raid操作，但执行过程中发现大部分map迅速完成，统计读取记录为0，而另外少部分map执行时间较长。\n\n分析流程发现，RaidNode采用同distcp相同的方式，先将需要raid的文件列表，以SequenceFile格式写入HDFS，且每10个文件写入一次SYNC标识，分片时再将每个文件构造成FileSplit作为分片单元；map读取输入使用SequenceFileRecordReader，以SYNC标识为起止位置。以(b)图为例，map1的起止位置跨越了SYNC1，因读取的数据为SYNC1和SYNC2之间的10个文件列表，而其它map的起止位置在同一SYNC区间内，则读取数据为0，这就是job倾斜的原因。\n\n![](/assets/images/2016/03/10/hadoop-raid/006.jpg)\n\n解决方案为每个文件后面都写入一次SYNC标识，多个文件就会平均分配到map中执行。而SYNC标识占用20个字节，且只在job执行结束SequenceFile就会清理掉，存储代价微乎其微。\n\n---\n\n* 原文链接：[Hadoop Raid-实战经验总结](http://data.qq.com/article?id=2929)\n","tags":["Raid"],"categories":["Hadoop"]},{"title":"RWN及Quorum与强一致性","url":"%2F2016%2F2016-02-26-rwn-quorum-strong-consistency%2F","content":"\n## 序\n\n本文主要讨论对等以及主从模型的读写冲突的解决方法。\n\n## 对等式分布模型\n\n`即有多个master，同时接受读写操作`\n\n### 写入冲突\n\n多个人在同时更新同一条数据（对于单机数据库，就是并发问题，可由乐观锁或悲观锁来解决；对于对等分布式模型，则需要保证顺序一致性，即所有节点都保证以相同顺序执行操作）。\n\n### 读取冲突\n\n从各个节点读取同一个数据的内容不一样。\n\n### RWN方案解决读冲突\n\n强一致性：strong consistency（读取的数据都是最新的），要求多少节点才行。\n\n#### write quorum\n\n假设某份数据需要复制到3个节点，为了保证强一致性，不需要所有节点都确认写入操作，只需要其中两个节点（也就是超半数节点）确认就可以了。在这种情况下，如果发生两个相互冲突的写入操作，那么只有其中一个操作能为超过半数的节点所认可，这就是写入仲裁（write quorum），如果用稍微正规一点的方式说，那就是W&gt;N/2，这个不等式的意思是参与写入操作的节点数W，必须超过副本节点数N的一半，副本节点数又称为复制因子（replication factor）。\n\n#### read quorum\n\n读取仲裁（read quorum），也就是说想保证能够读到最新的数据，必须与多少个节点联系才行。假设写入操作需要两个节点来确认（W=2），那么我们至少得联系两个节点，才能保证获取到最新数据。然而，假如某些写入操作只被一个节点所确认（W=1），那么我们就必须3个节点都通信一遍，才能确保获取到的数据是最新的。一个情况下，由于写入操作没有获得足够的节点支持率，所以可能会产生更新冲突。但是，只要从足够数量的节点中读出数据，就一定能侦测出此类冲突。因此，即使在写入操作不具备强一致性的情况下，也可以实现除具有强一致性的读取操作来。\n\n### RWN\n\n* R\n\n执行读取操作时所需联系的节点数R\n\n* W\n\n确认写入操作时所需征询的节点数W\n\n* N\n\n复制因子N\n\n这三者之间的关系，可以用一个不等式来表述，即只有当R+W&gt;N的时候，才能保证读取操作的强一致性。\n\n### 实例\n\n对于Riak这样的数据库，可以控制CAP中的参数：N（存取键值对的副本节点数）、R（顺利完成读取操作所需的最小节点数）、W（顺利完成写入操作所需的最小节点数）。假设Riak集群有5个节点，将N设为3，也就是所有数据都要至少复制到3个节点中，将R设为2，即get请求要求有两个节点应答，才能成功，将W设为2，即put请求必须写入到两个节点才算写入完毕。\n\n## 主从分布式模型\n\n针对主从分布式模型，只需要保证都向master写入数据，就可以避免写入冲突了，类似的，读取操作从master，就可以避免读写冲突/读取不一致了。\n\n## 参考\n\n* [NoSQL入门级资料整理（CAP原理、最终一致性）](http://blog.sina.com.cn/s/blog_3fe961ae010139u6.html)\n\n---\n\n* 原文链接：[RWN及Quorum与强一致性](https://segmentfault.com/a/1190000004499551)\n","tags":["Replication"],"categories":["Distributed"]},{"title":"负载均衡算法及手段","url":"%2F2016%2F2016-02-25-load-balancing-algorithm%2F","content":"\n## 序\n\n本文主要讲述负载均衡的一些基本东西。\n\n## 相关知识点\n\n### 冷备与热备\n\n* 冷备份(cool standby)，指配备平时不运行的备用设备，当运行设备发生故障时，使用备用设备替换。\n\n* 热备份(hot standby)，指在设备运行的同时运行备用设备，当运行设备发生故障时，能够自动替换备用设备。\n\n### fail-over与fail-back\n\n* fail-over，在空余结构中，停止运行设备，使用备用设备进行工作的过程称为替换，英文称为fail-over或者switch-over。\n\n* fail-back，替换后再次恢复到原来的运行设备，也就是从运行状态的备用设备再切换到原来的运行设备的过程，称为回退，英文称为fail-back或switch-back。\n\n### 冗余类型\n\n* 1.主备方式(Active-Standby)\n\n准备两台路由器，其中一台作为正常运行业务的活跃设备(active)，也可以称为主设备(master)或者首要设备(primary)。另一台作为发生故障时替换的备用设备(standby)，也可以称为备机(backup)、从设备(slave)、必要设备(secondary)。活跃设备和备用设备必须共享关于设备的设置信息。\n\n* 2.双活方式(Active-Active)\n\n准备两台路由器，其中一台作为首要设备(primary)，另一台作为次要设备(secondary)，二者同时运行来组成冗余结构。这种方式可以通过与负载均衡设备并用或者设置DNS、客户端一侧的路由信息来达到负载均衡的目的。\n\n* 3.集群方式(Cluster)\n\n在主备方式或双活方式中，使用3台以上的硬件协同组成冗余结构的方式。\n\n### L2与L3交换机\n\n* L2基于数据链路层，L3基于网络层，具有IP分组与路由选择功能。\n\n* L2可以通过使用VLAN分割广播域，但终端之间的数据帧交换必须位于同一VLAN范围内。 不同VLAN上的终端如有相互通信需求，则必须使用路由器。\n\n* L3交换机与路由器均可以实现跨VLAN路由，但L3交换机多用于在以太网构筑的Intranet内部转发分组，而路由器则大多作为连接互联网与Intranet内网之间的网关来使用。\n\n### L4与L7交换机\n\n* L4交换机\n\n能够支持到TCP层级访问控制的交换机，称为L4交换机。\n\n* L7交换机\n\n能够基于HTTP和HTTPS这类应用层L7参数进行负载均衡等操作的产品，称为L7交换机。\n\n## 负载均衡器\n\n可以是专用设备，也可以是在通用服务器上运行的应用程序。 分散请求到拥有相同内容或提供相同服务的服务器。 专用设备一般只有以太网接口，可以说是多层交换机的一种。 负载均衡器一般会被分配虚拟IP地址，所有来自客户端的请求都是针对虚拟IP地址完成的。负载均衡器通过负载均衡算法将来自客户端的请求转发到服务器的实际IP地址上。\n\n## 负载均衡算法\n\n```\nprivate Map<String,Integer> serverMap = new HashMap<String,Integer>(){\n    {\n        put(\"192.168.1.100\",1);\n        put(\"192.168.1.101\",1);\n        put(\"192.168.1.102\",4);\n        put(\"192.168.1.103\",1);\n        put(\"192.168.1.104\",1);\n        put(\"192.168.1.105\",3);\n        put(\"192.168.1.106\",1);\n        put(\"192.168.1.107\",2);\n        put(\"192.168.1.108\",1);\n        put(\"192.168.1.109\",1);\n        put(\"192.168.1.110\",1);\n    }\n};\n```\n\n### 1.随机算法\n\n* Random\n\n随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。\n\n```\npublic void random(){\n    List<String> keyList = new ArrayList<String>(serverMap.keySet());\n    Random random = new Random();\n    int idx = random.nextInt(keyList.size());\n    String server = keyList.get(idx);\n    System.out.println(server);\n}\n```\n\n* WeightRandom\n\n```\npublic void weightRandom(){\n    Set<String> keySet = serverMap.keySet();\n    List<String> servers = new ArrayList<String>();\n    for(Iterator<String> it = keySet.iterator();it.hasNext();){\n        String server = it.next();\n        int weithgt = serverMap.get(server);\n        for(int i=0;i<weithgt;i++){\n            servers.add(server);\n        }\n    }\n    String server = null;\n    Random random = new Random();\n    int idx = random.nextInt(servers.size());\n    server = servers.get(idx);\n    System.out.println(server);\n}\n```\n\n### 2.轮询及加权轮询\n\n* 轮询(Round Robbin)\n\n当服务器群中各服务器的处理能力相同时，且每笔业务处理量差异不大时，最适合使用这种算法。 轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。\n\n```\nprivate Integer pos = 0;\n    public void roundRobin(){\n    List<String> keyList = new ArrayList<String>(serverMap.keySet());\n    String server = null;\n    synchronized (pos){\n        if(pos > keyList.size()){\n            pos = 0;\n        }\n        server = keyList.get(pos);\n        pos++;\n    }\n    System.out.println(server);\n}\n```\n\n* 加权轮询(Weighted Round Robbin)\n\n为轮询中的每台服务器附加一定权重的算法。比如服务器1权重1，服务器2权重2，服务器3权重3，则顺序为1-2-2-3-3-3-1-2-2-3-3-3- ......\n\n```\npublic void weightRoundRobin(){\n    Set<String> keySet = serverMap.keySet();\n    List<String> servers = new ArrayList<String>();\n    for(Iterator<String> it = keySet.iterator();it.hasNext();){\n        String server = it.next();\n        int weithgt = serverMap.get(server);\n        for(int i=0;i<weithgt;i++){\n           servers.add(server);\n        }\n    }\n    String server = null;\n    synchronized (pos){\n        if(pos > keySet.size()){\n            pos = 0;\n        }\n        server = servers.get(pos);\n        pos++;\n    }\n    System.out.println(server);\n}\n```\n\n### 3.最小连接及加权最小连接\n\n* 最少连接(Least Connections)\n\n在多个服务器中，与处理连接数(会话数)最少的服务器进行通信的算法。即使在每台服务器处理能力各不相同，每笔业务处理量也不相同的情况下，也能够在一定程度上降低服务器的负载。\n\n* 加权最少连接(Weighted Least Connection)\n\n为最少连接算法中的每台服务器附加权重的算法，该算法事先为每台服务器分配处理连接的数量，并将客户端请求转至连接数最少的服务器上。\n\n### 4.哈希算法\n\n* 普通哈希\n\n```\npublic void hash(){\n    List<String> keyList = new ArrayList<String>(serverMap.keySet());\n    String remoteIp = \"192.168.2.215\";\n    int hashCode = remoteIp.hashCode();\n    int idx = hashCode % keyList.size();\n    String server = keyList.get(Math.abs(idx));\n    System.out.println(server);\n}\n```\n\n* 一致性哈希\n\n一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。\n\n### 5.IP地址散列\n\n通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处理。\n\n### 6.URL散列\n\n通过管理客户端请求URL信息的散列，将发送至相同URL的请求转发至同一服务器的算法。\n\n## 负载均衡算法的手段(`DNS->数据链路层->IP层->Http层`)\n\n### 1、DNS域名解析负载均衡(`延迟`)\n\n![](/assets/images/2016/02/25/load-balancing-algorithm/001.png)\n\n利用DNS处理域名解析请求的同时进行负载均衡是另一种常用的方案。在DNS服务器中配置多个A记录，如：www.mysite.com IN A 114.100.80.1、www.mysite.com IN A 114.100.80.2、www.mysite.com IN A 114.100.80.3.\n\n每次域名解析请求都会根据负载均衡算法计算一个不同的IP地址返回，这样A记录中配置的多个服务器就构成一个集群，并可以实现负载均衡。\n\nDNS域名解析负载均衡的优点是将负载均衡工作交给DNS，省略掉了网络管理的麻烦，缺点就是DNS可能缓存A记录，不受网站控制。\n\n事实上，大型网站总是部分使用DNS域名解析，作为第一级负载均衡手段，然后再在内部做第二级负载均衡。\n\n### 2、数据链路层负载均衡(`LVS`)\n\n![](/assets/images/2016/02/25/load-balancing-algorithm/002.png)\n\n数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡。\n\n这种数据传输方式又称作三角传输模式，负载均衡数据分发过程中不修改IP地址，只修改目的的mac地址，通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一样，从而达到负载均衡，这种负载均衡方式又称为直接路由方式（DR）.\n\n在上图中，用户请求到达负载均衡服务器后，负载均衡服务器将请求数据的目的mac地址修改为真是WEB服务器的mac地址，并不修改数据包目标IP地址，因此数据可以正常到达目标WEB服务器，该服务器在处理完数据后可以经过网管服务器而不是负载均衡服务器直接到达用户浏览器。\n\n使用三角传输模式的链路层负载均衡是目前大型网站所使用的最广的一种负载均衡手段。在linux平台上最好的链路层负载均衡开源产品是LVS(linux virtual server)。\n\n### 3、IP负载均衡(`SNAT`)\n\n![](/assets/images/2016/02/25/load-balancing-algorithm/003.png)\n\nIP负载均衡：即在网络层通过修改请求目标地址进行负载均衡。\n\n用户请求数据包到达负载均衡服务器后，负载均衡服务器在操作系统内核进行获取网络数据包，根据负载均衡算法计算得到一台真实的WEB服务器地址，然后将数据包的IP地址修改为真实的WEB服务器地址，不需要通过用户进程处理。真实的WEB服务器处理完毕后，相应数据包回到负载均衡服务器，负载均衡服务器再将数据包源地址修改为自身的IP地址发送给用户浏览器。\n\n这里的关键在于真实WEB服务器相应数据包如何返回给负载均衡服务器，一种是负载均衡服务器在修改目的IP地址的同时修改源地址，将数据包源地址改为自身的IP，即源地址转换（SNAT），另一种方案是将负载均衡服务器同时作为真实物理服务器的网关服务器，这样所有的数据都会到达负载均衡服务器。\n\nIP负载均衡在内核进程完成数据分发，较反向代理均衡有更好的处理性能。但由于所有请求响应的数据包都需要经过负载均衡服务器，因此负载均衡的网卡带宽成为系统的瓶颈。\n\n### 4、HTTP重定向负载均衡(`少见`)\n\n![](/assets/images/2016/02/25/load-balancing-algorithm/004.png)\n\nHTTP重定向服务器是一台普通的应用服务器，其唯一的功能就是根据用户的HTTP请求计算一台真实的服务器地址，并将真实的服务器地址写入HTTP重定向响应中（响应状态吗302）返回给浏览器，然后浏览器再自动请求真实的服务器。\n\n这种负载均衡方案的优点是比较简单，缺点是浏览器需要每次请求两次服务器才能拿完成一次访问，性能较差；使用HTTP302响应码重定向，可能是搜索引擎判断为SEO作弊，降低搜索排名。重定向服务器自身的处理能力有可能成为瓶颈。因此这种方案在实际使用中并不见多。\n\n### 5、反向代理负载均衡(`nginx`)\n\n![](/assets/images/2016/02/25/load-balancing-algorithm/005.png)\n\n传统代理服务器位于浏览器一端，代理浏览器将HTTP请求发送到互联网上。\n而反向代理服务器则位于网站机房一侧，代理网站web服务器接收http请求。\n\n反向代理的作用是保护网站安全，所有互联网的请求都必须经过代理服务器，相当于在web服务器和可能的网络攻击之间建立了一个屏障。\n\n除此之外，代理服务器也可以配置缓存加速web请求。当用户第一次访问静态内容的时候，静态内存就被缓存在反向代理服务器上，这样当其他用户访问该静态内容时，就可以直接从反向代理服务器返回，加速web请求响应速度，减轻web服务器负载压力。\n\n另外，反向代理服务器也可以实现负载均衡的功能。\n\n![](/assets/images/2016/02/25/load-balancing-algorithm/006.png)\n\n由于反向代理服务器转发请求在HTTP协议层面，因此也叫应用层负载均衡。优点是部署简单，缺点是可能成功系统的瓶颈。\n\n## 参考\n\n* [图解网络硬件](http://book.douban.com/subject/25919428/)\n\n* [分布式环境中的负载均衡策略](http://codemacro.com/2014/08/25/lb-policy/)\n\n* [负载均衡调度算法](http://mp.weixin.qq.com/s?__biz=MzAxNzA1ODY2OA==&amp;mid=201368320&amp;idx=1&amp;sn=de49e9836b7c34711db41c3e789de028&amp;scene=1#rd)\n\n* [Tengine ngx_http_sysguard_module 过载保护模块使用](http://luojianlong.blog.51cto.com/4412415/1382463)\n\n* [Nginx 简单的负载均衡配置示例[原创]](http://zyan.cc/post/306/)\n\n---\n\n* 原文链接：[负载均衡算法及手段](https://segmentfault.com/a/1190000004492447)\n","tags":["Distributed"],"categories":["Distributed"]},{"title":"复制、分片和路由","url":"%2F2016%2F2016-02-24-replication-fragmentation-routing%2F","content":"\n## 序\n\n本文主要讲述分布式nosql的两大特性：复制和分片。传统数据库采用纵向Scale Up的方式，即改善单机硬件资源配置来解决问题；主流大数据存储与计算系统采用横向Scale Out的方式，支持系统可扩展性，即通过增加机器来获得水平扩展能力。\n\n对于海量数据，通过数据分片（shard/partition）来讲数据进行切分并分配到各个机器中去，数据分片后，如何能够找到某条记录的存储位置就成为必然要解决的问题，这一般称为数据路由（Routing）。\n\n对于海量数据，通过数据分片实现系统的水平扩展，通过数据复制保证数据的高可用性。\n\n数据复制除了可保证可用性之外，还可以增加读操作的效率，即客户端可以从多个备份数据中选择物理距离较近的进行读取，这既增加了读操作的并发性又可以提高单次读的读取效率。\n\n分片与复制可以组合，即同时采用主从复制与分片，则系统有多个节点，对每项数据来说，负责它的主节点只有一个。\n\n## 聚合\n\nNoSQL本质上是面向聚合操作的，也就是它将一组相互关联的对象视为一个整体单元来操作，这个单元就叫做聚合。\n\n聚合是相对于元组来说的，元组不能在元组中嵌套另外一个元组，也不能包含由值或元组组成的列表，这是传统关系型数据库的规范。其优势是在于消除数据的冗余和一致性。但是对于join操作，复杂了的话，就很无能为力。\n\n聚合的话，一方面是可以很方面的解决join操作问题的，但是其弱点是对于检索记录（不按聚合维度检索），稍微欠缺。\n\n## 数据分布的两条路径\n\n1、复制（replication）：将同一份数据拷贝到多个节点（主从master-slave方式、对等式peer-to-peer）\n\n2、分片（sharding）：将不同数据存放在不同节点\n\n如果想增加系统的读取性能，复制，增加slave节点即可；\n\n如果想提升写入性能，则对数据进行分片。\n\n## 分片\n\n一般来说，数据库的繁忙体现在：不同用户需要访问数据集中的不同部分，这种情况下，我们把数据的各个部分存放在不同的服务器/节点中，每个服务器/节点负责自身数据的读取与写入操作，以此实现横向扩展，这种技术成为分片，即sharding。\n\n理想情况下，不同的节点服务于不同的用户，每个用户只需要与一个节点通信，并且很快就能获得服务器的响应。当然理想情况比较罕见，为了获得近乎理想的效果，必须保证需要同时访问的那些数据都存放在同一个节点上，而且节点必须排布好这些数据块，使得访问速度最优。\n\n为此，必须考虑：\n\n* 1 怎样存放数据，才能保证用户基本上只需要从一个节点获取它。如果使用的是面向聚合的数据库而非面向元组的数据库，那么就非常容易解决了。之所以设计聚合这一结构，就是为了把那些经常需要同时访问的数据存放在一起。因此，可以把聚合作为分布数据的单元。\n\n* 2 另外还要考虑的是：如何保持负载均衡。即如何把聚合数据均匀地分布在各个节点中，让它们需要处理的负载量相等。负载分布情况可能随着时间变化，因此需要一些领域特定的规则。比如有的需要按字典顺序，有的需要按逆域名序列等。\n\n很多NoSQL都提供自动分片（auto-sharding）功能，可以让数据库自己负责把数据分布到各个分片，并且将数据访问请求引导到适当的分片上。\n\n分片可以极大地提高读取性能，但对于要频繁写的应用，帮助不大。另外，分片对改善故障恢复能力并没有帮助，但是它减少了故障范围，只有访问这个节点的那些用户才会受影响，其余用户可以正常访问。虽然数据库缺失了一部分，但是还是其余部分还是可以正常运转。\n\n## 路由\n\n### 路由的两级映射抽象模型\n\n1）Key-Partition映射，数据记录到分片的映射（多对一）\n\n2）Partition-Machine映射，分片到物理机器的映射（多对一）\n\n### 分片类型：\n\n#### 1）哈希分片，点查询，采用哈希函数建立Key-Partition映射（大多数KV数据库都支持此方式）\n\n通过哈希函数来进行数据分片，主要有Round Robbin、虚拟桶、一致性哈希三种算法。\n\n* A、Round Robbin\n\n俗称哈希取模算法，H(key) = hash(key) mode K（其中对物理机进行从0到K-1编号，key为某个记录的主键，H（key）为存储该数据的物理机编号）。好处是简单，缺点是增减机器要重新hash，缺乏灵活性。它实际上是将物理机和数据分片两个功能点合二为一了，因而缺乏灵活性。\n\n* B、虚拟桶\n\nmembase在待存储记录和物理机之间引入了虚拟桶，形成两级映射。其中key-partition映射采用哈希函数，partition-machine采用表格管理实现。新加入机器时，只需要将原来一些虚拟桶划分给新的机器，只要修改partition-machine映射即可，具有灵活性。\n\n* C、一致性哈希\n\n一致性哈希是分布式哈希表的一种实现算法，将哈希数值空间按照大小组成一个首尾相接的环状序列，对于每台机器，可以根据IP和端口号经过哈希函数映射到哈希数值空间内。通过有向环顺序查找或路由表（Finger Table）来查找。对于一致性哈希可能造成的各个节点负载不均衡的情况，可以采用虚拟节点的方式来解决。一个物理机节点虚拟成若干虚拟节点，映射到环状结构的不同位置。\n\n#### 2）范围分片，范围查询，BigTable、Azure采用此方式，也可以支持点查询\n\n## 复制\n\n### 主从复制\n\nmaster-slave模式，其中有个master节点，存放权威数据，通常负责数据的更新，其余节点都叫做slave节点，复制操作就是让slave节点的数据与master节点的数据同步。\n好处是：\n\n1）在需要频繁读取的情况下，有助于提升数据的访问（读取从库分担压力），还可以增加多个slave节点进行水平扩展，同时处理更多的读取请求，但是对于写操作频繁的场景，则没有什么帮助\n\n2）可以增强读取操作的故障恢复能力。万一一个slave出故障，还有其他slave支撑访问。\n\n问题：\n\n数据一致性，如果数据更新没有全部通知到slave节点，则会导致数据不一致。\n\n### 对等复制\n\n主从复制有助于增强读取操作的故障恢复能力，然而对写操作没有帮助。它所提供的故障恢复能力，只有在从节点出错时才能体现出来，master仍然是系统的瓶颈和弱点。\n\n对等复制，是指两个节点相互为各自的副本，也同时可以接受写入请求，丢失其中一个不影响整个数据库的访问。\n\n但是，同时接受写入请求，容易出现数据不一致问题，实际使用上，通常是只有一个节点接受写入请求，另一个master作为stand-by，在对方挂掉的时候自动承接写操作请求，独当一面。\n\n## 参考\n\n* [大数据系列 (一)、数据分片与路由(Hash partition and Routing)](http://blog.csdn.net/gdhuyufei/article/details/42101231)\n\n---\n\n* 原文链接：[复制、分片和路由](https://segmentfault.com/a/1190000004485355)\n","tags":["Routing"],"categories":["Distributed"]},{"title":"副本更新策略","url":"%2F2016%2F2016-02-23-replica-update-policy%2F","content":"\n## 序\n\n本文主要摘要了一些主要的副本更新策略。\n\n## 1、同时更新\n\n* 类型A：没有任何协议，可能出现多个节点执行顺序交叉导致数据不一致情况。\n\n* 类型B：通过一致性协议唯一确定不同更新操作的执行顺序，从而保证数据一致性\n\n## 2、主从式更新\n\n多个副本之间存在一个主副本（Master Replica），其他副本为从副本，这种称为主从更新策略。所有对数据的更新首先提交到主副本，再由主副本通知从副本进行数据更新。如果同时产生多个数据更新操作，由主副本决定不同更新操作的顺序。\n\n### 类型A：同步方式\n\n主副本等待所有从副本更新完成之后才确认更新操作完成，这样确保数据的强一致性，但是会存在较大的请求延时，尤其是在多副本跨数据中心的情形下，因为请求延时取决于最慢的那个副本的更新速度。\n\n### 类型B：异步方式\n\n主副本在通知从副本更新之前即可确认更新操作。假设主副本还没有通知任何其他从副本就发生崩溃，那么数据一致性可能会出现问题，一般首先在另外的可靠存储位置将这次更新操作记录下来，以防这种情况发生。\n\n* 1）所有读请求都通过主副本来响应，任意一个副本接收到读请求后转发为主副本，可以保证强一致，但是本来可以由距离近的副本响应的操作又得转发给距离较远的主副本，增加了请求延时，**_Google的Chubby采用这种方式_**。\n\n* 2）任意一个副本都可以响应读请求，请求延时大大降低，但是可能导致读不一致，因为有些副本可能还存在旧版本的数据，**_Zookeeper就是采用这种方法获得低延时，但牺牲了一致性_**。\n\n### 类型C：混合方式\n\n同步混合异步，主副本首先同步更新部分从副本，然后确认更新操作完成，其他副本通关异步方式获得更新，**_Kafka就是采用这种混合方式来维护数据副本的不一致性_**。\n\n* 1）读操作至少要从一个同步更新的节点读出，类似RWN协议的R+W&gt;N，可保证强一致性，但是请求延时加大\n\n* 2）读操作不要求一定从至少一个同步更新节点读出，那么会出现类型B的第2种不一致性情形。\n\n## 3、任意节点更新\n\n不区分主从副本，任意节点都可以接收请求，然后又它去通知其他副本进行更新。\n\n### 类型A：同步通知其他副本\n\n存在和主从更新的类型A的情况，除此之外，为了识别出是否存在不同客户端向不同副本发送对同一数据的更新操作，还需要额外付出更多的请求延时\n\n### 类型B：异步通知其他副本\n\n存在主从更新的B方式问题。\n\n**_Dynamo/Cassandra/Riak同时采取了主从式更新的类型C（同步+异步），以及任意节点更新的策略_**。\n\n## 参考\n\n* [大数据技术系列----副本更新策略](http://blog.csdn.net/ni_guang2010/article/details/48493507)\n\n---\n\n* 原文链接：[副本更新策略](https://segmentfault.com/a/1190000004480546)\n","tags":["Replication"],"categories":["Distributed"]},{"title":"2PC到3PC到Paxos到Raft到ISR","url":"%2F2016%2F2016-02-22-2pc-3pc-paxos-raft-isr%2F","content":"\n## 序\n\n本文主要讲述2PC及3PC，以及Paxos以及Raft协议。\n\n## 两类一致性(`操作原子性与副本一致性`)\n\n* 2PC协议用于保证属于多个数据分片上的操作的原子性。这些数据分片可能分布在不同的服务器上，2PC协议保证多台服务器上的操作要么全部成功，要么全部失败。\n\n* Paxos协议用于保证同一个数据分片的多个副本之间的数据一致性。当这些副本分布到不同的数据中心时，这个需求尤其强烈。\n\n## 一、2PC（阻塞、数据不一致问题、单点问题）\n\nTwo-Phase Commit，两阶段提交\n\n### 1、阶段一：提交事务请求（投票阶段）\n\n（1）事务询问\n\n协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应\n\n（2）执行事务\n\n各参与者节点执行事务操作，并将Undo和Redo信息计入事务日志中\n\n（3）各参与者向协调者反馈事务询问的响应\n\n如果参与者成功执行了事务操作，那么就反馈给协调者Yes响应，表示事务可以执行；如果参与者没有成功执行事务，那么就反馈给协调者No响应，表示事务不可以执行。\n\n### 2、阶段二：执行事务提交（执行阶段）\n\n#### （1）执行事务提交\n\n![](/assets/images/2016/02/22/2pc-3pc-paxos-raft-isr/001.png)\n\n如果所有参与者的反馈都是Yes响应，那么\n\n* A、发送提交请求\n\n协调者向所有参与者节点发出Commit请求\n\n* B、事务提交\n\n参与者接收到Commit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源\n\n* C、反馈事务提交结果\n\n参与者在完成事务提交之后，向协调者发送ACK信息\n\n* D、完成事务\n\n协调者接收到所有参与者反馈的ACK消息后，完成事务\n\n#### （2）中断事务\n\n![](/assets/images/2016/02/22/2pc-3pc-paxos-raft-isr/002.png)\n\n任何一个参与者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。\n\n* A、发送回滚请求\n\n协调者向所有参与者节点发出Rollback请求\n\n* B、事务回滚\n\n参与者接收到rollback请求后，会利用其在阶段一中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放整个事务执行期间占用的资源\n\n* C、反馈事务回滚结果\n\n参与者在完成事务回滚之后，向协调者发送ACK信息\n\n* D、中断事务\n\n协调者接收到所有参与者反馈的ACK信息后，完成事务中断\n\n#### 优缺点\n\n优点：原理简单、实现方便\n\n缺点：同步阻塞、单点问题、数据不一致、太过保守\n\n* （1）同步阻塞\n\n同步阻塞会极大地限制分布式系统的性能。在二阶段提交的执行过程中，所有参与该事务操作的逻辑都处于阻塞状态，各个参与者在等待其他参与者响应的过程中，将无法进行其他任何操作。\n\n* （2）单点问题\n\n一旦协调者出现问题，那么整个二阶段提交流程将无法运转，更为严重的是，如果是在阶段二中出现问题，那么其他参与者将会一直处于锁定事务资源的状态中，无法继续完成事务操作。\n\n* （3）数据不一致\n\n在阶段二，当协调者向所有参与者发送commit请求之后，发生了局部网络异常或协调者在尚未发完commit请求之前自身发生了崩溃，导致最终只有部分参与者接收到了commit请求，于是这部分参与者执行事务提交，而没收到commit请求的参与者则无法进行事务提交，于是整个分布式系统出现了数据不一致性现象。\n\n* （4）太过保守\n\n如果参与者在与协调者通信期间出现故障，协调者只能靠超时机制来判断是否需要中断事务，这个策略比较保守，需要更为完善的容错机制，任意一个节点的失败都会导致整个事务的失败。\n\n## 二、3PC（解决2PC的阻塞，但还是可能造成数据不一致）\n\nThree-Phase Commit，三阶段提交，分为CanCommit、PreCommit、do Commit三个阶段。\n\n![](/assets/images/2016/02/22/2pc-3pc-paxos-raft-isr/003.png)\n\n为了避免在通知所有参与者提交事务时，其中一个参与者crash不一致时，就出现了三阶段提交的方式。三阶段提交在两阶段提交的基础上增加了一个preCommit的过程，当所有参与者收到preCommit后，并不执行动作，直到收到commit或超过一定时间后才完成操作。\n\n### 1、阶段一CanCommit\n\n* （1）事务询问\n\n协调者向各参与者发送CanCommit的请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。\n\n* （2）参与者向协调者反馈询问的响应\n\n参与者收到CanCommit请求后，正常情况下，如果自身认为可以顺利执行事务，那么会反馈Yes响应，并进入预备状态，否则反馈No。\n\n### 2、阶段二PreCommit\n\n#### （1）执行事务预提交\n\n如果协调者接收到各参与者反馈都是Yes，那么执行事务预提交\n\n* A、发送预提交请求\n\n协调者向各参与者发送preCommit请求，并进入prepared阶段\n\n* B、事务预提交\n\n参与者接收到preCommit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日记中\n\n* C、各参与者向协调者反馈事务执行的响应\n\n如果各参与者都成功执行了事务操作，那么反馈给协调者Ack响应，同时等待最终指令，提交commit或者终止abort\n\n#### （2）中断事务\n\n如果任何一个参与者向协调者反馈了No响应，或者在等待超时后，协调者无法接收到所有参与者的反馈，那么就会中断事务。\n\n* A、发送中断请求\n\n协调者向所有参与者发送abort请求\n\n* B、中断事务\n\n无论是收到来自协调者的abort请求，还是等待超时，参与者都中断事务\n\n### 3、阶段三doCommit\n\n#### （1）执行提交\n\n* A、发送提交请求\n\n假设协调者正常工作，接收到了所有参与者的ack响应，那么它将从预提交阶段进入提交状态，并向所有参与者发送doCommit请求\n\n* B、事务提交\n\n参与者收到doCommit请求后，正式提交事务，并在完成事务提交后释放占用的资源\n\n* C、反馈事务提交结果\n\n参与者完成事务提交后，向协调者发送ACK信息\n\n* D、完成事务\n\n协调者接收到所有参与者ack信息，完成事务\n\n#### （2）中断事务\n\n假设协调者正常工作，并且有任一参与者反馈No，或者在等待超时后无法接收所有参与者的反馈，都会中断事务\n\n* A、发送中断请求\n\n协调者向所有参与者节点发送abort请求\n\n* B、事务回滚\n\n参与者接收到abort请求后，利用undo日志执行事务回滚，并在完成事务回滚后释放占用的资源\n\n* C、反馈事务回滚结果\n\n参与者在完成事务回滚之后，向协调者发送ack信息\n\n* D、中断事务\n\n协调者接收到所有参与者反馈的ack信息后，中断事务。\n\n阶段三可能出现的问题：\n\n协调者出现问题、协调者与参与者之间网络出现故障。不论出现哪种情况，最终都会导致参与者无法及时接收到来自协调者的doCommit或是abort请求，针对这种情况，参与者都会在等待超时后，继续进行事务提交（timeout后中断事务）。\n\n优点：降低参与者阻塞范围，并能够在出现单点故障后继续达成一致\n\n缺点：引入preCommit阶段，在这个阶段如果出现网络分区，协调者无法与参与者正常通信，参与者依然会进行事务提交，造成数据不一致。\n\n## 三、Paxos（解决单点问题）\n\n基于消息传递且具有高度容错性的一致性算法。Paxos算法要解决的问题就是如何在可能发生几起宕机或网络异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。\n\n拜占庭问题：消息不完整或者被篡改。Paxos在维持领导者选举或者变量修改一致性上，采取一种类似议会投票的过半同意机制，比如设定一个领导者，需要将此看做一个议案，征求过半同意，每个节点通过一个议案会有编号记录，再次收到此领导者的不同人选，发现已经有编号记录便驳回，最后以多数通过的结果为准。\n\n我们举个简单的例子，来阐述一下Paxos的基本思想：假设我们有5台计算机A、B、C、D、E，每台计算机保存着公司CEO的信息，现在CEO任期到了，需要进行新一界选举了。\n\nA计算机发起一个选举议案，提议CEO为“张三”，如果没有其他候选人议案，也没有网络问题，只要其中半数以上计算机收到并通过议案，那么最终“张三”当选CEO。由于是分布式环境，并发请求、机器故障、网络故障等问题是常态，如果A和E同时提交选举议案，A提名“张三”，E提名“李四”，那么肯定会涉及多计算机的一致性问题了：假设A、B、C先收到A的议案，D、E先收到E的议案，那么A继续提交给D时，D告诉它已经先收到E的议案了，因此驳回了A的请求。同样E继续提交给A、B、C时也碰到相同的问题。\n\n我们可以通过“在每台计算机同时接受议案提交时设置一个编号，编号先的通过，编号后的驳回”的方式来实现。议案提交上去后，发现A、B、C投票“张三”为CEO，D、E投票“李四”为CEO，少数服从多数，因此最后结果为“张三”当选CEO。\n\n![](/assets/images/2016/02/22/2pc-3pc-paxos-raft-isr/004.png)\n\n如果是C计算机发生了网络问题或者故障，双方投票相同，那么选举无法完成。\n\n如果C计算机发生了网络问题或者故障，A、B、D投票“张三”，E投票“李四”，那么结果为“张三”当选，而C对于这些情况一无所知，但是当C计算机恢复正常时，他会发起一个“询问谁是CEO”的议案获取最新信息。简言之，Paxos对每个节点的并发修改采取编号记录的方式保持一致性，对多个节点的并发修改采取少数服从多数的方式保持一致性。Paxos有点类似分布式二阶段提交方式，但是又不同，二阶段提交不能是多数节点同意，必须是全部同意。为了遵守过半节点同意的约束，Paxos算法往往要求节点总数为奇数。\n\nPaxos 算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个「一致性算法」以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。从20世纪80年代起对于一致性算法的研究就没有停止过。\n\n简单说来，Paxos的目的是让整个集群的结点对某个值的变更达成一致。Paxos算法基本上来说是个民主选举的算法——大多数的决定会成个整个集群的统一决定。任何一个点都可以提出要修改某个数据的提案，是否通过这个提案取决于这个集群中是否有超过半数的结点同意（所以Paxos算法需要集群中的结点是单数）。\n\n这个算法有两个阶段（假设这个有三个结点：A，B，C）：\n\n### 第一阶段：Prepare阶段\n\nA把申请修改的请求Prepare Request发给所有的结点A，B，C。注意，Paxos算法会有一个Sequence Number（你可以认为是一个提案号，这个数不断递增，而且是唯一的，也就是说A和B不可能有相同的提案号），这个提案号会和修改请求一同发出，任何结点在“Prepare阶段”时都会拒绝其值小于当前提案号的请求。所以，结点A在向所有结点申请修改请求的时候，需要带一个提案号，越新的提案，这个提案号就越是是最大的。\n\n如果接收结点收到的提案号n大于其它结点发过来的提案号，这个结点会回应Yes（本结点上最新的被批准提案号），并保证不接收其它&lt;n的提案。这样一来，结点上在Prepare阶段里总是会对最新的提案做承诺。\n\n优化：在上述 prepare 过程中，如果任何一个结点发现存在一个更高编号的提案，则需要通知 提案人，提醒其中断这次提案。\n\n### 第二阶段：Accept阶段\n\n如果提案者A收到了超过半数的结点返回的Yes，然后他就会向所有的结点发布Accept Request（同样，需要带上提案号n），如果没有超过半数的话，那就返回失败。\n\n当结点们收到了Accept Request后，如果对于接收的结点来说，n是最大的了，那么，它就会通过request（修改这个值），如果发现自己有一个更大的提案号，那么，结点就会拒绝request（拒绝修改）。\n\n我们可以看以，这似乎就是一个“两段提交”的优化。其实，2PC/3PC都是分布式一致性算法的残次版本，Google Chubby的作者Mike Burrows说过这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品。\n\n我们还可以看到：对于同一个值的在不同结点的修改提案就算是在接收方被乱序收到也是没有问题的。\n\n## 四、Raft协议(`解决paxos的实现难度`)\n\nPaxos 相比 Raft 比较复杂和难以理解。角色扮演和流程比 Raft 都要啰嗦。比如 Agreement 这个流程，在 Paxos 里边：Client 发起请求举荐 Proposer 成为 Leader，Proposer 然后向全局 Acceptors 寻求确认，Acceptors 全部同意 Proposer 后，Proposer 的 Leader 地位得已承认，Acceptors 还得再向Learners 进行全局广播来同步。而在 Raft 里边，只有 Follower/Candidate/Leader 三种角色，角色本身代表状态，角色之间进行状态转移是一件非常自由民主的事情。Raft虽然有角色之分但是是全民参与进行选举的模式；但是在Paxos里边，感觉更像议员参政模式。\n\n### 三个角色\n\nfollower、candidate、leader。\n\n最开始大家都是follower，当follower监听不到leader，就可以自己成为candidate，发起投票。\n\n### leader选举：timeout限制\n\n#### 选举的timeout\n\nfollower成为candidate的超时时间，每个follower都在150ms and 300ms之间随机，之后看谁先timeout，谁就先成为candidate，然后它会先投自己一票，再向其他节点发起投票邀请。\n\n如果其他节点在这轮选举还没有投过票，那么就给candidate投票，然后重置自己的选举timeout。\n\n如果得到大多数的投票就成为leader，之后定期开始向follower发送心跳。\n\n如果两个follower同时成为candidate的话，如果最后得到的票数相同，则等待其他follower的选择timeout之后成为candidate，继续开始新一轮的选举。\n\n### log复制\n\nleader把变动的log借助心跳同步给follower，过半回复之后才成功提交，之后再下一次心跳之后，follower也commit变动，在自己的node上生效。\n\n分裂之后，另一个分区的follower接受不到leader的timeout，然后会有一个先timeout，成为candidate，最后成为leader。\n\n于是两个分区就有了两个leader。\n\n当客户端有变动时，其中的leader由于无法收到过半的提交，则保持未提交状态。有的leader的修改，可以得到过半的提交，则可以修改生效。\n\n当分裂恢复之后，leader开始对比选举的term，发现有更高的term存在时，他们会撤销未提交的修改，然后以最新的为准。\n\n## 五、ISR的机制(`解决f容错的2f+1成本问题`)\n\nKafka并没有使用Zab或Paxos协议的多数投票机制来保证主备数据的一致性，而是提出了ISR的机制（In-Sync Replicas）的机制来保证数据一致性。\n\nISR认为对于2f+1个副本来说，多数投票机制要求最多只能允许f个副本发生故障，如果要支持2个副本的容错，则需要至少维持5个副本，对于消息系统的场景来说，效率太低。\n\nISR的运行机制如下：将所有次级副本数据分到两个集合，其中一个被称为ISR集合，这个集合备份数据的特点是即时和主副本数据保持一致，而另外一个集合的备份数据允许其消息队列落后于主副本的数据。在做主备切换时，只允许从ISR集合中选择主副本，只有ISR集合内所有备份都写成功才能认为这次写入操作成功。在具体实现时，kafka利用zookeeper来保持每个ISR集合的信息，当ISR集合内成员变化时，相关构件也便于通知。通过这种方式，如果设定ISR集合大小为f+1，那么可以最多允许f个副本故障，而对于多数投票机制来说，则需要2f+1个副本才能达到相同的容错性。\n\n## 参考\n\n* [分布式系统的Raft算法](http://www.jdon.com/artichect/raft.html)\n\n* [英文动画演示Raft](http://thesecretlivesofdata.com/raft/)(推荐)\n\n* [paxos-by-example](https://angus.nyc/2012/paxos-by-example/)\n\n* [为啥CoreOS没用Paxos，重新搞了Raft？](http://chuansong.me/n/1019861)\n\n---\n\n* 原文链接：[2PC到3PC到Paxos到Raft到ISR](https://segmentfault.com/a/1190000004474543)\n","tags":["BASE"],"categories":["Distributed"]},{"title":"从ACID到CAP到BASE","url":"%2F2016%2F2016-02-21-acid-cap-base%2F","content":"\n## 序\n\n本文主要讲述分布式系统开发的一些相关理论基础。\n\n## 一、ACID\n\n事务的四个特征：\n\n### 1、Atomic原子性\n\n事务必须是一个原子的操作序列单元，事务中包含的各项操作在一次执行过程中，要么全部执行成功，要么全部不执行，任何一项失败，整个事务回滚，只有全部都执行成功，整个事务才算成功。\n\n### 2、Consistency一致性\n\n事务的执行不能破坏数据库数据的完整性和一致性，事务在执行之前和之后，数据库都必须处于一致性状态。\n\n### 3、Isolation隔离性\n\n在并发环境中，并发的事务是相互隔离的，一个事务的执行不能被其他事务干扰。即不同的事务并发操纵相同的数据时，每个事务都有各自完整的数据空间，即一个事务内部的操作及使用的数据对其他并发事务是隔离的，并发执行的各个事务之间不能相互干扰。\n\nSQL中的4个事务隔离级别：\n\n（1）读未提交\n\n允许脏读。如果一个事务正在处理某一数据，并对其进行了更新，但同时尚未完成事务，因此事务没有提交，与此同时，允许另一个事务也能够访问该数据。例如A将变量n从0累加到10才提交事务，此时B可能读到n变量从0到10之间的所有中间值。\n\n（2）读已提交\n\n允许不可重复读。只允许读到已经提交的数据。即事务A在将n从0累加到10的过程中，B无法看到n的中间值，之中只能看到10。同时有事务C进行从10到20的累加，此时B在同一个事务内再次读时，读到的是20。\n\n（3）可重复读\n\n允许幻读。保证在事务处理过程中，多次读取同一个数据时，其值都和事务开始时刻时是一致的。禁止脏读、不可重复读。幻读即同样的事务操作，在前后两个时间段内执行对同一个数据项的读取，可能出现不一致的结果。保证B在同一个事务内，多次读取n的值，读到的都是初始值0。幻读，就是不同事务，读到的n的数据可能是0，可能10，可能是20\n\n（4）串行化\n\n\n最严格的事务，要求所有事务被串行执行，不能并发执行。\n\n\n如果不对事务进行并发控制，我们看看数据库并发操作是会有那些异常情形\n\n* （1）一类丢失更新：两个事物读同一数据，一个修改字段1，一个修改字段2，后提交的恢复了先提交修改的字段。\n* （2）二类丢失更新：两个事物读同一数据，都修改同一字段，后提交的覆盖了先提交的修改。\n* （3）脏读：读到了未提交的值，万一该事物回滚，则产生脏读。\n* （4）不可重复读：两个查询之间，被另外一个事务修改了数据的内容，产生内容的不一致。\n* （5）幻读：两个查询之间，被另外一个事务插入或删除了记录，产生结果集的不一致。\n\n### 4、Durability持久性\n\n一个事务一旦提交，它对数据库中对应数据的状态变更就应该是永久性的，即使发生系统崩溃或机器宕机，只要数据库能够重新启动，那么一定能够将其恢复到事务成功结束时的状态。\n\n## 二、CAP定理\n\n一个分布式系统不可能同时满足一致性Consistency、可用性Availability、分区容错性Partition tolerance这三个基本需求，最多只能同时满足其中的两项。\n\n### 1、一致性\n\n分布式环境中，一致性是指多个副本之间能否保持一致的特性。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处理一致的状态。\n\n### 2、可用性\n\n系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。\n\n* （1）有限时间内\n\n对于用户的一个操作请求，系统必须能够在指定的时间（响应时间）内返回对应的处理结果，如果超过了这个时间范围，那么系统就被认为是不可用的。即这个响应时间必须在一个合理的值内，不让用户感到失望。\n\n* （2）返回正常结果\n\n要求系统在完成对用户请求的处理后，返回一个正常的响应结果。正常的响应结果通常能够明确地反映出对请求的处理结果，即成功或失败，而不是一个让用户感到困惑的返回结果。比如返回一个系统错误如OutOfMemory，则认为系统是不可用的。\n\n### 3、分区容错性\n\n即分布式系统在遇到任何网络分区故障时，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。\n\n网络分区，是指分布式系统中，不同的节点分布在不同的子网络（机房/异地网络）中，由于一些特殊的原因导致这些子网络之间出现网络不连通的状态，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干孤立的区域。组成一个分布式系统的每个节点的加入与退出都可以看做是一个特殊的网络分区。\n\n## 三、CAP的应用\n\n### 1、放弃P\n\n放弃分区容错性的话，则放弃了分布式，放弃了系统的可扩展性\n\n### 2、放弃A\n\n放弃可用性的话，则在遇到网络分区或其他故障时，受影响的服务需要等待一定的时间，再此期间无法对外提供政策的服务，即不可用\n\n### 3、放弃C\n\n放弃一致性的话（这里指强一致），则系统无法保证数据保持实时的一致性，在数据达到最终一致性时，有个时间窗口，在时间窗口内，数据是不一致的。\n\n对于分布式系统来说，P是不能放弃的，因此架构师通常是在可用性和一致性之间权衡。\n\n## 四、BASE定理\n\nBasically Available（基本可用）、Soft state（软状态）、Eventually consistent（最终一致性），基于CAP定理演化而来，核心思想是即时无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。\n\n### 1、Basically Available（基本可用）\n\n  基本可用是指分布式系统在出现不可预知的故障的时候，允许损失部分可用性，但不等于系统不可用。\n\n（1）响应时间上的损失\n\n   当出现故障时，响应时间增加\n\n（2）功能上的损失\n\n   当流量高峰期时，屏蔽一些功能的使用以保证系统稳定性（服务降级）\n\n\n### 2、Soft state（软状态）\n\n与硬状态相对，即是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。\n\n### 3、Eventually consistent（最终一致性）\n\n强调系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。其本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。\n\n最终一致性可分为如下几种：\n\n* （1）因果一致性（Causal consistency）\n即进程A在更新完数据后通知进程B，那么之后进程B对该项数据的范围都是进程A更新后的最新值。\n\n* （2）读己之所写（Read your writes）\n进程A更新一项数据后，它自己总是能访问到自己更新过的最新值。\n\n* （3）会话一致性（Session consistency）\n将数据一致性框定在会话当中，在一个会话当中实现读己之所写的一致性。即执行更新后，客户端在同一个会话中始终能读到该项数据的最新值\n\n* （4）单调读一致性（Monotonic read consistency）\n如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。\n\n* （5）单调写一致性（Monotoic write consistency）\n一个系统需要保证来自同一个进程的写操作被顺序执行。\n\nBASE定理是提出通过牺牲一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。\n\n## 其他\n\n待补充\n\n## 参考\n\n* [从Paxos到Zookeeper : 分布式一致性原理与实践](http://book.douban.com/subject/26292004/)\n\n---\n\n* 原文链接：[从ACID到CAP到BASE](https://segmentfault.com/a/1190000004468442)\n","tags":["BASE"],"categories":["Distributed"]},{"title":"High Availability启示录","url":"%2F2016%2F2016-02-14-high-availability-revelation%2F","content":"\n最近对HA（High Availability，以下简称HA）有些感想，在此以一个理工男的视角将其记录下来，希望能以飨读者。\n\n很多年以前，HA是个高大上的东西，只有一些大公司或关键业务才会使用。随着技术的演进，HA已变成了现代网络服务的必备。\n\n相信很多人一定了解HA的基本原理，但似乎也讲不出道道来，那就可以继续读下去。如果看官你对HA已经很精通了，那可直接跳到后记看启示录。\n\n![](/assets/images/2016/02/14/high-availability-revelation/001.jpeg)\n\n在探讨HA之前需要搞清下面几个概念或术语。\n\n## 术语\n\n### RAS\n\nRAS是三个词的缩写，即：\n\n*   可靠性（Reliability）\n\n*   可用性（Availability）\n\n*   可服务性（Serviceability/Maintainability）\n\nRAS起源于IBM对其主机质量的定义。详细定义可以参考wiki词条：http://en.wikipedia.org/wiki/Reliability,_availability_and_serviceability_(computing))。 \n\n可靠性用来定义指定时间内系统可靠程度，用MTBF（即平均故障间隔时间）来度量，MTBF表示平均无故障间隔时间，是指两次故障修复之间的平均时间。\n\n介绍可用性之前先看几个相关度量：\n\n#### MTTF， MTTR\n\nMTTF(mean-time-to-failure) 为平均无故障时间，即系统正常运行的时间。\n\nMTTR(mean-time-to-repair) 为平均故障恢复时间，即系统修复故障的平均时间。\n\nMTBF = MTTF + MTTR，对不能修复的故障用MTTF，对可修复的故障用MTBF，由于MTTR都远小于MTTF，所以MTBF约等于MTTF。\n\n可用性定义为： MTTF/(MTTF+MTTR)\n\n可用性用来描述系统在指定时间内可以正常工作的时间比例，通常用几个9来表示，如下图所示：\n\n![](/assets/images/2016/02/14/high-availability-revelation/002.jpeg)\n\n一般来说，HA就是指5个9，要做到6个9及以上的要求，所花费的代价会大幅增长。\n\n可服务性用来描述系统出问题时被修复的速度。由于这个时间会影响可用性，所以越快修复则系统可用性越大。\n\n可靠性和可用性在字面上理解感觉很相似，但是有区别的，可靠性一般与安全有关，可用性一般与用户体验有关。系统或许是可用的，但并不一定是可靠的。举例来说，一个系统可能从不宕机，但运行时数据经常发生损坏。\n\n不同系统对二者要求是不同的，例如对那些航空航天产品，可靠性要求就很高，可用性肯定次之，相反对于手机等民用产品可用性要求就比可靠性高些，飞机不可靠的话，道理你懂的。可靠性的增加会显著增加费用，如果手机做成象飞机那么可靠，费用就不是一般高了， 用户肯定也接受不了，再说也没有必要，大不了换个手机，而手机可用性不好会更影响用户情绪。\n\n现在RAS概念被用来评估一个系统，或一个软件层面，单纯强调一个特性没有意义。一个实际的系统应该根据应用场景在RAS和成本方面进行折中。\n\n### HA\n\nHA即 High Availability，顾名思义是高可用性。相应词条可见wiki: <span style=\"line-height:25.6px;\">http://en.wikipedia.org/wiki/High_availability\n\nHA是一个系统层面的概念，不是指单个节点。\n\nHA只是一个指标，即达到几个9以上才能称为高可用性，并没有规定具体系统的实现模板，细节等，但我这篇文章不只是谈HA这个指标，而是从概念，层次等各个方面来阐述HA系统。\n\n这里高可用性中的“高”是个相对概念，既然有高，那也应该有低可用性，很高可用性，极高可用性，有专家将这些等级做了个划分，如下图所示：\n\n![](/assets/images/2016/02/14/high-availability-revelation/003.jpeg)\n\n需要指出的是，目前HA一般指5个9，但这里的级别也是随着技术进步，软/硬件稳定性提高不断提高的，在未来或许5个9以上都是标配了。\n\n既然有HA，那肯定也有HR（High Reliability），即高可靠性，在涉及安全的领域也有很多相关标准，我这里不打算详细介绍（主要是没深入研究），只提几点：\n\n1.  串行部件组成的系统的可靠性是由可靠性最低的部件决定的。\n\n2.  并行部件组成的系统的可靠性是所有部件的可靠性乘积。\n\n3.  系统的可靠性是可以通过子系统的冗余来提高。\n\n4.  软件的可靠性是可以通过加强测试来提高。\n\n5.  硬件的可靠性的提高会显著提高成本。\n\n在现实生活中，HA系统也是比比皆是，比如有4个引擎发动机的大型飞机，就是一个HA系统，一个发动机坏了也不至于飞机失去动力而坠毁。当前各种分布式计算架构，存储架构也都是HA系统，包括我们人自身更是一个复杂的HA系统，单个细胞可以随便死去，我们人体可以生成新细胞来替换老细胞。\n\n所以HA系统的主要思想是通过对不可靠的单节点冗余来换取整体系统的稳定可用。\n\n世界本是虚实之间，虚的东西比如理想，比如精神都是很完美的，无故障，无错误的，实的东西就刚好相反，不完美，不可靠，有很多问题。针对于HA的节点来说也是一样不完美，不可靠，HA的意义就在于通过运行一套拥有冗余节点的系统，来对抗单个节点的不可靠，对外提供一个看起来比较完美的虚的接口，从而来提高整个系统的可靠性，可用性和可服务性（或叫可维护性）。\n\n不要说你发明了HA系统，这些都是大自然给我们的提示，也不要说你发现了HA系统，你有没有发现，它都在那里，不增不减。我们所做的都是在模仿大自然杰作而已。\n\n### HA三原则\n\n*   消除单节点故障\n\n*   互联可靠\n\n*   故障检测\n\n一个HA系统必须满足上面三个基本原则，否则就不可能被称为一个HA系统。\n\n第一条，消除单节点故障是指，系统必须提供节点冗余，这也意味做单节点不可能是HA系统。\n\n第二条，互联可靠是指，节点之间，节点和外界之间的连接必须是可靠的，这些连接本身不能存在单点故障。\n\n第三条，故障检测是指，系统必须能够检测到节点的故障，从而做出必要处理。\n\n### Fault Tolerance\n\nFault Tolerance系统是指系统在处理故障方面的能力程度。从系统层面来说，HA系统就是一个Fault Tolerance系统，但Fault Tolerance系统则不一定是一个HA系统，因为它更强调的是系统对故障的预估及处理能力。比如一个正在运行的进程，正常运行没有问题，但可能会遇到很多意外事件，比如磁盘满，网络断，用户输入buffer越界等，如果没有预估到这些事件，则可能会导致故障，那么这个程序就不是一个Fault Folerance很好的程序。\n\n另外Fault Tolerance系统早期常多用于硬件设计，我们这篇文章主要是探讨现代网络服务系统多着眼于系统。\n\nFault Tolerance字面可译作故障容忍，可以说其HA系统成败之关键，鉴于其重要性，早在1985年，IEEE的IFIP专家组就对Fault Tolerance做了深入研究，这些专家们就“Dependable Computing and Fault Tolerance”提出了一系列概念，这些概念不断演进和扩充，如今便有了下面这些所谓概念框架：\n\n![](/assets/images/2016/02/14/high-availability-revelation/004.jpeg)\n\n这些专家将Fault Tolerance概念整体纳入可信赖计算（Dependable Computing）范畴，并从三个角度来定义/度量可信赖计算，这三个角度分别是：\n\n1.  可信赖计算面临的威胁\n\n这些威胁可进一步定义为：缺陷(fault),错误（error),故障（failure，我觉得翻译成故障比失败更贴近中文一点）\n\n这些概念就是这样一环套一环的： 缺陷 --&gt; 错误 --&gt; 故障\n\n这些东东放到下面这个图中就比较容易理解了：\n\n![](/assets/images/2016/02/14/high-availability-revelation/005.jpeg)\n\n图中可以看出，当一个缺陷导致了错误，这个错误又导致故障发生，从而中断了正常的服务状态，而这个故障经过了一个延时后又被检测到了，并被修复了，最后服务又回到正常状态。\n\n*   **缺陷**比较好理解，就是模块，部件，人员等本身的问题，或由这些导致的问题，例如硬件缺陷，设计缺陷，人工操作，环境问题。\n\n*   **错误**难理解一点，错误被定义为上述缺陷导致的结果,是系统的一个状态。比如软件中有个野指针，这是一个缺陷，如果用这个野指针访问了一个内存便会导致一个错误。\n\n*   **故障**被定义为错误导致的结果，接上面例子，如果有个野指针访问了某个内存，而又没有通过异常处理机制捕获，则程序会出错导致非正常退出，这个错误最后造成一个软件服务故障。当然如果你能在其他模块中检测到这个故障，并且能够修理就是一个基本的Fault Tolerance系统了。\n\n构建可信赖计算的方法\n\n故障可以通过两种方法来消除，这两种方法分别是： 构建（Contruction，之前也被称为Procurement）, 验证（Validation）。这两种方法也分别对应于模块/组件的两个阶段：\n\n*   **构建**对应于模块/组件的构建阶段，在这个阶段又可以通过两种方法来处理故障，即故障避免(Fault avoidance)和故障容忍(Fault tolerance)。前者比较好理解，就是在软/硬件实现阶段将各种故障原因都考虑进去，并进行规避。后者则涉及到软/硬件的兼容性问题，比如后续版本对以前版本的兼容就可以避免此类故障。\n\n*   **验证**对应于模块/组件的运行阶段，在这个阶段可以做的事件有两种，第一种是故障消除（Fault Removal）,即出了问题后怎样想办法消除它，基本上属于事后补救。第二种是故障预测(Fault forecasting),即将故障扼杀在摇篮中，基本上属于事前预防。\n\n可信赖计算的的属性\n\nIFIP专家最早只提到两个属性，即Availability和Reliability,但到现在为止已经扩充到6种属性，即：\n\n可以看出，这些属性已经覆盖了之前提的RAS，这些属性都有相应公式进行度量，我在此就不展开了，有兴趣的可以谷哥或度娘。搞懂后就可以出去Zhuangbility了。\n\n*   Availability\n\n*   Reliability\n\n*   Safety\n\n*   Confidentiality\n\n*   Integrity\n\n*   Maintainability\n\n以上提到概念的只是可信赖计算概念的一小部分，也是很基础的一部分，里面还有很多门道，这里抛个砖，有兴趣的可以进一步学习，抛块玉给我。\n\n解释了这么多Fault Tolerance，可以看出专家与普通人的区别了吧：能对我们都知道的东西归个类，下个定义，用公式描述一下就是专家，否则就是路人甲。呵呵，只是逗比一下，专家也是真心不那么容易的，想象一下著名的CAP理论不也是在三个词之间玩文字游戏么？你心里就会说，why didn't I think of that? 就是啊，why? 因为你还没有打通任督二脉，还不是专家嘛。\n\n### Failover\n\nFailover字面意思是失效转移，这是HA的一项简单的容错功能，在早期简单的HA系统一般是AS(A: Active，S: Slave)双节点结构，即一主一备，两个节点之间通过一个串口或网线作为心跳线互相连接，平时只有Active节点工作，心跳断了后，主节点不管正不正常，都自动关闭，备份节点自动接管，并且升级为主节点，从而保持系统正常运行。当失效节点修好重新集成进来后，仍然保持为从节点。这样的切换过程被称为Failover。\n\n当然也有AA模式的双节点结构，这种情况下两个节点都可以同时工作，并且还可以做load Balance，但一般都用在轻量级状态同步，Failover系统主要是以容错功能为主。\n\n### LB\n\nLB是Load Balance，即负载均衡。这个其实HA系统的一个性能方面扩充，有些系统没有LB功能，但仍然可以做到5个9。LB的作用主要是提高系统的性能，LB本身也是一个值得大费笔墨的东西，这里先不展开，后面会阐述各种HA + LB的模式。\n\n## HA系统组成\n\n前面说了，HA系统种类很多，比如硬件类，像处理器HA，物理网络镜像，RAID0，cluster computing等等，实现形式也各不相同，这里我只讨论网络服务的HA系统（后面所说的HA系统都是指网络服务HA系统），并总结一下其基本组件及各种实现模式。\n\n现代HA系统几乎都有LB功能，一个重要原因是单个模块的可靠性相比以前有很大提高，如果仅做为备份则是很大的浪费。\n\n为了更好的描述HA系统，我画了一个2节点的HA网络服务架构图：\n\n![](/assets/images/2016/02/14/high-availability-revelation/006.jpeg)\n\n图中可以看出，每个节点都有通信模块，控制模块，状态管理模块。而每个节点的同样模块构成了HA系统的一个层，按照功能，HA系统可以简单的分为四个层：\n\n*   节点层\n\n*   网络层\n\n*   控制层\n\n*   业务层\n\n节点层是一个独立的节点，可以是物理节点，比如一个PC，也可以是逻辑节点，比如一个进程。但从HA实施来说，最好是物理上独立的节点，这样不会产生依赖，从而导致单点故障。\n\n网络层主要实现对外的虚接口，比如VIP。同时完成节点之间通信。很多现代的HA网络服务不单会提供HA服务，同时也兼顾性能，一般是HA + LB的混合体，即在HA基础之上会提供LB功能，LB功能一般是在HA组件的网络层提供，在实现方式上可能会有一个单独模块来进行流量调度，也可能是由节点之间互相协调流量调度，后面会对这部分详细介绍。\n\n控制层主要实现节点状态探测，失效接管，集成等功能，即Fault Tolerance。\n\n业务层主要是维护业务方面的状态一致性，业务状态是指节点上运行的服务本身的状态，这部份状态只跟这个节点上运行的服务相关，跟其他节点没有关系，即具有局部性，就像是个局部变量一样。业务层需要维护所有节点的业务状态的一致性，以便当某节点失效时，其他节点能从这个失效时的状态开始顺利的接管业务。这个如果节点没有业务状态，则这层可以不用实现。\n\n### HA分层\n\n上面提到HA系统一般会分为四层，但根据实际情况，有些层可能不需要或者会大幅简化，比如，如果是无状态系统，则业务层基本上就只需要关注自身业务就可以了。\n\n同时每个层的部署位置也可能不尽相同，比如，有些系统的业务层中的状态可能会下沉到一个独立的系统里，而不是分布在每个节点上，例如一些数据库系统可能将数据库放在SAN网络上，这样每个节点就不需要业务状态维护了。\n\n还有些系统需要更好的性能，可能会单独设立一个流量调度单元来完成。再比如，有些系统的控制层会将大部分逻辑放到另外一个子HA系统进行处理，而各节点的控制层作为客户端来与这个子HA系统进行交互。\n\n#### 节点层\n\n节点是HA服务的容器，HA服务对外是虚拟的，但最终会在某个节点上落地。节点必须为运行该服务提供合适的环境。\n\n节点之间是物理独立的，独立的目的就是要提供物理层面的冗余。上面说过了，节点也可以虚拟节点，比如在同一物理机上运行多个VM，然后在这些VM中运行服务，那么这些VM就是虚拟节点。但由于这些VM共同运行在一个物理机上，物理机down掉后所有这些VM节点会一起down，这样就违背了HA的第一条原则，即节点之间不存在单点故障。所以如果虚拟节点之间存在共同依赖关系时，这样就不可能成为一个完备的HA系统。但如果这些VM都运行在不同的物理机上时，便没有依赖关系，这样的HA系统便是完备的。\n\n此外节点之间的网络互联也是必须要考虑的，这里的互联是指物理层，包括逻辑层的互联。我将其划归节点层的目的是，这层是提供物理上的冗余，单个节点的冗余还不够，网络层面也必须有多路径冗余。\n\n#### 网络层\n\n这里网络层是指软件层面的网络服务。网络层主要有如下责任：\n\n*   实现虚接口\n\n*   节点通讯\n\n*   流量调度\n\n##### **虚接口**\n\n虚接口是HA系统非常重要的组成部分，虚接口主要作用是向外部提供一个访问接口，从而将内部实现与外部环境分隔开来，避免暴露内部实现细节，这也是软件设计的一个基本原则。其实现方式可以直接决定HA系统可用性。\n\n从概念上讲，接口一般是数据流集中汇聚之地，如果为HA设计一个集中的接口来转发外部请求，对软件设计来说是很方便的，貌似也可以。但别忘了，这种设计与HA系统基本原则相矛盾，如果这个接口挂掉了，那么整个HA系统就崩溃了，所以这种设计就不能称为HA系统，即使后端的处理节点可能是物理独立的。所以这里之所以称其为虚接口，就是因为对外部来说，用户访问的逻辑形式是集中的，但在内部实现时却是分散的，即最后实现时会在某个具体节点上落地。这样的虚接口才能满足HA系统要求。\n\n常见的虚接口形式有VIP(virtual ip), DNS, RPC，虚拟网络文件系统等。具体采用哪种形式应根据业务需求。现实实现时，由于有些功能是所有节点共有的，所以有时也会将这个虚接口单独作为一层来处理，此时，这层本身也可以是一个HA系统，所有外部请求将由这层来转发到实际处理的节点。例如lvs，分布式文件系统的meta节点等。\n\n###### **VIP**\n\nVIP是一种很常见的虚接口，在针对ip服务时几乎是标配，实现方式也有多种：\n\n*   **基于VRRP协议** VRRP协议通过为一个IP设置一个或几个备份下一跳路由的方法来构建VIP，当某个拥有VIP节点失效后，备份节点被接管，VIP被添加，下一跳路由会替换，从而新节点可以通过VIP进行通信。使用VRRP实现的VIP每次只会在一个节点落地，这就限制了其作为LB的功能，即如果业务是跟IP绑定的，则该业务同一时刻只能在一个节点处理，无法在其他不拥有这个IP的其他节点之间进行负载均衡。但VRRP比较简单可靠，同时实现了HA系统的节点探测，接管，迁移等事件，在HA系统要求不高的情况下，简化了HA系统的设计。\n\n*   **基于OSPF协议** 基于OSPF协议的VIP需要在每个节点上预先设置好同样的VIP，并且在每个节点上运行quagga的ospfd进程，其将邻居关系报告给ospf三层交换机，同时可以在三层交换机上设置到这些节点ospf cost值，如果这些节点的cost值相同，则三层交换将会对所有发达这些VIP的包进行负载均衡，否则只发到cost最低的节点。ospf三层交换机通过hello包来探测与之相连的节点，如果在所设的dead时间内，没有回应则会断掉路由，将流量切换到另一个备用节点。这种方案的优点是如果服务是无状态的，则做负载均衡很方便，但做HA系统的话，仍然需要各个节点自己来探测节点状态做故障容忍，否则其他节点无法知道这个节点失效信息。还要注意的是，由于ospf的节点失效消息跟HA系统自己的故障探测可能会有时差，并且接管节点也可能不一致，这样会导致这这种情况的发生： 1） ospf路由器已经将失效节点的流量信息切换到有效节点，但HA的故障探测并没有将该有效节点作为takeover节点，这就会导致严重问题。所以必须要求ospf的takeover 节点和HA的takeover节点必须一致。 2） ospf路由器先将流量切换到了有效的takeover节点，但由于HA系统的故障探测有延迟，HA系统还没有检测到故障节点，这样实际的HA系统的takeover节点还没有准备好处理新切换过来的流量，从而导致出错。所以为了处理这个问题，需要HA系统的takeover节点能够容忍这个时差。\n\n*   **基于clusterip** clusterip是通过iptables的模块实现的。这个方案通过为每个节点设置同一个clusterip作为VIP，并且在每个节点上为这个VIP设置同样的MAC地址（所有节点回包以这个MAC作为源地址），同时为每个节点设置一个节点号(node_number)，发到这个VIP的包所有节点都能收到，每个节点根据算法：hash(sourceip)%node_number来判断是否是自己的包，是就处理，否则丢弃。这个方案的优点是简单，无需更改路由。缺点是仍然要自己维护HA节点状态，同时由于每个包都同时发到所有节点，对系统整体性能有很大影响。\n\n*   **基于LVS** 这个想必阿里人都很熟，优点多多不再费口舌，我要说的是虽然其LB功能强，但其Director服务器本身就是单点故障，所以要做HA系统的话，首先要对Director进行HA改造。\n\n###### **DNS**\n\nDNS是另一种基于名字解析的虚接口，应用非常广泛，几乎所有大型网站都有基于DNS的HA实现，这里就不展开解释了。\n\n###### **其他虚接口**\n\n有些服务比如中间件，会用RPC作为虚接口，客户端不直接与后端服务打交道，而是先查询RPC服务器来列举后端有哪些可可供调用的服务，然后直接来调用。\n\n虚拟网络文件系统也是一种虚接口，通过元数据服务器来提供虚拟文件系统，文件系统空间由元数据服务器来管理，真实服务器不管理文件系统空间，客户端通过元数据服务器来操作文件系统，而由元数据服务器来提供真正的数据服务器，数据服务器之间互相备份，单个数据服务器宕机不会导致真个文件系统崩溃。典型的例子是google 的GFS。\n\n##### **节点通讯**\n\n对HA节点来说，相互之间通讯是必须的，无论有无LB功能，有无状态。这个功能可以很大也可以很小。最简单的通讯可以通过心跳实现，两个节点之间通过心跳协议交换状态。复杂系统可能会针对通讯构建更复杂的子模块。值得注意的是，通讯部分有很多故障源，就像前面提到过的一样，这些子模块也必须要提高故障容忍性。\n\n对于心跳协议这里再多说几句，心跳协议多用在双机热备上，即上面提到的failover模式。心跳协议主要用来在两个节点之间相互探测对方状态，可以通过串口线互联，也可以通过网线互联，值得注意的是，无论是串口线还是网线互联，如果只是单线连接很容易会产生**脑裂问题**，所谓**脑裂问题**就是，当心跳线断开后，双方节点无法知晓对方状态，都以为对方出了故障，从而出现对资源的争抢，导致系统混乱。\n\n脑裂问题发生的主要原因是，这个节点之间单线互联的心跳线违背的HA三原则，存在单点故障问题，所以要解决这个问题，可以采用双线互联，或采用另外一条辅助心跳线。\n\n##### **流量调度**\n\n就像之前提到的一样，我这里所提到的HA系统是指网络服务HA系统，涉及到网络服务一般都需要流量调度功能，这也基本上是标配。\n\n这里流量调度可以简单分为正常调度和异常调度两类：\n\n先说异常调度，其是指当某节点异常时，系统需要将流量调度到正常节点上继续处理，这是故障容忍功能的一部分。不同虚接口，不同架构会有不同的实现方式。对于vrrp或ospf实现的vip接口，流量调度主要是通过改变路由器和节点的路由表来实现异常流量调度，而lvs + NAT方式则通过一个控制节点来实现异常流量调度。\n\n对于正常调度，它主要是指Load Balance。Load Balance与HA结合是很自然的事情，一是单节点可用性比较高，如果仅用来作为备份节点实在是浪费。二则LB的很多事件跟HA相重叠，比如当进行流量调度时，需要探测节点状态，三则HA性能的横向扩展离不开LB。而影响LB性能指标的一个重要因素就是流量调度。具体到不同业务可以采用N多调度算法，这些算法有些也被广泛用在操作系统中对线程的调度，简单点的有直接对五元组hash（很多交换机甚至网卡也都支持，也有人将这种hash算法不叫LB，而叫LS(load sharing)），复杂点的有FIFO，时间片轮转，公平队列等，更复杂的有对QoS等进行评估，对流量进行统计等。所有这些算法都围绕一个主题：公平。但公平这事大家都懂的，你所追求的正是你所缺少的，流量调度也难有绝对公平，所以算法无非都是在时间和空间两个方面玩平衡。\n\n具体有哪些算法请大家自行脑补吧，在此不一一列举。\n\n#### 控制层\n\n控制层是HA系统最重要的组件，它直接关系到HA的可用性问题。\n\n就像Fault Tolerance节谈到的一样，控制层需要在构建和验证两个环节来消除/避免故障。这层可以做成Failover的简单方式，也可做成象hadoop的zookeeper那样的复杂系统。但无论实现简单还是复杂都是为了解决故障处理问题，性能问题。跟上节讲的一样，现在的HA系统实现都将LB集成在一起，但逻辑上讲控制层只负责故障处理，即Fault Tolarence。\n\n控制层之所以难搞要归结于HA系统的组成，前面提到过HA系统三原则要求之一是，节点之间需要互相独立，独立就是要民主嘛，而失败的民主就是一盘散沙，更难管理了。大家都知道，对软件问题来说，专制方式是最容易处理的，用一个皇帝节点来统管其他草民节点，简单粗暴也很有效。但专制的问题是这个皇帝节点如果出问题了，江山就倒了。所以矛盾就产生了，牛人的解决方案就粉墨登场了，道理也很简单，基本上是在民主方案基础上在多搞几个皇帝节点来个组团成一个皇帝委员会，同时委员会内皇帝节点之间也搞民主来选一个真正的领导，所有委员会内皇帝节点对外只呈现一个虚拟皇帝，所有草民节点都听这个虚拟皇帝的话，这样任何一个皇帝死掉，委员会内部立马民主选一个新皇帝来顶上，而草民节点看不到这个皇宫内部争斗大戏，仍然在听从那个虚拟节点的领导。草民节点死掉更简单了，皇帝节点会首先知晓，然后按实现事先设定好的规则来处理，该替换就替换，该公告就公告，如此这般江山社稷就稳固了。所以搞到最后，诸位可以看到，控制层本身就是一个HA系统了。\n\n但无论怎么实现，一个完备控制层要处理以下几个事情：\n\n*   故障检测\n\n    这是必须的，任何节点的故障需要被尽快被发现，然后被处理，不能让单节点故障在系统中扩散，也不能让其中断业务。\n\n*   节点接管\n\n    接管属于故障处理部分，这个步骤也需要尽快完成，以避免业务中断。\n\n*   状态同步\n\n    节点之间的状态应该互为备份，当某个节点出故障时，其他节点应该有其状态信息的拷贝。\n\n*   状态迁移\n\n    当接管节点准备好后，失效节点的状态能够顺利迁移到接管节点。\n\n*   节点集成\n\n    当新节点加入HA系统时，其他节点能够感知其存在，并且将自身状态信息同步到新节点。\n\n需要指出的是，以上这些步骤虽然属于控制层，但有时业务层也需要感知，比如业务是数据库，当节点失效时，数据库数据有可能出现不一致情况，此时控制层要将以上这些事件传递给数据库系统，数据库系统然后可以根据故障信息将数据恢复到以前的checkpoint.\n\n#### 业务层\n\n业务层的任务是运行具体的服务，有两种形式的服务，一种是带状态的，另一种是不带状态的。所谓状态是指服务运行过程中产生的能够影响服务运行的一些数据。比如tcp会话中的各种会话状态，数据库的session等等。由于这些数据是由业务来定义，所以需要业务层来处理。对不带状态的业务来说，处理起来就容易多了，这种情况下，无需状态同步，错误处理，节点集成，接管都很容易，每个节点都变成来料加工工厂，招之即来，挥之即去。一些AS/AA结构交换机正是通过这样的failover形式构造HA系统。\n\n对带状态的业务，业务层除了关注自身业务外，还需要关注状态同步，状态数据的一致性问题。有些复杂系统还会有作业调度系统，这个不是普通的LB，而是包括计算和数据在内的综合调度，比LB更优化了。\n\n依赖具体的业务不同，状态同步有时会变得很麻烦，甚至难以处理，比如ipsec HA中的包序号同步问题，这个序号是ipsec协议用来抗重放攻击的，每发送一个加密包这个序号会加1，这个序号就是一个状态数据，必须要同步到其他节点，以防这个节点失效后，其他节点能够从这个序号开始继续发送加密包，否则对端ipsec vpn服务器可能会将收到的包丢弃。现在的问题是，如果每次序号变化都同步到其他节点，隧道多的话，这会导致状态同步代价太高，性能大打折扣。不过幸好ipsec rfc提供了一个补救措施，即ipsec抗重放窗口可以接收比窗口右边沿大的序号，这样就可以不用连续同步序号，而是以一个步长的方式来同步了。但即使是这样，ipsec的ike协商阶段状态仍然没有被同步，因为这个阶段状态太多，变化太迅速，而且涉及内部太多数据结构，目前的方案是，由于这些状态只发生在一个独立节点上，如果该节点失效，其他节点接管时重新初始化这些连接即可。这里只给出ipsec HA作为例子说明状态同步问题，其他业务在实施HA之前必须要考虑到状态同步问题，可以采用的方案也比较多，像checkpoint，重新初始化等都可以。\n\n状态同步的另一个要考虑的问题是数据一致性问题。虽然可信赖计算没有将数据一致性纳入其中，但在实施HA时必须加以考虑。著名的CAP理论已经揭示了当数据被分割后，你就只能在数据的可用性和一致性二者中选其一了，而不能二者兼得。当然这也依赖HA的实施架构，如果采用sharing-disk方式，数据一致性就不会有大问题了。否则就要像各种分布式cluster方式一样要考虑当数据被分区后，怎样在数据一致性和可用性之前平衡了。这里不展开了，有兴趣再去互联网垃圾场翻几遍，肯定能挖到宝。\n\n## HA系统模式\n\n前面提到现在的HA系统一般都结合了LB，HA系统主要解决单点故障问题，LB主要解决热节点问题，这两方面问题有很多共性，节点过热的话会导致过载最终可能造成节点失效，而节点失效后又可能会导致其他节点更热，从而形成雪崩效应，最终导致整个系统崩溃。如果把热节点看成一个缺陷的话，必须在构造阶段想办法避免，而这就是Fault Tolerance范畴了。LB是解决热节点的有效方法，所以从这点可以看出，LB也是一个有效的Fault Tolerance方法。而同时HA用来做Fault Tolerance的一些事件也可以被用来处理LB，所以可以看出它们是一对好基友。\n\n从HA系统实施架构来看，各个分层不一定象上面那么清晰，而是根据具体业务需求来做最优调整，下面罗列了一些常见的HA系统架构：\n\n### Failover架构\n\nFailover架构是一种简单架构，前面也提到过，是一种双机热备，只有两个节点，一主一备。以前也有冷备，但可以想象，冷备极大的降低了可用性，一些硬件HA系统可能还有使用，但在网络服务方面没人使用。对热备来说也有共享存储和不共享存储两种：\n\n不共享存储的failover架构如下图所示：\n\n![](/assets/images/2016/02/14/high-availability-revelation/007.jpeg)\n\n这种结构一般用在无节点状态的系统中，比如交换机，也有通过VRRP之类协议来同步路由的AA/AS failover路由器采用这种架构。\n\n共享外置存储的failover架构如下图所示：\n\n![](/assets/images/2016/02/14/high-availability-revelation/008.jpeg)\n\n很多数据failover系统采用这种共享外置存储的架构，主要是数据库系统有很多状态，这种架构将状态保存到共享的外置存储后，主节点本身状态就无需同步到备用节点，简化了故障容忍性设计。\n\n### 平等节点架构\n\n平等节点架构中所有节点地位都是平等的，也就是所谓的sharing-nothing结构。就象前面阐述的一样，平等意味着民主，民主意味着权利下放，而权利也同时意味着责任，这也就说单个节点需要承担更多责任，这些责任便是如何来共同维护HA系统的可用性。有一些成熟的协议已经在HA系统的控制层面帮我们做了这些事情，比如VRRP协议。但业务状态同步问题还是需要业务服务自己来解决。我们的ipsec vpn网关便是采用这种架构。平等节点架构如下图所示：\n\n![](/assets/images/2016/02/14/high-availability-revelation/009.jpeg)\n\n### 共享存储架构\n\n也就是sharing-disk结构。共享外存架构的有点前面也提到过了，就是节点的业务状态同步可以大幅简化了，顶多是在节点失效或集成时进行状态回滚。这种架构一般要依赖一个具有高可用性的外置存储网络，比如SAN，FB，这些外置存储I/O的速度可以跟DAS设备（即本机磁盘）比拟。这样一来数据一致性问题变得不那么关键了，但I/O却成了系统的热点。架构如下图所示：\n\n![](/assets/images/2016/02/14/high-availability-revelation/0010.jpeg)\n\n### 多HA系统结构\n\n这样的HA系统里可能存在多个子HA系统，前面提到的hadoop zookeeper便是一个例子。这种系统的优点是，针对具体问题各个击破，谁热就给其降温(LB)，谁危险就对其做HA。\n\n架构如下图所示：\n\n![](/assets/images/2016/02/14/high-availability-revelation/0011.jpeg)\n\n可以看出，图中由多zookeeper server组成一个HA子系统为所有client节点服务，整个系统又是一个大的HA系统。\n\n## HA系统指标\n\n对于HA系统来说，可用性是其最重要的一项指标，虽然可信赖计算组列出了六大属性，但我觉得从实用角度来说，可维护性，数据一致性，性能指标应该要重点关注。\n\n其中可维护性又可以分为如下几个指标：\n\n*   故障恢复时间\n\n*   故障隔离能力\n\n*   升级能力\n\n性能指标又可分为如下两点：\n\n*   负载均衡能力\n\n*   横向扩充能力\n\n我不打算列一大堆公式来分析这些指标，因为每一种都有人做了详尽的研究，如果有人想分析，网上很容易找到相关资料，我这里只列出我们需要的关注点。\n\n## 后记\n\n絮絮叨叨说了那么多，好像也没新东西啊，现实就是这样，很多道理就像白开水，大家都懂，如果直接在课堂上喂你，你估计不喝，但如果调和一下，加点料，做成心灵鸡汤，你就觉得还蛮有滋味的，然后喝得很开心。所以我这篇文章也希望能将这些已有的东西整理加工一下，同时加了一些自己的料，做成料理，如果口味不好的话，还望看官见谅啊。\n\ncopy这词已经被重新发明了很多版本，不同人有不同叫法，律师叫剽窃，普通人叫模仿，打工皇帝叫复制，深圳华强北叫山寨，文人叫拾人牙慧，教授叫研究，学渣叫抄袭，发明家叫借鉴，牛顿叫站在巨人肩膀上，导演叫向xx致敬。如果说我这篇文章有些价值，那是因为站在了牛人的肩膀上，研究了很有价值的文章，比如wiki, lvs，vrrp, ibm等, 在此一并向他们致敬。\n\n说了这里，各位看官可能会问，你标题是HA启示录，那你的启示呢？放心，我不是标题党，还记得HA系统的三原则么？第一条是不能有单点故障，我们每个人作为独立的节点，无论在项目中，还是在公司里也不能出现单点故障问题，就是说，不要因为你的问题导致公司或项目玩不转，这个时侯就是你被替换，备份节点上线的时候了。第二条是可靠互联，我们自己要与上下游节点之间形成互联互通的可靠通信，否则封闭的节点无法组成完整的系统。第三条是故障检测机制，就是说我们要及时更新自己的状态，早请示晚汇报，要让自己问题被各节点及时知晓，不要积累问题，和扩散问题，导致系统架构的不可靠，因为前面说过了，单个节点本不可靠，出问题是正常的，但如果不检测和报告自己的问题，就是你自己的问题了，也就是你这个节点该修理的时候了。\n\n## 参考文献\n\n* Sam Siewert (Sam.Siewert@Colorado.edu), Adjunct Professor, University of Colorado: Big iron lessons, Part 2: Reliability and availability: What's the difference?\n* Jean-Claude Laprie: Dependable Computing: Concepts, Limits, Challenges\n* Sangeetha Seshadri, Ling Liu, Brian F. Cooper ({sangeeta,lingliu,cooperb}@cc.gatech.edu), Lawrence Chiu, Karan Gupta, Paul Muench({lchiu,guptaka,pmuench}@us.ibm.com): A Fault-Tolerant Middleware Architecture for High-Availability Storage Services\n* Magnus Gammelgård, Mathias Ekstedt, Per Närman : Architecture Scenario Analysis – Estimating the Credibility of the Results\n* Paulo Vera-Ssimo，Luís Rodrigues: Distributed Systems for System Architects\n* http://cailin.iteye.com/blog/2014486: zookeeper原理\n* wikipedia\n\n---\n\n* Author: 秣马\n* 原文链接：[High Availability启示录](https://yq.aliyun.com/articles/5555)\n","tags":["High-Availability"],"categories":["High-Availability"]},{"title":"用朴素贝叶斯进行文本分类(下)","url":"%2F2016%2F2016-02-03-nlp-naive-bayes-classifier-2%2F","content":"\n### 1.引言\n\n上一篇文章我们主要从理论上梳理了朴素贝叶斯方法进行文本分类的基本思路。这篇文章我们主要从实践上探讨一些应用过程中的tricks，并进一步分析贝叶斯方法，最后以情绪褒贬分析和拼写纠错为例展示这种简单强大的方法在自然语言处理问题上的具体应用。\n\n### 2.为什么不直接匹配关键词来识别垃圾邮件？\n\n看了上一篇文章的一些同学可能会问：“何必费这么大劲算那么多词的概率？直接看邮件中有没有‘代开发票’、‘转售发票’之类的关键词不就得了？如果关键词比较多就认为是垃圾邮件呗。”\n\n咳咳，其实关键词匹配的方法如果有效的话真不必用朴素贝叶斯。毕竟这种方法简单嘛，**就是一个字符串匹配**。从历史来看，之前没有贝叶斯方法的时候主要也是用关键词匹配。**但是这种方法准确率太低**。我们在工作项目中也尝试过用关键词匹配的方法去进行文本分类，发现大量误报。感觉就像扔到垃圾箱的邮件99%都是正常的！这样的效果不忍直视。而加一个朴素贝叶斯方法就可能把误报率拉低近一个数量级，体验好得不要不要的。\n\n**另一个原因是词语会随着时间不断变化**。发垃圾邮件的人也不傻，当他们发现自己的邮件被大量屏蔽之后，也会考虑采用新的方式，**如变换文字、词语、句式、颜色等方式来绕过反垃圾邮件系统**。比如对于垃圾邮件“我司可办理正规发票，17%增值税发票点数优惠”,他们采用火星文：“**涐司岢办理㊣規髮票，17%增値稅髮票嚸數優蕙**”，那么字符串匹配的方法又要重新找出这些火星文，一个一个找出关键词，重新写一些匹配规则。更可怕的是，这些规则可能相互之间的耦合关系异常复杂，要把它们梳理清楚又是大一个数量级的工作量。等这些规则失效了又要手动更新新的规则……**无穷无尽猫鼠游戏最终会把猫给累死**。\n\n而朴素贝叶斯方法却显示出无比的优势。因为它是**基于统计方法**的，只要训练样本中有更新的垃圾邮件的新词语，哪怕它们是火星文，**都能自动地把哪些更敏感的词语（如“髮”、“㊣”等）给凸显出来，并根据统计意义上的敏感性给他们分配适当的权重**，这样就不需要什么人工了，非常省事。**你只需要时不时地拿一些最新的样本扔到训练集中，重新训练一次即可**。\n\n小补充一下，对于火星文、同音字等替代语言，一般的分词技术可能会分得不准，最终可能只把一个一个字给分出来，成为“分字”。当然也可以用过n-gram之类的语言模型(后续博客马上提到，尽请关注)，拿到最常见短语。对于英文等天生自带空格来间隔单词的语言，分词则不是什么问题，使用朴素贝叶斯方法将会更加顺畅。\n\n### 3.工程上的一些tricks\n\n应用朴素贝叶斯方法的过程中，一些tricks能显著帮助工程解决问题。我们毕竟经验有限，无法将它们全都罗列出来，只能就所知的一点点经验与大家分享，欢迎批评指正。\n\n#### 3.1 trick1：取对数\n\n我们上一篇文章用来识别垃圾邮件的方法是比较以下两个概率的大小（字母S表示“垃圾邮件”,字母H表示“正常邮件”）：\n\n```\nC = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)\n × P(“保真”|S)P(“增值税”|S)P(“发票”|S)P(“点数”|S)P(“优惠”|S)P(“垃圾邮件”)\nC¯ = P(“我”|H)P(“司”|H)P(“可”|H)P(“办理”|H)P(“正规发票”|H)\n × P(“保真”|H)P(“增值税”|H)P(“发票”|H)P(“点数”|H)P(“优惠”|H)P(“正常邮件”)\n```\n\n但这里进行了**很多乘法运算，计算的时间开销比较大**。尤其是对于篇幅比较长的邮件，几万个数相乘起来还是非常花时间的。如果能**把这些乘法变成加法则方便得多**。刚好数学中的对数函数log就可以实现这样的功能。两边同时取对数（本文统一取底数为2），则上面的公式变为：\n\n```\nlogC = logP(“我”|S)+logP(“司”|S)+logP(“可”|S)+logP(“办理”|S)+logP(“正规发票”|S)+logP(“保真”|S)+logP(“增值税”|S)+logP(“发票”|S)+logP(“点数”|S)+logP(“优惠”|S)+logP(“垃圾邮件”)\nlogC¯ = logP(“我”|H)+logP(“司”|H)+logP(“可”|H)+logP(“办理”|H)+logP(“正规发票”|H)+logP(“保真”|H)+logP(“增值税”|H)+logP(“发票”|H)+logP(“点数”|H)+logP(“优惠”|H)+logP(“正常邮件”)\n```\n\n有同学可能要叫了：“做对数运算岂不会也很花时间？”的确如此，但是可以在训练阶段直接计算logP，然后把他们存在一张大的hash表里。**在判断的时候直接提取hash表中已经计算好的对数概率，然后相加即可。这样使得判断所需要的计算时间被转移到了训练阶段**，实时运行的时候速度就比之前快得多，这可不止几个数量级的提升。\n\n#### 3.2 trick2：转换为权重\n\n对于二分类，我们还可以继续提高判断的速度。既然要比较logC和logC¯的大小，那就可以直接将上下两式相减，并继续化简：\n\n```\nlogCC¯=logP(“我”|S)P(“我”|H)+logP(“司”|S)P(“司”|H)+logP(“可”|S)P(“可”|H)+logP(“办理”|S)P(“办理”|H)+logP(“正规发票”|S)P(“正规发票”|H)\n+logP(“保真”|S)P(“保真”|H)+logP(“增值税”|S)P(“增值税”|H)+logP(“发票”|S)P(“发票”|H)+logP(“点数”|S)P(“点数”|H)+logP(“优惠”|S)P(“优惠”|H)+logP(“正常邮件”|S)P(“正常邮件”)\n```\n\n`logCC¯`**如果大于0则属于垃圾邮件。我们可以把其中每一项作为其对应词语的权重**，比如`logP(“发票”|S)/P(“发票”|H)`就可以作为词语“发票”的权重，权重越大就越说明“发票”更可能是与“垃圾邮件”相关的特征。**这样可以根据权重的大小来评估和筛选显著的特征，比如关键词。而这些权重值可以直接提前计算好而存在hash表中**。判断的时候直接将权重求和即可。\n\n关键词hash表的样子如下，左列是权重，右列是其对应的词语，权重越高的说明越“关键”：\n\n![](/assets/images/2016/02/03/nlp-naive-bayes-classifier-2/hash.jpg)\n\n#### 3.3 trick3：选取topk的关键词\n\n前文说过可以通过提前选取关键词来提高判断的速度。有一种方法可以省略提前选取关键词的步骤，**就是直接选取一段文本中权重最高的K个词语，将其权重进行加和**。比如Paul Graham在《黑客与画家》中是选取邮件中权重最高的15个词语计算的。\n\n通过权重hash表可知，如果是所有词语的权重，则权重有正有负。如果只选择权重最高的K个词语，则它们的权重基本都是正的。所以就不能像之前那样判断logCC¯¯是否大于0来区分邮件了。而这**需要依靠经验选定一个正数的阈值（门槛值）**，依据logCC¯¯与该门槛值的大小来识别垃圾邮件。\n\n如下图所示，蓝色点代表垃圾邮件，绿色点代表正常邮件，横坐标为计算出来的logCC¯¯值，中间的红线代表阈值。\n\n![](/assets/images/2016/02/03/nlp-naive-bayes-classifier-2/垃圾邮件区分.jpg)\n\n#### 3.4 trick4：分割样本\n\n选取topk个词语的方法对于篇幅变动不大的邮件样本比较有效。但是对篇幅过大或者过小的邮件则会有判断误差。\n\n比如这个垃圾邮件的例子：（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)。分词出了10个词语，其中有“正规发票”、“发票”2个关键词。关键词的密度还是蛮大的，应该算是敏感邮件。但因为采用最高15个词语的权重求和，并且相应的阈值是基于15个词的情况有效，可能算出来的结果还小于之前的阈值，这就造成漏判了。\n\n类似的，如果一封税务主题的邮件有1000个词语，其中只有“正规发票”、“发票”、“避税方法”3个权重比较大的词语，它们只是在正文表述中顺带提到的内容。关键词的密度被较长的篇幅稀释了，应该算是正常邮件。但是却被阈值判断成敏感邮件，造成误判了。\n\n**这两种情况都说明topk关键词的方法需要考虑篇幅的影响**。这里有许多种处理方式，**它们的基本思想都是选取词语的个数及对应的阈值要与篇幅的大小成正比**，本文只介绍其中一种方方法：\n\n* 对于长篇幅邮件，按一定的大小，比如每500字，将其分割成小的文本段落，再对小文本段落采用topk关键词的方法。只要其中有一个小文本段落超过阈值就判断整封邮件是垃圾邮件。\n\n* 对于超短篇幅邮件，比如50字，可以按篇幅与标准比较篇幅的比例来选取topk，以确定应该匹配关键词语的个数。比如选取50/500×15≈2个词语进行匹配，相应的阈值可以是之前阈值的2/15。以此来判断则更合理。\n\n#### 3.5 trick5：位置权重\n\n到目前为止，我们对词语权重求和的过程都没有考虑邮件篇章结构的因素。比如“正规发票”如果出现在标题中应该比它出现在正文中对判断整个邮件的影响更大；而出现在段首句中又比其出现在段落正文中对判断整个邮件的影响更大。**所以可以根据词语出现的位置，对其权重再乘以一个放大系数，以扩大其对整封邮件的影响，提高识别准确度**。\n\n比如一封邮件其标题是“正规发票”（假设标题的放大系数为2），段首句是“发票”,“点数”,“优惠”（假设段首的放大系数为1.5），剩下的句子是（“我”,“司”,“可”,“办理”,“保真”）。则计算logCC¯时的公式就可以调整为：\n\n```\nlogCC¯=2×logP(“正规发票”|S)/P(“正规发票”|H)+1.5×logP(“发票”|S)/P(“发票”|H)+1.5×logP(“点数”|S)/P(“点数”|H)+1.5×logP(“优惠”|S)/P(“优惠”|H)\n+logP(“我”|S)/P(“我”|H)+logP(“司”|S)/P(“司”|H)+logP(“可”|S)/P(“可”|H)+logP(“办理”|S)/P(“办理”|H)+logP(“保真”|S)/P(“保真”|H)+logP(“正常邮件”|S/)P(“正常邮件”)\n```\n\n#### 3.6 trick6：蜜罐\n\n我们通过辛辛苦苦的统计与计算，好不容易得到了不同词语的权重。然而这并不是一劳永逸的。我们我们之前交代过，**词语及其权重会随着时间不断变化，需要时不时地用最新的样本来训练以更新词语及其权重**。\n\n而搜集最新垃圾邮件有一个技巧，就是随便注册一些邮箱，然后将它们公布在各大论坛上。接下来就坐等一个月，到时候收到的邮件就绝大部分都是垃圾邮件了（好奸诈）。再找一些正常的邮件，基本就能够训练了。这些用于自动搜集垃圾邮件的邮箱叫做“蜜罐”。**“蜜罐”是网络安全领域常用的手段，因其原理类似诱捕昆虫的装有蜜的罐子而得名**。比如杀毒软件公司会利用蜜罐来监视或获得计算机网络中的病毒样本、攻击行为等。\n\n### 4.贝叶斯方法的思维方式\n\n讲了这么多tricks，但这些手段都是建立在贝叶斯方法基础之上的。因此有必要探讨一下贝叶斯方法的思维方式，以便更好地应用这种方法解决实际问题。\n\n#### 4.1 逆概问题\n\n我们重新看一眼贝叶斯公式：\n\n```katex\nP(Y|X) = \\frac{P(X|Y)P(Y)}{P(X)}\n```\n\n先不考虑先验概率`P(Y)`与`P(X)`，观察两个后验概率`P(Y|X`)与`P(X|Y)`，可见贝叶斯公式能够揭示**两个相反方向的条件概率之间的转换关系**。\n\n从贝叶斯公式的发现历史来看，其就是为了处理所谓“逆概”问题而诞生的。比如`P(Y|X)`不能通过直接观测来得到结果，而`P(X|Y)`却容易通过直接观测得到结果，就可以通过贝叶斯公式**从间接地观测对象去推断不可直接观测的对象的情况**。\n\n好吧，我们说人话。基于邮件的文本内容判断其属于垃圾邮件的概率不好求（不可通过直接观测、统计得到），但是基于已经搜集好的垃圾邮件样本，去统计（直接观测）其文本内部各个词语的概率却非常方便。这就可以用贝叶斯方法。\n\n引申一步，基于样本特征去判断其所属标签的概率不好求，但是基于已经搜集好的打上标签的样本（有监督），却可以直接统计属于同一标签的样本内部各个特征的概率分布。因此贝叶斯方法的理论视角适用于一切分类问题的求解。\n\n#### 4.2 处理多分类问题\n\n前面我们一直在探讨二分类（判断题）问题，现在可以引申到多分类（单选题）问题了。\n\n还是用邮件分类的例子，这是现在不只要判断垃圾邮件，还要将正常邮件细分为私人邮件、工作邮件。现在有这3类邮件各1万封作为样本。需要训练出一个贝叶斯分类器。这里依次用Y1,Y2,Y3表示这三类邮件，用X表示被判断的邮件。套用贝叶斯公式有：\n\n```\nP(Y1|X)=P(X|Y1)P(Y1)P(X)\nP(Y2|X)=P(X|Y2)P(Y2)P(X)\nP(Y3|X)=P(X|Y3)P(Y3)P(X)\n```\n\n通过比较3个概率值的大小即可得到X所属的分类。发现三个式子的分母P(X)一样，比较大小时可以忽略不计，于是就可以用下面这一个式子表达上面3式：\n\n```\nP(Yi|X)∝P(X|Yi)P(Yi)\ni=1,2,3\n```\n\n其中∝表示“正比于”。而`P(X|Yi)`则有个特别高逼格的名字叫做“**似然函数**”。我们上大学的时候也被这个名字搞得晕晕乎乎的，其实它也是个概率，直接理解成“**`P(Yi|X)` 的逆反条件概率**” 就方便了。\n\n这里只是以垃圾邮件3分类问题举了个例子，**对于任意多分类的问题都可以用这样的思路去理解。比如新闻分类、情感喜怒哀乐分类等等**。\n\n#### 4.3 先验概率的问题\n\n在垃圾邮件的例子中，先验概率都相等，`P(Y1)=P(Y2)=P(Y3)=10000/30000=1/3`，所以上面是式子又可以进一步化简：\n\n```\nP(Yi|X)∝P(X|Yi)\ni=1,2,3\n```\n\n只需比较右边式子（也就是“似然函数”）的大小就可以了。这种方法就是传说中的**最大似然法**:不考虑先验概率而直接比较似然函数。\n\n关于选出最佳分类Yi是否要考虑先验概率P(Yi)的问题，曾经在频率学派和贝叶斯学派之间产生了激烈的教派冲突。统计学家（频率学派）说：我们让数据自己说话。言下之意就是要摒弃先验概率。而贝叶斯学派支持者则说：数据会有各种各样的偏差，而一个**靠谱的先验概率**则可以对这些随机噪音做到健壮。对此有兴趣的同学可以找更多资料进行了解，本文在此不做更多的引申，只基于垃圾邮件识别的例子进行探讨。\n\n比如我们在采集垃圾邮件样本的时候，不小心delete掉了一半的数据，就剩下5000封邮件。则计算出来的先验概率为:\n\n```\nP(Y1)=5000/25000=1/5，\nP(Y2)=P(Y3)=10000/25000=2/5\n```\n\n如果还用贝叶斯方法,就要在似然函数后面乘上先验概率。比如之前用最大似然法算出Y1垃圾邮件的概率大，但是因为`P(Y1)`特别小，用贝叶斯方法得出的结果是`Y2`私人邮件的概率大。那相信哪个呢？其实，我们删掉了部分带标签的样本，从计算结果看`P(Y1)`，`P(Y2)`，`P(Y3)`的概率分布变化了，但实际上**这三个类别的真实分布应该是一个客观的状态，不应该因为我们的计算方法而发生变化**。所以是我们计算出来的先验概率失真，应该放弃这样计算出来的先验概率，而用最大似然法。但即便我们不删掉一半垃圾邮件，这三类邮件的分布就真的是1:1:1那样平均吗？那也未必。**我们只是按1:1:1这样的方式进行了抽样而已，真正在邮箱里收到的这三类邮件的分布可能并不是这样。也就是说，在我们对于先验概率一无所知时，只能假设每种猜测的先验概率是均等的（其实这也是人类经验的结果），这个时候就只有用最大似然了**。在现实运用过程中如果发现最大似然法有偏差，可以考虑对不同的似然函数设定一些系数或者阈值，使其接近真实情况。\n\n但是，**如果我们有足够的自信，训练集中这三类的样本分布的确很接近真实的情况，这时就应该用贝叶斯方法**。难怪前面的贝叶斯学派强调的是“靠谱的先验概率”。所以说**贝叶斯学派的适用范围更广，关键要先验概率靠谱，而频率学派有效的前提也是他们的先验概率同样是经验统计的结果**。\n\n### 5.(朴素)贝叶斯方法的常见应用\n\n说了这么多理论的问题，咱们就可以探讨一下(朴素)贝叶斯方法在自然语言处理中的一些常见应用了。以下只是从原理上进行探讨，对于具体的技术细节顾及不多。\n\n#### 5.1 褒贬分析\n\n一个比较常见的应用场景是情感褒贬分析。比如你要统计微博上人们对一个新上映电影的褒贬程度评价：好片还是烂片。但是一条一条地看微博是根本看不过来，只能用自动化的方法。我们可以有一个很粗略的思路：\n\n* 首先是用爬虫将微博上提到这个电影名字的微博全都抓取下来，比如有10万条。\n* 然后用训练好的朴素贝叶斯分类器分别判断这些微博对电影是好评还是差评。\n* 最后统计出这些好评的影评占所有样本中的比例，就能形成微博网友对这个电影综合评价的大致估计。\n\n接下来的核心问题就是训练出一个靠谱的分类器。首先需要有打好标签的文本。这个好找，豆瓣影评上就有大量网友对之前电影的评价，并且对电影进行1星到5星的评价。我们可以认为3星以上的评论都是好评，3星以下的评论都是差评。这样就分别得到了好评差评两类的语料样本。剩下就可以用朴素贝叶斯方法进行训练了。基本思路如下：\n\n* 训练与测试样本：豆瓣影评的网友评论，用爬虫抓取下100万条。\n* 标签：3星以上的是好评，3星以下的是差评。\n* 特征：豆瓣评论分词后的词语。一个简单的方法是只选择其中的形容词，网上有大量的情绪词库可以为我们所用。\n* 然后再用常规的朴素贝叶斯方法进行训练。\n\n但是由于自然语言的特点，在提取特征的过程当中，有一些tricks需要注意：\n\n* **对否定句进行特别的处理**。比如这句话“我不是很喜欢部电影，因为它让我开心不起来。”其中两个形容词“喜欢”、“开心”都是褒义词，但是因为句子的否定句，所以整体是贬义的。有一种比较简单粗暴的处理方式，就是“**对否定词（“不”、“非”、“没”等）与句尾标点之间的所有形容词都采用其否定形式**”。则这句话中提取出来的形容词就应该是“不喜欢”和“不开心”。\n* 一般说来，最相关的情感词在一些文本片段中仅仅出现一次，词频模型起得作用有限，甚至是负作用，**则使用伯努利模型代替多项式模型**。这种情况在微博这样的小篇幅文本中似乎不太明显，但是在博客、空间、论坛之类允许长篇幅文本出现的平台中需要注意。\n* 其实，副词对情感的评价有一定影响。“不很喜欢”与“很不喜欢”的程度就有很大差异。但如果是朴素贝叶斯方法的话比较难处理这样的情况。我们可以考虑用语言模型或者加入词性标注的信息进行综合判断。这些内容我们将在之后的文章进行探讨。\n\n当然经过以上的处理，情感分析还是会有一部分误判。这里涉及到许多问题，都是情感分析的难点：\n\n* **情绪表达的含蓄微妙**：“导演你出来，我保证不打死你。”你让机器怎么判断是褒还是贬？\n* **转折性表达**：“我非常喜欢这些大牌演员，非常崇拜这个导演，非常赞赏这个剧本，非常欣赏他们的预告片，我甚至为了这部影片整整期待了一年，最后进了电影院发现这是个噩梦。” 五个褒义的形容词、副词对一个不那么贬义的词。机器自然判断成褒义，但这句话是妥妥的贬义。\n\n#### 5.2 拼写纠错\n\n拼写纠错本质上也是一个分类问题。但按照错误类型不同，又分为两种情况：\n\n* 非词错误（Non-word Errors）：指那些拼写错误后的词本身就不合法，如将“wifi”写成“wify”；\n* 真词错误（Real-word Errors）：指那些拼写错误后的词仍然是合法的情况，如将“wifi”写成“wife”。\n\n真词错误复杂一些，我们将在接下来的文章中进行探讨。而对于非词错误，就可以直接采用贝叶斯方法，其基本思路如下：\n\n* 标签：通过计算错误词语的最小编辑距离（之前咱们提到过的），获取最相似的候选词，每个候选词作为一个分类。\n* 特征：拼写错误的词本身。因为它就一个特征，所以没有什么条件独立性假设、朴素贝叶斯啥的。它就是纯而又纯的贝叶斯方法。\n* 判别公式:\n```\nP(候选词i|错误词)∝P(错误词|候选词i)P(候选词i)；i=1,2,3,...\n```\n* 训练样本1：该场景下的正常用词语料库，用于计算P(候选词i)。\n```\nP(候选词i)=候选词出现的次数所有词出现的次数\n```\n* 训练样本2：该场景下错误词与正确词对应关系的语料库，用于计算P(错误词|候选词i)\n```\nP(错误词|候选词i)=候选词被拼写成该“错误词”的次数候选词出现的次数\n```\n\n由于自然语言的特点，有一些tricks需要注意：\n\n* 据统计，80%的拼写错误编辑距离为1，几乎所有的拼写错误编辑距离小于等于2。我们只选择编辑距离为1或2的词作为候选词，这样就可以减少大量不必要的计算。\n* 由于我们只选择编辑距离为1或2的词，其差别只是一两个字母级别差别。因此计算似然函数的时候，可以只统计字母层面的编辑错误，这样搜集的样本更多，更满足大数定律，也更简单。对于编辑距离为1的似然函数计算公式可以进化为：\n\n```\nP(错误词|候选词i)=⎧⎩⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪字母“xy”被拼写成“y”的次数字母“xy”出现的次数,字母“x”被拼写成“xy”的次数字母“x”出现的次数,字母“x”被拼写成“y”的次数字母“x”出现的次数,字母“xy”被拼写成“yx的次数字母“xy”出现的次数,\n```\n\n* 键盘上临近的按键更容易拼写错误，据此可以对上面这个条件概率进行加权。\n\n![](/assets/images/2016/02/03/nlp-naive-bayes-classifier-2/keyboard.jpg)\n\n### 6.小结\n\n从这两篇文章大家基本可以看出，工程应用不同于学术理论，有许多tricks需要考虑，而理论本质就是翻来倒去折腾贝叶斯公式，都快玩出花来了。但是如果只用朴素贝叶斯，很多情况还是无法应付，需要我们在贝叶斯公式上再折腾出一些花样。详细内容，请听下回分解。\n\n---\n\n* 原文链接：[用朴素贝叶斯进行文本分类(下)](http://blog.csdn.net/han_xiaoyang/article/details/50616559)\n","tags":["Classifier"],"categories":["NLP"]},{"title":"用朴素贝叶斯进行文本分类(上)","url":"%2F2016%2F2016-02-01-nlp-naive-bayes-classifier-1%2F","content":"\n### 1. 引言\n\n贝叶斯方法是一个历史悠久，有着坚实的理论基础的方法，同时处理很多问题时直接而又高效，很多高级自然语言处理模型也可以从它演化而来。因此，学习贝叶斯方法，是研究自然语言处理问题的一个非常好的切入口。\n\n### 2. 贝叶斯公式\n\n贝叶斯公式就一行：\n\n```katex\nP(Y|X) = \\frac{P(X|Y)P(Y)}{P(X)}\n```\n\n而它其实是由以下的联合概率公式推导出来：\n\n```katex\nP(Y,X) = P(Y|X)P(X) = P(X|Y)P(Y)\n```\n\n其中`P(Y)`叫做先验概率，`P(Y|X)`叫做后验概率，`P(Y,X)`叫做联合概率。\n\n额，恩，没了，贝叶斯最核心的公式就这么些。\n\n### 3. 用机器学习的视角理解贝叶斯公式\n\n在机器学习的视角下，我们把`X`理解成“具有某特征”，把`Y`理解成“类别标签”(一般机器学习问题中都是`X`=>特征，`Y`=>结果对吧)。在最简单的二分类问题(是与否判定)下，我们将`Y`理解成“属于某类”的标签。于是贝叶斯公式就变形成了下面的样子:\n\n```\nP(“属于某类”|“具有某特征”)\n = P(“具有某特征”|“属于某类”) / P(“属于某类”)P(“具有某特征”)\n```\n\n我们尝试更口(shuo)语(ren)化(hua)的方式解释一下上述公式：\n\n```\nP(“属于某类”|“具有某特征”)\n = 在已知某样本“具有某特征”的条件下，该样本“属于某类”的概率。所以叫做『后验概率』。\nP(“具有某特征”|“属于某类”)\n = 在已知某样本“属于某类”的条件下，该样本“具有某特征”的概率。\nP(“属于某类”)\n = (在未知某样本具有该“具有某特征”的条件下，)该样本“属于某类”的概率。所以叫做『先验概率』。\nP(“具有某特征”)\n = (在未知某样本“属于某类”的条件下，)该样本“具有某特征”的概率。\n```\n\n而我们二分类问题的最终目的就是要判断`P(“属于某类”|“具有某特征”)`是否大于1/2就够了。贝叶斯方法把计算“具有某特征的条件下属于某类”的概率转换成需要计算“属于某类的条件下具有某特征”，而后者获取方法就简单多了，我们只需要找到一些包含已知特征标签的样本，即可进行训练。而样本的类别标签都是明确的，所以贝叶斯方法在机器学习里属于有监督学习方法。\n\n这里再补充一下，一般『先验概率』、『后验概率』是相对出现的，比如`P(Y)`与`P(Y|X)`是关于Y的先验概率与后验概率，`P(X)`与`P(X|Y)`是关于X的先验概率与后验概率。\n\n### 4. 垃圾邮件识别\n\n举个例子好啦，我们现在要对邮件进行分类，识别垃圾邮件和普通邮件，如果我们选择使用朴素贝叶斯分类器，那目标就是判断`P(“垃圾邮件”|“具有某特征”)`是否大于1/2。现在假设我们有垃圾邮件和正常邮件各1万封作为训练集。需要判断以下这个邮件是否属于垃圾邮件：\n\n```\n我司可办理正规发票(保真)17%增值税发票点数优惠！\n```\n\n也就是判断概率`P(“垃圾邮件”|“我司可办理正规发票(保真)17%增值税发票点数优惠！”)`是否大于1/2。\n\n咳咳，有木有发现，转换成的这个概率，计算的方法：就是写个计数器，然后+1+1+1统计出所有垃圾邮件和正常邮件中出现这句话的次数啊！！！好，具体点说：\n\n```\nP(“垃圾邮件”|“我司可办理正规发票(保真)17%增值税发票点数优惠！”)\n = 垃圾邮件中出现这句话的次数 / 垃圾邮件中出现这句话的次数 + 正常邮件中出现这句话的次数\n```\n\n### 5. 分词\n\n然后同学们开始朝我扔烂白菜和臭鸡蛋，骗纸！！误人子弟！！你以为发垃圾邮件的人智商都停留在20世纪吗！！你以为它们发邮件像抄作业一样不改内容吗！！哪来那么多相同的句子！！。\n\n咳咳，表闹，确实，在我们这样的样本容量下，『完全击中』的句子很少甚至没有(无法满足大数定律，)，算出来的概率会很失真。一方面找到庞大的训练集是一件非常困难的事情，另一方面其实对于任何的训练集，我们都可以构造出一个从未在训练集中出现的句子作为垃圾邮件(真心的，之前看过朴素贝叶斯分类分错的邮件，我觉得大中华同胞创(zao)新(jia)的能力简直令人惊(fa)呀(zhi))。\n\n一个很悲哀但是很现实的结论：\n\n**训练集是有限的，而句子的可能性则是无限的。所以覆盖所有句子可能性的训练集是不存在的**。\n\n所以解决方法是？\n\n对啦！句子的可能性无限，但是词语就那么些！！汉语常用字2500个，常用词语也就56000个(你终于明白小学语文老师的用心良苦了)。按人们的经验理解，两句话意思相近并不强求非得每个字、词语都一样。比如“我司可办理正规发票，17%增值税发票点数优惠！”，这句话就比之前那句话少了“(保真)”这个词，但是意思基本一样。如果把这些情况也考虑进来，那样本数量就会增加，这就方便我们计算了。\n\n于是，我们可以不拿句子作为特征，而是拿句子里面的词语(组合)作为特征去考虑。比如正规发票可以作为一个单独的词语，增值税也可以作为一个单独的词语等等。\n\n“我司可办理正规发票，17%增值税发票点数优惠！”就可以变成(“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”))。\n\n于是你接触到了中文NLP中，最最最重要的技术之一：分词！！！也就是把一整句话拆分成更细粒度的词语来进行表示。咳咳，另外，分词之后去除标点符号、数字甚至无关成分(停用词)是特征预处理中的一项技术。\n\n**中文分词是一个专门的技术领域(我不会告诉你某搜索引擎厂码砖工有专门做分词的！！！)，我们将在下一篇文章探讨，这里先将其作为一个已知情况进行处理。具体细节请见下回分晓**\n\n我们观察(“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)，**这可以理解成一个向量：向量的每一维度都表示着该特征词在文本中的特定位置存在。这种将特征拆分成更小的单元，依据这些更灵活、更细粒度的特征进行判断的思维方式，在自然语言处理与机器学习中都是非常常见又有效的**。\n\n因此贝叶斯公式就变成了：\n\n```\nP(“垃圾邮件”|(“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”))\n = P((“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|\"垃圾邮件\")P(“垃圾邮件”) / P((“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”))\nP(“正常邮件”|(“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”))\n = P((“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|\"正常邮件\")P(“正常邮件”) / P((“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”))\n\n```\n### 6. 条件独立假设\n\n有些同学说…好像…似乎…经过上面折腾，概率看起来更复杂了-_-!\n\n那…那我们简化一下…\n\n概率`P((“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|\"垃圾邮件\")`依旧不够好求，我们引进一个很朴素的近似。为了让公式显得更加紧凑，我们令字母S表示“垃圾邮件”,令字母H表示“正常邮件”。近似公式如下：\n\n```\nP((“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|S)\n = P(“我”|S)×P(“司”|S)×P(“可”|S)×P(“办理”|S)×P(“正规发票”|S)\n×P(“保真”|S)×P(“增值税”|S)×P(“发票”|S)×P(“点数”|S)×P(“优惠”|S)\n```\n\n这就是传说中的**条件独立假设**。基于正常邮件的条件独立假设的式子与上式类似，此处省去。接着，将条件独立假设代入上面两个相反事件的贝叶斯公式。\n\n于是我们就只需要比较以下两个式子的大小：\n\n```\nC = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)\n×P(“保真”|S)P(“增值税”|S)P(“发票”|S)P(“点数”|S)P(“优惠”|S)P(“垃圾邮件”)\nC¯¯ = P(“我”|H)P(“司”|H)P(“可”|H)P(“办理”|H)P(“正规发票”|H)\n×P(“保真”|H)P(“增值税”|H)P(“发票”|H)P(“点数”|H)P(“优惠”|H)P(“正常邮件”)\n```\n\n厉(wo)害(cao)！酱紫处理后式子中的每一项都特别好求！只需要分别统计各类邮件中该关键词出现的概率就可以了！！！比如：\n\n```\nP(“发票”|S) = 垃圾邮件中所有“发票”的次数 / 垃圾邮件中所有词语的次数\n```\n\n统计次数非常方便，而且样本数量足够大，算出来的概率比较接近真实。于是垃圾邮件识别的问题就可解了。\n\n### 7. 朴素贝叶斯(Naive Bayes)，“Naive”在何处？\n\n加上条件独立假设的贝叶斯方法就是朴素贝叶斯方法(Naive Bayes)。Naive的发音是“乃一污”，意思是“朴素的”、“幼稚的”、“蠢蠢的”。咳咳，也就是说，大神们取名说该方法是一种比较萌蠢的方法，为啥？\n\n将句子(“我”,“司”,“可”,“办理”,“正规发票”)中的(“我”,“司”)与(“正规发票”)调换一下顺序，就变成了一个新的句子(“正规发票”,“可”,“办理”,“我”,“司”)。新句子与旧句子的意思完全不同。但由于乘法交换律，朴素贝叶斯方法中算出来二者的条件概率完全一样！计算过程如下：\n\n```\nP((“我”,“司”,“可”,“办理”,“正规发票”)|S)\n = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)\n = P(“正规发票”|S)P(“可”|S)P(“办理”|S)P(“我”|S)P(“司”|S)\n = P((“正规发票”,“可”,“办理”,“我”,“司”)|S)\n```\n\n也就是说，在朴素贝叶斯眼里，“我司可办理正规发票”与“正规发票可办理我司”完全相同。朴素贝叶斯失去了词语之间的顺序信息。这就相当于把所有的词汇扔进到一个袋子里随便搅和，贝叶斯都认为它们一样。因此这种情况也称作词袋子模型(bag of words)。\n\n![](/assets/images/2016/02/01/nlp-naive-bayes-classifier-1/bag_of_words.jpg)\n\n词袋子模型与人们的日常经验完全不同。比如，在条件独立假设的情况下，“武松打死了老虎”与“老虎打死了武松”被它认作一个意思了。恩，朴素贝叶斯就是这么单纯和直接，对比于其他分类器，好像是显得有那么点萌蠢。\n\n### 8. 简单高效，吊丝逆袭\n\n虽然说朴素贝叶斯方法萌蠢萌蠢的，但实践证明在垃圾邮件识别的应用还令人诧异地好。Paul Graham先生自己简单做了一个朴素贝叶斯分类器，“1000封垃圾邮件能够被过滤掉995封，并且没有一个误判”。(Paul Graham《黑客与画家》)\n\n那个…效果为啥好呢？\n\n有人对此提出了一个理论解释，并且建立了什么时候朴素贝叶斯的效果能够等价于非朴素贝叶斯的充要条件，这个解释的核心就是：有些独立假设在各个分类之间的分布都是均匀的所以对于似然的相对大小不产生影响；即便不是如此，也有很大的可能性各个独立假设所产生的消极影响或积极影响互相抵消，最终导致结果受到的影响不大。具体的数学公式请参考[paper](http://www.cs.unb.ca/profs/hzhang/publications/FLAIRS04ZhangH.pdf)。”(刘未鹏《：平凡而又神奇的贝叶斯方法》)\n\n恩，这个分类器中最简单直接看似萌蠢的小盆友『朴素贝叶斯』，实际上却是简单、实用、且强大的。\n\n### 9. 处理重复词语的三种方式\n\n我们之前的垃圾邮件向量(“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)，其中每个词都不重复。而这在现实中其实很少见。因为如果文本长度增加，或者分词方法改变，必然会有许多词重复出现，因此需要对这种情况进行进一步探讨。比如以下这段邮件：\n\n```\n“代开发票。增值税发票，正规发票。”\n分词后为向量：\n(“代开”,“发票”,“增值税”,“发票”,“正规”,“发票”)\n```\n\n其中“发票”重复了三次。\n\n#### 9.1 多项式模型：\n\n如果我们考虑重复词语的情况，也就是说，重复的词语我们视为其出现多次，直接按条件独立假设的方式推导，则有\n\n```\nP((“代开”,“发票”,“增值税”,“发票”,“正规”,“发票”)|S)\n = P(“代开””|S)P(“发票”|S)P(“增值税”|S)P(“发票”|S)P(“正规”|S)P(“发票”|S)\n = P(“代开””|S)P3(“发票”|S)P(“增值税”|S)P(“正规”|S)\n注意这一项:P3(“发票”|S)。\n```\n\n在统计计算`P(发票|S)`时，每个被统计的垃圾邮件样本中重复的词语也统计多次。\n\n```\nP(“发票”|S)\n = 每封垃圾邮件中出现“发票”的次数的总和每封垃圾邮件中所有词出现次数(计算重复次数)的总和\n```\n\n你看这个多次出现的结果，出现在概率的指数/次方上，因此这样的模型叫作多项式模型。\n\n#### 9.2 伯努利模型\n\n另一种更加简化的方法是将重复的词语都视为其只出现1次，\n\n```\nP((“代开”,“发票”,“增值税”,“发票”,“正规”,“发票”)|S)\n = P(“发票”|S)P(“代开””|S)P(“增值税”|S)P(“正规”|S)\n```\n\n统计计算`P(“词语”|S)`时也是如此。\n\n```\nP(“发票”|S) = 出现“发票”的垃圾邮件的封数 / 每封垃圾邮件中所有词出现次数(出现了只计算一次)的总和\n```\n\n这样的模型叫作伯努利模型(又称为二项独立模型)。这种方式更加简化与方便。当然它丢失了词频的信息，因此效果可能会差一些。\n\n#### 9.3 混合模型\n\n第三种方式是在计算句子概率时，不考虑重复词语出现的次数，但是在统计计算词语的概率`P(“词语”|S)`时，却考虑重复词语的出现次数，这样的模型可以叫作混合模型。\n\n我们通过下图展示三种模型的关系。\n\n![](/assets/images/2016/02/01/nlp-naive-bayes-classifier-1/bayes_three_pattern.jpg)\n\n实践中采用哪种模型，关键看具体的业务场景。笔者的简单经验是，对于垃圾邮件识别，混合模型更好些。\n\n### 10. 去除停用词与选择关键词\n\n我们继续观察(“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)这句话。其实，像“我”、“可”之类词其实非常中性，无论其是否出现在垃圾邮件中都无法帮助判断的有用信息。所以可以直接不考虑这些典型的词。这些无助于我们分类的词语叫作“停用词”(Stop Words)。这样可以减少我们训练模型、判断分类的时间。\n\n于是之前的句子就变成了(“司”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)。\n\n我们进一步分析。以人类的经验，其实“正规发票”、“发票”这类的词如果出现的话，邮件作为垃圾邮件的概率非常大，可以作为我们区分垃圾邮件的“关键词”。而像“司”、“办理”、“优惠”这类的词则有点鸡肋，可能有助于分类，但又不那么强烈。如果想省事做个简单的分类器的话，则可以直接采用“关键词”进行统计与判断，剩下的词就可以先不管了。于是之前的垃圾邮件句子就变成了(“正规发票”,“发票”)。这样就更加减少了我们训练模型、判断分类的时间，速度非常快。\n\n“停用词”和“关键词”一般都可以提前靠人工经验指定。不同的“停用词”和“关键词”训练出来的分类器的效果也会有些差异。那么有没有量化的指标来评估不同词语的区分能力？在我们之前的文章《机器学习系列(6)_从白富美相亲看特征选择与预处理(下)》其实就提供了一种评价方法，大家可以参考。此处就不赘述了。\n\n### 11. 浅谈平滑技术\n\n我们来说个问题(中文NLP里问题超级多，哭瞎T_T)，比如在计算以下独立条件假设的概率：\n\n```\nP((“我”,“司”,“可”,“办理”,“正规发票”)|S)\n = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)\n```\n\n我们扫描一下训练集，发现“正规发票”这个词从出现过！！！，于是`P(“正规发票”|S)=0`…问题严重了，整个概率都变成0了！！！朴素贝叶斯方法面对一堆0，很凄惨地失效了…更残酷的是这种情况其实很常见，因为哪怕训练集再大，也可能有覆盖不到的词语。本质上还是样本数量太少，不满足大数定律，计算出来的概率失真。为了解决这样的问题，一种分析思路就是直接不考虑这样的词语，但这种方法就相当于默认给`P(“正规发票”|S)`赋值为1。其实效果不太好，大量的统计信息给浪费掉了。我们进一步分析，既然可以默认赋值为1，为什么不能默认赋值为一个很小的数？这就是平滑技术的基本思路，依旧保持着一贯的作风，朴实/土但是直接而有效。\n\n对于伯努利模型，`P(“正规发票”|S)`的一种平滑算法是：\n\n```\nP(“正规发票”|S) = 出现“正规发票”的垃圾邮件的封数+1 / 每封垃圾邮件中所有词出现次数(出现了只计算一次)的总和+2\n```\n\n对于多项式模型，`P(“正规发票”|S)`的一种平滑算法是：\n\n```\nP(“发票”|S) = 每封垃圾邮件中出现“发票”的次数的总和+1 / 每封垃圾邮件中所有词出现次数(计算重复次数)的总和+被统计的词表的词语数量\n```\n\n说起来，平滑技术的种类其实非常多，有兴趣的话回头我们专门拉个专题讲讲好了。这里只提一点，就是所有的平滑技术都是给未出现在训练集中的词语一个估计的概率，而相应地调低其他已经出现的词语的概率。\n\n平滑技术是因为数据集太小而产生的现实需求。如果数据集足够大，平滑技术对结果的影响将会变小。\n\n### 12. 小结\n\n我们找了个最简单常见的例子：垃圾邮件识别，说明了一下朴素贝叶斯进行文本分类的思路过程。基本思路是先区分好训练集与测试集，对文本集合进行分词、去除标点符号等特征预处理的操作，然后使用条件独立假设，将原概率转换成词概率乘积，再进行后续的处理。\n\n```\n贝叶斯公式 + 条件独立假设 = 朴素贝叶斯方法\n```\n\n基于对重复词语在训练阶段与判断(测试)阶段的三种不同处理方式，我们相应的有伯努利模型、多项式模型和混合模型。在训练阶段，如果样本集合太小导致某些词语并未出现，我们可以采用平滑技术对其概率给一个估计值。而且并不是所有的词语都需要统计，我们可以按相应的停用词和关键词对模型进行进一步简化，提高训练和判断速度。\n\n因为公式比较多，为了防止看到公式就狗带的情况，我们尽量用口(shuo)语(ren)化(hua)的方式表达公式，不严谨之处还望见谅，有纰漏之处欢迎大家指出。\n\n---\n\n* 原文链接：[用朴素贝叶斯进行文本分类(上)](http://blog.csdn.net/han_xiaoyang/article/details/50616559)\n","tags":["Classifier"],"categories":["NLP"]},{"title":"从破译外星人文字浅谈自然语言处理的基础","url":"%2F2016%2F2016-01-20-nlp-basis%2F","content":"\n### 1. 如果让你破译“三体”人文字你会怎么办？\n\n我们试着开一下脑洞：假如你有一个优盘，里面存了大量“三体”人（刘慈欣小说中的高智能外星人）的网络文本信息，你会怎样通过这些信息去了解外星文明并从中获取有价值的技术情报？当然，“三体”人的文字都长这样儿： \n\n![](/assets/images/2016/01/20/nlp-basis/001.jpg)\n\n“全是乱码，根本摸不着头脑！”\n\n好吧，的确是这样。**其实在计算机的眼中，人类的语言跟外星人的语言也没什么两样**。\n\n**让计算机“理解”人类语言中的种种信息，甚至像人类一样做出反应，这些是自然语言处理的主要内容。**\n\n那我们怎么分析呢？首先，我们尝试找出最小观察对象，发现外星人文字好像是一块一块的方块字，每一个方块字可以作为我们的一个分析的基本语言单位。我们对这些方块字做一些基本的统计，大致就能知道“三体”人语言的基本词汇量、常用词、罕见词、常用固定搭配等等。可见**统计方法是一个比较有用的利器**。\n\n而且，我们发现，有些方块字直接由一个空格将其隔开。因此将方块字区分成不同的区域，每一个区域是否可以理解成一句话？这个工作就是**“断句”**，也是自然语言处理当中的一个典型问题。\n\n然后空行可以作为**分段**。按照人类语言的经验，可能段首第一句话会包含更多的信息。\n\n还能继续分析吗？似乎比较难了。可是后来你发现，这个优盘中的外星人**语料库有些是“标记”了的**。比如有些信息是像在豆瓣网站中那样被组织的。里面每段话都有一些类似“好评”“差评”的标记。基于这些标记，你可以统计出某些词在好评中出现的概率比差评的更高，这些词可能就是“褒义词”。类似的，你也可以统计出一些“贬义词”。基于这些褒、贬义词，可以去判断其他文本的褒贬性。这就是自然语言处理中的“**褒贬分析**”过程。\n\n……\n\n由此可见，当面对一种一无所知的语言的时候，**似乎最直接的方法就是掌握大量的语料库，而且这些语料最好是经过各种方式标注了的**。然后对其进行****各种各样的统计，发掘一些有价值的信息**。这是传说中自然语言处理的**经验主义视角**。\n\n### 2. 自然语言处理要解决的问题:\n\n其实，自然语言处理的应用非常广泛，如：\n\n* **垃圾邮件识别**\n\n    通过自动分析邮件中的文本内容，判断该邮件是否垃圾邮件。\n\n* **中文输入法**\n\n    通过识别输入的拼音字符串，识别用户希望输入的汉字。\n\n* **机器翻译**\n\n    将文本从一种语言转成另一种语言，如中英文机器翻译。\n\n* **自动问答、客服机器人**\n\n   用文本输入一个问题，再返回一段文本作为问题的答案。\n\n……\n\n这里简单罗列了一些NLP的**常见领域：分词，词性标注，命名实体识别，句法分析，语义识别，垃圾邮件识别，拼写纠错，词义消歧，语音识别，音字转换,机器翻译，自动问答……**\n\n如果对自然语言处理的应用场景不太了解，可以去腾讯的中文语义平台简单玩几个例子就熟悉了。\n\n### 3. 自然语言处理的发展现状\n\n根据stafford教授Dan Jurafsky的介绍：\n\n* **有些问题得到了基本解决**，如：词性标注、命名实体识别、垃圾邮件识别。\n* **有些问题取得长足进展**，如：情感分析、共指消解、词义消歧、句法分析、机器翻译、信息抽取。\n* **有些问题依然充满挑战**，如：自动问答、复述、文摘提取、会话机器人等。\n\n### 4. 用算法统摄问题\n\n大家可能感受到了，自然语言处理的问题非常庞杂，一时还真不太好系统地梳理。\n\n然而，从我们的学习自然语言处理的经验来看，**通过机器学习的基本思路，可以将很多问题都抽象成同样的算法和模型来处理，这样会清晰很多**。\n\n比如，**词性标注，垃圾邮件识别，褒贬分析，拼写纠错等问题都可以归结成简单的分类问题**。这就好用我们之前掌握的机器学习分类方法去很好地处理。\n\n又比如，对于**机器翻译，语音识别，音字转换等等领域，都可以抽象成运用隐马尔科夫模型去处理，而这本身是一个更加复杂的分类问题**。\n\n因此本系列文章尽量**从算法原理的角度去梳理自然语言处理的问题，把这些原理在具体场景的不同变换方式给展示出来**。\n\n### 5. 文本处理基础\n\n#### 5.1 正则表达式\n\n对于英文等字符串类型的自然语言，**正则表达式能够很好地做一些简单的处理工作。如词干提取，大小写转换**等。\n\n现在主流的编程语言对正则表达式都有较好的支持，如Grep、Awk、Sed、Python、Perl、Java、C/C++。可以通过简单的编程完成一些基本任务。\n\n#### 5.2 分词\n\n对于英文，分词比较直观。**一般被空格区分开来的就是不同的词。但是有些不同的词汇表达需要我们细心判断**： \n\n![](/assets/images/2016/01/20/nlp-basis/002.jpg)\n\n这需要我们根据不同的条件**做一些简单的判断规则**。\n\n这样的方法对英语这种包含固定分隔符的语言行之有效。但**对于汉语、日语、德语以及我们上面的“三体文”等文本则不再适用，需要有专门的分词技术**。我们将在之后的文章中进行探讨。\n\n* 莎拉波娃现在居住在美国东南部的佛罗里达。\n* 莎拉波娃 现在 居住 在 美国 东南部 的 佛罗里达\n\n#### 5.3 编辑距离\n\n编辑距离（Minimum Edit Distance，MED），又称Levenshtein距离，是指**两个字符串之间，由一个转成另一个所需要的最少编辑操作次数**。 \n\n允许的编辑操作包括：\n\n* 将一个字符替换成另一个字符（substitution，s）\n* 插入一个字符（insert，i）\n* 删除一个字符（delete，d）\n\n一个简单的示意图如下：\n\n![](/assets/images/2016/01/20/nlp-basis/003.jpg)\n\n我们可以使用**动态规划**算法解最小编辑距离，其形式化定义如下：\n\n![](/assets/images/2016/01/20/nlp-basis/005.jpg)\n\n通过这种方法，给字符串之间定义了一个量化的“距离”的概念，而且很有解释力。\n\n在机器学习中，**有了“距离”就可以做很多事情。比如判断两个字符串的相似性，做一些分类、聚类的工作**。\n\n在工程上，**编辑距离可以用来提供用于拼写纠错的侯选单词**。比如我用英文输入法输入一个“girlfriand”的单词。但是词库中没有“girlfriand”这个词。则可以寻找与“girlfriand”编辑距离为1或2的其他字符串，如“girlfriend”、“girlfriends”，作为纠正拼写错误的候选词。剩下的问题就是判断哪个侯选词的作为纠正词的概率更高而已。\n\n### 6. 分类问题基础\n\n由于**自然语言处理中相当一部分都可以抽象成分类问题去处理。我们在这里补充一些分类问题的基本知识**，方便以后探讨。\n\n#### 6.1 分类问题的多种类型\n\n1. **二分类：判断题**\n\n    1.1 褒贬分析：判断一段文本是“褒”还是“贬”。\n\n    1.2 垃圾邮件识别：判断一封邮件是“正常邮件”还是“垃圾邮件”。\n\n2. **多分类：单选题**\n\n    2.1 词性标注：判断一个词语是名词、动词、形容词、副词等等。\n\n    2.2 拼写纠错：判断多个侯选词中的哪个词可以作为最终的纠正词。\n\n    2.3 中文分词：从多种分词序列中挑选最优序列。\n\n    2.4 机器翻译：从多个备选翻译句子中，判断出最优翻译语句。\n\n3. **类重叠分类：多选题**\n\n    3.1 主题分析：判断一个新闻同时包含哪几类主题（美食、食品安全、健康等）\n\n![](/assets/images/2016/01/20/nlp-basis/006.jpg)\n\n有时候管多选题叫做软分类，单选题叫硬分类。\n\n#### 6.2 多分类的评估指标\n\n对于一般二分类，我们评估的指标有**召回率、精确度和F值**。对于多分类我们也有类似的评价标准。如果**cij为有多少篇ci的文档被自动分类到cj类别下**，则有：\n\n![](/assets/images/2016/01/20/nlp-basis/008.jpg)\n\n### 7. 小结\n\n本文主要是讲了一些自然语言处理的浅层内容。我们从从破译外星人文字导出自然语言处理过程中的经验主义视角。因为业务场景十分繁杂，我们打算从机器学习算法的角度去观察这些业务场景，以便有个清晰的认识。文本处理的一些基础内容，如正则表达式、分词断句等是自然语言预处理过程中的常用手段。编辑距离是衡量两个字符串相似性的尺度。了解这些基础之后，就可以进行一些典型的自然语言处理问题了，比如文本分类。我们将在接下来的文章中一一介绍。\n\n---\n\n* 原文链接：[从破译外星人文字浅谈自然语言处理的基础](http://blog.csdn.net/han_xiaoyang/article/details/50545650)\n","tags":["NLP"],"categories":["NLP"]},{"title":"机器学习系列(4)_机器学习算法一览，应用建议与解决思路","url":"%2F2016%2F2016-01-06-ml-overview%2F","content":" \n## 1.引言\n\n提起笔来写这篇博客，突然有点愧疚和尴尬。愧疚的是，工作杂事多，加之懒癌严重，导致这个系列一直没有更新，向关注该系列的同学们道个歉。尴尬的是，按理说，机器学习介绍与算法一览应该放在最前面写，详细的应用建议应该在讲完机器学习常用算法之后写，突然莫名奇妙在中间插播这么一篇，好像有点打乱主线。 \n\n老话说『亡羊补牢，为时未晚』，前面开头忘讲的东西，咱在这块儿补上。我们先带着大家过一遍传统机器学习算法，基本思想和用途。把问题解决思路和方法应用建议提前到这里的想法也很简单，希望能提前给大家一些小建议，对于某些容易出错的地方也先给大家打个预防针，这样在理解后续相应机器学习算法之后，使用起来也有一定的章法。\n\n## 2.机器学习算法简述\n\n按照不同的分类标准，可以把机器学习的算法做不同的分类。\n\n### 2.1 从机器学习问题角度分类\n\n我们先从机器学习问题本身分类的角度来看，我们可以分成下列类型的算法：\n\n**监督学习算法**\n\n机器学习中有一大部分的问题属于『监督学习』的范畴，简单口语化地说明，这类问题中，给定的训练样本中，每个样本的输入x都对应一个确定的结果y，我们需要训练出一个模型(数学上看是一个x→y的映射关系f)，在未知的样本x′给定后，我们能对结果y′做出预测。\n\n这里的预测结果如果是离散值(很多时候是类别类型，比如邮件分类问题中的垃圾邮件/普通邮件，比如用户会/不会购买某商品)，那么我们把它叫做分类问题(classification problem)；如果预测结果是连续值(比如房价，股票价格等等)，那么我们把它叫做回归问题(regression problem)。\n\n有一系列的机器学习算法是用以解决监督学习问题的，比如最经典的用于分类问题的朴素贝叶斯、逻辑回归、支持向量机等等；比如说用于回归问题的线性回归等等。\n\n**无监督学习**\n\n有另外一类问题，给我们的样本并没有给出『标签/标准答案』，就是一系列的样本。而我们需要做的事情是，在一些样本中抽取出通用的规则。这叫做『无监督学习』。包括关联规则和聚类算法在内的一系列机器学习算法都属于这个范畴。\n\n**半监督学习**\n\n这类问题给出的训练数据，有一部分有标签，有一部分没有标签。我们想学习出数据组织结构的同时，也能做相应的预测。此类问题相对应的机器学习算法有自训练(Self-Training)、直推学习(Transductive Learning)、生成式模型(Generative Model)等。\n\n总体说来，最常见是前两类问题，而对应前两类问题的一些机器学习算法如下：\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptml_algorithms.png)\n\n### 2.2 从算法的功能角度分类\n\n我们也可以从算法的共性(比如功能，运作方式)角度对机器学习算法分类。下面我们根据算法的共性去对它们归个类。不过需要注意的是，我们下面的归类方法可能对分类和回归有比较强的倾向性，而这两类问题也是最常遇到的。\n\n#### 2.2.1 回归算法(Regression Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Regression-Algorithms.png)\n\n回归算法是一种通过最小化预测值与实际结果值之间的差距，而得到输入特征之间的最佳组合方式的一类算法。对于连续值预测有线性回归等，而对于离散值/类别预测，我们也可以把逻辑回归等也视作回归算法的一种，常见的回归算法如下：\n\n* Ordinary Least Squares Regression (OLSR)\n* Linear Regression\n* Logistic Regression\n* Stepwise Regression\n* Locally Estimated Scatterplot Smoothing (LOESS)\n* Multivariate Adaptive Regression Splines (MARS)\n\n#### 2.2.2 基于实例的算法(Instance-based Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Instance-based-Algorithms.png)\n\n这里所谓的基于实例的算法，我指的是我们最后建成的模型，对原始数据样本实例依旧有很强的依赖性。这类算法在做预测决策时，一般都是使用某类相似度准则，去比对待预测的样本和原始样本的相近度，再给出相应的预测结果。常见的基于实例的算法有：\n\n* k-Nearest Neighbour (kNN)\n* Learning Vector Quantization (LVQ)\n* Self-Organizing Map (SOM)\n* Locally Weighted Learning (LWL)\n\n#### 2.2.3 决策树类算法(Decision Tree Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Decision-Tree-Algorithms.png)\n\n决策树类算法，会基于原始数据特征，构建一颗包含很多决策路径的树。预测阶段选择路径进行决策。常见的决策树算法包括：\n\n* Classification and Regression Tree (CART)\n* Iterative Dichotomiser 3 (ID3)\n* C4.5 and C5.0 (different versions of a powerful approach)\n* Chi-squared Automatic Interaction Detection (CHAID)\n* M5\n* Conditional Decision Trees\n\n#### 2.2.4 贝叶斯类算法(Bayesian Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Bayesian-Algorithms.png)\n\n这里说的贝叶斯类算法，指的是在分类和回归问题中，隐含使用了贝叶斯原理的算法。包括：\n\n* Naive Bayes\n* Gaussian Naive Bayes\n* Multinomial Naive Bayes\n* Averaged One-Dependence Estimators (AODE)\n* Bayesian Belief Network (BBN)\n* Bayesian Network (BN)\n\n#### 2.2.5 聚类算法(Clustering Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Clustering-Algorithms.png)\n\n聚类算法做的事情是，把输入样本聚成围绕一些中心的『数据团』，以发现数据分布结构的一些规律。常用的聚类算法包括：\n\n* K-Means\n* Hierarchical Clustering\n* Expectation Maximisation (EM)\n\n#### 2.2.6 关联规则算法(Association Rule Learning Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Assoication-Rule-Learning-Algorithms.png)\n\n关联规则算法是这样一类算法：它试图抽取出，最能解释观察到的训练样本之间关联关系的规则，也就是获取一个事件和其他事件之间依赖或关联的知识，常见的关联规则算法有：\n\n* Apriori algorithm\n* Eclat algorithm\n\n#### 2.2.7 人工神经网络类算法(Artificial Neural Network Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Artificial-Neural-Network-Algorithms.png)\n\n这是受人脑神经元工作方式启发而构造的一类算法。需要提到的一点是，我把『深度学习』单拎出来了，这里说的人工神经网络偏向于更传统的感知算法，主要包括：\n\n* Perceptron\n* Back-Propagation\n* Radial Basis Function Network (RBFN)\n\n#### 2.2.8 深度学习(Deep Learning Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Deep-Learning-Algorithms.png)\n\n深度学习是近年来非常火的机器学习领域，相对于上面列的人工神经网络算法，它通常情况下，有着更深的层次和更复杂的结构。有兴趣的同学可以看看我们另一个系列机器学习与计算机视觉，最常见的深度学习算法包括：\n\n* Deep Boltzmann Machine (DBM)\n* Deep Belief Networks (DBN)\n* Convolutional Neural Network (CNN)\n* Stacked Auto-Encoders\n\n#### 2.2.9 降维算法(Dimensionality Reduction Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Dimensional-Reduction-Algorithms.png)\n\n从某种程度上说，降维算法和聚类其实有点类似，因为它也在试图发现原始训练数据的固有结构，但是降维算法在试图，用更少的信息(更低维的信息)总结和描述出原始信息的大部分内容。 \n\n有意思的是，降维算法一般在数据的可视化，或者是降低数据计算空间有很大的作用。它作为一种机器学习的算法，很多时候用它先处理数据，再灌入别的机器学习算法学习。主要的降维算法包括：\n\n* Principal Component Analysis (PCA)\n* Principal Component Regression (PCR)\n* Partial Least Squares Regression (PLSR)\n* Sammon Mapping\n* Multidimensional Scaling (MDS)\n* Linear Discriminant Analysis (LDA)\n* Mixture Discriminant Analysis (MDA)\n* Quadratic Discriminant Analysis (QDA)\n* Flexible Discriminant Analysis (FDA)\n\n#### 2.2.10 模型融合算法(Ensemble Algorithms)\n\n![](/assets/images/2016/01/06/ml-overview/Ensemble-Algorithms.png)\n\n严格意义上来说，这不算是一种机器学习算法，而更像是一种优化手段/策略，它通常是结合多个简单的弱机器学习算法，去做更可靠的决策。拿分类问题举个例，直观的理解，就是单个分类器的分类是可能出错，不可靠的，但是如果多个分类器投票，那可靠度就会高很多。常用的模型融合增强方法包括：\n\n* Random Forest\n* Boosting\n* Bootstrapped Aggregation (Bagging)\n* AdaBoost\n* Stacked Generalization (blending)\n* Gradient Boosting Machines (GBM)\n* Gradient Boosted Regression Trees (GBRT)\n\n### 2.3 机器学习算法使用图谱\n\nscikit-learn作为一个丰富的Python机器学习库，实现了绝大多数机器学习的算法，有相当多的人在使用，于是我这里很无耻地把machine learning cheat sheet for sklearn搬过来了，原文可以看这里。哈哈，既然讲机器学习，我们就用机器学习的语言来解释一下，这是针对实际应用场景的各种条件限制，对scikit-learn里完成的算法构建的一颗决策树，每一组条件都是对应一条路径，能找到相对较为合适的一些解决方法，具体如下：\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptsklearn_ml_cheat_sheet.png)\n\n首先样本量如果非常少的话，其实所有的机器学习算法都没有办法从里面『学到』通用的规则和模式，so多弄点数据是王道。然后根据问题是有/无监督学习和连续值/离散值预测，分成了分类、聚类、回归和维度约减四个方法类，每个类里根据具体情况的不同，又有不同的处理方法。\n\n## 3. 机器学习问题解决思路\n\n上面带着代价走马观花过了一遍机器学习的若干算法，下面我们试着总结总结在拿到一个实际问题的时候，如果着手使用机器学习算法去解决问题，其中的一些注意点以及核心思路。主要包括以下内容：\n\n* 拿到数据后怎么了解数据(可视化)\n* 选择最贴切的机器学习算法\n* 定位模型状态(过/欠拟合)以及解决方法\n* 大量极的数据的特征分析与可视化\n* 各种损失函数(loss function)的优缺点及如何选择\n\n多说一句，这里写的这个小教程，主要是作为一个通用的建议和指导方案，你不一定要严格按照这个流程解决机器学习问题。\n\n### 3.1 数据与可视化\n\n我们先使用scikit-learn的make_classification函数来生产一份分类数据，然后模拟一下拿到实际数据后我们需要做的事情。\n\n```python\n#numpy科学计算工具箱\nimport numpy as np\n#使用make_classification构造1000个样本，每个样本有20个feature\nfrom sklearn.datasets import make_classification\nX, y = make_classification(1000, n_features=20, n_informative=2, \n                           n_redundant=2, n_classes=2, random_state=0)\n#存为dataframe格式\nfrom pandas import DataFrame\ndf = DataFrame(np.hstack((X, y[:, None])),columns = range(20) + [\"class\"])\n```\n\n我们生成了一份包含1000个分类数据样本的数据集，每个样本有20个数值特征。同时我们把数据存储至pandas中的DataFrame数据结构中。我们取前几行的数据看一眼：\n\n```python\ndf[:6]\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_concept6_rows.png)\n\n不幸的是，肉眼看数据，尤其是维度稍微高点的时候，很有可能看花了也看不出看不出任何线索。幸运的是，我们对于图像的理解力，比数字好太多，而又有相当多的工具可以帮助我们『可视化』数据分布。\n\n> 我们在处理任何数据相关的问题时，了解数据都是很有必要的，而可视化可以帮助我们更好地直观理解数据的分布和特性\n\n数据的可视化有很多工具包可以用，比如下面我们用来做数据可视化的工具包Seaborn。最简单的可视化就是数据散列分布图和柱状图，这个可以用Seanborn的pairplot来完成。以下图中2种颜色表示2种不同的类，因为20维的可视化没有办法在平面表示，我们取出了一部分维度，两两组成pair看数据在这2个维度平面上的分布状况，代码和结果如下：\n\n```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#使用pairplot去看不同特征维度pair下数据的空间分布状况\n_ = sns.pairplot(df[:50], vars=[8, 11, 12, 14, 19], hue=\"class\", size=1.5)\nplt.show()\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptpairlot_distrib.png)\n\n我们从散列图和柱状图上可以看出，确实有些维度的特征相对其他维度，有更好的区分度，比如第11维和14维看起来很有区分度。这两个维度上看，数据点是近似线性可分的。而12维和19维似乎呈现出了很高的负相关性。接下来我们用Seanborn中的corrplot来计算计算各维度特征之间(以及最后的类别)的相关性。代码和结果图如下：\n\n```python\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12, 10))\n_ = sns.corrplot(df, annot=False)\nplt.show()\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptcov.png)\n\n相关性图很好地印证了我们之前的想法，可以看到第11维特征和第14维特征和类别有极强的相关性，同时它们俩之间也有极高的相关性。而第12维特征和第19维特征却呈现出极强的负相关性。强相关的特征其实包含了一些冗余的特征，而除掉上图中颜色较深的特征，其余特征包含的信息量就没有这么大了，它们和最后的类别相关度不高，甚至各自之间也没什么先惯性。\n\n插一句，这里的维度只有20，所以这个相关度计算并不费太大力气，然而实际情形中，你完全有可能有远高于这个数字的特征维度，同时样本量也可能多很多，那种情形下我们可能要先做一些处理，再来实现可视化了。别着急，一会儿我们会讲到。\n\n### 3.2 机器学习算法选择\n\n数据的情况我们大致看了一眼，确定一些特征维度之后，我们可以考虑先选用机器学习算法做一个baseline的系统出来了。这里我们继续参照上面提到过的机器学习算法使用图谱。 \n\n我们只有1000个数据样本，是分类问题，同时是一个有监督学习，因此我们根据图谱里教的方法，使用LinearSVC(support vector classification with linear kernel)试试。注意，LinearSVC需要选择正则化方法以缓解过拟合问题；我们这里选择使用最多的L2正则化，并把惩罚系数C设为10。我们改写一下sklearn中的学习曲线绘制函数，画出训练集和交叉验证集上的得分：\n\n```python\nfrom sklearn.svm import LinearSVC\nfrom sklearn.learning_curve import learning_curve\n#绘制学习曲线，以确定模型的状况\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    画出data在某模型上的learning curve.\n    参数解释\n    ----------\n    estimator : 你用的分类器。\n    title : 表格的标题。\n    X : 输入的feature，numpy类型\n    y : 输入的target vector\n    ylim : tuple格式的(ymin, ymax), 设定图像中纵坐标的最低点和最高点\n    cv : 做cross-validation的时候，数据分成的份数，其中一份作为cv集，其余n-1份作为training(默认为3份)\n    \"\"\"\n\n    plt.figure()\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=5, n_jobs=1, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    plt.legend(loc=\"best\")\n    plt.grid(\"on\") \n    if ylim:\n        plt.ylim(ylim)\n    plt.title(title)\n    plt.show()\n\n#少样本的情况情况下绘出学习曲线\nplot_learning_curve(LinearSVC(C=10.0), \"LinearSVC(C=10.0)\",\n                    X, y, ylim=(0.8, 1.01),\n                    train_sizes=np.linspace(.05, 0.2, 5))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptlearning_curve_1.png)\n\n这幅图上，我们发现随着样本量的增加，训练集上的得分有一定程度的下降，交叉验证集上的得分有一定程度的上升，但总体说来，两者之间有很大的差距，训练集上的准确度远高于交叉验证集。这其实意味着我们的模型处于过拟合的状态，也即模型太努力地刻画训练集，一不小心把很多噪声的分布也拟合上了，导致在新数据上的泛化能力变差了。\n\n#### 3.2.1 过拟合的定位与解决\n\n问题来了，过拟合咋办？ \n\n针对过拟合，有几种办法可以处理：\n\n**增大样本量**\n\n这个比较好理解吧，过拟合的主要原因是模型太努力地去记住训练样本的分布状况，而加大样本量，可以使得训练集的分布更加具备普适性，噪声对整体的影响下降。恩，我们提高点样本量试试：\n\n```python\n#增大一些样本量\nplot_learning_curve(LinearSVC(C=10.0), \"LinearSVC(C=10.0)\",\n                    X, y, ylim=(0.8, 1.1),\n                    train_sizes=np.linspace(.1, 1.0, 5))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptlearning_curve_2.png)\n\n是不是发现问题好了很多？随着我们增大训练样本量，我们发现训练集和交叉验证集上的得分差距在减少，最后它们已经非常接近了。增大样本量，最直接的方法当然是想办法去采集相同场景下的新数据，如果实在做不到，也可以试试在已有数据的基础上做一些人工的处理生成新数据(比如图像识别中，我们可能可以对图片做镜像变换、旋转等等)，当然，这样做一定要谨慎，强烈建议想办法采集真实数据。\n\n**减少特征的量(只用我们觉得有效的特征)**\n\n比如在这个例子中，我们之前的数据可视化和分析的结果表明，第11和14维特征包含的信息对识别类别非常有用，我们可以只用它们。\n\n```python\nplot_learning_curve(LinearSVC(C=10.0), \"LinearSVC(C=10.0) Features: 11&14\", X[:, [11, 14]], y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_concept1114.png)\n\n从上图上可以看出，过拟合问题也得到一定程度的缓解。不过我们这是自己观察后，手动选出11和14维特征。那能不能自动进行特征组合和选择呢，其实我们当然可以遍历特征的组合样式，然后再进行特征选择(前提依旧是这里特征的维度不高，如果高的话，遍历所有的组合是一个非常非常非常耗时的过程！！)：\n\n```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\n# SelectKBest(f_classif, k=2) 会根据Anova F-value选出 最好的k=2个特征\n\nplot_learning_curve(Pipeline([(\"fs\", SelectKBest(f_classif, k=2)), # select two features\n                               (\"svc\", LinearSVC(C=10.0))]), \"SelectKBest(f_classif, k=2) + LinearSVC(C=10.0)\", X, y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptbest_2.png)\n\n如果你自己跑一下程序，会发现在我们自己手造的这份数据集上，这个特征筛选的过程超级顺利，但依旧像我们之前提过的一样，这是因为特征的维度不太高。 \n\n从另外一个角度看，我们之所以做特征选择，是想降低模型的复杂度，而更不容易刻画到噪声数据的分布。从这个角度出发，我们还可以有(1)多项式你和模型中降低多项式次数 (2)神经网络中减少神经网络的层数和每层的结点数 (c)SVM中增加RBF-kernel的bandwidth等方式来降低模型的复杂度。 \n\n话说回来，即使以上提到的办法降低模型复杂度后，好像能在一定程度上缓解过拟合，但是我们一般还是不建议一遇到过拟合，就用这些方法处理，优先用下面的方法：\n\n**增强正则化作用(比如说这里是减小LinearSVC中的C参数)**\n\n正则化是我认为在不损失信息的情况下，最有效的缓解过拟合现象的方法。\n\n```python\nplot_learning_curve(LinearSVC(C=0.1), \"LinearSVC(C=0.1)\", X, y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptregularization.png)\n\n调整正则化系数后，发现确实过拟合现象有一定程度的缓解，但依旧是那个问题，我们现在的系数是自己敲定的，有没有办法可以自动选择最佳的这个参数呢？可以。我们可以在交叉验证集上做grid-search查找最好的正则化系数(对于大数据样本，我们依旧需要考虑时间问题，这个过程可能会比较慢):\n\n```python\nfrom sklearn.grid_search import GridSearchCV\nestm = GridSearchCV(LinearSVC(), \n                    param_grid={\"C\": [0.001, 0.01, 0.1, 1.0, 10.0]})\nplot_learning_curve(estm, \"LinearSVC(C=AUTO)\", \n                    X, y, ylim=(0.8, 1.0),\n                    train_sizes=np.linspace(.05, 0.2, 5))\nprint \"Chosen parameter on 100 datapoints: %s\" % estm.fit(X[:500], y[:500]).best_params_\n```\n\n在500个点得到的结果是：{‘C’: 0.01} \n\n使用新的C参数，我们再看看学习曲线： \n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptauto_ regularization.png)\n\n对于特征选择的部分，我打算多说几句，我们刚才看过了用sklearn.feature_selection中的SelectKBest来选择特征的过程，也提到了在高维特征的情况下，这个过程可能会非常非常慢。那我们有别的办法可以进行特征选择吗？比如说，我们的分类器自己能否甄别那些特征是对最后的结果有益的？这里有个实际工作中用到的小技巧。\n\n我们知道：\n\n* l2正则化，它对于最后的特征权重的影响是，尽量打散权重到每个特征维度上，不让权重集中在某些维度上，出现权重特别高的特征。\n* 而l1正则化，它对于最后的特征权重的影响是，让特征获得的权重稀疏化，也就是对结果影响不那么大的特征，干脆就拿不着权重。\n\n那基于这个理论，我们可以把SVC中的正则化替换成l1正则化，让其自动甄别哪些特征应该留下权重。\n\n```python\nplot_learning_curve(LinearSVC(C=0.1, penalty='l1', dual=False), \n                    \"LinearSVC(C=0.1, penalty='l1')\", X, y, ylim=(0.8, 1.0), \n                    train_sizes=np.linspace(.05, 0.2, 5))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptl1_regularization.png)\n\n好了，我们一起来看看最后特征获得的权重：\n\n```python\nestm = LinearSVC(C=0.1, penalty='l1', dual=False)\nestm.fit(X[:450], y[:450])  # 用450个点来训练\nprint \"Coefficients learned: %s\" % est.coef_\nprint \"Non-zero coefficients: %s\" % np.nonzero(estm.coef_)[1]\n```\n\n得到结果：\n\n```\nCoefficients learned: [[ 0.          0.          0.          0.          0.          0.01857999\n   0.          0.          0.          0.004135    0.          1.05241369\n   0.01971419  0.          0.          0.          0.         -0.05665314\n   0.14106505  0.        ]]\nNon-zero coefficients: [5 9 11 12 17 18]\n```\n\n你看，5 9 11 12 17 18这些维度的特征获得了权重，而第11维权重最大，也说明了它影响程度最大。\n\n#### 3.2.2 欠拟合定位与解决\n\n我们再随机生成一份数据[1000*20]的数据(但是分布和之前有变化)，重新使用LinearSVC来做分类。\n\n```python\n#构造一份环形数据\nfrom sklearn.datasets import make_circles\nX, y = make_circles(n_samples=1000, random_state=2)\n#绘出学习曲线\nplot_learning_curve(LinearSVC(C=0.25),\"LinearSVC(C=0.25)\",X, y, ylim=(0.5, 1.0),train_sizes=np.linspace(.1, 1.0, 5))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptlearning_curve_3.png)\n\n简直烂出翔了有木有，二分类问题，我们做随机猜测，准确率都有0.5，这比随机猜测都高不了多少！！！怎么办？\n\n不要盲目动手收集更多资料，或者调整正则化参数。我们从学习曲线上其实可以看出来，训练集上的准确度和交叉验证集上的准确度都很低，这其实就对应了我们说的『欠拟合』状态。别急，我们回到我们的数据，还是可视化看看：\n\n```python\nf = DataFrame(np.hstack((X, y[:, None])), columns = range(2) + [\"class\"])\n_ = sns.pairplot(df, vars=[0, 1], hue=\"class\", size=3.5)\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptdata_visualization.png)\n\n你发现什么了，数据根本就没办法线性分割！！！，所以你再找更多的数据，或者调整正则化参数，都是无济于事的！！！\n\n那我们又怎么解决欠拟合问题呢？通常有下面一些方法：\n\n**调整你的特征(找更有效的特征！！)**\n\n比如说我们观察完现在的数据分布，然后我们先对数据做个映射：\n\n```python\n# 加入原始特征的平方项作为新特征\nX_extra = np.hstack((X, X[:, [0]]**2 + X[:, [1]]**2))\n\nplot_learning_curve(LinearSVC(C=0.25), \"LinearSVC(C=0.25) + distance feature\", X_extra, y, ylim=(0.5, 1.0), train_sizes=np.linspace(.1, 1.0, 5))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptnon-linear-feature.png)\n\n卧槽，少年，这准确率，被吓尿了有木有啊！！！所以你看，选用的特征影响太大了，当然，我们这里是人工模拟出来的数据，分布太明显了，实际数据上，会比这个麻烦一些，但是在特征上面下的功夫还是很有回报的。\n\n**使用更复杂一点的模型(比如说用非线性的核函数)**\n\n我们对模型稍微调整了一下，用了一个复杂一些的非线性rbf kernel：\n\n```python\nfrom sklearn.svm import SVC\n# note: we use the original X without the extra feature\nplot_learning_curve(SVC(C=2.5, kernel=\"rbf\", gamma=1.0), \"SVC(C=2.5, kernel='rbf', gamma=1.0)\",X, y, ylim=(0.5, 1.0), train_sizes=np.linspace(.1, 1.0, 5))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptcomplex_model.png)\n\n你看，效果依旧很赞。\n\n### 3.3 关于大数据样本集和高维特征空间\n\n我们在小样本的toy dataset上，怎么捣鼓都有好的方法。但是当数据量和特征样本空间膨胀非常厉害时，很多东西就没有那么好使了，至少是一个很耗时的过程。举个例子说，我们现在重新生成一份数据集，但是这次，我们生成更多的数据，更高的特征维度，而分类的类别也提高到5。\n\n#### 3.3.1 大数据情形下的模型选择与学习曲线\n\n在上面提到的那样一份数据上，我们用LinearSVC可能就会有点慢了，我们注意到机器学习算法使用图谱推荐我们使用SGDClassifier。其实本质上说，这个模型也是一个线性核函数的模型，不同的地方是，它使用了随机梯度下降做训练，所以每次并没有使用全部的样本，收敛速度会快很多。再多提一点，SGDClassifier对于特征的幅度非常敏感，也就是说，我们在把数据灌给它之前，应该先对特征做幅度调整，当然，用sklearn的StandardScaler可以很方便地完成这一点。\n\nSGDClassifier每次只使用一部分(mini-batch)做训练，在这种情况下，我们使用交叉验证(cross-validation)并不是很合适，我们会使用相对应的progressive validation：简单解释一下，estimator每次只会拿下一个待训练batch在本次做评估，然后训练完之后，再在这个batch上做一次评估，看看是否有优化。\n\n```python\n#生成大样本，高纬度特征数据\nX, y = make_classification(200000, n_features=200, n_informative=25, n_redundant=0, n_classes=10, class_sep=2, random_state=0)\n\n#用SGDClassifier做训练，并画出batch在训练前后的得分差\nfrom sklearn.linear_model import SGDClassifier\nest = SGDClassifier(penalty=\"l2\", alpha=0.001)\nprogressive_validation_score = []\ntrain_score = []\nfor datapoint in range(0, 199000, 1000):\n    X_batch = X[datapoint:datapoint+1000]\n    y_batch = y[datapoint:datapoint+1000]\n    if datapoint > 0:\n        progressive_validation_score.append(est.score(X_batch, y_batch))\n    est.partial_fit(X_batch, y_batch, classes=range(10))\n    if datapoint > 0:\n        train_score.append(est.score(X_batch, y_batch))\n\nplt.plot(train_score, label=\"train score\")\nplt.plot(progressive_validation_score, label=\"progressive validation score\")\nplt.xlabel(\"Mini-batch\")\nplt.ylabel(\"Score\")\nplt.legend(loc='best')  \nplt.show()                     \n```\n\n得到如下的结果： \n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptSGDClassifier.png)\n\n从这个图上的得分，我们可以看出在50个mini-batch迭代之后，数据上的得分就已经变化不大了。但是好像得分都不太高，所以我们猜测一下，这个时候我们的数据，处于欠拟合状态。我们刚才在小样本集合上提到了，如果欠拟合，我们可以使用更复杂的模型，比如把核函数设置为非线性的，但遗憾的是像rbf核函数是没有办法和SGDClassifier兼容的。因此我们只能想别的办法了，比如这里，我们可以把SGDClassifier整个替换掉了，用多层感知神经网来完成这个任务，我们之所以会想到多层感知神经网，是因为它也是一个用随机梯度下降训练的算法，同时也是一个非线性的模型。当然根据机器学习算法使用图谱，也可以使用核估计(kernel-approximation)来完成这个事情。\n\n#### 3.3.2 大数据量下的可视化\n\n大样本数据的可视化是一个相对比较麻烦的事情，一般情况下我们都要用到降维的方法先处理特征。我们找一个例子来看看，可以怎么做，比如我们数据集取经典的『手写数字集』，首先找个方法看一眼这个图片数据集。\n\n```python\n#直接从sklearn中load数据集\nfrom sklearn.datasets import load_digits\ndigits = load_digits(n_class=6)\nX = digits.data\ny = digits.target\nn_samples, n_features = X.shape\nprint \"Dataset consist of %d samples with %d features each\" % (n_samples, n_features)\n\n# 绘制数字示意图\nn_img_per_row = 20\nimg = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\nfor i in range(n_img_per_row):\n    ix = 10 * i + 1\n    for j in range(n_img_per_row):\n        iy = 10 * j + 1\n        img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))\n\nplt.imshow(img, cmap=plt.cm.binary)\nplt.xticks([])\nplt.yticks([])\n_ = plt.title('A selection from the 8*8=64-dimensional digits dataset')\nplt.show()\n```\n\n![](/assets/images/2016/01/06/ml-overview/8-8.png)\n\n我们总共有1083个训练样本，包含手写数字(0,1,2,3,4,5)，每个样本图片中的像素点平铺开都是64位，这个维度显然是没办法直接可视化的。下面我们基于scikit-learn的示例教程对特征用各种方法做降维处理，再可视化。\n\n**随机投射**\n\n我们先看看，把数据随机投射到两个维度上的结果：\n\n```python\n#import所需的package\nfrom sklearn import (manifold, decomposition, random_projection)\nrp = random_projection.SparseRandomProjection(n_components=2, random_state=42)\n\n#定义绘图函数\nfrom matplotlib import offsetbox\ndef plot_embedding(X, title=None):\n    x_min, x_max = np.min(X, 0), np.max(X, 0)\n    X = (X - x_min) / (x_max - x_min)\n\n    plt.figure(figsize=(10, 10))\n    ax = plt.subplot(111)\n    for i in range(X.shape[0]):\n        plt.text(X[i, 0], X[i, 1], str(digits.target[i]),\n                 color=plt.cm.Set1(y[i] / 10.),\n                 fontdict={'weight': 'bold', 'size': 12})\n\n    if hasattr(offsetbox, 'AnnotationBbox'):\n        # only print thumbnails with matplotlib > 1.0\n        shown_images = np.array([[1., 1.]])  # just something big\n        for i in range(digits.data.shape[0]):\n            dist = np.sum((X[i] - shown_images) ** 2, 1)\n            if np.min(dist) < 4e-3:\n                # don't show points that are too close\n                continue\n            shown_images = np.r_[shown_images, [X[i]]]\n            imagebox = offsetbox.AnnotationBbox(\n                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n                X[i])\n            ax.add_artist(imagebox)\n    plt.xticks([]), plt.yticks([])\n    if title is not None:\n        plt.title(title)\n\n#记录开始时间\nstart_time = time.time()\nX_projected = rp.fit_transform(X)\nplot_embedding(X_projected, \"Random Projection of the digits (time: %.3fs)\" % (time.time() - start_time))\n```\n\n结果如下： \n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptrandom_projection.png)\n\n**PCA降维**\n\n在维度约减/降维领域有一个非常强大的算法叫做PCA(Principal Component Analysis，主成分分析)，它能将原始的绝大多数信息用维度远低于原始维度的几个主成分表示出来。PCA在我们现在的数据集上效果还不错，我们来看看用PCA对原始特征降维至2维后，原始样本在空间的分布状况：\n\n```python\nfrom sklearn import (manifold, decomposition, random_projection)\n#TruncatedSVD 是 PCA的一种实现\nX_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X)\n#记录时间\nstart_time = time.time()\nplot_embedding(X_pca,\"Principal Components projection of the digits (time: %.3fs)\" % (time.time() - start_time))\n```\n\n得到的结果如下： \n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptPCA.png)\n\n我们可以看出，效果还不错，不同的手写数字在2维平面上，显示出了区域集中性。即使它们之间有一定的重叠区域。\n\n如果我们用一些非线性的变换来做降维操作，从原始的64维降到2维空间，效果更好，比如这里我们用到一个技术叫做t-SNE，sklearn的manifold对其进行了实现：\n\n```python\nfrom sklearn import (manifold, decomposition, random_projection)\n#降维\ntsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\nstart_time = time.time()\nX_tsne = tsne.fit_transform(X)\n#绘图\nplot_embedding(X_tsne,\n               \"t-SNE embedding of the digits (time: %.3fs)\" % (time.time() - start_time))\n```\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptt-SNE.png)\n\n我们发现结果非常的惊人，似乎这个非线性变换降维过后，仅仅2维的特征，就可以将原始数据的不同类别，在平面上很好地划分开。不过t-SNE也有它的缺点，一般说来，相对于线性变换的降维，它需要更多的计算时间。也不太适合在大数据集上全集使用。\n\n### 3.4 损失函数的选择\n\n损失函数的选择对于问题的解决和优化，非常重要。我们先来看一眼各种不同的损失函数：\n\n```python\nimport numpy as np\nimport matplotlib.plot as plt\n# 改自http://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_loss_functions.html\nxmin, xmax = -4, 4\nxx = np.linspace(xmin, xmax, 100)\nplt.plot([xmin, 0, 0, xmax], [1, 1, 0, 0], 'k-',\n         label=\"Zero-one loss\")\nplt.plot(xx, np.where(xx < 1, 1 - xx, 0), 'g-',\n         label=\"Hinge loss\")\nplt.plot(xx, np.log2(1 + np.exp(-xx)), 'r-',\n         label=\"Log loss\")\nplt.plot(xx, np.exp(-xx), 'c-',\n         label=\"Exponential loss\")\nplt.plot(xx, -np.minimum(xx, 0), 'm-',\n         label=\"Perceptron loss\")\n\nplt.ylim((0, 8))\nplt.legend(loc=\"upper right\")\nplt.xlabel(r\"Decision function $f(x)$\")\nplt.ylabel(\"$L(y, f(x))$\")\nplt.show()\n```\n\n得到结果图像如下：\n\n![](/assets/images/2016/01/06/ml-overview/ml_conceptloss_function.png)\n\n不同的损失函数有不同的优缺点：\n\n* 0-1损失函数(zero-one loss)非常好理解，直接对应分类问题中判断错的个数。但是比较尴尬的是它是一个非凸函数，这意味着其实不是那么实用。\n* hinge loss(SVM中使用到的)的健壮性相对较高(对于异常点/噪声不敏感)。但是它没有那么好的概率解释。\n* log损失函数(log-loss)的结果能非常好地表征概率分布。因此在很多场景，尤其是多分类场景下，如果我们需要知道结果属于每个类别的置信度，那这个损失函数很适合。缺点是它的健壮性没有那么强，相对hinge loss会对噪声敏感一些。\n* 多项式损失函数(exponential loss)(AdaBoost中用到的)对离群点/噪声非常非常敏感。但是它的形式对于boosting算法简单而有效。\n* 感知损失(perceptron loss)可以看做是hinge loss的一个变种。hinge loss对于判定边界附近的点(正确端)惩罚力度很高。而perceptron loss，只要样本的判定类别结果是正确的，它就是满意的，而不管其离判定边界的距离。优点是比hinge loss简单，缺点是因为不是max-margin boundary，所以得到模型的泛化能力没有hinge loss强。\n\n## 4. 总结\n\n全文到此就结束了。先走马观花看了一遍机器学习的算法，然后给出了对应scikit-learn的『秘密武器』机器学习算法使用图谱，紧接着从了解数据(可视化)、选择机器学习算法、定位过/欠拟合及解决方法、大量极的数据可视化和损失函数优缺点与选择等方面介绍了实际机器学习问题中的一些思路和方法。本文和文章机器学习系列(3)_逻辑回归应用之Kaggle泰坦尼克之灾都提及了一些处理实际机器学习问题的思路和方法，有相似和互补之处，欢迎大家参照着看。\n \n---\n\n* 原文链接：[机器学习系列(4)_机器学习算法一览，应用建议与解决思路](http://blog.csdn.net/han_xiaoyang/article/details/50469334)\n","tags":["Machine-Learning"],"categories":["Machine-Learning"]},{"title":"机器学习系列(3)_逻辑回归应用之Kaggle泰坦尼克之灾","url":"%2F2015%2F2015-11-12-ml-logistic-regression-3%2F","content":" \n## 1.引言\n\n先说一句，年末双十一什么的一来，真是非(mang)常(cheng)欢(gou)乐(le)！然后push自己抽出时间来写这篇blog的原因也非常简单：\n\n* 写完前两篇逻辑回归的介绍和各个角度理解之后，我们讨论群(戳我入群)的小伙伴们纷纷表示『好像很高级的样纸，but 然并卵 啊！你们倒是拿点实际数据来给我们看看，这玩意儿 有！什！么！用！啊！』\n* talk is cheap, show me the code！\n* no example say a jb！\n\nOK，OK，这就来了咯，同学们别着急，我们先找个简单的实际例子，来看看，所谓的数据挖掘或者机器学习实际应用到底是怎么样一个过程。\n\n『喂，那几个说要看大数据上机器学习应用的，对，就是说你们！别着急好么，我们之后拉点大一点实际数据用liblinear或者spark,MLlib跑给你们看，行不行？咱们先拿个实例入入门嘛』\n\n好了，我是一个严肃的技术研究和分享者，咳咳，不能废话了，各位同学继续往下看吧！\n\n## 2.背景\n\n### 2.1 关于Kaggle\n\n* 我是Kaggle地址，翻我牌子\n* 亲，逼格这么高的地方，你一定听过对不对？是！这就是那个无数『数据挖掘先驱』们，在回答”枪我有了，哪能找到靶子练练手啊？”时候的答案！\n* 这是一个要数据有数据，要实际应用场景有场景，要一起在数据挖掘领域high得不要不要的小伙伴就有小伙伴的地方啊！！！\n\n艾玛，逗逼模式开太猛了。恩，不闹，不闹，说正事，Kaggle是一个数据分析建模的应用竞赛平台，有点类似KDD-CUP（国际知识发现和数据挖掘竞赛），企业或者研究者可以将问题背景、数据、期望指标等发布到Kaggle上，以竞赛的形式向广大的数据科学家征集解决方案。而热爱数(dong)据(shou)挖(zhe)掘(teng)的小伙伴们可以下载/分析数据，使用统计/机器学习/数据挖掘等知识，建立算法模型，得出结果并提交，排名top的可能会有奖金哦！\n\n### 2.2 关于泰坦尼克号之灾\n\n带大家去该问题页面溜达一圈吧\n\n* 下面是问题背景页\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/001.png)\n\n* 下面是可下载Data的页面 \n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/002.png)\n\n* 下面是小伙伴们最爱的forum页面，你会看到各种神级人物厉(qi)害(pa)的数据处理/建模想法，你会直视『世界真奇妙』。 \n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/003.png)\n\n泰坦尼克号问题之背景\n\n* 就是那个大家都熟悉的『Jack and Rose』的故事，豪华游艇倒了，大家都惊恐逃生，可是救生艇的数量有限，无法人人都有，副船长发话了『lady and kid first！』，所以是否获救其实并非随机，而是基于一些背景有rank先后的。\n\n* 训练和测试数据是一些乘客的个人信息以及存活状况，要尝试根据它生成合适的模型并预测其他人的存活状况。\n\n* 对，这是一个二分类问题，是我们之前讨论的logistic regression所能处理的范畴。\n\n## 3.说明\n\n接触过Kaggle的同学们可能知道这个问题，也可能知道RandomForest和SVM等等算法，甚至还对多个模型做过融合，取得过非常好的结果，那maybe这篇文章并不是针对你的，你可以自行略过。\n\n我们因为之前只介绍了Logistic Regression这一种分类算法。所以本次的问题解决过程和优化思路，都集中在这种算法上。其余的方法可能我们之后的文章里会提到。\n\n说点个人的观点。不一定正确。 \n\n```\n『解决一个问题的方法和思路不止一种』 \n『没有所谓的机器学习算法优劣，也没有绝对高性能的机器学习算法，只有在特定的场景、数据和特征下更合适的机器学习算法。』\n```\n\n## 4.怎么做？\n\n手把手教程马上就来，先来两条我看到的，觉得很重要的经验。\n\n* 印象中Andrew Ng老师似乎在coursera上说过，应用机器学习，千万不要一上来就试图做到完美，先撸一个baseline的model出来，再进行后续的分析步骤，一步步提高，所谓后续步骤可能包括『分析model现在的状态(欠/过拟合)，分析我们使用的feature的作用大小，进行feature selection，以及我们模型下的bad case和产生的原因』等等。\n\n* Kaggle上的大神们，也分享过一些experience，说几条我记得的哈：\n\n  * 『对数据的认识太重要了！』\n  * 『数据中的特殊点/离群点的分析和处理太重要了！』\n  * 『特征工程(feature engineering)太重要了！在很多Kaggle的场景下，甚至比model本身还要重要』\n  * 『要做模型融合(model ensemble)啊啊啊！』\n\n## 5.初探数据\n\n先看看我们的数据，长什么样吧。在Data下我们train.csv和test.csv两个文件，分别存着官方给的训练和测试数据。\n\n```python\nimport pandas as pd #数据分析\nimport numpy as np #科学计算\nfrom pandas import Series,DataFrame\n\ndata_train = pd.read_csv(\"/Users/Hanxiaoyang/Titanic_data/Train.csv\")\ndata_train\n```\n\npandas是常用的Python数据处理包，把csv文件读入成dataframe各式，我们在ipython notebook中，看到data_train如下所示：\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/004.png)\n\n这就是典型的dataframe格式，如果你没接触过这种格式，完全没有关系，你就把它想象成Excel里面的列好了。 \n\n我们看到，总共有12列，其中Survived字段表示的是该乘客是否获救，其余都是乘客的个人信息，包括：\n\n```\nPassengerId => 乘客ID\nPclass => 乘客等级(1/2/3等舱位)\nName => 乘客姓名\nSex => 性别\nAge => 年龄\nSibSp => 堂兄弟/妹个数\nParch => 父母与小孩个数\nTicket => 船票信息\nFare => 票价\nCabin => 客舱\nEmbarked => 登船港口\n```\n\n逐条往下看，要看完这么多条，眼睛都有一种要瞎的赶脚。好吧，我们让dataframe自己告诉我们一些信息，如下所示：\n\n```python\ndata_train.info()\n```\n\n看到了如下的信息： \n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/005.png)\n\n上面的数据说啥了？它告诉我们，训练数据中总共有891名乘客，但是很不幸，我们有些属性的数据不全，比如说：\n\n```\nAge（年龄）属性只有714名乘客有记录\nCabin（客舱）更是只有204名乘客是已知的\n```\n\n似乎信息略少啊，想再瞄一眼具体数据数值情况呢？恩，我们用下列的方法，得到数值型数据的一些分布(因为有些属性，比如姓名，是文本型；而另外一些属性，比如登船港口，是类目型。这些我们用下面的函数是看不到的)：\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/006.png)\n\n我们从上面看到更进一步的什么信息呢？ \n\nmean字段告诉我们，大概0.383838的人最后获救了，2/3等舱的人数比1等舱要多，平均乘客年龄大概是29.7岁(计算这个时候会略掉无记录的)等等…\n\n## 6.数据初步分析\n\n每个乘客都这么多属性，那我们咋知道哪些属性更有用，而又应该怎么用它们啊？说实话这会儿我也不知道，但我们记得前面提到过\n\n```\n『对数据的认识太重要了！』\n『对数据的认识太重要了！』\n『对数据的认识太重要了！』\n```\n\n重要的事情说三遍，恩，说完了。仅仅最上面的对数据了解，依旧无法给我们提供想法和思路。我们再深入一点来看看我们的数据，看看每个/多个 属性和最后的Survived之间有着什么样的关系呢。\n\n### 6.1 乘客各属性分布\n\n脑容量太有限了…数值看花眼了。我们还是统计统计，画些图来看看属性和结果之间的关系好了，代码如下：\n\n```python\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nfig.set(alpha=0.2)  # 设定图表颜色alpha参数\n\nplt.subplot2grid((2,3),(0,0))             # 在一张大图里分列几个小图\ndata_train.Survived.value_counts().plot(kind='bar')# 柱状图 \nplt.title(u\"获救情况 (1为获救)\") # 标题\nplt.ylabel(u\"人数\")  \n\nplt.subplot2grid((2,3),(0,1))\ndata_train.Pclass.value_counts().plot(kind=\"bar\")\nplt.ylabel(u\"人数\")\nplt.title(u\"乘客等级分布\")\n\nplt.subplot2grid((2,3),(0,2))\nplt.scatter(data_train.Survived, data_train.Age)\nplt.ylabel(u\"年龄\")                         # 设定纵坐标名称\nplt.grid(b=True, which='major', axis='y') \nplt.title(u\"按年龄看获救分布 (1为获救)\")\n\nplt.subplot2grid((2,3),(1,0), colspan=2)\ndata_train.Age[data_train.Pclass == 1].plot(kind='kde')   \ndata_train.Age[data_train.Pclass == 2].plot(kind='kde')\ndata_train.Age[data_train.Pclass == 3].plot(kind='kde')\nplt.xlabel(u\"年龄\")# plots an axis lable\nplt.ylabel(u\"密度\") \nplt.title(u\"各等级的乘客年龄分布\")\nplt.legend((u'头等舱', u'2等舱',u'3等舱'),loc='best') # sets our legend for our graph.\n\nplt.subplot2grid((2,3),(1,2))\ndata_train.Embarked.value_counts().plot(kind='bar')\nplt.title(u\"各登船口岸上船人数\")\nplt.ylabel(u\"人数\")  \nplt.show()\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/007.png)\n\nbingo，图还是比数字好看多了。所以我们在图上可以看出来，被救的人300多点，不到半数；3等舱乘客灰常多；遇难和获救的人年龄似乎跨度都很广；3个不同的舱年龄总体趋势似乎也一致，2/3等舱乘客20岁多点的人最多，1等舱40岁左右的最多(→_→似乎符合财富和年龄的分配哈，咳咳，别理我，我瞎扯的)；登船港口人数按照S、C、Q递减，而且S远多于另外俩港口。\n\n这个时候我们可能会有一些想法了：\n\n* 不同舱位/乘客等级可能和财富/地位有关系，最后获救概率可能会不一样\n* 年龄对获救概率也一定是有影响的，毕竟前面说了，副船长还说『小孩和女士先走』呢\n* 和登船港口是不是有关系呢？也许登船港口不同，人的出身地位不同？\n\n口说无凭，空想无益。老老实实再来统计统计，看看这些属性值的统计分布吧。\n\n### 6.2 属性与获救结果的关联统计\n\n```python\n#看看各乘客等级的获救情况\nfig = plt.figure()\nfig.set(alpha=0.2)  # 设定图表颜色alpha参数\n\nSurvived_0 = data_train.Pclass[data_train.Survived == 0].value_counts()\nSurvived_1 = data_train.Pclass[data_train.Survived == 1].value_counts()\ndf=pd.DataFrame({u'获救':Survived_1, u'未获救':Survived_0})\ndf.plot(kind='bar', stacked=True)\nplt.title(u\"各乘客等级的获救情况\")\nplt.xlabel(u\"乘客等级\") \nplt.ylabel(u\"人数\") \nplt.show()\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/008.png)\n\n啧啧，果然，钱和地位对舱位有影响，进而对获救的可能性也有影响啊←_← \n\n咳咳，跑题了，我想说的是，明显等级为1的乘客，获救的概率高很多。恩，这个一定是影响最后获救结果的一个特征。\n\n```python\n#看看各性别的获救情况\nfig = plt.figure()\nfig.set(alpha=0.2)  # 设定图表颜色alpha参数\n\nSurvived_m = data_train.Survived[data_train.Sex == 'male'].value_counts()\nSurvived_f = data_train.Survived[data_train.Sex == 'female'].value_counts()\ndf=pd.DataFrame({u'男性':Survived_m, u'女性':Survived_f})\ndf.plot(kind='bar', stacked=True)\nplt.title(u\"按性别看获救情况\")\nplt.xlabel(u\"性别\") \nplt.ylabel(u\"人数\")\nplt.show()\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/009.png)\n\n歪果盆友果然很尊重lady，lady first践行得不错。性别无疑也要作为重要特征加入最后的模型之中。\n\n再来个详细版的好了。\n\n```python\n #然后我们再来看看各种舱级别情况下各性别的获救情况\nfig=plt.figure()\nfig.set(alpha=0.65) # 设置图像透明度，无所谓\nplt.title(u\"根据舱等级和性别的获救情况\")\n\nax1=fig.add_subplot(141)\ndata_train.Survived[data_train.Sex == 'female'][data_train.Pclass != 3].value_counts().plot(kind='bar', label=\"female highclass\", color='#FA2479')\nax1.set_xticklabels([u\"获救\", u\"未获救\"], rotation=0)\nax1.legend([u\"女性/高级舱\"], loc='best')\n\nax2=fig.add_subplot(142, sharey=ax1)\ndata_train.Survived[data_train.Sex == 'female'][data_train.Pclass == 3].value_counts().plot(kind='bar', label='female, low class', color='pink')\nax2.set_xticklabels([u\"未获救\", u\"获救\"], rotation=0)\nplt.legend([u\"女性/低级舱\"], loc='best')\n\nax3=fig.add_subplot(143, sharey=ax1)\ndata_train.Survived[data_train.Sex == 'male'][data_train.Pclass != 3].value_counts().plot(kind='bar', label='male, high class',color='lightblue')\nax3.set_xticklabels([u\"未获救\", u\"获救\"], rotation=0)\nplt.legend([u\"男性/高级舱\"], loc='best')\n\nax4=fig.add_subplot(144, sharey=ax1)\ndata_train.Survived[data_train.Sex == 'male'][data_train.Pclass == 3].value_counts().plot(kind='bar', label='male low class', color='steelblue')\nax4.set_xticklabels([u\"未获救\", u\"获救\"], rotation=0)\nplt.legend([u\"男性/低级舱\"], loc='best')\n\nplt.show()\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/010.png)\n\n恩，坚定了之前的判断。\n\n我们看看各登船港口的获救情况。\n\n```python\nfig = plt.figure()\nfig.set(alpha=0.2)  # 设定图表颜色alpha参数\n\nSurvived_0 = data_train.Embarked[data_train.Survived == 0].value_counts()\nSurvived_1 = data_train.Embarked[data_train.Survived == 1].value_counts()\ndf=pd.DataFrame({u'获救':Survived_1, u'未获救':Survived_0})\ndf.plot(kind='bar', stacked=True)\nplt.title(u\"各登录港口乘客的获救情况\")\nplt.xlabel(u\"登录港口\") \nplt.ylabel(u\"人数\") \n\nplt.show()\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/011.png)\n\n下面我们来看看 堂兄弟/妹，孩子/父母有几人，对是否获救的影响。\n\n```python\ng = data_train.groupby(['SibSp','Survived'])\ndf = pd.DataFrame(g.count()['PassengerId'])\nprint df\n\ng = data_train.groupby(['SibSp','Survived'])\ndf = pd.DataFrame(g.count()['PassengerId'])\nprint df\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/012.png)\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/013.png)\n\n好吧，没看出特别特别明显的规律(为自己的智商感到捉急…)，先作为备选特征，放一放。\n\n```python\n#ticket是船票编号，应该是unique的，和最后的结果没有太大的关系，先不纳入考虑的特征范畴把\n#cabin只有204个乘客有值，我们先看看它的一个分布\ndata_train.Cabin.value_counts()\n```\n\n部分结果如下： \n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/014.png)\n\n这三三两两的…如此不集中…我们猜一下，也许，前面的ABCDE是指的甲板位置、然后编号是房间号？…好吧，我瞎说的，别当真…\n\n关键是Cabin这鬼属性，应该算作类目型的，本来缺失值就多，还如此不集中，注定是个棘手货…第一感觉，这玩意儿如果直接按照类目特征处理的话，太散了，估计每个因子化后的特征都拿不到什么权重。加上有那么多缺失值，要不我们先把Cabin缺失与否作为条件(虽然这部分信息缺失可能并非未登记，maybe只是丢失了而已，所以这样做未必妥当)，先在有无Cabin信息这个粗粒度上看看Survived的情况好了。\n\n```python\nfig = plt.figure()\nfig.set(alpha=0.2)  # 设定图表颜色alpha参数\n\nSurvived_cabin = data_train.Survived[pd.notnull(data_train.Cabin)].value_counts()\nSurvived_nocabin = data_train.Survived[pd.isnull(data_train.Cabin)].value_counts()\ndf=pd.DataFrame({u'有':Survived_cabin, u'无':Survived_nocabin}).transpose()\ndf.plot(kind='bar', stacked=True)\nplt.title(u\"按Cabin有无看获救情况\")\nplt.xlabel(u\"Cabin有无\") \nplt.ylabel(u\"人数\")\nplt.show()\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/015.png)\n\n咳咳，有Cabin记录的似乎获救概率稍高一些，先这么着放一放吧。\n\n## 7.简单数据预处理\n\n大体数据的情况看了一遍，对感兴趣的属性也有个大概的了解了。 \n\n下一步干啥？咱们该处理处理这些数据，为机器学习建模做点准备了。\n\n对了，我这里说的数据预处理，其实就包括了很多Kaggler津津乐道的feature engineering过程，灰常灰常有必要！\n\n```\n『特征工程(feature engineering)太重要了！』 \n『特征工程(feature engineering)太重要了！』 \n『特征工程(feature engineering)太重要了！』\n```\n\n恩，重要的事情说三遍。\n\n先从最突出的数据属性开始吧，对，Cabin和Age，有丢失数据实在是对下一步工作影响太大。\n\n先说Cabin，暂时我们就按照刚才说的，按Cabin有无数据，将这个属性处理成Yes和No两种类型吧。\n\n再说Age：\n\n通常遇到缺值的情况，我们会有几种常见的处理方式\n\n* 如果缺值的样本占总数比例极高，我们可能就直接舍弃了，作为特征加入的话，可能反倒带入noise，影响最后的结果了\n* 如果缺值的样本适中，而该属性非连续值特征属性(比如说类目属性)，那就把NaN作为一个新类别，加到类别特征中\n* 如果缺值的样本适中，而该属性为连续值特征属性，有时候我们会考虑给定一个step(比如这里的age，我们可以考虑每隔2/3岁为一个步长)，然后把它离散化，之后把NaN作为一个type加到属性类目中。\n* 有些情况下，缺失的值个数并不是特别多，那我们也可以试着根据已有的值，拟合一下数据，补充上。\n\n本例中，后两种处理方式应该都是可行的，我们先试试拟合补全吧(虽然说没有特别多的背景可供我们拟合，这不一定是一个多么好的选择)\n\n我们这里用scikit-learn中的RandomForest来拟合一下缺失的年龄数据(注：RandomForest是一个用在原始数据中做不同采样，建立多颗DecisionTree，再进行average等等来降低过拟合现象，提高结果的机器学习算法，我们之后会介绍到)\n\n```python\nfrom sklearn.ensemble import RandomForestRegressor\n\n### 使用 RandomForestClassifier 填补缺失的年龄属性\ndef set_missing_ages(df):\n\n    # 把已有的数值型特征取出来丢进Random Forest Regressor中\n    age_df = df[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\n\n    # 乘客分成已知年龄和未知年龄两部分\n    known_age = age_df[age_df.Age.notnull()].as_matrix()\n    unknown_age = age_df[age_df.Age.isnull()].as_matrix()\n\n    # y即目标年龄\n    y = known_age[:, 0]\n\n    # X即特征属性值\n    X = known_age[:, 1:]\n\n    # fit到RandomForestRegressor之中\n    rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)\n    rfr.fit(X, y)\n\n    # 用得到的模型进行未知年龄结果预测\n    predictedAges = rfr.predict(unknown_age[:, 1::])\n\n    # 用得到的预测结果填补原缺失数据\n    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n\n    return df, rfr\n\ndef set_Cabin_type(df):\n    df.loc[ (df.Cabin.notnull()), 'Cabin' ] = \"Yes\"\n    df.loc[ (df.Cabin.isnull()), 'Cabin' ] = \"No\"\n    return df\n\ndata_train, rfr = set_missing_ages(data_train)\ndata_train = set_Cabin_type(data_train)\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/016.png)\n\n恩。目的达到，OK了。\n\n因为逻辑回归建模时，需要输入的特征都是数值型特征，我们通常会先对类目型的特征因子化。 \n\n什么叫做因子化呢？举个例子：\n\n以Cabin为例，原本一个属性维度，因为其取值可以是[‘yes’,’no’]，而将其平展开为’Cabin_yes’,’Cabin_no’两个属性\n\n* 原本Cabin取值为yes的，在此处的”Cabin_yes”下取值为1，在”Cabin_no”下取值为0\n* 原本Cabin取值为no的，在此处的”Cabin_yes”下取值为0，在”Cabin_no”下取值为1\n\n我们使用pandas的”get_dummies”来完成这个工作，并拼接在原来的”data_train”之上，如下所示。\n\n```python\ndummies_Cabin = pd.get_dummies(data_train['Cabin'], prefix= 'Cabin')\n\ndummies_Embarked = pd.get_dummies(data_train['Embarked'], prefix= 'Embarked')\n\ndummies_Sex = pd.get_dummies(data_train['Sex'], prefix= 'Sex')\n\ndummies_Pclass = pd.get_dummies(data_train['Pclass'], prefix= 'Pclass')\n\ndf = pd.concat([data_train, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\ndf.drop(['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\ndf\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/017.png)\n\nbingo，我们很成功地把这些类目属性全都转成0，1的数值属性了。\n\n这样，看起来，是不是我们需要的属性值都有了，且它们都是数值型属性呢。\n\n有一种临近结果的宠宠欲动感吧，莫急莫急，我们还得做一些处理，仔细看看Age和Fare两个属性，乘客的数值幅度变化，也忒大了吧！！如果大家了解逻辑回归与梯度下降的话，会知道，各属性值之间scale差距太大，将对收敛速度造成几万点伤害值！甚至不收敛！ (╬▔皿▔)…所以我们先用scikit-learn里面的preprocessing模块对这俩货做一个scaling，所谓scaling，其实就是将一些变化幅度较大的特征化到[-1,1]之内。\n\n```python\nimport sklearn.preprocessing as preprocessing\nscaler = preprocessing.StandardScaler()\nage_scale_param = scaler.fit(df['Age'])\ndf['Age_scaled'] = scaler.fit_transform(df['Age'], age_scale_param)\nfare_scale_param = scaler.fit(df['Fare'])\ndf['Fare_scaled'] = scaler.fit_transform(df['Fare'], fare_scale_param)\ndf\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/018.png)\n\n恩，好看多了，万事俱备，只欠建模。马上就要看到成效了，哈哈。我们把需要的属性值抽出来，转成scikit-learn里面LogisticRegression可以处理的格式。\n\n## 8.逻辑回归建模\n\n我们把需要的feature字段取出来，转成numpy格式，使用scikit-learn中的LogisticRegression建模。\n\n```python\nfrom sklearn import linear_model\n\n# 用正则取出我们要的属性值\ntrain_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\ntrain_np = train_df.as_matrix()\n\n# y即Survival结果\ny = train_np[:, 0]\n\n# X即特征属性值\nX = train_np[:, 1:]\n\n# fit到RandomForestRegressor之中\nclf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\nclf.fit(X, y)\n\nclf\n```\n\ngood，很顺利，我们得到了一个model，如下： \n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/019.png)\n\n先淡定！淡定！你以为把test.csv直接丢进model里就能拿到结果啊…骚年，图样图森破啊！我们的”test_data”也要做和”train_data”一样的预处理啊！！\n\n```python\ndata_test = pd.read_csv(\"/Users/Hanxiaoyang/Titanic_data/test.csv\")\ndata_test.loc[ (data_test.Fare.isnull()), 'Fare' ] = 0\n# 接着我们对test_data做和train_data中一致的特征变换\n# 首先用同样的RandomForestRegressor模型填上丢失的年龄\ntmp_df = data_test[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\nnull_age = tmp_df[data_test.Age.isnull()].as_matrix()\n# 根据特征属性X预测年龄并补上\nX = null_age[:, 1:]\npredictedAges = rfr.predict(X)\ndata_test.loc[ (data_test.Age.isnull()), 'Age' ] = predictedAges\n\ndata_test = set_Cabin_type(data_test)\ndummies_Cabin = pd.get_dummies(data_test['Cabin'], prefix= 'Cabin')\ndummies_Embarked = pd.get_dummies(data_test['Embarked'], prefix= 'Embarked')\ndummies_Sex = pd.get_dummies(data_test['Sex'], prefix= 'Sex')\ndummies_Pclass = pd.get_dummies(data_test['Pclass'], prefix= 'Pclass')\n\n\ndf_test = pd.concat([data_test, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\ndf_test.drop(['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\ndf_test['Age_scaled'] = scaler.fit_transform(df_test['Age'], age_scale_param)\ndf_test['Fare_scaled'] = scaler.fit_transform(df_test['Fare'], fare_scale_param)\ndf_test\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/020.png)\n\n不错不错，数据很OK，差最后一步了。 \n\n下面就做预测取结果吧！！\n\n```python\ntest = df_test.filter(regex='Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\npredictions = clf.predict(test)\nresult = pd.DataFrame({'PassengerId':data_test['PassengerId'].as_matrix(), 'Survived':predictions.astype(np.int32)})\nresult.to_csv(\"/Users/Hanxiaoyang/Titanic_data/logistic_regression_predictions.csv\", index=False)\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/021.png)\n\n啧啧，挺好，格式正确，去make a submission啦啦啦！\n\n在Kaggle的Make a submission页面，提交上结果。如下： \n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/022.png)\n\n0.76555，恩，结果还不错。毕竟，这只是我们简单分析处理过后出的一个baseline模型嘛。\n\n## 9.逻辑回归系统优化\n\n### 9.1 模型系数关联分析\n\n亲，你以为结果提交上了，就完事了？ \n\n我不会告诉你，这只是万里长征第一步啊(泪牛满面)！！！这才刚撸完baseline model啊！！！还得优化啊！！！\n\n看过Andrew Ng老师的machine Learning课程的同学们，知道，我们应该分析分析模型现在的状态了，是过/欠拟合？，以确定我们需要更多的特征还是更多数据，或者其他操作。我们有一条很著名的learning curves对吧。\n\n不过在现在的场景下，先不着急做这个事情，我们这个baseline系统还有些粗糙，先再挖掘挖掘。\n\n* 首先，Name和Ticket两个属性被我们完整舍弃了(好吧，其实是因为这俩属性，几乎每一条记录都是一个完全不同的值，我们并没有找到很直接的处理方式)。\n\n* 然后，我们想想，年龄的拟合本身也未必是一件非常靠谱的事情，我们依据其余属性，其实并不能很好地拟合预测出未知的年龄。再一个，以我们的日常经验，小盆友和老人可能得到的照顾会多一些，这样看的话，年龄作为一个连续值，给一个固定的系数，应该和年龄是一个正相关或者负相关，似乎体现不出两头受照顾的实际情况，所以，说不定我们把年龄离散化，按区段分作类别属性会更合适一些。\n\n上面只是我瞎想的，who knows是不是这么回事呢，老老实实先把得到的model系数和feature关联起来看看。\n\n```python\npd.DataFrame({\"columns\":list(train_df.columns)[1:], \"coef\":list(clf.coef_.T)})\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/023.png)\n\n首先，大家回去前两篇文章里瞄一眼公式就知道，这些系数为正的特征，和最后结果是一个正相关，反之为负相关。\n\n我们先看看那些权重绝对值非常大的feature，在我们的模型上：\n\n* Sex属性，如果是female会极大提高最后获救的概率，而male会很大程度拉低这个概率。\n* Pclass属性，1等舱乘客最后获救的概率会上升，而乘客等级为3会极大地拉低这个概率。\n* 有Cabin值会很大程度拉升最后获救概率(这里似乎能看到了一点端倪，事实上从最上面的有无Cabin记录的Survived分布图上看出，即使有Cabin记录的乘客也有一部分遇难了，估计这个属性上我们挖掘还不够)\n* Age是一个负相关，意味着在我们的模型里，年龄越小，越有获救的优先权(还得回原数据看看这个是否合理）\n* 有一个登船港口S会很大程度拉低获救的概率，另外俩港口压根就没啥作用(这个实际上非常奇怪，因为我们从之前的统计图上并没有看到S港口的获救率非常低，所以也许可以考虑把登船港口这个feature去掉试试)。\n* 船票Fare有小幅度的正相关(并不意味着这个feature作用不大，有可能是我们细化的程度还不够，举个例子，说不定我们得对它离散化，再分至各个乘客等级上？)\n\n噢啦，观察完了，我们现在有一些想法了，但是怎么样才知道，哪些优化的方法是promising的呢？\n\n因为test.csv里面并没有Survived这个字段(好吧，这是废话，这明明就是我们要预测的结果)，我们无法在这份数据上评定我们算法在该场景下的效果…\n\n而『每做一次调整就make a submission，然后根据结果来判定这次调整的好坏』其实是行不通的…\n\n### 9.2 交叉验证\n\n重点又来了：\n\n```\n『要做交叉验证(cross validation)!』 \n『要做交叉验证(cross validation)!』 \n『要做交叉验证(cross validation)!』\n```\n\n恩，重要的事情说三遍。我们通常情况下，这么做cross validation：把train.csv分成两部分，一部分用于训练我们需要的模型，另外一部分数据上看我们预测算法的效果。\n\n我们用scikit-learn的cross_validation来帮我们完成小数据集上的这个工作。\n\n先简单看看cross validation情况下的打分\n\n```python\nfrom sklearn import cross_validation\n\n #简单看看打分情况\nclf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\nall_data = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\nX = all_data.as_matrix()[:,1:]\ny = all_data.as_matrix()[:,0]\nprint cross_validation.cross_val_score(clf, X, y, cv=5)\n```\n\n结果是下面酱紫的：\n\n```\n[0.81564246 0.81005587 0.78651685 0.78651685 0.81355932]\n```\n\n似乎比Kaggle上的结果略高哈，毕竟用的是不是同一份数据集评估的。\n\n等等，既然我们要做交叉验证，那我们干脆先把交叉验证里面的bad case拿出来看看，看看人眼审核，是否能发现什么蛛丝马迹，是我们忽略了哪些信息，使得这些乘客被判定错了。再把bad case上得到的想法和前头系数分析的合在一起，然后逐个试试。\n\n下面我们做数据分割，并且在原始数据集上瞄一眼bad case：\n\n```python\n# 分割数据，按照 训练数据:cv数据 = 7:3的比例\nsplit_train, split_cv = cross_validation.train_test_split(\u001ddf, test_size=0.3, random_state=0)\ntrain_df = split_train.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n# 生成模型\nclf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\nclf.fit(train_df.as_matrix()[:,1:], train_df.as_matrix()[:,0])\n\n# 对cross validation数据进行预测\n\ncv_df = split_cv.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\npredictions = clf.predict(cv_df.as_matrix()[:,1:])\n\norigin_data_train = pd.read_csv(\"/Users/HanXiaoyang/Titanic_data/Train.csv\")\nbad_cases = origin_data_train.loc[origin_data_train['PassengerId'].isin(split_cv[predictions != cv_df.as_matrix()[:,0]]['PassengerId'].values)]\nbad_cases\n```\n\n我们判定错误的 bad case 中部分数据如下： \n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/024.png)\n\n大家可以自己跑一遍试试，拿到bad cases之后，仔细看看。也会有一些猜测和想法。其中会有一部分可能会印证在系数分析部分的猜测，那这些优化的想法优先级可以放高一些。\n\n现在有了”train_df” 和 “vc_df” 两个数据部分，前者用于训练model，后者用于评定和选择模型。可以开始可劲折腾了。\n\n我们随便列一些可能可以做的优化操作：\n\n* Age属性不使用现在的拟合方式，而是根据名称中的『Mr』『Mrs』『Miss』等的平均值进行填充。\n* Age不做成一个连续值属性，而是使用一个步长进行离散化，变成离散的类目feature。\nCabin再细化一些，对于有记录的Cabin属性，我们将其分为前面的字母部分(我猜是位置和船层之类的信息) 和 后面的数字部分(应该是房间号，有意思的事情是，如果你仔细看看原始数据，你会发现，这个值大的情况下，似乎获救的可能性高一些)。\n* Pclass和Sex俩太重要了，我们试着用它们去组出一个组合属性来试试，这也是另外一种程度的细化。\n* 单加一个Child字段，Age<=12的，设为1，其余为0(你去看看数据，确实小盆友优先程度很高啊)\n* 如果名字里面有『Mrs』，而Parch>1的，我们猜测她可能是一个母亲，应该获救的概率也会提高，因此可以多加一个Mother字段，此种情况下设为1，其余情况下设为0\n* 登船港口可以考虑先去掉试试(Q和C本来就没权重，S有点诡异)\n* 把堂兄弟/兄妹 和 Parch 还有自己 个数加在一起组一个Family_size字段(考虑到大家族可能对最后的结果有影响)\n* Name是一个我们一直没有触碰的属性，我们可以做一些简单的处理，比如说男性中带某些字眼的(‘Capt’, ‘Don’, ‘Major’, ‘Sir’)可以统一到一个Title，女性也一样。\n\n大家接着往下挖掘，可能还可以想到更多可以细挖的部分。我这里先列这些了，然后我们可以使用手头上的”train_df”和”cv_df”开始试验这些feature engineering的tricks是否有效了。\n\n试验的过程比较漫长，也需要有耐心，而且我们经常会面临很尴尬的状况，就是我们灵光一闪，想到一个feature，然后坚信它一定有效，结果试验下来，效果还不如试验之前的结果。恩，需要坚持和耐心，以及不断的挖掘。\n\n我最好的结果是在『Survived~C(Pclass)+C(Title)+C(Sex)+C(Age_bucket)+C(Cabin_num_bucket)Mother+Fare+Family_Size』下取得的，结果如下(抱歉，博主君commit的时候手抖把页面关了，于是没截着图，下面这张图是在我得到最高分之后，用这次的结果重新make commission的，截了个图，得分是0.79426，不是目前我的最高分哈，因此排名木有变…)：\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/025.png)\n\n### 9.3 learning curves\n\n有一个很可能发生的问题是，我们不断地做feature engineering，产生的特征越来越多，用这些特征去训练模型，会对我们的训练集拟合得越来越好，同时也可能在逐步丧失泛化能力，从而在待预测的数据上，表现不佳，也就是发生过拟合问题。\n\n从另一个角度上说，如果模型在待预测的数据上表现不佳，除掉上面说的过拟合问题，也有可能是欠拟合问题，也就是说在训练集上，其实拟合的也不是那么好。\n\n额，这个欠拟合和过拟合怎么解释呢。这么说吧：\n\n* 过拟合就像是你班那个学数学比较刻板的同学，老师讲过的题目，一字不漏全记下来了，于是老师再出一样的题目，分分钟精确出结果。but数学考试，因为总是碰到新题目，所以成绩不咋地。\n* 欠拟合就像是，咳咳，和博主level差不多的差生。连老师讲的练习题也记不住，于是连老师出一样题目复习的周测都做不好，考试更是可想而知了。\n\n而在机器学习的问题上，对于过拟合和欠拟合两种情形。我们优化的方式是不同的。\n\n对过拟合而言，通常以下策略对结果优化是有用的：\n\n* 做一下feature selection，挑出较好的feature的subset来做training\n* 提供更多的数据，从而弥补原始数据的bias问题，学习到的model也会更准确\n\n而对于欠拟合而言，我们通常需要更多的feature，更复杂的模型来提高准确度。\n\n著名的learning curve可以帮我们判定我们的模型现在所处的状态。我们以样本数为横坐标，训练和交叉验证集上的错误率作为纵坐标，两种状态分别如下两张图所示：过拟合(overfitting/high variace)，欠拟合(underfitting/high bias)\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/026.png)\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/027.png)\n\n我们也可以把错误率替换成准确率(得分)，得到另一种形式的learning curve(sklearn 里面是这么做的)。\n\n回到我们的问题，我们用scikit-learn里面的learning_curve来帮我们分辨我们模型的状态。举个例子，这里我们一起画一下我们最先得到的baseline model的learning curve。\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.learning_curve import learning_curve\n\n# 用sklearn的learning_curve得到training_score和cv_score，使用matplotlib画出learning curve\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1, \n                        train_sizes=np.linspace(.05, 1., 20), verbose=0, plot=True):\n    \"\"\"\n    画出data在某模型上的learning curve.\n    参数解释\n    ----------\n    estimator : 你用的分类器。\n    title : 表格的标题。\n    X : 输入的feature，numpy类型\n    y : 输入的target vector\n    ylim : tuple格式的(ymin, ymax), 设定图像中纵坐标的最低点和最高点\n    cv : 做cross-validation的时候，数据分成的份数，其中一份作为cv集，其余n-1份作为training(默认为3份)\n    n_jobs : 并行的的任务数(默认1)\n    \"\"\"\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    if plot:\n        plt.figure()\n        plt.title(title)\n        if ylim is not None:\n            plt.ylim(*ylim)\n        plt.xlabel(u\"训练样本数\")\n        plt.ylabel(u\"得分\")\n        plt.gca().invert_yaxis()\n        plt.grid()\n\n        plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, \n                         alpha=0.1, color=\"b\")\n        plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, \n                         alpha=0.1, color=\"r\")\n        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\", label=u\"训练集上得分\")\n        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\", label=u\"交叉验证集上得分\")\n\n        plt.legend(loc=\"best\")\n\n        plt.draw()\n        plt.show()\n        plt.gca().invert_yaxis()\n\n    midpoint = ((train_scores_mean[-1] + train_scores_std[-1]) + (test_scores_mean[-1] - test_scores_std[-1])) / 2\n    diff = (train_scores_mean[-1] + train_scores_std[-1]) - (test_scores_mean[-1] - test_scores_std[-1])\n    return midpoint, diff\n\nplot_learning_curve(clf, u\"学习曲线\", X, y)\n```\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/028.png)\n\n在实际数据上看，我们得到的learning curve没有理论推导的那么光滑哈，但是可以大致看出来，训练集和交叉验证集上的得分曲线走势还是符合预期的。\n\n目前的曲线看来，我们的model并不处于overfitting的状态(overfitting的表现一般是训练集上得分高，而交叉验证集上要低很多，中间的gap比较大)。因此我们可以再做些feature engineering的工作，添加一些新产出的特征或者组合特征到模型中。\n\n## 10.模型融合(model ensemble)\n\n好了，终于到这一步了，我们要祭出机器学习/数据挖掘上通常最后会用到的大杀器了。恩，模型融合。\n\n```\n『强迫症患者』打算继续喊喊口号… \n『模型融合(model ensemble)很重要！』 \n『模型融合(model ensemble)很重要！』 \n『模型融合(model ensemble)很重要！』 \n```\n\n重要的事情说三遍，恩，噢啦。\n\n先解释解释，一会儿再回到我们的问题上哈。 \n\n啥叫模型融合呢，我们还是举几个例子直观理解一下好了。\n\n大家都看过知识问答的综艺节目中，求助现场观众时候，让观众投票，最高的答案作为自己的答案的形式吧，每个人都有一个判定结果，最后我们相信答案在大多数人手里。\n\n再通俗一点举个例子。你和你班某数学大神关系好，每次作业都『模仿』他的，于是绝大多数情况下，他做对了，你也对了。突然某一天大神脑子犯糊涂，手一抖，写错了一个数，于是…恩，你也只能跟着错了。 \n\n我们再来看看另外一个场景，你和你班5个数学大神关系都很好，每次都把他们作业拿过来，对比一下，再『自己做』，那你想想，如果哪天某大神犯糊涂了，写错了，but另外四个写对了啊，那你肯定相信另外4人的是正确答案吧？\n\n最简单的模型融合大概就是这么个意思，比如分类问题，当我们手头上有一堆在同一份数据集上训练得到的分类器(比如logistic regression，SVM，KNN，random forest，神经网络)，那我们让他们都分别去做判定，然后对结果做投票统计，取票数最多的结果为最后结果。\n\nbingo，问题就这么完美的解决了。\n\n模型融合可以比较好地缓解，训练过程中产生的过拟合问题，从而对于结果的准确度提升有一定的帮助。\n\n话说回来，回到我们现在的问题。你看，我们现在只讲了logistic regression，如果我们还想用这个融合思想去提高我们的结果，我们该怎么做呢？\n\n既然这个时候模型没得选，那咱们就在数据上动动手脚咯。大家想想，如果模型出现过拟合现在，一定是在我们的训练上出现拟合过度造成的对吧。\n\n那我们干脆就不要用全部的训练集，每次取训练集的一个subset，做训练，这样，我们虽然用的是同一个机器学习算法，但是得到的模型却是不一样的；同时，因为我们没有任何一份子数据集是全的，因此即使出现过拟合，也是在子训练集上出现过拟合，而不是全体数据上，这样做一个融合，可能对最后的结果有一定的帮助。对，这就是常用的Bagging。\n\n我们用scikit-learn里面的Bagging来完成上面的思路，过程非常简单。代码如下：\n\n```python\nfrom sklearn.ensemble import BaggingRegressor\n\ntrain_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass.*|Mother|Child|Family|Title')\ntrain_np = train_df.as_matrix()\n\n# y即Survival结果\ny = train_np[:, 0]\n\n# X即特征属性值\nX = train_np[:, 1:]\n\n# fit到BaggingRegressor之中\nclf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\nbagging_clf = BaggingRegressor(clf, n_estimators=20, max_samples=0.8, max_features=1.0, bootstrap=True, bootstrap_features=False, n_jobs=-1)\nbagging_clf.fit(X, y)\n\ntest = df_test.filter(regex='Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass.*|Mother|Child|Family|Title')\npredictions = bagging_clf.predict(test)\nresult = pd.DataFrame({'PassengerId':data_test['PassengerId'].as_matrix(), 'Survived':predictions.astype(np.int32)})\nresult.to_csv(\"/Users/HanXiaoyang/Titanic_data/logistic_regression_bagging_predictions.csv\", index=False)\n```\n\n然后你再Make a submission，恩，发现对结果还是有帮助的。\n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/029.png)\n\n## 11.总结\n\n文章稍微有点长，非常感谢各位耐心看到这里。 \n\n总结的部分，我就简短写几段，出现的话，很多在文中有对应的场景，大家有兴趣再回头看看。\n\n对于任何的机器学习问题，不要一上来就追求尽善尽美，先用自己会的算法撸一个baseline的model出来，再进行后续的分析步骤，一步步提高。\n\n在问题的结果过程中：\n\n```\n『对数据的认识太重要了！』\n『数据中的特殊点/离群点的分析和处理太重要了！』\n『特征工程(feature engineering)太重要了！』\n『模型融合(model ensemble)太重要了！』\n```\n\n本文中用机器学习解决问题的过程大概如下图所示： \n\n![](/assets/images/2015/11/12/ml-logistic-regression-3/030.png)\n\n## 12.关于数据和代码\n\n本文中的数据和代码已经上传至github中，欢迎大家下载和自己尝试。\n \n---\n\n* 原文链接：[机器学习系列(3)_逻辑回归应用之Kaggle泰坦尼克之灾](http://blog.csdn.net/han_xiaoyang/article/details/49797143 )\n","tags":["Logistic-Regression"],"categories":["Machine-Learning"]},{"title":"Succinct RDDs in Apache Spark","url":"%2F2015%2F2015-11-05-succinct-rdds-in-apache-spark%2F","content":"\nWe have open-sourced [Apache Spark](http://spark.apache.org/) and [Apache Spark SQL](http://spark.apache.org/docs/latest/sql-programming-guide.html) interfaces for [Succinct](http://succinct.cs.berkeley.edu/) as a [Spark Package](http://spark-packages.org/package/amplab/succinct). The package facilitates compressing RDDs in Apache Spark and DataFrames in Apache Spark SQL and enables queries directly on the compressed representation.\n\n### Interface\n\nThe Succinct on Apache Spark exposes the following APIs:\n\n* A SuccinctRDD API that views an RDD as an unstructured “flat-file” and enables queries on its compressed representation.\n* A SuccinctKVRDD API that provides a key-value abstraction for the data, and supports search and random-access over the values.\n* A SuccinctJsonRDD API that enables random access and search on a collection of compressed JSON documents.\n* DataFrame API that integrates with the Apache Spark SQL interface via Data Sources, and supports SQL queries on compressed structured data. The Apache Spark SQL interface is currently experimental, and only efficient for selected SQL operators. We aim to make the Apache Spark SQL integration more efficient in future releases.\n\n### SuccinctRDD\n\nSuccinctRDD provides a “flat file” view for an RDD, where the entire RDD is viewed as a single unstructured file. For instance, applications in log analytics can directly employ SuccinctRDD to perform efficient search (e.g., errors for debugging) and random access  (e.g., extract logs at certain timestamps) on unstructured logs. This functionality is similar to Lucene, which uses full-text indexing to enable search over unstructured data.\n\n#### API\n\nSuccinctRDD supports the following operations:\n\n| Operation | Meaning |\n| --------- | ------- |\n| extract(offset, length) | The extract operation provides random access to any offset in the flat file. |\n| search(query) | Returns offsets (into the flat file) of all occurrences of the query string in uncompressed flat file (while operating directly on the compressed RDD). Applications can search for arbitrary strings in the text; that is, query strings are not limited to be specific words in the text. |\n| count(query) | The count interface is an extremely fast operation, and returns the number of occurrences of the query string in the uncompressed flat file. |\n\n#### Example\n\nSuccinctRDD can be used as follows:\n\n```scala\nimport edu.berkeley.cs.succinct._\n\n// Read text data from file; sc is the SparkContext\nval wikiData = sc.textFile(\"/path/to/data\").map(_.getBytes)\n\n// Converts the wikiData RDD to a SuccinctRDD, serializing each record into an\n// array of bytes. We persist the RDD in memory to perform in-memory queries.\nval wikiSuccinctData = wikiData.succinct.persist()\n\n// Count the number of occurrences of \"Berkeley\" in the RDD\nval berkeleyOccCount = wikiSuccinctData.count(\"Berkeley\")\nprintln(\"# of times Berkeley appears in text = \" + berkeleyOccCount)\n\n// Find all offsets of occurrences of \"Berkeley\" in the RDD\nval searchOffsets = wikiSuccinctData.search(\"Berkeley\")\nprintln(\"First 10 locations in the RDD where Berkeley occurs: \")\nsearchOffsets.take(10).foreach(println)\n\n// Find all occurrences of the regular expression \"(berkeley|stanford)\\\\.edu\"\nval regexOccurrences = wikiSuccinctData.regexSearch(\"(stanford|berkeley)\\\\.edu\").collect()\nprintln(\"# of matches for the regular expression (stanford|berkeley)\\\\.edu = \" + regexOccurrences.count)\n\n// Extract 10 bytes at offset 5 in the RDD\nval extractedData = wikiSuccinctData.extract(5, 10)\nprintln(\"Extracted data = [\" + new String(extractedData) + \"]\")\n```\n\n#### Performance\n\nWe compare the performance of Succinct on Apache Spark against Apache Spark’s native (uncompressed) RDDs. We use a collection of 40GB Wikipedia articles, all combined into a single text corpus. All benchmarks were run on an Amazon EC2 cluster with five c3.4xlarge (one used as a master), each having 30GB RAM and 16 vCPUs. Note that Succinct on Apache Spark requires significantly less memory (roughly 23GB) and could easily run the entire benchmark on a single server. However, we use a larger cluster to compare Succinct on Apache Spark’s performance against the best-case scenario for native Apache Spark — when everything for native Apache Spark fits in memory. The search queries use words with varying number of occurrences (1–10,000) with uniform random distribution across 10 bins (1–1000, 1000-2000, etc). Note that the y-axis is on log scale.\n\n![](http://blog.hyperj.net/assets/images/2015/11/05/succinct-rdds-in-apache-spark/flat-file.png)\n\nWe note that Succinct on Apache Spark provides significant speed ups over native Apache Spark (as much as two to three orders of magnitude) even when native Apache Spark RDD fits in memory, while executing queries on compressed data. These are the benefits of avoiding data scans, the second problem we highlighted at the outset of the post. Also note that Succinct on Apache Spark requires roughly 2x lower memory than native Apache Spark RDD, and can thus provide such low latency performance for a larger range of input dataset sizes compared to native Apache Spark.\n\n#### Comments\n\n**Input Constraints.** We don’t support non-ASCII characters in the input for now, since the algorithms depend on using certain non-ASCII characters as internal symbols.\n\n**Construction Time.** Another constraint to consider is the construction time for Succinct data-structures. As for any block compression scheme, Succinct requires non-trivial amount of time to compress an input dataset. It is strongly advised that the SuccinctRDD be cached in memory (using RDD.cache()) and persisted on disk after construcion completes, to be able to re-use the constructed data-structures without trigerring re-construction:\n\n```scala\nimport edu.berkeley.cs.succinct._\n\n// Read text data from file; sc is the SparkContext\nval wikiData = sc.textFile(\"/path/to/data\").map(_.getBytes)\n\n// Construct the succinct RDD and save it as follows\nwikiData.saveAsSuccinctFile(\"/path/to/data\")\n\n// Load into memory again as follows; sc is the SparkContext\nval loadedSuccinctRDD = sc.succinctFile(\"/path/to/data\")\n```\n\n### SuccinctKVRDD\n\nThe SuccinctKVRDD interface models semi-structured data, similar to those seen in document stores or key-value stores. Example use-cases include searching across the collection wikipedia articles, and extracting relevant parts of the article-text, or searching across tweets stored in a key-value store and retrieving tweets from a particular user. The functionality of the SuccinctKVRDD is akin to Elasticsearch, which supports search on documents over a document-store interface.\n\nThe SuccinctKVRDD implements the RDD[(K, Array[Byte]] interface, where key can be of the specified (ordered) type while the value is a serialized array of bytes.\n\n#### API\n\nSuccinctKVRDD supports the following operations:\n\n| Operation | Meaning |\n| --------- | ------- |\n| get(key) | Random access functionality similar to typical Key-Value stores and documents stores; the value or the document is returned. |\n| extract(key, offset, length) | Random access within a value/document given the relative offset. This may be useful when an application may not want to access the entire document, but only a subset of the document. |\n| search(query) | Similar to flat file interface, but now returns the keys (or document identifiers) whose values (or document text) contain the query string. |\n| searchOffsets(query) | Finds actual matches for the search query, and returns (key, offset) pairs corresponding to each match. The offset is relative to the beginning of the value/document. |\n| count(query) | Returns the number of actual matches for the search query across the values/documents. |\n\n#### Example\n\nSuccinctKVRDD can be used as follows:\n\n```scala\nimport edu.berkeley.cs.succinct.kv._\n\nval wikiData = ctx.textFile(dataPath, partitions).map(_.getBytes)\nval wikiKVData = wikiData.zipWithIndex().map(t => (t.\\_2, t.\\_1))\n\nval succinctKVRDD = wikiKVData.succinctKV\n\n// Get the value for key 0\nval value = succinctKVRDD.get(0)\nprintln(\"Value corresponding to key 0 = \" + new String(value))\n\n// Fetch 3 bytes at offset 1 for the value corresponding to key = 0\nval valueData = succinctKVRDD.extract(0, 1, 3)\nprintln(\"Value data for key 0 at offset 1 and length 3 = \" + new String(valueData))\n\n// count the number of occurrences of \"Berkeley\" accross all values\nval count = succinctKVRDD.count(\"Berkeley\")\nprintln(\"Number of times Berkeley occurs in the values: \" + count)\n\n// Get the individual occurrences of Berkeley as offsets into each value\nval searchOffsets = succinctKVRDD.searchOffsets(\"Berkeley\")\nprintln(\"First 10 matches for Berkeley as (key, offset) pairs: \")\nsearchOffsets.take(10).foreach(println)\n\n// Search for values containing \"Berkley\", and fetch corresponding keys\nval keys = succinctKVRDD.search(\"Berkeley\")\nprintln(\"First 10 keys matching the search query:\")\nkeys.take(10).foreach(println)\n\n// Regex search to find values containing matches of \"(stanford|berkeley)\\\\.edu\", \n// and fetch the corresponding of keys\nval regexKeys = succinctKVRDD.regexSearch(\"(stanford|berkeley)\\\\.edu\")\nprintln(\"First 10 keys matching the regex query:\")\nregexKeys.take(10).foreach(println)\n```\n\n#### Performance\n\nWe evaluate the performance of Succinct on Apache Spark against native Apache Spark RDD for the key-value store and document store functionality, using a setup similar to that of flat file interface with the only change that we use a 50GB dataset composed of metadata for video streams from [Conviva](http://www.conviva.com/) for the KV-store; for document store, we use the same Wikipedia dataset, but now each article has a unique documentID.\n\n![](http://blog.hyperj.net/assets/images/2015/11/05/succinct-rdds-in-apache-spark/kv-small.png)\n\nAs with the flat file interface, Succinct on Apache Spark for the key-value store functionality achieves two to three orders of magnitude faster performance compared to Apache Spark’s native RDD.\n\nFor search performance, we compare Succinct’s performance against both Apache Spark’s native RDD, as well as against Elasticsearch – a popular document-store that supports search across documents.\n\n![](http://blog.hyperj.net/assets/images/2015/11/05/succinct-rdds-in-apache-spark/kv-document-search.png)\n\nInterestingly, Succinct on Apache Spark is roughly 2.75x faster than Elasticsearch! This is when ElasticSearch does not have the overhead of Apache Spark’s job execution, and has all the data fit completely in memory. Succinct on Apache Spark achieves this speed up while requiring roughly 2.5x lower memory than [ElasticSearch](https://www.elastic.co/) (due to compression, and due to storing no additional indexes)! As earlier, Succinct is over two orders of magnitude faster than Apache Spark’s native RDDs. Random access on documents has performance similar to that for flat files.\n\n#### Comments\n\nThe input constraints for SuccinctRDD carry over to the SuccinctKVRDD as well. Similar to the flat-file interface, we suggest that the KV data be persisted to disk for repeated-use scenarios:\n\n```scala\nimport edu.berkeley.cs.succinct.kv._\n\n// Read data from file; sc is the SparkContext\nval wikiData = ctx.textFile(\"/path/to/data\").map(_.getBytes)\nval wikiKVData = wikiData.zipWithIndex().map(t => (t.\\_2, t.\\_1))\n\n// Construct the SuccinctKVRDD and save it as follows\nwikiKVData.saveAsSuccinctKV(\"/path/to/data\")\n\n// Load into memory again as follows; sc is the SparkContext\nval loadedSuccinctKVRDD = sc.succinctKV(\"/path/to/data\")\n```\n\n### DataFrame\n\nApache Spark 1.3 added a new DataFrame API that provides powerful and convenient operators to work with structured data. We provide access to Succinct-encoded data through the DataFrame API via [Data Sources](https://databricks.com/blog/2015/01/09/spark-sql-data-sources-api-unified-data-access-for-the-spark-platform.html) as an experimental feature. While it is quite efficient for several filters, we are working on several interesting projects to efficiently support other operators.\n\nAt a high level, the DataFrame interface enables search and random access on structured data like tables. An example use-case for this interface is point queries on columnar stores. For instance, given a table with the schema [UserID, Location D.O.B., Salary], we might want to search for all users that were born between 1980 and 1985.\n\n#### API\n\nSince Succinct is implemented as a Data Source in Apache Spark SQL, the API for DataFrames remains unchanged. The API documentation for DataFrames can be found [here](http://spark.apache.org/docs/latest/sql-programming-guide.html).\n\n#### Example\n\nThe DataFrame API can be used as follows:\n\n```scala\nimport edu.berkeley.cs.succinct.sql._\n\n// Create a schema\nval citySchema = StructType(Seq(\n  StructField(\"Name\", StringType, false),\n  StructField(\"Length\", IntegerType, true),\n  StructField(\"Area\", DoubleType, false),\n  StructField(\"Airport\", BooleanType, true)))\n\n// Create an RDD of Rows with some data\nval cityRDD = sparkContext.parallelize(Seq(\n  Row(\"San Francisco\", 12, 44.52, true),\n  Row(\"Palo Alto\", 12, 22.33, false),\n  Row(\"Munich\", 8, 3.14, true)))\n\n// Create a data frame from the RDD and the schema\nval cityDataFrame = sqlContext.createDataFrame(cityRDD, citySchema)\n\n// Save the DataFrame in the \"Succinct\" format\ncityDataFrame.write.format(\"edu.berkeley.cs.succinct.sql\").save(\"/path/to/data\")\n\n// Read the Succinct DataFrame from the saved path\nval succinctCities = sqlContext.succinctFile(\"/path/to/data\")\n\n// Filter and prune\nval bigCities = succinctCities.filter(\"Area >= 22.0\").select(\"Name\").collect\n\n// Alternately, use the DataFrameReader API:\ncityDataFrame.write.format(\"edu.berkeley.cs.succinct.sql\").save(\"/path/to/data\")\nval succinctCities2 = sqlContext.read.format(\"edu.berkeley.cs.succinct.sql\").load(\"/path/to/data\")\nval smallCities = succinctCities2.filter(\"Area <= 10.0\").select(\"Name\").collect\n```\n\n#### Performance\n\nFor this interface, we compare Succinct’s performance to the columnar Parquet DataSource supported natively by Apache Spark. We revisit the 40GB of Conviva Dataset, which has roughly 98 columns and 43.7 million rows, and consider the following SQL query:\n\n```sql\nSELECT * FROM conviva_table WHERE col[i]=value\n```\n\nWe vary the columns and the value being matched, and analyze the variation of the performance of this query as the number of matched rows increase. This particular query involves both search (to perform the filter based on the WHERE clause) and random access (to obtain all the other column values for the matched column value, based on the SELECT * projection). We note Succinct’s latency for performing random access increases with the amount of data extracted and the latency for search increases with the number of matched results.\n\n![](http://blog.hyperj.net/assets/images/2015/11/05/succinct-rdds-in-apache-spark/df-cardinality.png)\n\nThis is evident in the results above; interestingly, Succinct can find as many as 100,000 matches with latency lower than that for Parquet’s columnar representation.\n\n#### Comments\n\nThe DataFrame API for Succinct is experimental for now, and only supports selected data types and filters. The supported Apache Spark SQL types include:\n\n```\nBooleanType\nByteType\nShortType\nIntegerType\nLongType\nFloatType\nDoubleType\nDecimalType\nStringType\n```\n\nThe supported filters include:\n\n```\nStringStartsWith\nStringEndsWith\nStringContains\nEqualTo\nLessThan\nLessThanOrEqual\nGreaterThan\nGreaterThanOrEqual\n```\n\nNote that certain SQL operations, like joins, might be inefficient on the DataFrame API for now. We plan on improving the performance for generic SQL operations in a future release.\n\n### Getting Started\n\nSuccinct on Apache Spark includes a few [examples](https://github.com/amplab/succinct/blob/master/spark/src/main/scala/edu/berkeley/cs/succinct/examples) that elucidate the usage of its API. To run these examples, we provide convenient scripts to run them in the bin/ directory. In particular, to execute the [Wikipedia Search](https://github.com/amplab/succinct/blob/master/spark/src/main/scala/edu/berkeley/cs/succinct/examples/WikiSearch.scala) example using SuccinctRDD, run as follows:\n\n```shell\n./bin/wiki-search [num-partitions]\n```\n\nThe num-partitions parameter is simply the number of partitions that the original dataset should be divided into for creating Succinct data structures. This defaults to 1 by default; **note that due to Java constraints, we do not support partitions of sizes greater than 2GB yet.**\n\nThe [KV Search](https://github.com/amplab/succinct/blob/master/spark/src/main/scala/edu/berkeley/cs/succinct/examples/KVSearch.scala\"KV Search\") and [Table Search](https://github.com/amplab/succinct/blob/master/spark/src/main/scala/edu/berkeley/cs/succinct/examples/TableSearch.scala) examples are executed similarly.\n\n### Requirements and Dependency\n\nSuccinct on Apache Spark requires Apache Spark 1.6+.\n\n#### Maven\n\nIn your pom.xml, add:\n\n```xml\n<dependencies>\n  <!-- list of dependencies -->\n  <dependency>\n    <groupId>amplab</groupId>\n    <artifactId>succinct</artifactId>\n    <version>0.1.7</version>\n  </dependency>\n</dependencies>\n<repositories>\n  <!-- list of other repositories -->\n  <repository>\n    <id>SparkPackagesRepo</id>\n    <url>http://dl.bintray.com/spark-packages/maven</url>\n  </repository>\n</repositories>\n```\n\n#### SBT\n\nAdd the dependency to your SBT project by adding the following to build.sbt (see the [Spark Packages listing](http://spark-packages.org/package/amplab/succinct) for spark-submit and Maven instructions):\n\n```shell\nresolvers += \"Spark Packages Repo\" at \"http://dl.bintray.com/spark-packages/maven\"\nlibraryDependencies += \"amplab\" % \"succinct\" % \"0.1.7\"\n```\n\nThe succinct-spark jar file can also be added to a Spark shell using the --jars command line option. For example, to include it when starting the spark shell:\n\n```shell\n$ bin/spark-shell --jars succinct-0.1.7.jar\n```\n\n相关链接：[Succinct](http://succinct.cs.berkeley.edu/wp/wordpress/)、\n[Spark](http://spark.apache.org/)\n\n---\n\n* 原文链接：[+Apache Spark](http://succinct.cs.berkeley.edu/wp/wordpress/?page_id=8)\n","tags":["Spark"],"categories":["Succinct"]},{"title":"Succinct on Apache Spark: Queries on Compressed RDDs","url":"%2F2015%2F2015-11-05-succinct-on-apache-spark%2F","content":"\nWe are very excited to announce the release of Succinct on Apache Spark, an Apache Spark package that integrates Succinct within the Apache Spark ecosystem. Succinct on Apache Spark enables search, count, range and random access queries on compressed RDDs. This allows users to use Apache Spark as a document store (with search on documents) similar to ElasticSearch, a key-value store (with search on values) similar to HyperDex, and an experimental DataFrame interface (with search along columns in a table). When used as a document store, Succinct on Apache Spark is 2.75x faster than ElasticSearch for search queries while requiring 2.5x lower storage, and over 75x faster than native Apache Spark.\n\n**Succinct on Apache Spark: Overview**\n\nAs we discussed in our last post, search is becoming an increasingly powerful primitive in big data analytics and web services. Many web services support some form of search, including LinkedIn search, Twitter search, Facebook search, Netflix search, airlines, hotels, as well as services specifically built around search — Google, Bing, Yelp, to name a few. Apache Spark supports search via full RDD scans. While fast enough for small datasets, data scans become inefficient as dataset become even moderately large. One way to avoid data scans is to implement indexes, but can significantly increase the memory overhead.\n\nSuccinct on Apache Spark achieves a unique tradeoff — storage overhead no worse (and often lower) than data-scan based techniques and query latency comparable to index-based techniques. Succinct on Apache Spark enables search (and a wide range of other queries) directly on compressed representation of the RDDs. What differentiates Succinct on Apache Spark is that queries are supported without storing any secondary indexes, without data scans and without data decompression — all the required information is embedded within the compressed RDD and queries are executed directly on the compressed RDD.\n\nIn addition, Succinct supports random access of records without scanning the entire RDD, a functionality that we believe will significantly speed up a large number of applications.\n\n**An example**\n\nConsider a collection of Wikipedia articles stored on HDFS as a flat unstructured file. Let us see how Succinct on Apache Spark supports the above functionalities:\n\n```scala\n// Import SuccinctRDD\nimport edu.berkeley.cs.succinct._\n\n// Create a Spark RDD as a collection of articles; ctx is the SparkContext\nval articlesRDD = ctx.textFile(\"/path/to/data\").map(_.getBytes)\n\n// Compress the input RDD into a Succinct RDD, and persist it in memory\n// Note that this is a time consuming step (usually at 8GB/hour/core) since data needs to be compressed. \n// We are actively working on making this step faster.\nval succinctRDD = articlesRDD.succcinct.persist()\n\n// SuccinctRDD supports a set of powerful primitives directly on compressed RDD\n// Let us start by counting the number of occurrences of \"Berkeley\" across all Wikipedia articles\nval count = succinctRDD.count(\"Berkeley\")\n\n// Now suppose we want to find all offsets in the collection at which “Berkeley” occurs; and \n// create an RDD containing all resulting offsets \nval offsetsRDD = succinctRDD.search(\"Berkeley\")\n\n// Let us look at the first ten results in the above RDD\nval offsets = offsetsRDD.take(10)\n\n// Finally, let us extract 20 bytes before and after one of the occurrences of “Berkeley”\nval offset = offsets(0)\nval data = succinctRDD.extract(offset - 20, 40)\n```\n\nMany more examples on using Succinct on Apache Spark are outlined [here](http://succinct.cs.berkeley.edu/wp/wordpress/?page_id=8).\n\n**Performance**\n\n![](http://blog.hyperj.net/assets/images/2015/11/05/succinct-on-apache-spark/kv-document-search-2.png)\nkv-document-search-2The figure compares the search performance of Succinct on Apache Spark against ElasticSearch and native Apache Spark. We use a 40GB collection of Wikipedia documents over a 4-server Amazon EC2 cluster with 120GB RAM (so that all systems fit in memory). The search queries use words with varying number of occurrences (1–10,000) with uniform random distribution across 10 bins (1–1000, 1000-2000, etc). Note that the y-axis is on log scale.\n\nInterestingly, Succinct on Apache Spark is roughly 2.75x faster than Elasticsearch. This is when ElasticSearch does not have the overhead of Apache Spark’s job execution, and have all the data fit in memory. Succinct achieves this speed up while requiring roughly 2.5x lower memory than ElasticSearch (due to compression, and due to storing no additional indexes)! Succinct on Apache Spark is over two orders of magnitude faster than Apache Spark’s native RDDs due to avoiding data scans. Random access on documents has similar performance gains (with some caveats).\n\nBelow, we describe a few interesting use cases for Succinct on Apache Spark, including a number of interfaces exposed in the release. For more details on the Succinct on Apache Spark release (and Succinct in general), usage and benchmark results, please see [+Apache Spark webpage](http://spark.apache.org/), [the NSDI paper](https://www.usenix.org/system/files/conference/nsdi15/nsdi15-paper-agarwal.pdf), or a more detailed [technical report](http://www.cs.berkeley.edu/~rachit/succinct-techreport.pdf).\n\n**Succinct on Apache Spark: Abstractions and use cases**\n\nSuccinct on Apache Spark exposes three interfaces, each of which may have several interesting use cases. We outline some of them below:\n\n* SuccinctRDD\n  * Interface: Flat (unstructured) files\n  * Example application: log analytics\n  * Example: one can search across logs (e.g., errors for debugging), or perform random access (e.g., extract logs at certain timestamps).\n  * System with similar functionality: Lucene\n* SuccinctKVRDD\n  * Interface: Semi-structured data\n  * Example application: document stores, key-value stores\n  * Example:\n    * (document stores) search across a collection of Wikipedia documents and return all documents that contain, say, string “University of California at Berkeley”. Extract all (or a part of) documents.\n    * (key-value stores) search across a set of tweets stored in a key-value store for tweets that contain “Succinct”. Extract all tweets from the user “_ragarwal_”.\n  * System with similar functionality: ElasticSearch\n* (An experimental) DataFrame interface\n  * Interface: Search and random access on structured data like tables\n  * Example applications: point queries on columnar stores\n  * Example: given a table with schema {userID, location, date-of-birth, salary, ..}, find all users who were born between 1980 and 1985.\n  * Caveat: We are currently working on some very exciting projects to support a number of additional SQL operators efficiently directly on compressed RDDs.\n\n**When not to use Succinct on Apache Spark**\n\nThere are a few applications that are not suitable for Succinct on Apache Spark — long sequential reads, and search for strings that occur very frequently (you may not want to search for “a” or “the”).\n\n**Looking Ahead**\n\nWe at AMPLab are working on several interesting projects to make Succinct on Apache Spark more memory efficient, faster and more expressive. To give you an idea about what is next, we are going to close this post with a hint on our next post: executing Regular Expression queries directly on compressed RDDs. Stay tuned!\n\n相关链接：[Succinct](http://succinct.cs.berkeley.edu/wp/wordpress/)\n\n---\n\n* 原文链接：[Succinct on Apache Spark: Queries on Compressed RDDs](http://succinct.cs.berkeley.edu/wp/wordpress/?p=230)\n","tags":["Spark"],"categories":["Succinct"]},{"title":"机器学习系列(2)_从初等数学视角解读逻辑回归","url":"%2F2015%2F2015-10-22-ml-logistic-regression-2%2F","content":" \n## 一、 引言\n\n前一篇文章《机器学习系列(1)_逻辑回归初步》中主要介绍了逻辑回归的由来，作用和简单的应用，这里追加这篇《机器学习系列(2)用初等数学视角解读逻辑回归》来看看从直观的数学视角，可以怎么去理解逻辑回归的思想思路。\n\n> 为了降低理解难度，本文试图用最基础的初等数学来解读逻辑回归，少用公式，多用图形来直观解释推导公式的现实意义，希望使读者能够对逻辑回归有更直观的理解。\n\n## 二、 逻辑回归问题的通俗几何描述\n\n逻辑回归处理的是分类问题。我们可以用通俗的几何语言重新表述它： \n\n空间中有两群点，一群是圆点“〇”，一群是叉点“X”。我们希望从空间中选出一个分离边界，将这两群点分开。\n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/001.png)\n\n> 注：分离边界的维数与空间的维数相关。如果是二维平面，分离边界就是一条线（一维）。如果是三维空间，分离边界就是一个空间中的面（二维）。如果是一维直线，分离边界就是直线上的某一点。不同维数的空间的理解下文将有专门的论述。\n\n为了简化处理和方便表述，我们做以下4个约定：\n\n* 我们先考虑在二维平面下的情况。\n* 而且，我们假设这两类是线性可分的：即可以找到一条最佳的直线，将两类点分开。\n* 用离散变量y表示点的类别，y只有两个可能的取值。y=1表示是叉点“X”，y=0表示是是圆点“〇”。\n* 点的横纵坐标用x(X1,X2)表示。\n\n于是，现在的问题就变成了：怎么依靠现有这些点的坐标（X1,X2）和标签（y），找出分界线的方程。\n\n## 三、 如何用解析几何的知识找到逻辑回归问题的分界线？\n\n* 我们用逆推法的思路： \n   \n   假设我们已经找到了这一条线，再寻找这条线的性质是什么。根据这些性质，再来反推这条线的方程。\n   \n* 这条线有什么性质呢？ \n   \n   首先，它能把两类点分开来。——好吧，这是废话。(￣▽￣)” \n\n   然后，两类点在这条线的法向量p上的投影的值的正负号不一样，一类点的投影全是正数，另一类点的投影值全是负数！\n      \n      首先，这个性质是非常好，可以用来区分点的不同的类别。\n      \n      而且，我们对法向量进行规范:只考虑延长线通过原点的那个法向量p。这样的话，只要求出法向量p，就可以唯一确认这条分界线，这个分类问题就解决了。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/002.png)\n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/003.png)\n\n* 还有什么方法能将法向量p的性质处理地更好呢？\n\n   因为计算各个点到法向量p投影，需要先知道p的起点的位置，而起点的位置确定起来很麻烦，我们就干脆将法向量平移使其起点落在坐标系的原点，成为新向量p’。因此，所有点到p’的投影也就变化了一个常量。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/004.png)\n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/005.png)\n\n   假设这个常量为θ0，p’向量的横纵坐标为(θ1,θ2)。空间中任何一个点x (X1,X2)到p’的投影就是θ1X1+θ2X2，再加上前面的常量值就是：θ0+θ1X1+θ2X2 \n   \n   看到上面的式子有没有感到很熟悉？这不就是逻辑回归函数hθ(x)=g(θ0+θ1X1+θ2X2)中括号里面的部分吗？ \n   \n   令z=θ0+θ1X1+θ2X2 就可以根据z的正负号来判断点x的类别了。\n\n## 四、 从概率角度理解z的含义。\n\n由以上步骤，我们由点x的坐标得到了一个新的特征z，那么:\n\nz的现实意义是什么呢？\n\n首先，我们知道，z可正可负可为零。而且，z的变化范围可以一直到正负无穷大。 \n\nz如果大于0，则点x属于y=1的类别。而且z的值越大，说明它距离分界线的距离越大，更可能属于y=1类。 \n\n那可否把z理解成点x属于y=1类的概率P(y=1|x) （下文简写成P）呢？显然不够理想，因为概率的范围是0到1的。 \n\n但是我们可以将概率P稍稍改造一下：令Q=P/(1-P)，期望用Q作为z的现实意义。我们发现，当P的在区间[0,1]变化时，Q在[0,+∞)区间单调递增。函数图像如下（以下图像可以直接在度娘中搜“x/(1-x)”，超快）: \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/006.png)\n\n但是Q的变化率在[0,+∞)还不够，我们是希望能在(-∞,+∞)区间变化的。而且在P=1/2的时候刚好是0。这样才有足够的解释力。\n\n> 注：因为P=1/2说明该点属于两个类别的可能性相当，也就是说这个点恰好在分界面上，那它在法向量的投影自然就是0了。\n\n而在P=1/2时，Q=1，距离Q=0还有一段距离。那怎么通过一个函数变换然它等于0呢？有一个天然的函数log，刚好满足这个要求。 \n\n于是我们做变换R=log(Q)=log(P/(1-P))，期望用R作为z的现实意义。画出它的函数图像如图： \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/007.png)\n\n这个函数在区间[0,1]中可正可负可为零，单调地在(-∞,+∞)变化，而且1/2刚好就是唯一的0值!基本完美满足我们的要求。 \n\n回到我们本章最初的问题，\n\n> “我们由点x的坐标得到了一个新的特征z，那么z的具体意义是什么呢？”\n\n由此，我们就可以将z理解成x属于y=1类的概率P经过某种变换后对应的值。也就是说，z= log(P/(1-P))。反过来就是P=g(z)=1/(1+e-z)。图像如下： \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/008.png)\n\n这两个函数log(P/(1-P)) 、1/(1+e-z)看起来熟不熟悉？\n\n> 这就是传说中的logit函数和sigmoid函数!\n\n小小补充一下：\n\n* 在概率理论中，Q=P/(1-P)的意义叫做赔率(odds)。世界杯赌过球的同学都懂哈。赔率也叫发生比，是事件发生和不发生的概率比。\n\n* 而z= log(P/(1-P))的意义就是对数赔率或者对数发生比（log-odds）。\n\n于是，我们不光得到了z的现实意义，还得到了z映射到概率P的拟合方程：\n\n> P=hθ(x)=g(θ0+θ1X1+θ2X2)= g(z)=1/(1+e-z)\n\n有了概率P，我们顺便就可以拿拟合方程P=g(z)=1/(1+e-z)来判断点x所属的分类：\n\n> 当P>=1/2的时候，就判断点x属于y=1的类别；当P<1/2，就判断点x属于y=0的类别。\n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/009.png)\n\n## 五、 构造代价函数求出参数的值\n\n到目前为止我们就有两个判断某点所属分类的办法，一个是判断z是否大于0，一个是判断g(z)是否大于1/2。 \n\n然而这并没有什么X用，\n\n> 以上的分析都是基于“假设我们已经找到了这条线”的前提得到的，但是最关键的(θ0,θ1,θ2)三个参数仍未找到有效的办法求出来。\n\n还有没有其他的性质可供我们利用来求出参数(θ0,θ1,θ2)的值？\n\n* 我们漏了一个关键的性质：这些样本点已经被标注了y=0或者y=1的类别!\n* 我们一方面可以基于z是否大于0或者g(z) 是否大于1/2来判断一个点的类别，另一方又可以依据这些点已经被标注的类别与我们预测的类别的插值来评估我们预测的好坏。\n* 这种衡量我们在某组参数下预估的结果和实际结果差距的函数，就是传说中的代价函数Cost Function。\n* 当代价函数最小的时候，相应的参数(θ0,θ1,θ2)就是我们希望的最优解。\n\n由此可见，设计一个好的代价函数，将是我们处理好分类问题的关键。而且不同的代价函数，可能会有不同的结果。因此更需要我们将代价函数设计得解释性强，有现实针对性。 \n\n为了衡量“预估结果和实际结果的差距”，我们首先要确定“预估结果”和“实际结果”是什么。\n\n“实际结果”好确定，就是y=0还是y=1。\n\n“预估结果”有两个备选方案，经过上面的分析，我们可以采用z或者g(z)。但是显然g(z)更好，因为g(z)的意义是概率P，刚好在[0,1]范围之间，与实际结果{0，1}很相近，而z的意思是逻辑发生比，范围是整个实数域(-∞,+∞)，不太好与y={0，1}进行比较。\n\n接下来是衡量两个结果的“差距”。\n\n我们首先想到的是y-hθ(x)。 \n\n但这是当y=1的时候比较好。如果y=0，则y- hθ(x)= - hθ(x)是负数，不太好比较，则采用其绝对值hθ(x)即可。综合表示如下： \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/010.png)\n\n但这个函数有个问题：求导不太方便，进而用梯度下降法就不太方便。\n\n因为梯度下降法超出的初等数学的范围，这里就暂且略去不解释了。\n\n于是对上面的代价函数进行了简单的处理，使之便于求导。结果如下： \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/011.png)\n\n代价函数确定了，接下来的问题就是机械计算的工作了。常见的方法是用梯度下降法。于是，我们的平面线形可分的问题就可以说是解决了。\n\n## 六、 从几何变换的角度重新梳理我们刚才的推理过程。\n\n回顾我们的推理过程，我们其实是在不断地将点x(X1,X2)进行几何坐标变换的过程。\n\n第一步是将分布在整个二维平面的点x(X1,X2)通过线性投影映射到一维直线中，成为点x(z)\n\n第二步是将分布在整个一维直线的点x(z)通过sigmoid函数映射到一维线段[0,1]中成为点x(g(z))。\n\n第三步是将所有这些点的坐标通过代价函数统一计算成一个值，如果这是最小值，相应的参数就是我们所需要的理想值。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/012.png)\n\n## 七、 对于简单的非线性可分的问题。\n\n由以上分析可知。比较关键的是第一步，我们之所以能够这样映射是因为假设我们点集是线性可分的。但是如果分离边界是一个圆呢？考虑以下情况。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/013.png)\n\n我们仍用逆推法的思路： \n\n通过观察可知，分离边界如果是一个圆比较合理。\n\n假设我们已经找到了这个圆，再寻找这个圆的性质是什么。根据这些性质，再来反推这个圆的方程。\n\n我们可以依据这个性质： \n\n圆内的点到圆心的距离小于半径，圆外的点到圆心的距离大于半径\n\n假设圆的半径为r，空间中任何一个点x (X1,X2)到原点的距离为X12+X22。\n\n令z= X12+X22-r2，就可以根据z的正负号来判断点x的类别了\n\n然后令P=hθ(x)=g( X12+X22-r2)= g(z)=1/(1+e-z)，就可以继续依靠我们之前的逻辑回归的方法来处理和解释问题了。\n\n从几何变换的角度重新梳理我们刚才的推理过程。 \n\n第一步是将分布在整个二维平面的点x(X1,X2)通过某种方式映射到一维直线中，成为点x(z)\n\n第二步是将分布在整个一维射线的点x(z)通过sigmoid函数映射到一维线段[0,1]中成为点x(g(z))。\n\n第三步是将所有这些点的坐标通过代价函数统一计算成一个值v，如果这是最小值，相应的参数就是我们所需要的理想值。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/014.png)\n\n## 八、 从特征处理的角度重新梳理我们刚才的分析过程\n\n其实，做数据挖掘的过程，也可以理解成做特征处理的过程。我们典型的数据挖掘算法，也就是将一些成熟的特征处理过程给固定化的结果。 \n\n对于逻辑回归所处理的分类问题，我们已有的特征是这些点的坐标(X1,X2)，我们的目标就是判断这些点所属的分类y=0还是y=1。那么最理想的想法就是希望对坐标(X1,X2)进行某种函数运算，得到一个（或者一些）新的特征z，基于这个特征z是否大于0来判断该样本所属的分类。 \n\n对我们上一节非线性可分问题的推理过程进行进一步抽象，我们的思路其实是：\n\n第一步，将点x(X1,X2的坐标通过某种函数运算，得到一个新的类似逻辑发生比的特征，z=f(X1,X2)= X12+X22-r2\n\n第二步是将特征z通过sigmoid函数得到新的特征q=g(z)= 1/(1+e-z)= 1/(1+e-f(X1,X2))。\n\n第三步是将所有这些点的特征q通过代价函数统一计算成一个值v=J(q1,q2,…)，如果这是最小值，相应的参数(r)就是我们所需要的理想值。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/015.png)\n\n## 九、 对于复杂的非线性可分的问题\n\n由以上分析可知。比较关键的是第一步，如何设计转换函数z=f(X1,X2)。我们现在开始考虑分离边界是一个极端不规则的曲线的情况。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/016.png)\n\n我们仍用逆推法的思路：\n\n通过观察等先验的知识（或者完全不观察乱猜），我们可以假设分离边界是某种6次曲线（这个曲线方程可以提前假设得非常复杂，对应着各种不同的情况）。\n\n第一步：将点x(X1,X2)的坐标通过某种函数运算，得到一个新的特征z=f(X1,X2)=θ0+θ1X1+θ2X2+θ3X12+θ4X1X2+θ5X22+…+θ26X1X25+θ27X26。并假设z是某种程度的逻辑发生比，通过其是否大于0来判断样本所属分类。\n\n第二步：将特征z通过sigmoid函数映射到新的特征q=g(z)= 1/(1+e-z)\n\n第三步：将所有这些样本的特征q通过逻辑回归的代价函数统一计算成一个值v=J(q1,q2,…)，如果这是最小值，相应的参数(θ0,θ1,θ2,…, θ27)就是我们所需要的理想值。\n\n## 十、 多维逻辑回归的问题\n\n以上考虑的问题都是基于在二维平面内进行分类的情况。其实，对于高维度情况的分类也类似。 \n\n高维空间的样本，其区别也只是特征坐标更多，比如四维空间的点x的坐标为(X1,X2，X3,X4)。但直接运用上文特征处理的视角来分析，不过是对坐标x(X1,X2，X3,X4)进行参数更多的函数运算得到新的特征z=f(X1,X2，X3,X4)。并假设z是某种程度的逻辑发生比，通过其是否大于0来判断样本所属分类。 \n\n而且，如果是高维线性可分的情况，则可以有更近直观的理解。\n\n如果是三维空间，分离边界就是一个空间中的一个二维平面。两类点在这个二维平面的法向量p上的投影的值的正负号不一样，一类点的投影全是正数，另一类点的投影值全是负数。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/017.png)\n\n如果是高维空间，分离边界就是这个空间中的一个超平面。两类点在这个超平面的法向量p上的投影的值的正负号不一样，一类点的投影全是正数，另一类点的投影值全是负数。\n\n特殊的，如果是一维直线空间，分离边界就是直线上的某一点p。一类点在点p的正方向上，另一类点在点p的负方向上。这些点在直线上的坐标可以天然理解成类似逻辑发生比的情况。可见一维直线空间的分类问题是其他所有高维空间投影到法向量后的结果，是所有逻辑回归问题的基础。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/018.png)\n\n## 十一、 多分类逻辑回归的问题\n\n以上考虑的问题都是二分类的问题，基本就是做判断题。但是对于多分类的问题，也就是做选择题，怎么用逻辑回归处理呢？\n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/019.png)\n\n其基本思路也是二分类，做判断题。 \n\n比如你要做一个三选一的问题，有ABC三个选项。首先找到A与BUC（”U”是并集符号）的分离边界。然后再找B与AUC的分离边界，C与AUB的分离边界。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/020.png)\n\n这样就能分别得到属于A、B、C三类的概率，综合比较，就能得出概率最大的那一类了。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/021.png)\n\n## 十二、 总结列表\n\n为了把本文的关系梳理清楚，我们画了以下这张图表。 \n\n![](/assets/images/2015/10/22/ml-logistic-regression-2/022.png)\n\n---\n\n* 原文链接：[机器学习系列(2)_从初等数学视角解读逻辑回归](http://blog.csdn.net/han_xiaoyang/article/details/49332321)\n","tags":["Logistic-Regression"],"categories":["Machine-Learning"]},{"title":"机器学习系列(1)_逻辑回归初步","url":"%2F2015%2F2015-10-14-ml-logistic-regression%2F","content":"\n## 1、总述\n\n逻辑回归是应用非常广泛的一个分类机器学习算法，它将数据拟合到一个logit函数(或者叫做logistic函数)中，从而能够完成对事件发生的概率进行预测。\n\n## 2、由来\n\n要说逻辑回归，我们得追溯到线性回归，想必大家对线性回归都有一定的了解，即对于多维空间中存在的样本点，我们用特征的线性组合去拟合空间中点的分布和轨迹。如下图所：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/001.png)\n\n线性回归能对连续值结果进行预测，而现实生活中常见的另外一类问题是，分类问题。最简单的情况是是与否的二分类问题。比如说医生需要判断病人是否生病，银行要判断一个人的信用程度是否达到可以给他发信用卡的程度，邮件收件箱要自动对邮件分类为正常邮件和垃圾邮件等等。\n\n当然，我们最直接的想法是，既然能够用线性回归预测出连续值结果，那根据结果设定一个阈值是不是就可以解决这个问题了呢？事实是，对于很标准的情况，确实可以的，这里我们套用Andrew Ng老师的课件中的例子，下图中X为数据点肿瘤的大小，Y为观测结果是否是恶性肿瘤。通过构建线性回归模型，如hθ(x)所示，构建线性回归模型后，我们设定一个阈值0.5，预测hθ(x)≥0.5的这些点为恶性肿瘤，而hθ(x)<0.5为良性肿瘤。\n\n![](/assets/images/2015/10/14/ml-logistic-regression/002.png)\n\n但很多实际的情况下，我们需要学习的分类数据并没有这么精准，比如说上述例子中突然有一个不按套路出牌的数据点出现，如下图所示：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/003.png)\n\n你看，现在你再设定0.5，这个判定阈值就失效了，而现实生活的分类问题的数据，会比例子中这个更为复杂，而这个时候我们借助于线性回归+阈值的方式，已经很难完成一个鲁棒性很好的分类器了。\n\n在这样的场景下，逻辑回归就诞生了。它的核心思想是，如果线性回归的结果输出是一个连续值，而值的范围是无法限定的，那我们有没有办法把这个结果值映射为可以帮助我们判断的结果呢。而如果输出结果是 (0,1) 的一个概率值，这个问题就很清楚了。我们在数学上找了一圈，还真就找着这样一个简单的函数了，就是很神奇的sigmoid函数(如下)：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/004.png)\n\n如果把sigmoid函数图像画出来，是如下的样子：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/005.png)\n\n从函数图上可以看出，函数y=g(z)在z=0的时候取值为1/2，而随着z逐渐变小，函数值趋于0，z逐渐变大的同时函数值逐渐趋于1，而这正是一个概率的范围。\n\n所以我们定义线性回归的预测函数为Y=WTX，那么逻辑回归的输出Y= g(WTX)，其中y=g(z)函数正是上述sigmoid函数(或者简单叫做S形函数)。\n\n## 3、判定边界\n\n我们现在再来看看，为什么逻辑回归能够解决分类问题。这里引入一个概念，叫做判定边界，可以理解为是用以对不同类别的数据分割的边界，边界的两旁应该是不同类别的数据。\n\n从二维直角坐标系中，举几个例子，大概是如下这个样子：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/006.png)\n\n有时候是这个样子：\n    \n![](/assets/images/2015/10/14/ml-logistic-regression/007.png)\n\n甚至可能是这个样子：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/008.png)\n\n上述三幅图中的红绿样本点为不同类别的样本，而我们划出的线，不管是直线、圆或者是曲线，都能比较好地将图中的两类样本分割开来。这就是我们的判定边界，下面我们来看看，逻辑回归是如何根据样本点获得这些判定边界的。\n\n我们依旧借用Andrew Ng教授的课程中部分例子来讲述这个问题。\n\n回到sigmoid函数，我们发现：\n\n当g(z)≥0.5时, z≥0;\n\n对于hθ(x)=g(θTX)≥0.5, 则θTX≥0, 此时意味着预估y=1;\n\n反之，当预测y = 0时，θTX<0;\n\n所以我们认为θTX =0是一个决策边界，当它大于0或小于0时，逻辑回归模型分别预测不同的分类结果。\n\n先看第一个例子hθ(x)=g(θ0+θ1X1+θ2X2)，其中θ0 ,θ1 ,θ2分别取-3, 1, 1。则当−3+X1+X2≥0时, y = 1; 则X1+X2=3是一个决策边界，图形表示如下，刚好把图上的两类点区分开来：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/009.png)\n\n例1只是一个线性的决策边界，当hθ(x)更复杂的时候，我们可以得到非线性的决策边界，例如：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/010.png)\n\n这时当x12+x22≥1时，我们判定y=1，这时的决策边界是一个圆形，如下图所示：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/011.png)\n\n所以我们发现，理论上说，只要我们的hθ(x)设计足够合理，准确的说是g(θTx)中θTx足够复杂，我们能在不同的情形下，拟合出不同的判定边界，从而把不同的样本点分隔开来。\n\n## 4、代价函数与梯度下降\n\n我们通过对判定边界的说明，知道会有合适的参数θ使得θTx=0成为很好的分类判定边界，那么问题就来了，我们如何判定我们的参数θ是否合适，有多合适呢？更进一步，我们有没有办法去求得这样的合适参数θ呢？\n\n这就是我们要提到的代价函数与梯度下降了。\n\n所谓的代价函数Cost Function，其实是一种衡量我们在这组参数下预估的结果和实际结果差距的函数，比如说线性回归的代价函数定义为:\n\n![](/assets/images/2015/10/14/ml-logistic-regression/012.png)\n\n当然我们可以和线性回归类比得到一个代价函数，实际就是上述公式中hθ(x)取为逻辑回归中的g(θTx)，但是这会引发代价函数为“非凸”函数的问题，简单一点说就是这个函数有很多个局部最低点，如下图所示：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/013.png)\n\n而我们希望我们的代价函数是一个如下图所示，碗状结构的凸函数，这样我们算法求解到局部最低点，就一定是全局最小值点。\n\n![](/assets/images/2015/10/14/ml-logistic-regression/014.png)\n\n因此，上述的Cost Function对于逻辑回归是不可行的，我们需要其他形式的Cost Function来保证逻辑回归的成本函数是凸函数。\n\n我们跳过大量的数学推导，直接出结论了，我们找到了一个适合逻辑回归的代价函数:\n\n![](/assets/images/2015/10/14/ml-logistic-regression/015.png)\n\nAndrew Ng老师解释了一下这个代价函数的合理性，我们首先看当y=1的情况：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/016.png)\n\n如果我们的类别y = 1, 而判定的hθ(x)=1，则Cost = 0，此时预测的值和真实的值完全相等，代价本该为0；而如果判断hθ(x)→0，代价->∞，这很好地惩罚了最后的结果。\n\n而对于y=0的情况，如下图所示，也同样合理：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/017.png)\n\n下面我们说说梯度下降，梯度下降算法是调整参数θ使得代价函数J(θ)取得最小值的最基本方法之一。从直观上理解，就是我们在碗状结构的凸函数上取一个初始值，然后挪动这个值一步步靠近最低点的过程，如下图所示：\n    \n![](/assets/images/2015/10/14/ml-logistic-regression/018.png)\n\n我们先简化一下逻辑回归的代价函数：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/019.png)\n\n从数学上理解，我们为了找到最小值点，就应该朝着下降速度最快的方向(导函数/偏导方向)迈进，每次迈进一小步，再看看此时的下降最快方向是哪，再朝着这个方向迈进，直至最低点。\n\n用迭代公式表示出来的最小化J(θ)的梯度下降算法如下：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/020.png)\n\n![](/assets/images/2015/10/14/ml-logistic-regression/021.png)\n\n## 5、代码与实现\n\n我们来一起看两个具体数据上做逻辑回归分类的例子，其中一份数据为线性判定边界，另一份为非线性。\n\n示例1。\n\n第一份数据为data1.txt，部分内容如下：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/022.png)\n\n我们先来看看数据在空间的分布，代码如下。\n\n```python\nfrom numpy import loadtxt, where  \nfrom pylab import scatter, show, legend, xlabel, ylabel  \n  \n#load the dataset  \ndata = loadtxt('/home/HanXiaoyang/data/data1.txt', delimiter=',')  \n  \nX = data[:, 0:2]  \ny = data[:, 2]  \n  \npos = where(y == 1)  \nneg = where(y == 0)  \nscatter(X[pos, 0], X[pos, 1], marker='o', c='b')  \nscatter(X[neg, 0], X[neg, 1], marker='x', c='r')  \nxlabel('Feature1/Exam 1 score')  \nylabel('Feature2/Exam 2 score')  \nlegend(['Fail', 'Pass'])  \nshow()  \n```\n\n得到的结果如下：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/023.png)\n\n下面我们写好计算sigmoid函数、代价函数、和梯度下降的程序：\n\n```python\ndef sigmoid(X):  \n    '''''Compute sigmoid function '''  \n    den =1.0+ e **(-1.0* X)  \n    gz =1.0/ den  \n    return gz  \ndef compute_cost(theta,X,y):  \n    '''''computes cost given predicted and actual values'''  \n    m = X.shape[0]#number of training examples  \n    theta = reshape(theta,(len(theta),1))  \n      \n    J =(1./m)*(-transpose(y).dot(log(sigmoid(X.dot(theta))))- transpose(1-y).dot(log(1-sigmoid(X.dot(theta)))))  \n      \n    grad = transpose((1./m)*transpose(sigmoid(X.dot(theta))- y).dot(X))  \n    #optimize.fmin expects a single value, so cannot return grad  \n    return J[0][0]#,grad  \ndef compute_grad(theta, X, y):  \n    '''''compute gradient'''  \n    theta.shape =(1,3)  \n    grad = zeros(3)  \n    h = sigmoid(X.dot(theta.T))  \n    delta = h - y  \n    l = grad.size  \n    for i in range(l):  \n        sumdelta = delta.T.dot(X[:, i])  \n        grad[i]=(1.0/ m)* sumdelta *-1  \n    theta.shape =(3,)  \n    return  grad  \n```\n\n我们用梯度下降算法得到的结果判定边界是如下的样子：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/024.png)\n\n最后我们使用我们的判定边界对training data做一个预测，然后比对一下准确率：\n\n```python\ndef predict(theta, X):  \n    '''''Predict label using learned logistic regression parameters'''  \n    m, n = X.shape  \n    p = zeros(shape=(m,1))  \n    h = sigmoid(X.dot(theta.T))  \n    for it in range(0, h.shape[0]):  \n        if h[it]>0.5:  \n            p[it,0]=1  \n        else:  \n            p[it,0]=0  \n    return p  \n#Compute accuracy on our training set  \np = predict(array(theta), it)  \nprint'Train Accuracy: %f'%((y[where(p == y)].size / float(y.size))*100.0)\n```\n\n计算出来的结果是89.2%\n\n示例2.\n\n第二份数据为data2.txt，部分内容如下：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/025.png)\n\n我们同样把数据的分布画出来，如下：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/026.png)\n\n我们发现在这个例子中，我们没有办法再用一条直线把两类样本点近似分开了，所以我们打算试试多项式的判定边界，那么我们先要对给定的两个feature做一个多项式特征的映射。比如说，我们做了如下的一个映射：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/027.png)\n\n代码如下：\n\n```python\ndef map_feature(x1, x2):  \n    ''''' \n    Maps the two input features to polonomial features. \n    Returns a new feature array with more features of \n    X1, X2, X1 ** 2, X2 ** 2, X1*X2, X1*X2 ** 2, etc... \n    '''  \n    x1.shape =(x1.size,1)  \n    x2.shape =(x2.size,1)  \n    degree =6  \n    mapped_fea = ones(shape=(x1[:,0].size,1))  \n    m, n = mapped_fea.shape  \n    for i in range(1, degree +1):  \n        for j in range(i +1):  \n            r =(x1 **(i - j))*(x2 ** j)  \n            mapped_fea = append(<span style=\"font-family: Arial, Helvetica, sans-serif;\">mapped_fea</span><span style=\"font-family: Arial, Helvetica, sans-serif;\">, r, axis=1)</span>  \n    return mapped_fea  \nmapped_fea = map_feature(X[:,0], X[:,1])\n```\n\n接着做梯度下降：\n\n```python\ndef cost_function_reg(theta, X, y, l):  \n    '''''Compute the cost and partial derivatives as grads \n    '''  \n    h = sigmoid(X.dot(theta))  \n    thetaR = theta[1:,0]  \n    J =(1.0/ m)*((-y.T.dot(log(h)))-((1- y.T).dot(log(1.0- h)))) \\  \n            +(l /(2.0* m))*(thetaR.T.dot(thetaR))  \n    delta = h - y  \n    sum_delta = delta.T.dot(X[:,1])  \n    grad1 =(1.0/ m)* sumdelta  \n    XR = X[:,1:X.shape[1]]  \n    sum_delta = delta.T.dot(XR)  \n    grad =(1.0/ m)*(sum_delta + l * thetaR)  \n    out = zeros(shape=(grad.shape[0], grad.shape[1]+1))  \n    out[:,0]= grad1  \n    out[:,1:]= grad  \n    return J.flatten(), out.T.flatten()  \nm, n = X.shape  \ny.shape =(m,1)  \nit = map_feature(X[:,0], X[:,1])  \n#Initialize theta parameters  \ninitial_theta = zeros(shape=(it.shape[1],1))  \n#Use regularization and set parameter lambda to 1  \nl =1  \n# Compute and display initial cost and gradient for regularized logistic  \n# regression  \ncost, grad = cost_function_reg(initial_theta, it, y, l)  \ndef decorated_cost(theta):  \n    return cost_function_reg(theta, it, y, l)  \nprint fmin_bfgs(decorated_cost, initial_theta, maxfun=500)  \n```\n\n接着在数据点上画出判定边界：\n\n```python\n#Plot Boundary  \nu = linspace(-1,1.5,50)  \nv = linspace(-1,1.5,50)  \nz = zeros(shape=(len(u), len(v)))  \nfor i in range(len(u)):  \n    for j in range(len(v)):  \n        z[i, j]=(map_feature(array(u[i]), array(v[j])).dot(array(theta)))  \nz = z.T  \ncontour(u, v, z)  \ntitle('lambda = %f'% l)  \nxlabel('Microchip Test 1')  \nylabel('Microchip Test 2')  \nlegend(['y = 1','y = 0','Decision boundary'])  \nshow()  \ndef predict(theta, X):  \n    '''''Predict whether the label \n    is 0 or 1 using learned logistic \n    regression parameters '''  \n    m, n = X.shape  \n    p = zeros(shape=(m,1))  \n    h = sigmoid(X.dot(theta.T))  \n    for it in range(0, h.shape[0]):  \n        if h[it]>0.5:  \n            p[it,0]=1  \n        else:  \n            p[it,0]=0  \n    return p  \n#% Compute accuracy on our training set  \np = predict(array(theta), it)  \nprint'Train Accuracy: %f'%((y[where(p == y)].size / float(y.size))*100.0)  \n```\n\n得到的结果如下图所示：\n\n![](/assets/images/2015/10/14/ml-logistic-regression/028.png)\n\n我们发现我们得到的这条曲线确实将两类点区分开来了。\n\n## 6、总结\n\n最后我们总结一下逻辑回归。它始于输出结果为有实际意义的连续值的线性回归，但是线性回归对于分类的问题没有办法准确而又具备鲁棒性地分割，因此我们设计出了逻辑回归这样一个算法，它的输出结果表征了某个样本属于某类别的概率。\n\n逻辑回归的成功之处在于，将原本输出结果范围可以非常大的θTX 通过sigmoid函数映射到(0,1)，从而完成概率的估测。\n\n而直观地在二维空间理解逻辑回归，是sigmoid函数的特性，使得判定的阈值能够映射为平面的一条判定边界，当然随着特征的复杂化，判定边界可能是多种多样的样貌，但是它能够较好地把两类样本点分隔开，解决分类问题。\n\n求解逻辑回归参数的传统方法是梯度下降，构造为凸函数的代价函数后，每次沿着偏导方向(下降速度最快方向)迈进一小部分，直至N次迭代后到达最低点。\n\n## 7、补充\n\n本文的2份数据分别为[data1.txt](/assets/images/2015/10/14/ml-logistic-regression/data1.txt)和[data2.txt](/assets/images/2015/10/14/ml-logistic-regression/data2.txt)，欢迎大家自己动手尝试。\n\n关于逻辑回归的完整ipython notebook示例代码可以在我的github上(https://github.com/HanXiaoyang/ML_examples/tree/master/logistic_regression)下载到，欢迎指正。\n\n---\n\n* 原文链接：[机器学习系列(1)_逻辑回归初步](http://blog.csdn.net/han_xiaoyang/article/details/49123419)\n","tags":["Logistic-Regression"],"categories":["Machine-Learning"]},{"title":"Introduction to the Succinct project","url":"%2F2015%2F2015-10-09-introduction-succinct-project%2F","content":"\nWeb applications and services today collect, store and analyze an immense amount of data. The sheer size of the data has fundamentally changed the bottlenecks in systems for big data analytics. In particular, memory bandwidth and CPU performance continue to grow at a rate much faster than bandwidth between CPU and slower storage devices (SSD, disk, etc.). The result is an I/O bottleneck, that is (and will continue to be) getting worse!\n\nA fundamental approach to alleviating the I/O bottleneck is to use data compression. Traditional compression techniques have led to significant gains in terms of [storage costs](http://rainstor.com/compression-tames-big-data-on-hadoop/), [energy costs](http://conferences.sigcomm.org/sigcomm/2010/papers/green/p23.pdf), and [performance](http://blog.cloudera.com/blog/2009/12/7-tips-for-improving-mapreduce-performance/) for a wide variety of batch processing jobs. Traditional compression techniques have also been used for reducing I/O bottlenecks in columnar stores with significant performance improvements for OLAP workloads that typically require scanning the entire dataset (see [Daniel Abadi’s thesis](http://cs-www.cs.yale.edu/homes/dna/papers/abadiphd.pdf), [this paper](http://cs-www.cs.yale.edu/homes/dna/papers/abadisigmod06.pdf), and  references within).\n\nHowever, the aforementioned compression and query execution techniques are unsuitable for a wide variety of workloads that do not necessarily require data scans (e.g., point queries). One example is search, a fundamental primitive supported by many web applications and services. Examples include Facebook search, Twitter search, LinkedIn search, Airline and hotel search, and services that are specifically built around search (Google, Bing, Yelp, to name a few). Another example is random access as typically performed via get() interface in key-value stores, NoSQL stores, document stores, etc. Queries in such workloads are often short-lived (ideally sub-millisecond), and data scans and/or decompression lead to significant performance degradation. Given the large number of applications that run such workloads, we at AMPLab decided to take a stab at this problem and asked the following fundamental question:\n\nIs it possible to execute point queries (e.g., search and random access) directly on compressed data without performing data scans?\nExploring the above question led to the Succinct project! At a high-level, Succinct enables a wide range of queries including search, range and wildcard queries over arbitrary strings as well as random access into the input data directly on a compressed representation of the input. What differentiates Succinct from previous systems that support point queries is that Succinct supports these queries without storing any indexes, without data scans and without data decompression — all the required information is embedded within the compressed representation and queries are executed directly on the compressed representation.\n\nOn real-world and benchmark datasets, Succinct can execute sub-millisecond search queries while keeping as much as an order of magnitude more input data in faster storage compared to state-of-the-art systems that provide similar functionality using indexes. For example, on a server with 128GB RAM, Succinct can push as much as 163 — 250GB of raw data, depending on the dataset, while executing search queries within a millisecond. Thus, Succinct executes more queries in faster storage, leading to lower query latency than existing systems for a much larger range of input sizes.\n\nOver next couple of weeks, we will be providing much more information on Succinct — the techniques, tradeoffs and benchmark results over several real-world applications! We are also very excited about the upcoming open-source release of Succinct on Apache Spark, making point queries extremely efficient on Apache Spark. Stay tuned!\n\nFinally, over next couple of weeks, I will write a lot more about several very exciting follow up projects on Succinct that we have been working on at AMPLab.\n\n相关链接：[Succinct](http://succinct.cs.berkeley.edu/wp/wordpress/)\n\n---\n\n* 原文链接：[Introduction to the Succinct project](http://succinct.cs.berkeley.edu/wp/wordpress/?p=143)\n","tags":["Succinct"],"categories":["Succinct"]},{"title":"How to setup High Availability for Ambari server?","url":"%2F2015%2F2015-09-29-ambari-server-high-availability%2F","content":"\n目前，Ambari 项目本身并没有提供HA支持或方案，以下所描述的内容均来自于网上用户给出的实现及方案。\n该特性可能会在 Ambari 2.4 或 2.5 版本得到支持, 这主要依赖于社区的开发路径和方向。\n\nHigh availability for Ambari Server can be achieved by enabling a rapid failover mechanism (an active-passive setup) \nthrough an external monitoring tool e.g. Upstart, Supervisor or some other Daemon tool.\n\nCustomers deploys two (2) Ambari servers configured exactly same having same Ambari property files. \nOne of the server is kept active while the other is stopped.\n\nThe responsibilities of the external monitoring service are:\n\n* Ensure there is only one active instance of Ambari Server\n* Monitor the active instance and if it’s down then make a decision to \neither bring the same instance back up or the replacement instance\n* Ensure that the agents are re-configured to communicate with the active Ambari Server instance\n\nRequirements for HA\n\n* The Ambari DB must be an external DB instance (do not use embedded postgres)\n* Both Ambari Server instances must be configured similarly (options available via ambari-server setup command)\n* Appropriate load-balancer setup to route client requests to the active Ambari Server instance\n\nAt this point there is no plan to inherently support an active-passive deployment. \nThere are some work-items to make it easier to have an external logic enable failover \nsuch as configuring Ambari Agents to take a list of hostnames for the servers and select the active one to auto-register.\n\nInstead of using an external monitoring tool such as Upstart or Supervisor, \nI would recommend using a cluster software solution.\n\nIn the past, I have used (not for Hadoop) with good success the Pacemaker software ([Clusterlabs](http://clusterlabs.org)). \nIt not only detects some failure, but also automatically raises up the standby daemon, \ncan handle dependencies (first recovering the database, then the application), define some fencing, \ndo placement policies (avoiding having the database and the application on the same node for instance)...\n\nLinks：\n\n* [Issues: AMBARI-4016](https://issues.apache.org/jira/browse/AMBARI-4016)\n* [Issues: AMBARI-7896](https://issues.apache.org/jira/browse/AMBARI-7896)\n* [Issues: AMBARI-17126](https://issues.apache.org/jira/browse/AMBARI-17126)\n\n---\n\n* Link：[How to setup High Availability for Ambari server?](https://community.hortonworks.com/questions/402/how-to-setup-high-availability-for-ambari-server.html)\n","tags":["HA"],"categories":["Ambari"]},{"title":"Ranger 介绍","url":"%2F2015%2F2015-09-10-ranger-introduction%2F","content":"\nRanger为Hadoop集群提供了全面数据和服务的安全保证。Ranger提供了以授权，认证，审计和数据保护为核心的中央安全管理策略来满足企业对安全的要求。\n\nRanger可以对Hadoop生态的组件如Hive，Hbase进行细粒度的数据访问控制。在Ranger的控制台，管理用户可以通过配置策略，轻松的控制用户访问HDFS的文件夹、文件，Hive、HBase的数据库、表、字段的权限。这些策略可以针对不同的用户和组进行设置，同时可以与Hadoop权限进行无缝对接。\n\n## 安全问题\n\n* 合规安全: 法律法规、安全体系、安全标准、行业安全；\n\n* 基础安全: 物理环境安全、网络安全、系统安全、传输安全；\n\n* 服务安全: 数据清洗、数据检测、用户认证、行为审计、搜索治理、访问授权、权限分割；\n\n* 数据安全: 数据传输加密、底层数据加密、数据访问授权、数据销毁；\n\n* 操作安全: 安全运维、数据备份、灾难恢复、业务连续性。\n\n## 概念&技术\n\n* ACL(Access Control List): ACL即Access Control List 主要的目的是提供传统的Owner、Group、Others的Read、Write、Execute权限之外的具体权限设置，ACL可以针对单一用户、单一文件或目录来进行R，W，X的权限控制，对于需要特殊权限的使用状况有一定帮助。如，某一个文件，不让单一的某个用户访问。\n\n* LDAP(Lightweight Directory Acess Protocol)/AD(Active Directory): LDAP（轻量级目录访问协议，Lightweight Directory Access Protocol)是实现提供被称为目录服务的信息服务。目录服务是一种特殊的数据库系统，其专门针对读取，浏览和搜索操作进行了特定的优化。目录一般用来包含描述性的，基于属性的信息并支持精细复杂的过滤能力。目录一般不支持通用数据库针对大量更新操作操作需要的复杂的事务管理或回卷策略。而目录服务的更新则一般都非常简单。这种目录可以存储包括个人信息、WEB链结、JPEG图像等各种信息。为了访问存储在目录中的信息，就需要使用运行在TCP/IP 之上的访问协议—LDAP。\n\n* Kerberos(KDC): Kerberos协议主要用于计算机网络的身份鉴别(Authentication)， 其特点是用户只需输入一次身份验证信息就可以凭借此验证获得的票据(Ticket-Granting Ticket)访问多个服务，即SSO(Single Sign On)。由于在每个Client和Service之间建立了共享密钥，使得该协议具有相当的安全。Kerberos集成起来比较复杂，配置繁琐。用户权限的修改，机器的减容扩容，会造成证书要重新生成，再分发证书，重启hadoop，且需要解决单点和自身问题。\n\n* Knox: Apache Knox Gateway 项目的目的是为了简化和标准化发布和实现安全的 Hadoop 集群，拓展了Hadoop的安全边界，通过集中式的 REST APIs 访问服务，通过Apache Shiro(LDAP做数据源)为Hadoop相关项目的认证、授权(Service Level)和审计提供服务，它目前支持的服务有YARN、WebHDFS、WebHCat/Templeton、Oozie、HBase/Stargate、Hive (via WebHCat/JDBC)，对终端用户屏蔽了主机及端口等信息，代码侵入性强，一旦Knox服务出现问题，很难回退。\n\n* Atlas: Apache Atlas 是一个可伸缩和可扩展的核心功能治理服务。企业可以利用它高效的管理 Hadoop 以及整个企业数据生态的集成。核心功能包括：数据分类、集中审计、搜索、安全和策略引擎。\n\n## Ranger 介绍\n\n### Ranger 架构\n\n![](http://blog.hyperj.net/assets/images/2015/09/10/ranger-introduction/ranger.png)\n\n### Ranger + Knox 架构\n\n![](http://blog.hyperj.net/assets/images/2015/09/10/ranger-introduction/knox.png)\n\n* Administration\n\n中央管理和一致的安全，为整个集群设置策略。\n\n![](http://blog.hyperj.net/assets/images/2015/09/10/ranger-introduction/ranger-administration.png)\n\n* Authentication/Perimeter Security\n\n认证服务。\n\n![](http://blog.hyperj.net/assets/images/2015/09/10/ranger-introduction/ranger-authentication.png)\n\n* Authorization\n\n授权服务。\n\n* Audit\n\n基于 Solr，提供审计服务。\n\n* Data Protection\n\n数据保护，通过Ranger KMS组件。\n\n### WHAT RANGER DOES\n\nRanger可以对Hadoop生态的组件如Hive，Hbase进行细粒度的数据访问控制。在Ranger的控制台，管理用户可以通过配置策略，轻松的控制用户访问HDFS的文件夹、文件，Hive、HBase的数据库、表、字段的权限。这些策略可以针对不同的用户和组进行设置，同时可以与Hadoop权限进行无缝对接。\n\n管理用户也可以使用Ranger来管理审计跟踪和政策分析对环境的更深层次的控制。该解决方案还提供了一个选项委托某些数据的管理与其他组拥有者，具有安全集中数据所有权的目的。\n\nRanger策略包括两个主要部分：资源，如HDFS文件/目录，Hive数据库/表/列，HBase的表/列族/列；规则，类似用户/组，访问类型和定制的条件下，对于该访问应被允许规范。\n\nRanger目前支持授权，认证，审核，数据对以下组件加密和安全管理：HDFS、YARN、Hive、HBase、Storm、Knox、Solr、Kafka。\n\n![](http://blog.hyperj.net/assets/images/2015/09/10/ranger-introduction/ranger-service.png)\n\n* HDFS: folder/file(recursive) - Read/Write/Execute\n\n* Hive: Database/Table/Column/UDF - Select/Update/Create/Drop/Alter/Index/Lock/All\n\n* HBase: Table/Column-family/Column - Read/Write/Create/Admin\n\n* Knox: Topology/Service - IP Address Range/Allow\n\n* Storm: Topology - Submit Topology/File upload/Get Nimbus Conf/Get Cluster info/File Download/Kill Topology/Rebalance/Activate/Deactivate/Get Topology Conf/Get Topology/Get User Topology/Get Topology Info/Upload New Credential\n\n* YARN: Queue - Submit-job/Admin-queue\n\n* Solr: Collection - Querry/Update/Others/Solr Admin\n\n* Kafka: Topic - Publish/Consume/Configure/Describe/Kafka Admin\n\n### HOW RANGER WORKS\n\nRANGER是分散式架构，有下列内部组件：\n\n* Ranger Portal: 安全管理中心界面，用户可以创建和更新策略，然后将其存储在策略数据库。每个组件轮询这些策略以规则。还包括发送从HDFS插件用于存储或在关系数据库中收集的审核数据的审计服务器的内插件。\n\n* Ranger Plugins: 插件是轻量级的Java程序，嵌入群集每个组件的进程中。当用户请求通过该组件，这些插件拦截请求并评估其对安全策略。还插件收集来自用户的请求数据，并按照一个单独的线程来将此数据发送回服务器的审核。\n\n* User Group Sync: Ranger提供了一个用户同步工具从Unix或LDAP或AD用户和组。用户或组信息存储下来，并用于策略的定义。\n\n* Ranger KMS(Key Management Service)\n\n   HDFS的静态数据加密，对读取和写入HDFS实现了端到端加密的数据。端到端加密意味着只通过客户端对数据进行加密和解密。HDFS本身没有访问加密数据的键。\n   \n   静态数据加密的加密方式有如下几种：AES/CTR/NoPadding - 128/256\n\n   HDFS静态数据加密涉及以下几方面内容：\n\n    1. **加密密钥**：一个新的水平的访问保护，除了标准HDFS权限。\n    2. **HDFS加密区**：一个特殊的HDFS目录中所有的数据都是加密的编写，并解密阅读。\n    3. 每个加密区与一个加密密钥创建时指定的区域。\n    4. 每个文件有一个独特的加密密钥，称为 \"Data Encryption Key\" (DEK)。\n    5. HDFS没有DEKs。HDFS只看到一串加密字节。\n    6. HDFS存储 \"Encrypted Data Encryption Keys\" (EDEKs)作为文件的元数据的一部分NameNode。\n    7. 客户端解密EDEK和使用相关的DEK来加密和解密数据读写操作。\n\n![](http://blog.hyperj.net/assets/images/2015/09/10/ranger-introduction/ranger-encryption.png)\n\n## 相关问题\n\n网络，DWZ，防火墙，SSL，高可用，服务治理，挖掘分析，实时监控、分析，机器学习，用户系统集成，应用接口开发与对接（按阶段）\n\n## Links\n\n* [Ranger Wiki Page](https://cwiki.apache.org/confluence/display/RANGER/Index)\n","tags":["Ranger"],"categories":["Ranger"]},{"title":"深入理解JVM（6）: Java对象内存分配策略","url":"%2F2015%2F2015-09-07-jvm-object-memory-allocation-strategy%2F","content":"\nJava技术体系中所提倡的自动内存管理最终可以归结为自动化地解决了两个问题：给对象分配内存以及回收分配给对象的内存。\n\n对象的内存回收，可参考 [java内存回收1](http://blog.hyperj.net/2015/2015-09-03-jvm-gc/) 和  [java内存回收2](http://blog.hyperj.net/2015/2015-09-03-jvm-gc2/) 。\n\n对象的内存分配，往大方向讲，就是在堆上分配，对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配。少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。\n\n本文中的内存分配策略指的是Serial / Serial Old收集器下（ParNew / Serial Old收集器组合的规则也基本一致）的内存分配和回收的策略。\n\n### 1. **对象优先在Eden分配**\n\n大多数情况下，对象在**新生代Eden区**中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。\n\n* **代码示例：**\n\n```java\nprivate static final int _1MB = 1024 * 1024;  \n/**  \n* VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 \n*/  \npublic static void testAllocation() {  \n   byte[] allocation1, allocation2, allocation3, allocation4;  \n   allocation1 = new byte[2 * _1MB];  \n   allocation2 = new byte[2 * _1MB];  \n   allocation3 = new byte[2 * _1MB];  \n   allocation4 = new byte[4 * _1MB];  // 出现一次Minor GC  \n}\n```\n\n运行结果：\n\n```log\n[GC [DefNew: 6651K->148K(9216K), 0.0070106 secs] 6651K->6292K(19456K), 0.0070426 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]   \nHeap  \ndef new generation   total 9216K, used 4326K [0x029d0000, 0x033d0000, 0x033d0000)  \neden space 8192K,  51% used [0x029d0000, 0x02de4828, 0x031d0000)  \nfrom space 1024K,  14% used [0x032d0000, 0x032f5370, 0x033d0000)  \nto   space 1024K,   0% used [0x031d0000, 0x031d0000, 0x032d0000)  \ntenured generation   total 10240K, used 6144K [0x033d0000, 0x03dd0000, 0x03dd0000)  \n the space 10240K,  60% used [0x033d0000, 0x039d0030, 0x039d0200, 0x03dd0000)  \ncompacting perm gen  total 12288K, used 2114K [0x03dd0000, 0x049d0000, 0x07dd0000)  \n the space 12288K,  17% used [0x03dd0000, 0x03fe0998, 0x03fe0a00, 0x049d0000)  \nNo shared spaces configured.\n```\n\n代码的`testAllocation()`方法中，尝试分配3个2MB大小和1个4MB大小的对象，在运行时通过-Xms20M、 -Xmx20M、 -Xmn10M这3个参数限制了Java堆大小为20MB，不可扩展，其中10MB分配给新生代，剩下的10MB分配给老年代。`-XX:SurvivorRatio=8`决定了新生代中Eden区与一个Survivor区的空间比例是8∶1，从输出的结果也可以清晰地看到`eden space 8192K、from space 1024K、to space 1024K`的信息，新生代总可用空间为9216KB（Eden区+1个Survivor区的总容量）。\n\n执行`testAllocation()`中分配allocation4对象的语句时会发生一次Minor GC，这次GC的结果是新生代6651KB变为148KB，而总内存占用量则几乎没有减少（因为allocation1、allocation2、allocation3三个对象都是存活的，虚拟机几乎没有找到可回收的对象）。这次GC发生的原因是给allocation4分配内存的时候，发现Eden已经被占用了6MB，剩余空间已不足以分配allocation4所需的4MB内存，因此发生Minor GC。GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间（Survivor空间只有1MB大小），所以只好通过分配担保机制提前转移到老年代去。\n\n这次GC结束后，4MB的allocation4对象顺利分配在Eden中，因此程序执行完的结果是Eden占用4MB（被allocation4占用），Survivor空闲，老年代被占用6MB（被allocation1、allocation2、allocation3占用）。通过GC日志可以证实这一点。\n\n### 2. **大对象直接进入老年代**\n\n所谓的大对象是指，需要**大量连续内存空间**的Java对象，最典型的大对象就是那种很长的字符串以及数组。\n\n大对象对虚拟机的内存分配来说就是一个坏消息（比遇到一个大对象更加坏的消息就是遇到一群“朝生夕灭”的“短命大对象”，写程序的时候应当避免），经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。\n\n虚拟机提供了一个`-XX:PretenureSizeThreshold`参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存复制（复习一下：新生代采用复制算法收集内存）。\n\n* **代码示例：**\n\n```java\nprivate static final int _1MB = 1024 * 1024;   \n/**  \n* VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 \n* -XX:PretenureSizeThreshold=3145728 \n*/  \npublic static void testPretenureSizeThreshold() {  \nbyte[] allocation;  \nallocation = new byte[4 * _1MB];  //直接分配在老年代中  \n}\n```\n    \n运行结果：\n\n```log\n1.Heap  \n2.def new generation   total 9216K, used 671K [0x029d0000, 0x033d0000, 0x033d0000)  \n3.eden space 8192K,   8% used [0x029d0000, 0x02a77e98, 0x031d0000)  \n4.from space 1024K,   0% used [0x031d0000, 0x031d0000, 0x032d0000)  \n5.to   space 1024K,   0% used [0x032d0000, 0x032d0000, 0x033d0000)  \n6.tenured generation   total 10240K, used 4096K [0x033d0000, 0x03dd0000, 0x03dd0000)  \n7.the space 10240K,  40% used [0x033d0000, 0x037d0010, 0x037d0200, 0x03dd0000)  \n8.compacting perm gen  total 12288K, used 2107K [0x03dd0000, 0x049d0000, 0x07dd0000)  \n9.the space 12288K,  17% used [0x03dd0000, 0x03fdefd0, 0x03fdf000, 0x049d0000)  \n10.No shared spaces configured.\n```\n\n执行代码中的`testPretenureSizeThreshold()`方法后，我们看到Eden空间几乎没有被使用，而老年代的10MB空间被使用了40%，也就是4MB的allocation对象直接就分配在老年代中，这是因为`PretenureSizeThreshold`被设置为3MB（就是3145728，这个参数不能像-Xmx之类的参数一样直接写3MB），因此超过3MB的对象都会直接在老年代进行分配。\n\n注意:`PretenureSizeThreshold`参数只对Serial和ParNew两款收集器有效，Parallel Scavenge收集器不认识这个参数，Parallel Scavenge收集器一般并不需要设置。\n\n如果遇到必须使用此参数的场合，可以考虑ParNew加CMS的收集器组合。\n\n### 3. **<strong>长期存活的对象将进入老年代**</strong>\n\n为了在内存回收时能识别哪些对象应放在新生代，哪些对象应放在老年代中。虚拟机给每个对象定义了一个对象年龄（Age）计数器。\n\n* **对象年龄的判定：**\n\n如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。\n\n对象在Survivor区中每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。\n\n对象晋升老年代的年龄阈值，可以通过参数`-XX:MaxTenuringThreshold`设置。\n* **代码示例**：\n\n```java\nprivate static final int _1MB = 1024 * 1024;  \n/**  \n* VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1 \n* -XX:+PrintTenuringDistribution  \n*/  \n@SuppressWarnings(\"unused\")  \npublic static void testTenuringThreshold() {  \nbyte[] allocation1, allocation2, allocation3;  \nallocation1 = new byte[_1MB / 4];    \n // 什么时候进入老年代取决于XX:MaxTenuringThreshold设置  \nallocation2 = new byte[4 * _1MB];  \nallocation3 = new byte[4 * _1MB];  \nallocation3 = null;  \nallocation3 = new byte[4 * _1MB];  \n}\n```\n\n以MaxTenuringThreshold=1参数来运行的结果：\n\n```log\n1.[GC [DefNew  \n2.Desired Survivor size 524288 bytes, new threshold 1 (max 1)  \n3.- age   1:     414664 bytes,     414664 total  \n4.: 4859K->404K(9216K), 0.0065012 secs] 4859K->4500K(19456K), 0.0065283 secs] [Times: user=0.02 sys=0.00, real=0.02 secs]   \n5.[GC [DefNew  \n6.Desired Survivor size 524288 bytes, new threshold 1 (max 1)  \n7.: 4500K->0K(9216K), 0.0009253 secs] 8596K->4500K(19456K), 0.0009458 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]   \n8.Heap  \n9.def new generation   total 9216K, used 4178K [0x029d0000, 0x033d0000, 0x033d0000)  \n10.eden space 8192K,  51% used [0x029d0000, 0x02de4828, 0x031d0000)  \n11.from space 1024K,   0% used [0x031d0000, 0x031d0000, 0x032d0000)  \n12.to   space 1024K,   0% used [0x032d0000, 0x032d0000, 0x033d0000)  \n13.to   space 1024K,   0% used [0x032d0000, 0x032d0000, 0x033d0000)  \n14.to   space 1024K,   0% used [0x032d0000, 0x032d0000, 0x033d0000)  \n15.to   space 1024K,   0% used [0x032d0000, 0x032d0000, 0x033d0000)  \n16.tenured generation   total 10240K, used 4500K [0x033d0000, 0x03dd0000, 0x03dd0000)  \n17.the space 10240K,  43% used [0x033d0000, 0x03835348, 0x03835400, 0x03dd0000)  \n18.compacting perm gen  total 12288K, used 2114K [0x03dd0000, 0x049d0000, 0x07dd0000)  \n19.the space 12288K,  17% used [0x03dd0000, 0x03fe0998, 0x03fe0a00, 0x049d0000)  \n20.No shared spaces configured.\n```\n\n以MaxTenuringThreshold=15参数来运行的结果：\n\n```log\n1.[GC [DefNew  \n2.Desired Survivor size 524288 bytes, new threshold 15 (max 15)  \n3.- age   1:     414664 bytes,     414664 total  \n4.: 4859K->404K(9216K), 0.0049637 secs] 4859K->4500K(19456K), 0.0049932 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]   \n5.[GC [DefNew  \n6.Desired Survivor size 524288 bytes, new threshold 15 (max 15)  \n7.- age   2:     414520 bytes,     414520 total  \n8.: 4500K->404K(9216K), 0.0008091 secs] 8596K->4500K(19456K), 0.0008305 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]   \n9.Heap  \n10.def new generation   total 9216K, used 4582K [0x029d0000, 0x033d0000, 0x033d0000)  \n11.eden space 8192K,  51% used [0x029d0000, 0x02de4828, 0x031d0000)  \n12.from space 1024K,  39% used [0x031d0000, 0x03235338, 0x032d0000)  \n13.to   space 1024K,   0% used [0x032d0000, 0x032d0000, 0x033d0000)  \n14.tenured generation   total 10240K, used 4096K [0x033d0000, 0x03dd0000, 0x03dd0000)  \n15.the space 10240K,  40% used [0x033d0000, 0x037d0010, 0x037d0200, 0x03dd0000)  \n16.compacting perm gen  total 12288K, used 2114K [0x03dd0000, 0x049d0000, 0x07dd0000)  \n17.the space 12288K,  17% used [0x03dd0000, 0x03fe0998, 0x03fe0a00, 0x049d0000)  \n18.No shared spaces configured.\n```\n\n\n分别以`-XX:MaxTenuringThreshold=1`和`-XX:MaxTenuringThreshold=15`两种设置来执行代码清单3-7中的`testTenuringThreshold()`方法，此方法中的allocation1对象需要256KB内存，Survivor空间可以容纳。当MaxTenuringThreshold=1时，allocation1对象在第二次GC发生时进入老年代，新生代已使用的内存GC后非常干净地变成0KB。而MaxTenuringThreshold=15时，第二次GC发生后，allocation1对象则还留在新生代Survivor空间，这时新生代仍然有404KB被占用。\n\n### 4. **<strong>动态对象年龄判定**</strong>\n\n为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代.\n\n* **动态对象年龄判定**\n\n    如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到`MaxTenuringThreshold`中要求的年龄。\n\n* **代码示例**\n\n```java\nprivate static final int _1MB = 1024 * 1024;  \n/**  \n* VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 \n* -XX:+PrintTenuringDistribution  \n*/  \n@SuppressWarnings(\"unused\")  \npublic static void testTenuringThreshold2() { \nbyte[] allocation1, allocation2, allocation3, allocation4;  \nallocation1 = new byte[_1MB / 4];   \n  // allocation1+allocation2大于survivo空间一半  \nallocation2 = new byte[_1MB / 4];    \nallocation3 = new byte[4 * _1MB];  \nallocation4 = new byte[4 * _1MB];  \nallocation4 = null;  \nallocation4 = new byte[4 * _1MB];  \n}\n```\n\n```log\n1.[GC [DefNew  \n2.Desired Survivor size 524288 bytes, new threshold 1 (max 15)  \n3.- age   1:     676824 bytes,     676824 total  \n4.: 5115K->660K(9216K), 0.0050136 secs] 5115K->4756K(19456K), 0.0050443 secs] [Times: user=0.00 sys=0.01, real=0.01 secs]   \n5.[GC [DefNew  \n6.Desired Survivor size 524288 bytes, new threshold 15 (max 15)  \n7.: 4756K->0K(9216K), 0.0010571 secs] 8852K->4756K(19456K), 0.0011009 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]   \n8.Heap  \n9.def new generation   total 9216K, used 4178K [0x029d0000, 0x033d0000, 0x033d0000)  \n10.eden space 8192K,  51% used [0x029d0000, 0x02de4828, 0x031d0000)  \n11.from space 1024K,   0% used [0x031d0000, 0x031d0000, 0x032d0000)  \n12.to   space 1024K,   0% used [0x032d0000, 0x032d0000, 0x033d0000)  \n13.tenured generation   total 10240K, used 4756K [0x033d0000, 0x03dd0000, 0x03dd0000)  \n14.the space 10240K,  46% used [0x033d0000, 0x038753e8, 0x03875400, 0x03dd0000)  \n15.compacting perm gen  total 12288K, used 2114K [0x03dd0000, 0x049d0000, 0x07dd0000)  \n16.the space 12288K,  17% used [0x03dd0000, 0x03fe09a0, 0x03fe0a00, 0x049d0000)  \n17.No shared spaces configured.\n```\n\n执行代码中的`testTenuringThreshold2()`方法，并设置`-XX:MaxTenuringThreshold=15`，会发现运行结果中Survivor的空间占用仍然为0%，而老年代比预期增加了6%，也就是说，allocation1、allocation2对象都直接进入了老年代，而没有等到15岁的临界年龄。因为这两个对象加起来已经到达了512KB，并且它们是同年的，满足同年对象达到Survivor空间的一半规则。我们只要注释掉其中一个对象new操作，就会发现另外一个就不会晋升到老年代中去了。\n\n### 5. **<strong>空间分配担保**</strong>\n\n在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。\n\n下面解释一下“冒险”是冒了什么风险，前面提到过，新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多空间。\n\n取平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避免Full GC过于频繁.\n\n参考书籍：《深入理解Java虚拟机：JVM高级特性与最佳实践》\n\n---\n\n* 原文链接：[深入理解JVM（6）: Java对象内存分配策略](http://www.jianshu.com/p/fa3569127416)\n","tags":["GC"],"categories":["JVM"]},{"title":"深入理解JVM（5）: Java垃圾收集器","url":"%2F2015%2F2015-09-03-jvm-gc2%2F","content":"\n如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。\n\nJava虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。\n\n![](/assets/images/2015/09/03/jvm-gc2/001.jpg)\n\n图中展示了7种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。\n\n### 概念理解\n\n1. **并发和并行**\n这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，它们可以解释如下。\n\n   * **并行（Parallel）**：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。\n\n   * **并发（Concurrent）**：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上。\n\n2. **Minor GC 和 Full GC**\n\n   * **新生代GC（Minor GC）**：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。\n\n   * **老年代GC（Major GC / Full GC）**：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。\n\n3. **吞吐量**\n\n吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）。\n\n虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。\n\n### 一、Serial收集器\n\nSerial收集器是最基本、发展历史最悠久的收集器，曾经（在JDK 1.3.1之前）是虚拟机新生代收集的唯一选择。\n\n![](/assets/images/2015/09/03/jvm-gc2/002.jpg)\n\n1. **特性：**\n\n这个收集器是一个`单线程`的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。`Stop The World`\n\n2. **应用场景：**\n\nSerial收集器是虚拟机运行在Client模式下的默认新生代收集器。\n\n3. **优势：**\n\n简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。\n\n### 二、ParNew收集器\n\n![](/assets/images/2015/09/03/jvm-gc2/003.jpg)\n\n1. **特性：**\n\nParNew收集器其实就是Serial收集器的**多线程版本**，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。\n\n2. **应用场景：**\n\nParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器。\n\n很重要的原因是：除了Serial收集器外，目前只有它能与CMS收集器配合工作。\n\n在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器——CMS收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。\n\n不幸的是，CMS作为老年代的收集器，却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK 1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。\n\n3. **Serial收集器  VS ParNew收集器：**\n\nParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越Serial收集器。\n\n然而，随着可以使用的CPU的数量的增加，它对于GC时系统资源的有效利用还是很有好处的。\n\n### 三、Parallel Scavenge收集器\n\n1. **特性：**\n\nParallel Scavenge收集器是一个**新生代收集器**，它也是使用**复制算法**的收集器，又是**并行**的多线程收集器。\n\n2. **应用场景：**\n\n停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。\n\n3. **对比分析：**\n\n   * **Parallel Scavenge收集器  VS CMS等收集器：**\nParallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个**可控制的吞吐量**（Throughput）。\n由于与吞吐量关系密切，Parallel Scavenge收集器也经常称为“吞吐量优先”收集器。\n\n   * **Parallel Scavenge收集器  VS ParNew收集器：**\nParallel Scavenge收集器与ParNew收集器的一个重要区别是它具有自适应调节策略。\n\n   * **GC自适应的调节策略**：\nParallel Scavenge收集器有一个参数-`XX:+UseAdaptiveSizePolicy`。当这个参数打开之后，就不需要手工指定新生代的大小、Eden与Survivor区的比例、晋升老年代对象年龄等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。\n\n### 四、Serial Old收集器\n\n![](/assets/images/2015/09/03/jvm-gc2/004.jpg)\n\n1. **特性：**\n\nSerial Old是Serial收集器的**老年代版本**，它同样是一个**单线程收集器**，使用**标记－整理**算法。\n\n2. **应用场景：**\n\n   * **Client模式**\nSerial Old收集器的主要意义也是在于给Client模式下的虚拟机使用。\n\n   * **Server模式**\n如果在Server模式下，那么它主要还有两大用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。\n\n### 五、**Parallel Old收集器**\n\n![](/assets/images/2015/09/03/jvm-gc2/005.jpg)\n\n1. **特性：**\n\nParallel Old是Parallel Scavenge收集器的**老年代版本**，使用**多线程**和**“标记－整理”**算法。\n\n2. **应用场景：**\n\n在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。\n\n这个收集器是在JDK 1.6中才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直处于比较尴尬的状态。原因是，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old收集器外别无选择（Parallel Scavenge收集器无法与CMS收集器配合工作）。由于老年代Serial Old收集器在服务端应用性能上的“拖累”，使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”。直到Parallel Old收集器出现后，“吞吐量优先”收集器终于有了比较名副其实的应用组合。\n\n### 六、**CMS收集器**\n\n1. **特性：**\n\nCMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。\n\n![](/assets/images/2015/09/03/jvm-gc2/006.jpg)\n\nCMS收集器是基于**“标记—清除”**算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤：\n\n   * **初始标记（CMS initial mark）**\n初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。\n\n   * **并发标记（CMS concurrent mark）**\n并发标记阶段就是进行GC Roots Tracing的过程。\n\n   * **重新标记（CMS remark）**\n重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短，仍然需要“Stop The World”。\n\n   * **并发清除（CMS concurrent sweep）**\n并发清除阶段会清除对象。\n\n由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。\n\n2. **优点：**\n\nCMS是一款优秀的收集器，它的主要优点在名字上已经体现出来了：**并发收集**、**低停顿**。\n\n3. **缺点：**\n\n   * **CMS收集器对CPU资源非常敏感**\n其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。\nCMS默认启动的回收线程数是（CPU数量+3）/ 4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就可能变得很大。\n\n   * **CMS收集器无法处理浮动垃圾**\nCMS收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。\n\n由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。\n\n也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。\n\n   * **CMS收集器会产生大量空间碎片**\nCMS是一款基于“标记—清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。\n\n空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。\n\n### 七、**G1收集器**\n\n![](/assets/images/2015/09/03/jvm-gc2/007.jpg)\n\n1. **特性：**\n\nG1（Garbage-First）是一款面向**服务端应用**的垃圾收集器。HotSpot开发团队赋予它的使命是未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点。\n\n   * **并行与并发**\nG1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。\n\n   * **分代收集**\n与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。\n\n   * **空间整合**\n与CMS的“标记—清理”算法不同，G1从**整体来看是基于“标记—整理”**算法实现的收集器，从**局部（两个Region之间）上来看是基于“复制”**算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。\n\n   * **可预测的停顿**\n这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。\n\n在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。\n\nG1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。\n\n2. **执行过程：**\nG1收集器的运作大致可划分为以下几个步骤：\n\n   * **初始标记（Initial Marking）**\n初始标记阶段仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。\n\n   * **并发标记（Concurrent Marking）**\n并发标记阶段是从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。\n\n   * **最终标记（Final Marking）**\n最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程`Remembered Set Logs`里面，最终标记阶段需要把`Remembered Set Logs`的数据合并到`Remembered Set`中，这阶段需要停顿线程，但是可并行执行。\n\n   * **筛选回收（Live Data Counting and Evacuation）**\n筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。\n\n### **八、总结**\n\n虽然我们是在对各个收集器进行比较，但并非为了挑选出一个最好的收集器。因为直到现在为止还没有最好的收集器出现，更加没有万能的收集器，所以我们选择的只是对具体应用最合适的收集器。这点不需要多加解释就能证明：如果有一种放之四海皆准、任何场景下都适用的完美收集器存在，那HotSpot虚拟机就没必要实现那么多不同的收集器了。\n\n![](/assets/images/2015/09/03/jvm-gc2/008.jpg)\n\n推荐阅读：《深入理解Java虚拟机：JVM高级特性与最佳实践》周志明著\n\n---\n\n* 原文链接：[深入理解JVM（5）: Java垃圾收集器](http://www.jianshu.com/p/50d5c88b272d)\n","tags":["GC"],"categories":["JVM"]},{"title":"深入理解JVM（4）: Java垃圾收集 （GC）","url":"%2F2015%2F2015-09-03-jvm-gc%2F","content":"\n> Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人却想出来。\n\n对于垃圾收集（Gabage Collection，GC）, 我们需要考虑三件事情：\n\n* 哪些内存需要回收？\n* 什么时候回收？\n* 如何回收？\n\n### 一、GC的工作区域（哪些内存需要回收？）\n\n* * *\n\nJava虚拟机的内存区域中，程序计数器、虚拟机栈和本地方法栈三个区域是线程私有的，随线程生而生，随线程灭而灭；栈中的栈帧随着方法的进入和退出而进行入栈和出栈操作，每个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，因此这几个区域的内存分配和回收都具有确定性。在这几个区域不需要过多考虑回收的问题，因为方法结束或线程结束时，内存自然就跟随着回收了。\n\n**垃圾回收重点关注的是堆和方法区部分的内存**。因为一个接口中的多个实现类需要的内存可能不一样，一个方法的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，所以垃圾回收器所关注的主要是这部分的内存。\n\n### 二、垃圾对象的判定（什么时候回收？）\n\nJava堆中存放着几乎所有的对象实例，垃圾收集器对堆中的对象进行回收前，要先确定这些对象是否还有用，哪些还活着。对象死去的时候才需要回收。\n\n1. **判断对象是否存活的算法：**\n\n  * **引用计数算法**\n  \n  给对象添加一个引用计数器，每当有一个地方引用它时，计数器值就加1，当引用失效时，计数器值就减1，任何时刻计数器为0的对象就是不可能再被使用的。\n\n  （1）优点：引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的选择.\n  （2）缺点：Java虚拟机并没有选择这种算法来进行垃圾回收，主要原因是它很难解决对象之间的相互循环引用问题。\n\n```java\npublic class ReferenceCountingGC {\n    public Object instance = null;\n    private static final int _1MB = 1024 * 1024;\n    // 这个成员属性的唯一意义就是占点内存，以便在能在GC日志中看清楚是否有回收过\n    private byte[] bigSize = new byte[2 * _1MB];\n    public static void testGC() {\n       ReferenceCountingGC objA = new ReferenceCountingGC();\n       ReferenceCountingGC objB = new ReferenceCountingGC();\n       objA.instance = objB;\n       objB.instance = objA;\n       objA = null;\n       objB = null;\n       // 假设在这行发生GC，objA和objB是否能被回收？\n       System.gc();\n    }\n}\n```\n\n对象objA和objB都有字段instance，赋值令`objA.instance = objB;`以及`objB.instance = objA;`，除此之外，这两个对象再无任何其他引用，实际上这两个对象已经不可能再被访问，但是因为它们互相引用着对方，导致它们的引用计数值都不为0，引用计数算法无法通知GC收集器回收它们。\n\n  * **可达性分析算法**\n  \n  这种算法的基本思路是通过一系列名为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，就证明此对象是不可用的。\n  \n  Java语言是通过可达性分析算法来判断对象是否存活的。\n  \n![](/assets/images/2015/09/03/jvm-gc/001.jpg)\n    \n在Java语言里，可作为**GC Roots的对象**包括下面几种：\n\n  * 虚拟机栈（栈帧中的本地变量表）中引用的对象。\n  * 方法区中的类静态属性引用的对象。\n  * 方法区中的常量引用的对象。\n  * 本地方法栈中JNI（Native方法）的引用对象。\n\n2. **正确理解引用：**\n\n无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。\n\n在JDK 1.2以前，Java中的引用的定义很传统：如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。这种定义很纯粹，但是太过狭隘，一个对象在这种定义下只有被引用或者没有被引用两种状态，对于如何描述一些“食之无味，弃之可惜”的对象就显得无能为力。\n\n我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存之中；如果内存空间在进行垃圾收集后还是非常紧张，则可以抛弃这些对象。很多系统的缓存功能都符合这样的应用场景。\n\n\n在JDK 1.2之后，Java对引用的概念进行了扩充，将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。\n\n  * **强引用**就是指在程序代码之中普遍存在的，类似`Object obj = new Object()`这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。\n  * **软引用**是用来描述一些**还有用但并非必需**的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK 1.2之后，提供了`SoftReference`类来实现软引用。\n  * **弱引用**也是用来描述**非必需**对象的，但是它的强度比软引用**更弱**一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK 1.2之后，提供了`WeakReference`类来实现弱引用。\n  * **虚引用**也称为幽灵引用或者幻影引用，它是**最弱**的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个**系统通知**。在JDK 1.2之后，提供了`PhantomReference`类来实现虚引用。\n\n3. **对象死亡的标记过程：**\n\n即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：\n\n  * 如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被**第一次标记**并且进行一次筛选，筛选的条件是此对象是否有必要执行`finalize()`方法。当对象没有覆盖`finalize()`方法，或者`finalize()`方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。\n    如果这个对象被判定为有必要执行`finalize()`方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在`finalize()`方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。\n  * `finalize()`方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行**第二次**小规模的标记，如果对象要在 `finalize()`中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。\n\n下面的代码演示了两点：\n\n1.对象可以在被GC时自我拯救。\n\n2.这种自救的机会只有一次，因为一个对象的finalize()方法最多只会被系统自动调用一次\n\n```java\npublic class FinalizeEscapeGC {\n    public static FinalizeEscapeGC SAVE_HOOK = null;\n    public void isAlive() {\n        System.out.println(\"yes, i am still alive :)\");\n    }\n    @Override\n    protected void finalize() throws Throwable {\n        super.finalize();\n        System.out.println(\"finalize mehtod executed!\");\n        FinalizeEscapeGC.SAVE_HOOK = this;\n    }\n    public static void main(String[] args) throws Throwable {\n        SAVE_HOOK = new FinalizeEscapeGC();\n        //对象第一次成功拯救自己\n        SAVE_HOOK = null;\n        System.gc();\n        // 因为Finalizer方法优先级很低，暂停0.5秒，以等待它\n        Thread.sleep(500);\n        if (SAVE_HOOK != null) {\n            SAVE_HOOK.isAlive();\n        } else {\n            System.out.println(\"no, i am dead :(\");\n        }\n        // 下面这段代码与上面的完全相同，但是这次自救却失败了\n        SAVE_HOOK = null;\n        System.gc();\n        // 因为Finalizer方法优先级很低，暂停0.5秒，以等待它\n        Thread.sleep(500);\n        if (SAVE_HOOK != null) {\n            SAVE_HOOK.isAlive();\n        } else {\n            System.out.println(\"no, i am dead :(\");\n        }\n    }\n}\n\nfinalize mehtod executed!\nyes, i am still alive :)    \nno, i am dead :(\n```\n\nPS ： `finalize()`的运行代价高昂，不确定性大，无法保证各个对象的调用顺序，应该尽量避免使用。\n\n4. **回收方法区：**\n\n很多人认为方法区（或者HotSpot虚拟机中的永久代）是没有垃圾收集的，Java虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区中进行垃圾收集的“性价比”一般比较低：在堆中，尤其是在新生代中，常规应用进行一次垃圾收集一般可以回收70%～95%的空间，而永久代的垃圾收集效率远低于此。\n\n  * **永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类。**\n\n  * 回收废弃常量与回收Java堆中的对象非常类似。\n\n  以常量池中字面量的回收为例，假如一个字符串“abc”已经进入了常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说，就是没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果这时发生内存回收，而且必要的话，这个“abc”常量就会被系统清理出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。\n  \n  * 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是“无用的类”：\n  * 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。\n  * 加载该类的ClassLoader已经被回收。\n  * 该类对应的java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样，不使用了就必然会回收。是否对类进行回收，需要虚拟机的参数进行控制。\n\n在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。\n\n### 三、垃圾收集算法 ( 如何回收？)\n\n由于垃圾收集算法的实现涉及大量的程序细节，而且各个平台的虚拟机操作内存的方法又各不相同，以下只是介绍几种算法的思想及其发展过程。\n\n1. **标记-清除算法：**\n\n最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。\n\n缺点：\n\n（1）效率问题，标记和清除两个过程的效率都不高；\n\n（2）空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。\n\n![](/assets/images/2015/09/03/jvm-gc/002.jpg)\n\n2. **复制算法：**\n\n\n为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。\n\n（1）优点：每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。\n\n（2）缺点：算法的代价是将内存缩小为了原来的一半，未免太高了一点。\n\n![](/assets/images/2015/09/03/jvm-gc/003.jpg)\n\n现在的商业虚拟机都采用这种收集算法来**回收新生代**，研究表明，新生代中的对象98%是“朝生夕死”的，所以并不需要按照1∶1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。\n\n当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8∶1，也就是每次新生代中可用内存空间为整个新生代容量的90%，只有10%的内存会被“浪费”。\n\n当然，90%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行**分配担保**（Handle Promotion）。\n\n3. **标记-整理算法：**\n\n\n复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。\n\n根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。\n\n![](/assets/images/2015/09/03/jvm-gc/004.jpg)\n\n4. **分代收集算法：**\n\n当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。\n\n（1）在**新生代**中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用**复制算法**，只需要付出少量存活对象的复制成本就可以完成收集。\n\n（2）在**老年代**中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用**\"标记—清理\"**或者**\"标记—整理\"**算法来进行回收。\n\n推荐阅读：《深入理解Java虚拟机：JVM高级特性与最佳实践》周志明著\n\n---\n\n* 原文链接：[深入理解JVM（4）: Java垃圾收集 （GC）](http://www.jianshu.com/p/424e12b3a08f)\n","tags":["GC"],"categories":["JVM"]},{"title":"深入理解JVM（3）: 虚拟机类加载机制","url":"%2F2015%2F2015-08-31-jvm-class-loading-mechanism%2F","content":"\n> 本文根据《深入理解java虚拟机》第7章内容整理\n\n### 一、基本概念\n\n虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。\n\n与那些在编译时需要进行链接工作的语言不同，在Java语言里，类型的加载、连接和初始化过程都是在程序运行期间完成的，这种策略虽然会令类加载时稍微增加一些性能开销，但是会为Java应用程序提供高度的灵活性，Java可以动态扩展的语言特性就是依赖运行期间动态加载和动态链接这个特点实现的。\n\n**类的生命周期：**\n\n类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载7个阶段。其中验证、准备、解析3个部分统称为连接。\n\n![](/assets/images/2015/08/31/jvm-class-loading-mechanism/001.jpg)\n\n这些阶段通常都是互相交叉地混合式进行的，通常会在一个阶段执行的过程中调用、激活另一个阶段。\n\n例如：加载阶段与连接阶段的部分内容（如一部分字节码的文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的内容，这两个阶段的开始时间仍然保持着固定的先后顺序。\n\n### 二、类加载的时机\n\nJava虚拟机规范没有强制性约束在什么时候开始类加载过程，但是对于初始化阶段，虚拟机规范则严格规定了有且只有5种情况必需立即对类进行“初始化”（而加载、验证、准备阶段自然需要在此之前开始）。\n\n1. 遇到`new`、`getstatic`、`putstatic`或`invokestatic`这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。\n\n    生成这4条指令最常见的Java代码场景是：使用new关键字实例化对象时、读取或者设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）时、以及调用一个类的静态方法的时候。\n\n2. 使用`java.lang.reflect`包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。\n\n3. 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。\n\n4. 当虚拟机启动时，用户需要指定一个要执行的主类（包含`main()`方法的那个类），虚拟机会先初始化这个类。\n\n5. 当使用JDK1.7的动态语言支持时，如果一个`java.lang.invoke.MethodHandle`实例最后的解析结果  `REF_getStatic`、`REF_putStatic`、`REF_invokeStatic`的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。\n\n对于这5种会触发类进行初始化的场景，在java虚拟机规范中限定了“有且只有”这5种场景会触发。\n\n这5种场景中的行为称为对一个类的**主动引用**，除此以外的所有引用类的方式都不会触发类的初始化，称为**被动引用**。\n\n**被动引用示例：**\n\n1.  通过子类引用父类的静态字段，不会导致子类初始化。\n\n```java\npublic class SuperClass {  \n    static{  \n        System.out.println(\"SuperClass init!\");  \n    }  \n    public static int value = 123;  \n    }  \n    public class SubClass extends SuperClass {  \n    static{  \n        System.out.println(\"SubClass init!\");  \n    }  \n    }  \n    public class NotInitialization {  \n    public static void main(String[] args) {  \n        System.out.println(SubClass.value);  \n    }  \n} \n\nSuperClass init!  \n123\n```\n\n对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。\n\n2. 通过数组定义来引用类，不会触发此类的初始化。\n\n```java\npublic class SuperClass {  \n    static{  \n        System.out.println(\"SuperClass init!\");  \n    }  \n    public static int value = 123;  \n    }  \n    public class NotInitialization {  \n    public static void main(String[] args) {  \n        SuperClass[] scs = new SuperClass[10];  \n    }  \n}\n\n输出结果为空\n```\n\n没有输出`SuperClass init！`说明没有触发类`com.zm.classloading.SuperClass`的初始化阶段，但是这段代码会触发`[Lcom.zm.classloading.SuperClass`类的初始化阶段。这个类是由虚拟机自动生成的，直接继承于`java.lang.Object`的子类，创建动作由字节码指令 `newarray`触发。\n\n3.  常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。\n\n```java\npublic class ConstClass {\n    static{\n        System.out.println(\"ConstClass init!\");\n    }\n    public static final String HELLOWORLD = \"hello world\";\n    }\n    public class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(ConstClass.HELLOWORLD);\n    }\n}\n\nhello world\n```\n\n 虽然在Java源码中引用了ConstClass类中的常量`HELLOWORLD`，但其实在编译阶段通过常量传播优化，已经将此常量的值`hello world`存储到了NotInitialization类的常量池中，以后NotInitialization对于常量`ConstClass.HELLOWORLD`的引用实际上都被转化为NotInitialization类对自身常量池的引用了。实际上NotInitialization的Class文件之中已经不存在ConstClass类的符号引用入口了。\n\n**接口的加载过程：**\n\n接口也有初始化过程，这与类是一致的，上述的代码中都是使用静态语句块`static{}`来输出初始化信息的，而接口中不能使用`static{}`语句块，但编译器仍然会为接口生成`&lt;clinit&gt;()`类构造器，用于初始化接口中所定义的成员变量。\n\n接口的加载过程与类加载的区别在于上面提到的5种“有且仅有”需要初始化场景中的第3种：当一个类在初始化时要求其父类全部都已经初始化过了，但是一个接口在初始化时，并不要求其父接口都全部完成了初始化，只有在真正用到父接口的时候（如引用父接口中定义的常量）才会初始化。\n\n### 三、类加载的过程\n\n下面我们来详细了解类加载的全过程，也就是加载、验证、准备、解析和初始化这五个阶段的过程。\n\n1. **加载**\n\n首先要说明的是“加载”（Loading）阶段只是“类加载”（Class Loading）过程的一个阶段。不要混淆了这两个概念。在加载阶段，虚拟机需要完成以下三件事情：\n\n1）通过一个类的全限定名来获取定义此类的二进制字节流。\n\n2）将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。\n\n3）在内存中生成一个代表这个类的`java.lang.Class`对象，作为方法区这个类各种数据的访问入口。\n\n相对于类加载过程的其他阶段，一个非数组类的加载阶段（准确的说，是加载阶段中获取类的二进制字节流的动作）是开发人员可控性最强的，因为该阶段既可以使用系统提供的引导类加载器完成，也可以由用户自定义的类加载器来完成，开发人员可以通过定义自己的类加载器去控制字节流的获取方式。\n\n对于数组类而言，数组类本身不通过类加载器创建，它是由虚拟机直接创建的。但是数组类的元数据类型最终还是要靠类加载器去创建的。\n\n加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，方法区中的数据存储格式由JVM自行定义。然后在内存中实例化一个`java.lang.Class`对象，这个对象将作为程序访问方法区中这些类型数据的外部接口。（对于HotSpot虚拟机而言，Class对象比较特殊，它虽然是对象，但是存放在方法区里面）\n\n2. **验证**\n\n验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。\n\n整体上看，验证阶段会完成下面4个阶段的检验动作：文件格式验证、元数据验证、字节码验证和符号引用验证。\n\n  * **1）文件格式验证**：这一阶段要验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。\n\n    * 是否以魔术0xCAFEBABE开头；\n    * 主次版本号是否是在当前虚拟机处理范围之内；\n    * 常量池的常量中是否有不被支持的常量类型（检查常量tag标志）；\n    . . .\n\n    第一阶段的主要目的是保证输入的字节流能正确地解析并存储于方法区之内，格式上符合一个Java类型信息的要求。\n  \n    这阶段的验证是基于二进制字节流进行的，只有通过了这个阶段的验证后，字节流才会进入内存的方法区中进行存储，所以后面的3个验证阶段全部是基于方法区的存储结构进行的，不会再直接操作字节流。\n   \n  * **2）元数据验证**：这一阶段主要是对字节码描述的信息进行**语义分析**，以保证其描述的信息符合Java语言规范的要求。\n\n    * 这个类是否有父类；\n    * 这个类的父类是否继承了不允许被继承的类（被final修饰的类）；\n    * 如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法；\n    * 类中的字段、方法是否与父类产生矛盾（如覆盖了父类的final字段，不符合规则的重载）；\n    . . .\n    \n    第二阶段的主要目的是对类的元数据信息进行语义校验，保证不存在不符合Java规范的元数据类型。\n    \n    * **3）字节码验证**：这一阶段是整个验证过程中最复杂的一个阶段，主要目的是通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。\n    \n    在第二阶段对元数据信息中的数据类型做完校验后，这阶段将对类的方法体进行校验分析。保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。\n\n    * 保证跳转指令不会跳转到方法体之外的字节码指令上；\n    * 保证方法体中的类型转换是有效的，例如将子类对象赋给父类对象是安全的，但是把父类对象赋值给子类数据类型，甚至是和它毫无继承关系的一个数据类型，则是危险和不安全的；\n    * 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作，例如不会出现在操作数栈中放置了一个int类型数据，使用时却按long类型来加载人本地变量表中。\n    . . .\n    \n    * **4）符号引用验证**：这一阶段主要是在虚拟机将符号引用转化为直接引用的时候进行校验，这个转化动作是发生在解析阶段。符号引用可以看做是对类自身以外（常量池的各种符号引用）的信息进行匹配性的校验。\n\n    * 符号引用中通过字符串描述的全限定名是否能找到相应的类；\n    * 在指定类中是否存在符合方法的字段描述符以及简单名称所描述方法和字段；\n    * 符号引用中的类、字段、方法的访问性（`private、public、protected、default`）是否可以被当前类访问；\n    . . .\n    \n    符号引用验证的目的是确保解析动作能正常执行，如果无法通过符号引用验证，那么将会抛出异常。\n    \n    验证阶段对于虚拟机的类加载机制来说，是一个非常重要但不一定是必要的阶段。如果所运行的全部代码都已经被反复使用和验证过，在实施阶段就可以考虑使用`-Xverify:none`参数来关闭大部分的类验证措施，从而缩短虚拟机类加载的时间。\n    \n3. **准备**\n\n准备阶段是正式为**类变量**分配内存并设置**类变量初始值**的阶段，这些内存都将在方法区中进行分配。\n\n   * 这个时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起被分配在Java堆中。\n   * 这里所说的初始值“通常情况”下是数据类型的零值，例如`public static int value = 123` ；value在准备阶段后的初始值是0而不是123，因为此时尚未执行任何的Java方法，而把value赋值为123的putStatic指令是程序被编译后，存放在类构造器&lt;clinit&gt;()方法之中，把value赋值为123的动作将在初始化阶段才会执行。\n   * 通常情况下初始值为零值，相对的会存在特殊情况：如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量就会被初始化为ConstantValue属性所指定的值，例如`public static final int value = 123`  编译时javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将变量赋值为123。\n\n4. **解析**\n\n解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。\n\n在Class文件中符号引用以`CONSTANT_Class_info`、`CONSTANT_Fieldref_info`、`CONSTANT_Methodref_info`等类型的常量出现。\n\n   * **符号引用**（Symbolic Reference）：\n   \n   符号引用以一组符号来描述所引用的目标，符号引用可以是任何形式的字面量，只要使用时能无歧义的定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载在内存中。各种虚拟机实现的内存布局可以各不相同，但是他们能接受的符号引用必须都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。\n    \n   * **直接引用**（Direct Reference）：\n   直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现的内存布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般都不相同，如果有了直接引用，那引用的目标必定已经在内存中存在。\n\n\n对于同一个符号引用可能会出现多次解析请求，虚拟机可能会对第一次解析的结果进行缓存。\n\n解析动作主要针对：类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。\n\n个人理解：一个java类将会编译成一个class文件。在编译时，java类并不知道引用类的实际内存地址，因此只能使用符号引用来代替。比如org.simple.People类引用org.simple.Tool类，在编译时People类并不知道Tool类的实际内存地址，因此只能使用符号org.simple.Tool(假设)来表示Tool类的地址。而在类加载器加载People类时，此时可以通过虚拟机获取Tool类的实际内存地址，因此便可以既将符号org.simple.Tool替换为Tool类的实际内存地址，及直接引用地址。\n\n5. **初始化**\n\n类初始化阶段是类加载过程的最后一步，前面的类加载过程中，除了加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码。\n\n初始化阶段是执行类构造器`&lt;clinit&gt;()`方法的过程。对于`&lt;clinit&gt;()`方法具体介绍如下：\n\n   * **(1)**`&lt;clinit&gt;()`方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（`static{}`块）中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序所决定。\n    静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，**在前面的静态语句块可以赋值，但是不能访问**。\n\n```java\npublic class Test {\n    static{\n        i =0;  //给变量赋值可以正常编译通过\n        //  System.out.println(i);  //这句编译器会提示“非法向前引用”\n    }\n    static int i = 1;\n}\n```\n\n   * **(2)**`&lt;clinit&gt;()`方法与类的构造函数不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的`&lt;clinit&gt;()`方法执行之前，父类的`&lt;clinit&gt;()`方法已经执行完毕，因此在虚拟机中第一个执行的`&lt;clinit&gt;()`方法的类一定是`java.lang.Object`。\n   * **(3)** 由于父类的`&lt;clinit&gt;()`方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作。如下面的例子所示，输出结果为2而不是1。\n\n```java\npublic class Parent {  \n    public static int A = 1;  \n    static{  \n       A = 2;  \n    }  \n    }    \n    public class Sub extends Parent{  \n    public static int B = A;  \n    }   \n    public class Test {  \n    public static void main(String[] args) {  \n       System.out.println(Sub.B);  \n    }  \n}\n```\n\n   * **(4)** `&lt;clinit&gt;()`方法对于类或者接口来说并不是必需的，如果一个类中没有静态语句块也没有对变量的赋值操作，那么编译器可以不为这个类生成`&lt;clinit&gt;()`方法。\n   * **(5)** 接口中不能使用静态语句块，但仍然有变量赋值的初始化操作，因此接口也会生成`&lt;clinit&gt;()`方法。但是接口与类不同，执行接口的`&lt;clinit&gt;()`方法不需要先执行父接口的`&lt;clinit&gt;()`方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也不会执行接口的`&lt;clinit&gt;()`方法。\n   * **(6)** 虚拟机会保证一个类的`&lt;clinit&gt;()`方法在多线程环境中被正确地加锁和同步。如果有多个线程去同时初始化一个类，那么只会有一个线程去执行这个类的`&lt;clinit&gt;()`方法，其它线程都需要阻塞等待，直到活动线程执行`&lt;clinit&gt;()`方法完毕。如果在一个类的`&lt;clinit&gt;()`方法中有耗时很长的操作，那么就可能造成多个进程阻塞。\n\n### 总结\n\n虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。\n\n---\n\n* 原文链接：[深入理解JVM（3）: 虚拟机类加载机制](http://www.jianshu.com/p/a9d8c1a37b8c)\n","tags":["Classloader"],"categories":["JVM"]},{"title":"深入理解JVM（2）: Java堆中对象创建、布局、访问全过程","url":"%2F2015%2F2015-08-30-jvm-object-creation-data-access%2F","content":"\n### 一、对象的创建\n\n`new Animal();`\n\n1. **类加载检查：**\n\n检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类的加载过程。\n\n2. **为对象分配内存**\n\n对象所需内存的大小在类加载完成后便完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。\n\n2.1 根据Java堆中是否规整有两种**内存的分配方式**：（Java堆是否规整由所采用的垃圾收集器是否带有压缩整理功能决定）\n\n  * **指针碰撞(Bump the pointer)**:\n  Java堆中的内存是规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，分配内存也就是把指针向空闲空间那边移动一段与内存大小相等的距离。例如：Serial、ParNew等收集器。\n\n  * **空闲列表(Free List)**:\n  Java堆中的内存不是规整的，已使用的内存和空闲的内存相互交错，就没有办法简单的进行指针碰撞了。虚拟机必须维护一张列表，记录哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录。例如：CMS这种基于Mark-Sweep算法的收集器。\n\n2.2 分配内存时解决**并发问题**的两种方案：\n\n对象创建在虚拟机中时非常频繁的行为，即使是仅仅修改一个指针指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。\n\n  * 对分配内存空间的动作进行**同步处理**---实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性；\n  * 把内存分配的动作按照线程划分为在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲(**TLAB**)。哪个线程要分配内存，就在哪个线程的TLAB上分配。只有TLAB用完并分配新的TLAB时，才需要同步锁定。\n\n3. **内存空间初始化**\n\n虚拟机将分配到的内存空间都初始化为零值（不包括对象头）,如果使用了TLAB，这一工作过程也可以提前至TLAB分配时进行。\n\n内存空间初始化保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。\n\n4. **对象设置**\n\n虚拟机对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头之中。\n\n5. **&lt;init&gt;**\n\n在上面的工作都完成之后，从虚拟机的角度看，一个新的对象已经产生了。\n但是从Java程序的角度看，对象的创建才刚刚开始&lt;init&gt;方法还没有执行，所有的字段都还是零。\n\n所以，一般来说（由字节码中是否跟随invokespecial指令所决定），执行new指令之后会接着执行&lt;init&gt;方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算产生出来。\n\n### 二、对象的内存布局\n\n在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头(Header)、实例数据(Instance Data)和对齐填充(Padding)。\n\n1. **对象头：**\n\nHotSpot虚拟机的对象头包括两部分信息。\n\n1.1 第一部分用于存储**对象自身**的**运行时数据**，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。\n\n![](/assets/images/2015/08/30/jvm-object-creation-data-access/001.png)\n\n1.2 另外一个部分是**类型指针**，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。\n\n如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中无法确定数组的大小。(并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据并不一定要经过对象本身，可参考 三对象的访问定位)\n\n2. **实例数据：**\n\n实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类中继承下来的，还是在子类中定义的，都需要记录下来。\n\nHotSpot虚拟机默认的分配策略为longs/doubles、ints、shorts/chars、bytes/booleans、oop，从分配策略中可以看出，相同宽度的字段总是分配到一起。\n\n3. **对齐填充：**\n\n对齐填充并不是必然存在的，也没有特定的含义，仅仅起着占位符的作用。\n\n由于HotSpot虚拟机的自动内存管理系统要求对象的起始地址必须是8字节的整数倍，也就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或者2倍），因此，当对象实例数据部分没有对齐的时候，就需要通过对齐填充来补全。\n\n#### 三、对象的访问定位\n\n建立对象是为了使用对象，我们的Java程序需要通过栈上的引用数据来操作堆上的具体对象。\n对象的访问方式取决于虚拟机实现，目前主流的访问方式有使用句柄和直接指针两种。\n\n1. **使用句柄：**\n\n如果使用句柄的话，那么Java堆中将会划分出一块内存来作为句柄池，引用中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。\n\n![](/assets/images/2015/08/30/jvm-object-creation-data-access/002.jpg)\n\n优势：引用中存储的是稳定的句柄地址，在对象被移动(垃圾收集时移动对象是非常普遍的行为)时只会改变句柄中的实例数据指针，而引用本身不需要修改。\n\n2. **直接指针：**\n\n如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而引用中存储的直接就是对象地址。\n\n![](/assets/images/2015/08/30/jvm-object-creation-data-access/003.jpg)\n\n优势：速度更快，节省了一次指针定位的时间开销。由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是非常可观的执行成本。（例如HotSpot）\n\n---\n\n* 原文链接：[深入理解JVM（2）: Java堆中对象创建、布局、访问全过程](http://www.jianshu.com/p/ac162726d7de)\n","tags":["Object"],"categories":["JVM"]},{"title":"深入理解JVM（1）: Java内存区域划分","url":"%2F2015%2F2015-08-29-jvm-memory-partition%2F","content":"\n### 介绍\n\nJava虚拟机在运行时Java程序的过程中会把它管理的内存划分为若干个不同的数据区域。\n\n![](/assets/images/2015/08/29/jvm-memory-partition/001.jpg)\n\n### 一、程序计数器\n\n1. 程序计数器可以看做是当前线程所执行的字节码的行号指示器。在JVM的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。\n\n2. 由于JVM的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，为了在线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，独立存储，互不影响。所以，程序计数器是**线程私有**的内存区域。\n\n3. 如果线程执行的是一个Java方法，计数器记录的是正在执行的虚拟机字节码指令的地址；\n 如果线程执行的是一个Native方法，计数器的值为空。\n\n4. Java虚拟机规范中唯一一个**没有规定任何OutOfMemoryError情况**的区域。\n\n### 二、Java虚拟机栈\n\n1. Java虚拟机栈描述的是Java**方法执行**的内存模型：每个方法执行的同时会创建一个**栈帧**，栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。\n\n![](/assets/images/2015/08/29/jvm-memory-partition/002.png)\n\n2. Java虚拟机栈是**线程私有**的，它的生命周期与线程相同。\n\n3. 程序员主要关注的**stack栈内存**，就是虚拟机栈中**局部变量表**部分。\n局部变量表存放了编译时期可知的各种**基本数据类型**和**对象引用**。\n局部变量表所需的内存空间在编译时期完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。\n\n4. Java虚拟机规范对这个区域规定了两种异常情况：\n\n  * 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出`StackOverflowError` 异常；\n  * 如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出`OutOfMemoryError`异常；（当前大部分JVM都可以动态扩展，只不过JVM规范也允许固定长度的虚拟机栈）\n\n### 三、本地方法栈\n\n1. 本地方法栈与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法服务（也就是字节码），而本地方法栈为虚拟机使用到的Native方法服务。\n\n2. Java虚拟机规范对本地方法栈使用的语言、使用方法与数据结构并没有强制规定，因此可以由虚拟机自由实现。例如：HotSpot虚拟机直接将本地方法栈和虚拟机栈合二为一。\n\n3. 同虚拟机栈相同，Java虚拟机规范对这个区域也规定了两种异常情况`StackOverflowError` 和 `OutOfMemoryError`异常。\n\n### 四、Java堆\n\n1. Java堆是被所有的**线程共享**的一块内存区域，在虚拟机启动时创建。\n   Java堆的唯一目的就是存放对象实例，**几乎所有**的**对象实例**都在这里分配内存。\n\n2. Java堆是垃圾回收器管理的主要区域，因此也被称为**\"GC堆\"**。\n   从内存回收的角度看，由于现在收集器基本都采用分代收集算法，所以Java堆可以细分为：新生代、老生代；\n   从内存分配的角度看，线程共享的Java堆可能划分出多个线程私有的分配缓冲区（TLAB）；\n   不论如何划分，都与存放的内容无关，无论哪个区域，存储的仍然是对象实例。\n\n3. Java虚拟机规范规定，Java堆可以处于**物理上不连续**的内存空间中，只要**逻辑上是连续**的即可，就像我们的磁盘空间一样。在实现上，既可以是固定大小的，也可以是可扩展的，不过当前主流JVM都是按照可扩展来实现的。\n\n4. Java虚拟机规范规定，如果在堆上没有内存完成实例分配，并且堆上也无法再扩展时，将会抛出`OutOfMemoryError`异常。\n\n5. **内存泄露和内存溢出**\n\nJava堆内存的OOM异常是非常常见的异常情况，重点是根据内存中的对象是否是必要的，来弄清楚到底是出现了内存泄露(Memory Leak)还是内存溢出(Memory Overflow).\n\n  * 内存泄露：指程序中一些对象不会被GC所回收，它始终占用内存，即**被分配的对象引用链可达但已无用**。（可用内存减少）\n  * 内存溢出：程序运行过程中**无法申请到足够的内存**而导致的一种错误。内存溢出通常发生于OLD段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况。\n\n内存泄露是内存溢出的一种诱因，不是唯一因素。\n\n### 五、方法区\n\n1. 方法区也是被所有的**线程共享**的一块内存区域。它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n\n2. Java虚拟机规范对方法区的限制非常宽松，除了和Java堆一样 不需要连续的内存和可以选择固定大小或者可扩展之外，还可以选择不实现垃圾回收。\n\n这区域的内存回收目标主要是针对常量池的回收和类型的卸载，一般而言，这个区域的内存回收比较难以令人满意，尤其是类型的回收，条件相当苛刻，但是这部分区域的内存回收确实是必要的。\n\n3. Java虚拟机规范规定，当方法区无法满足内存分配的需求时，\n将抛出`OutOfMemoryError`异常。\n\n4. **运行时常量池**\n\n运行时常量池是方法区的一部分。CLass文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。\n\n运行时常量池相对于CLass文件常量池的另外一个重要特征是**具备动态性**，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入CLass文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用比较多的就是**String类的intern()**方法。\n\n5. **String.intern()**\n\n`String.intern()`是一个Native方法，它的作用是：如果字符串常量池中已经包含了一个等于此String对象的字符串，则返回代表池中这个字符串的String对象；否则，将此String对象包含的字符串添加到常量池中，并且返回此字符串的引用。\n\n```\npublic static void main(String[] args) {\n    String str1 = new StringBuilder(\"计算机\").append(\"软件\").toString();\n    System.out.println(str1.intern() == str1);\n    String str2 = new StringBuilder(\"ja\").append(\"va\").toString();\n    System.out.println(str2.intern() == str2);\n}\n```\n\n这段代码在JDK1.6中运行，会得到两个false，而在JDK1.7中运行，会得到一个true和一个false。原因是：\n\n* 在JDK1.6中`intern()`方法会把首次遇到的字符串实例复制到永久代中，返回的也是永久代中这个字符串实例的引用，而由StringBuilder创建的字符串实例在Java堆上，所以必然不是一个引用。\n* 在JDK1.7中`intern()`方法不会复制实例，只是在常量池中记录首次出现的实例引用，因此`intern()`返回的引用和由StringBuilder创建的字符串实例是同一个。\n* str2返回false是因为Java这个字符串在执行`StringBuilder(\"ja\").append(\"va\").toString()`之前已经出现过，字符串常量池中已经有它的引用了，不符合首次出现的原则，而`\"计算机软件\"`这个字符串是首次出现的。\n\n**推荐阅读**：《深入理解Java虚拟机》周志明著\n\n---\n\n* 原文链接：[深入理解JVM（1）: Java内存区域划分](http://www.jianshu.com/p/7ebbe102c1ae)\n","tags":["JVM"],"categories":["JVM"]},{"title":"日志：每个软件工程师都应该知道的有关实时数据的统一抽象","url":"%2F2015%2F2015-08-21-log-what-every-software-engineer-should-know-about-real-time-datas-unifying%2F","content":"\n我在六年前加入到`LinkedIn`公司，那是一个令人兴奋的时刻：我们刚开始面临单一庞大的集中式数据库的限制问题，需要过渡到一套专门的分布式系统。\n这是一个令人兴奋的经历：我们构建、部署和运行分布式图数据库（`distributed graph database`）、分布式搜索后端（`distributed search backend`）、\n`Hadoop`以及第一代和第二代键值数据存储（`key-value store`），而且这套系统一直运行至今。\n\n这个过程中，我学到的最有益的事情是我们所构建这套系统的许多组件其核心都包含了一个很简单的概念：日志。\n日志有时会叫成 预先写入日志（`write-ahead logs`）、提交日志（`commit logs`）或者事务日志（`transaction logs`），几乎和计算机本身形影不离，\n是许多分布式数据系统（`distributed data system`）和实时应用架构（`real-time application architecture`）的核心。\n\n不懂得日志，你就不可能真正理解数据库、`NoSQL`存储、键值存储（`key value store`）、数据复制（`replication`）、`paxos`、`Hadoop`、版本控制（`version control`），甚至几乎任何一个软件系统；然而大多数软件工程师对日志并不熟悉。我有意于改变这个现状。\n本文我将带你浏览有关日志需要了解的一切，包括日志是什么，如何在数据集成（`data integration`）、实时处理（`real time processing`）和系统构建中使用日志。\n\n目录\n-----------------\n\n- 译序\n- 概述（日志每个软件工程师都应该知道的有关实时数据的统一抽象）\n- 第一部分：日志是什么？\n    1. 数据库中的日志\n    1. 分布式系统中的日志\n    1. 变更日志（`changelog`）101：表与事件的二象性（`duality`）\n    1. 接下来的内容\n- 第二部分：数据集成\n    1. 数据集成：两个难题\n        - 事件数据管道\n        - 专用数据系统（`specialized data systems`）的爆发\n    1. 日志结构化的（`log-structured`）数据流\n    1. 在`LinkedIn`\n    1. `ETL`与数据仓库的关系\n    1. 日志文件与事件\n    1. 构建可伸缩的日志\n- 第三部分：日志与实时流处理\n    1. 数据流图（`data flow graphs`）\n    1. 有状态的实时流处理\n    1. 日志合并（`log compaction`）\n- 第四部分：系统构建（`system building`）\n    1. 分解单品方式而不是打包套餐方式（`Unbundling`）？\n    1. 日志在系统架构中的地位\n- 结束语及参考资料\n    1. 学术论文、系统、讨论和博客\n    1. 一些相关的开源软件\n- 译跋\n\n说明\n-----------------\n\n这篇文章是`LinkedIn`的`Kreps`发表的一篇博文，虽然很长，但被称为[程序员史诗般必读文章](http://bryanpendleton.blogspot.hk/2014/01/the-log-epic-software-engineering.html)。\n\n[学习笔记：The Log（我所读过的最好的一篇分布式技术文章）](http://www.cnblogs.com/foreach-break/p/notes_about_distributed_system_and_The_log.html)对本文做了很赞的摘要和解读。\n\n但作为一篇 **经典** 文章，还是值得去完整地研读和理解：\n\n1. 原文可以作为大数据/分布式系统领域一份导论式的资料。   \n    作者对整个领域的理解和实战精深广博，抓出并梳理了这个领域的核心：日志。\n2. 原文作为一手资料，有完整的分析过程，能够深入和核对自己的理解。\n3. 摘要和解读不能替代自己理解。  \n    信息被传递和过滤得越多，丢失和偏差也就越多。\n\n---\n\n* 原文链接：[The Log: What every software engineer should know about real-time data's unifying abstraction](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying) - [Jay Kreps](http://www.linkedin.com/in/jaykreps)\n* 开源中国译文：[日志：每个软件工程师都应该知道的有关实时数据的统一概念](http://www.oschina.net/translate/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)\n* 伯乐在线译文：[The Log：每个程序员都应该知道有关实时数据的统一抽象](http://blog.jobbole.com/89674/) - [李鼎(哲良)](http://oldratlee.com/)\n","tags":["Log"],"categories":["Log"]},{"title":"远程通信（RPC，Webservice，RMI，JMS、EJB、JNDI的区别）对比","url":"%2F2015%2F2015-06-27-distributed-communication-rpc-webservice-rmi-jms-ejb-jndi%2F","content":"\n## 说明\n\n总结这些概念都是易混淆，最基本概念定义复习和深入理解，同时也是架构师必备课程。\n\n### RPC（Remote Procedure Call Protocol）\n\nRPC使用C/S方式，采用http协议,发送请求到服务器，等待服务器返回结果。这个请求包括一个参数集和一个文本集，通常形成“classname.methodname”形式。优点是跨语言跨平台，C端、S端有更大的独立性，缺点是不支持对象，不支持异步调用，无法在编译器检查错误，只能在运行期检查。\n\n### Web Service\n\nWeb Service提供的服务是基于web容器的，底层使用http协议，类似一个远程的服务提供者，比如天气预报服务，对各地客户端提供天气预报，是一种请求应答的机制，是跨系统跨平台的。就是通过一个servlet，提供服务出去。\n\n首先客户端从服务器的到WebService的WSDL，同时在客户端声称一个代理类(Proxy Class)这个代理类负责与WebService服务器进行Request和Response当一个数据（XML格式的）被封装成SOAP格式的数据流发送到服务器端的时候，就会生成一个进程对象并且把接收到这个Request的SOAP包进行解析，然后对事物进行处理，处理结束以后再对这个计算结果进行SOAP包装，然后把这个包作为一个Response发送给客户端的代理类(Proxy Class)，同样地，这个代理类也对这个SOAP包进行解析处理，继而进行后续操作。这就是WebService的一个运行过程。\n\nWeb Service大体上分为5个层次:\n\n1. Http传输信道\n2. XML的数据格式\n3. SOAP封装格式\n4. WSDL的描述方式\n5. UDDI UDDI是一种目录服务，企业可以使用它对Webservices进行注册和搜索\n\n### RMI（Remote Method Invocation）\n\n![](/assets/images/2015/06/27/distributed-communication-rpc-webservice-rmi-jms-ejb-jndi/001.png)\n\nRMI采用stubs和skeletons来进行远程对象(remote object)的通讯。stub充当远程对象的客户端代理，有着和远程对象相同的远程接口，远程对象的调用实际是通过调用该对象的客户端代理对象stub来完成的，通过该机制RMI就好比它是本地工作，采用tcp/ip协议，客户端直接调用服务端上的一些方法。优点是强类型，编译期可检查错误，缺点是只能基于Java语言，客户机与服务器紧耦合；\n\nJRMP是Java持有的，基于流的协议，完成一个对象的Java到Java的远程调用；IIOP是CORBA对象请求代理之间交流的协议，Java中使得程序可以和其他语言的CORBA实现互操作性的协议，和JRMP互补。\n\t优点：支持分布式对象、跨平台，stubs/skeletons机制；缺点：不能跨语言。\n\n### JMS（Java Messaging Service）\n\nJMS是Java的消息服务，JMS的客户端之间可以通过JMS服务进行异步的消息传输。JMS支持两种消息模型：Point-to-Point（P2P）和Publish/Subscribe（Pub/Sub），即点对点和发布订阅模型。\n\t优点：支持异步通信、消息produce和recept松耦合。\n\n### EJB(enterprise java bean)\n\nejb是JavaEE中的一个规范，该规范描述了分布式应用程序需要解决的问题，例如事务处理、安全、日志、分布式等，而同时呢，sun公司也实现了自己定义的这一个标准，相当于自己颁布一个标准然后，又给出了实现供别人使用，实现以很多API的方式提供给用的人。\n\nejb是按照java服务器接口定义的java类，可以理解为一个特殊的java类，放在容器里容器可以帮助该类管理事务、分布式、安全等，一般小的程序不会用到，只有大型分布式系统才会用到ejb，既然ejb是一个java类或是一个组件，颗粒较小，这也是与Webservice的区别之一，下面会说到，它就可以被其它一个或多个模块调用。包含了三种类型的Bean，可以通过注释JPA一个规范来标记,其中有一种Bean，叫MDB消息驱动bean，它的通信机制涉及到了JMS协议。\n\nejb可以进行远程调用，但是不能够跨语言，ejb是同步调用，而平时我们说的的ejb异步调用指的是ejb的MDB异步通信。\n\n### JNDI（Java naming and Directory Interface）\n\nJava命名与目录接口，包含两个服务，命名服务奖名称和对象联系起来，使得我们可以用名称访问对象，目录服务是一种命名服务，在这种服务里，对象不但有名称，还有属性。\n\n使用JNDI，一个J2EE应用程序可以存储和动态获取任何类型的命名Java对象。因为JNDI不依赖于任何特定的执行，应用程序可以使用JNDI访问各种命名目录服务，包括现有的诸如LDAP、NDS、DNS、NIS、COS命名和RMI注册等服务。这使得J2EE应用程序可以和传统的应用程序和系统共存。\n\n![](/assets/images/2015/06/27/distributed-communication-rpc-webservice-rmi-jms-ejb-jndi/002.png)\n\n从JNDI的架构中可以看出，JNDI分为三部分，应用程序编程接口（API）和服务供应商接口（SPI），前者Java应用程序访问各种命名和目录服务，开发上层应用的程序员就不必去关心底层具体的技术细节，后者则是设计来供任意一种服务的供应商（也包括目录服务供应商）使用，这一层一般由供应商去完成。\n\n## 对比学习\n\n### EJB与JMS的关系\n\n它们其实是没有多大关系的，它们都是JavaEE的规范，ejb的一种类MDB实现了JMS规范，当然是先JMS规范的不止有ejb的mdb，比如apache ActiveMQ也是\n\n### Web service与EJB\n\n对这两个常常有点迷惑人，因为他们都实现了分布式应用调用，虽然他们很相似但是还是有很多区别的，首先通信协议是不一样的，ejb采用rmi-iiop协议，Web service利用http协议传输数据，优点常识的都知道http协议支持的较广泛，从这点来看Web Service层次要高一些、俗话说站得高看得远。\n\nWebservice主要关注于解决异构系统、不同语言系统通信，其关注的是分布式服务开发、着手点要高、站的角度高，而ejb可以看做是分布式编程平台，通过容器和组件，简化了程序开发、调试和部署等它关注的是分布式组件开发，粒度小。\n\nWeb service可以看做是异构系统、异构语言系统间通信的一个标准，而ejb只属于J2EE规范的一部分。ejb底层用rmi-iiop协议进行通信，防火墙会阻止；web service是基于http协议进行通信，防火墙不会阻止。\n\n## 几者的区别与联系\n\n### RPC与RMI\n\n（1）RPC跨语言，而RMI只支持Java。\n\n（2）RMI调用远程对象方法，允许方法返回Java对象以及基本数据类型，而RPC不支持对象的概念，传送到RPC服务的消息由外部数据表示(External Data Representation,XDR)语言表示，这种语言抽象了字节序类和数据类型结构之间的差异。只有由XDR定义的数据类型才能被传递，可以说RMI是面向对象方式的Java RPC。\n\n（3）在方法调用上，RMI中，远程接口使每个远程方法都具有方法签名。如果一个方法在服务器上执行，但是没有相匹配的签名被添加到这个远程接口上，那么这个新方法就不能被RMI客户方所调用。在RPC中，当一个请求到达RPC服务器时，这个请求就包含了一个参数集和一个文本值，通常形成“classname.methodname”的形式。这就向RPC服务器表明，被请求的方法在为“classname”的类中，名叫“methodname”。然后RPC服务器就去搜索与之相匹配的类和方法，并把它作为那种方法参数类型的输入。这里的参数类型是与RPC请求中的类型是匹配的。一旦匹配成功，这个方法就被调用了，其结果被编码后返回客户方。\n\n### JMS和RMI\n\n采用JMS服务，对象是在物理上被异步从网络的某个JVM上直接移动到另一个JVM上（是消息通知机制）而RMI对象是绑定在本地JVM中，只有函数参数和返回值是通过网络传送的（是请求应答机制）。\n\nRMI一般都是同步的，也就是说，当client调用Server的一个方法的时候，需要等到对方的返回，才能继续执行client端，这个过程调用本地方法感觉上是一样的，这也是RMI的一个特点。\n\nJMS一般只是一个点发出一个Message到MessageServer,发出之后一般不会关心谁用了这个message。所以，一般RMI的应用是紧耦合，JMS的应用相对来说是松散耦合应用。\n\n# Webservice与JMS\n\nWebservice专注于远程服务调用，jms专注于信息交换。\n\n大多数情况下Webservice是两系统间的直接交互（Consumer<-->Producer），而大多数情况下jms是三方系统交互（Consumer<-Broker->Producer）。当然，JMS也可以实现request-response模式的通信，只要Consumer或Producer其中一方兼任broker即可。\n\nJMS可以做到异步调用完全隔离了客户端和服务提供者，能够抵御流量洪峰；WebService服务通常为同步调用，需要有复杂的对象转换，相比SOAP，现在JSON，rest都是很好的http架构方案；（举一个例子，电子商务的分布式系统中，有支付系统和业务系统，支付系统负责用户付款，在用户在银行付款后需要通知各个业务系统，那么这个时候，既可以用同步也可以用异步，使用异步的好处就能抵御网站暂时的流量高峰，或者能应对慢消费者。）\n\nJMS是java平台上的消息规范。一般jms消息不是一个xml，而是一个java对象，很明显，jms没考虑异构系统，说白了，JMS就没考虑非java的东西。但是好在现在大多数的jms provider（就是JMS的各种实现产品）都解决了异构问题。相比WebService的跨平台各有千秋吧。\n\n### RMI与JNDI\n\nRMI是一个能够建立一个N层应用，扩展中间层，将属于不同应用的分布对象包容起来，使用跨过中间层来共享数据和逻辑，能真正实现分布式的解决方案。通过它能够在运行时，通过网络发现不同机器的服务程序，并对应用间的通信进行管理，能确保像本地一样使用远程对象。在RMI中使用rmiregistry时存在一定的问题，rmiregistry只是用作测试基于RMI的应用程序的一种方法，当停止并重新启动rmiregistry时，需要中心注册其中的所有对象，针对这种情况，一般会使用JNDI为远程对象使用一个命名和目录服务，使用LDAP来保存远程对象。RMI只是一种远程对象访问的接口规范，遵循此规范的对象可被远程访问，但是要使用rmi的服务注册程序注册之后才能够被远程调用。JNDi是Java命名和目录服务访问接口，通过JNDI，可以访问已经在命名和目录服务器中注册的服务对象，因此，可以把rmi对象注册在Ldap命名目录服务器中，然后使用JNDI对远程对象进行访问和调用。\n\n各个对象都有侧重点，作为架构师（技术选型）、性能优化都需要基本知识给予强大的理论支持，各有千秋，充分结合项目的实际情况做出选择。\n\n---\n\n* 原文链接：[远程通信（RPC，Webservice，RMI，JMS、EJB、JNDI的区别）对比](http://blog.csdn.net/lishehe/article/details/46654499)\n","tags":["Communication"],"categories":["Communication"]},{"title":"Debugging an Apache Storm topology","url":"%2F2015%2F2015-05-27-debugging-an-apache-storm-topology%2F","content":" \n# Short Description:\n\nIn this article we'll cover a number debugging and monitoring  features introduced in Apache Storm 1.0.\n\n# Article\n\nApache Storm is a distributed real-time computation system for processing large volumes of high-velocity data. Debugging a distributed system is inherently hard since there are many moving parts spread across a large number of hosts in a cluster. Tracing failures to a particular component or a host in the system is hard and requires one to collect and analyze a lot of logs and debug/trace processes running in the distributed cluster.\n\nIn the past the support for debugging topologies in an Apache storm cluster was very minimal. Users would have to first turn on debug logs, restart the workers, redeploy the topologies and then collect logs from different worker nodes and analyze them. If they wanted to take a jstack dump or profile the workers, they would have to login to the worker hosts and run the commands manually which was painful. If one wanted to inspect the tuples flowing through the topology pipeline, they would have to add special “debug” bolts to log the tuples to some log and then remove the debug bolts from the topology before putting it back into production.\n\nIn this article we will go through the new features added in Apache Storm 1.0 that makes the various aspects of debugging a storm topology much easier and user friendly.\n\n## 1. Dynamic Log Levels\n\nStorm allows users and administrators to dynamically change the log level settings of a running topology both from the Storm UI and the command line. None of the Storm processes need to be restarted for the settings to take effect. Users can also specify an optional timeout after which those changes will be automatically reverted. The resulting log files are also easily searchable from the Storm UI and logviewer service.\n\nThe log level settings apply the same way as you'd expect from log4j. If you set the log level of a parent logger, the child loggers start using that level (unless the children have a more restrictive level already).\n\n### 1.1. Enabling via Storm UI\n\nIn order to set a level, click on a running topology and then click on “Change Log Level” in the Topology Actions section.\n\n![](/assets/images/2015/05/27/debugging-an-apache-storm-topology/001.png)\n\nFigure 1: Changing the log levels of a topology.\n\nNext, provide the logger name, select the level you want (e.g. WARN), and a timeout in seconds (or 0 if not needed). Then click on “Add”.\n\nIn the example above (Figure 1), while running a storm starter topology, the root logger is set to ERROR and storm.starter is set to DEBUG. That way one can look more specifically into the debug logs from the “storm.starter” packages while the other logs are suppressed.\n\nTo clear the log level click on the “Clear” button. This reverts the log level back to what it was before you added the setting. The log level line will disappear from the UI.\n\n![](/assets/images/2015/05/27/debugging-an-apache-storm-topology/002.png)\n\nFigure 2: Clearing the dynamic log levels.\n\n### 1.2. Using the CLI\n\nLog level can be set via the command line as follows,\n\n```\n./bin/storm set_log_level [topology name]-l [logger name]=[LEVEL]:[TIMEOUT]\n```\n\nFor example: \n\n```\n./bin/storm set_log_level my_topology -l ROOT=DEBUG:30Sets the ROOT logger to DEBUG for 30 seconds.\n\n./bin/storm set_log_level my_topology -r ROOT\n```\n\nClears the ROOT logger dynamic log level, resetting it to its original value.\n\nSee JIRA [STORM-412](https://issues.apache.org/jira/browse/STORM-412) for more details.\n\n## 2. Topology Event logging\n\nTopology event inspector provides the ability to view the tuples as they flow through different stages in a storm topology. This could be useful for inspecting the tuples emitted from a spout or a bolt in the topology pipeline while the topology is running, without stopping or redeploying the topology. The normal flow of tuples from the spouts to the bolts is not affected by turning on event logging.\n\n### 2.1. Enabling event logging\n\nNote: Event logging is disabled by default and needs to be enabled first by setting the storm config \"topology.eventlogger.executors\" to a non zero value. Please see the Configuration section for more details.\n\nEvents can be logged by clicking the \"Debug\" button under the topology actions in the topology view. This logs the tuples from all the spouts and bolts in a topology at the specified sampling percentage.\n\n![](/assets/images/2015/05/27/debugging-an-apache-storm-topology/003.png)\n\nFigure 3: Enable event logging at topology level.\n\nYou could also enable event logging at a specific spout or bolt level by going to the corresponding component page and clicking \"Debug\" under component actions.\n\n![](/assets/images/2015/05/27/debugging-an-apache-storm-topology/004.png)\n\nFigure 4: Enable event logging at component level.\n\n## 2.2. Viewing the event logs\n\nThe Storm \"logviewer\" should be running for viewing the logged tuples. If not already running log viewer can be started by running the \"bin/storm logviewer\" command from the storm installation directory. For viewing the tuples, go to the specific spout or bolt component page from storm UI and click on the \"events\" link under the component summary (as highlighted in Figure 4 above).\n\nThis would open up a view like below where you can navigate between different pages and view the logged tuples.\n\n![](/assets/images/2015/05/27/debugging-an-apache-storm-topology/005.png)\n\nFigure 5: Viewing the logged events.\n\nEach line in the event log contains an entry corresponding to a tuple emitted from a specific spout/bolt in a comma separated format:\n\n```\nTimestamp, Component name, Component task-id, MessageId (in case of anchoring), List of emitted values\n```\n\n### 2.3. Disabling the event logs\n\nEvent logging can be disabled at a specific component or at the topology level by clicking the \"Stop Debug\" under the topology or component actions in the Storm UI.\n\n![](/assets/images/2015/05/27/debugging-an-apache-storm-topology/006.png)\n\nFigure 6: Disable event logging at topology level.\n\n### 2.4. Configuration\n\nEvent logging sends events (tuples) from each component to an internal eventlogger bolt. By default Storm does not start any event logger tasks due to a slight performance degradation when event logging is turned on. This can be changed by setting the below parameter when submitting your topology (either globally in the storm.yaml or using the command line options).\n\n\n| Parameter | Meaning | When to use |\n| --------- | ------- | ----------- |\n| topology.eventlogger.executors: 0 | No event logger tasks are created (default). | If you don’t intend to inspect tuples and don’t want the slight performance hit. |\n| topology.eventlogger.executors: 1 | One event logger task for the topology. | If you want to sample a low percentage of tuples from a specific spout or a bolt. This could be the most common use case. |\n| topology.eventlogger.executors: nil | One event logger task per worker. | If you want to sample entire topology (all spouts and bolt) at a very high sampling percentage and the tuple rate is very high. |\n\n### 2.5. Extending event logging\n\nStorm provides the IEventLogger interface, which is used by the event logger bolt to log the events. The default implementation is FileBasedEventLogger, which logs the events to an events.log file ( logs/workers-artifacts/&lt;topology-id&gt;/&lt;worker-port&gt;/events.log). Alternative implementations of the IEventLogger interface can be added to extend the event logging functionality (say build a search index or log the events into a database)\n\n```java\n/**\n * EventLogger interface for logging the event info to a sink like log file or db\n * for inspecting the events via UI for debugging.\n */\npublic interface IEventLogger {\n    void prepare(Map stormConf, TopologyContext context);\n    /**\n     * Invoked when the {@link EventLoggerBolt} receives a tuple from the spouts or bolts that\n     * have event logging enabled.\n     *\n     * @param e the event\n     */\n    void log(EventInfo e);\n    /**\n     * Invoked when the event logger bolt is cleaned up\n     */\n    void close();\n}\n```\n\nSee JIRA [STORM-954](https://issues.apache.org/jira/browse/STORM-954) for more details.\n\n## 3. Distributed Log Search\n\nAnother improvement to Storm's UI is the addition of distributed log search. This capability allows users to search across all log files of a specific topology, including archived logs. The search results will include matches from all supervisor nodes.\n\n![](/assets/images/2015/05/27/debugging-an-apache-storm-topology/007.png)\n\nFigure 7: A distributed log search output\n\nThis feature is very helpful to search for patterns across workers or supervisors of a topology. Similar log search is also supported within specific worker log files via the UI.\n\nSee JIRA [STORM-902](https://issues.apache.org/jira/browse/STORM-902) for more details.\n\n## 4. Dynamic Worker Profiling\n\nUsers can now request worker profile data directly from Storm UI, including Heap dumps, JStack output and JProfile recordings without restarting their topologies.\n\nThe generated files are then available for download for offline analysis via log viewer with various debugging tools. It is also now possible to restart workers via the Storm UI.\n\n![](/assets/images/2015/05/27/debugging-an-apache-storm-topology/008.png)\n\nFigure 8: Profiling and debugging workers\n\nThe output can be viewed from the worker log viewer UI by switching to the appropriate file.\n\n![](/assets/images/2015/05/27/debugging-an-apache-storm-topology/009.png)\n\n\nFigure 9: Jstack output viewed from the Storm UI\n\nSee JIRA [STORM-1157](https://issues.apache.org/jira/browse/STORM-1157) for more details.\n\n## 5. Conclusion\n\nWe covered some of the new features added in Apache Storm 1.0 that should make the various aspects of debugging a Storm topology much easier, intuitive and more user friendly. These features allow Apache Storm users to quickly troubleshoot their topologies whenever any issues are encountered.\n\n参考链接：\n\n* [Storm Logs](http://storm.apache.org/releases/2.0.0-SNAPSHOT/Logs.html)\n* [Enabling Distributed Log Search](https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/bk_storm-component-guide/content/storm-enabling-distr-log-search.html)\n \n---\n\n* 原文链接：[Debugging an Apache Storm topology](https://community.hortonworks.com/content/kbentry/36151/debugging-an-apache-storm-topology.html)\n","tags":["Debug"],"categories":["Storm"]},{"title":"解析大数据基准测试——TPC-H or TPC-DS","url":"%2F2015%2F2015-05-14-bigdata-tpc-benchmarks%2F","content":"\n为了方便企业选择合适的大数据测试基准，本文将在分析总结现有成果的基础，进一步讨论大数据测试基准应该具有的要素；并以此为基础，对比现有的大数据测试基准；然后重点讨论TPC-DS测试基准。\n\n【编者按】基于业内对大数据技术的需求，各种基于开源技术的商业产品得到了长足的发展。然而对于用户来说，如何才能客观地比较不同的数据管理系统，基准测试的研究也被提了出来。本文中，谭磊讲解了大数据测试基准应该具有的要素，并以此为基础对比了现有的大数据测试基准，然后重点讨论TPC-DS测试基准。\n\n以下为原文\n\n随着开源Hapdoop、Map/Reduce、Spark、HDFS、HBASE等技术的商用化，大数据管理技术得到了突飞猛进的发展。一般来说，大数据具有3V特性，即Volume（海量）、Velocity（高速）和Variety（多样）[1]。TPC联合主席、Cisco高级工程师Raghunath Nambiar进一步认为大数据还面临Value（价值）和Veracity（精确）的挑战。如何客观地比较不同数据管理系统，即大数据测试基准的选择，成为一个重要的研究课题。\n\n事务性能管理委员会(TPC)是目前最知名的数据管理系统评测基准标准化组织。在过去二十多年间，该机构发布了多款数据库评测基准，如TPC-A、TPC-D、TPC-H和TPC-DS，在业界得到了广泛应用[2]。BigBench和BigFrame是对TPC-DS进行多样化的数据扩充的测试基准。近年来，Apache开源社区针对Map/reduce架构开发了多款性能测试用例，如TestDFSIO、teraSort。国内对大数据测试基准的研究起步较晚，尚未建立起权威的测试基准。目前由中国信息通信研究院牵头，联合中科院计算所及国内外知名公司和机构共同制定的大数据测试基准正在金罗密布的测试中[3]。\n\n为了方便企业选择合适的大数据测试基准，本文将在分析总结现有成果的基础，进一步讨论大数据测试基准应该具有的要素；并以此为基础，对比现有的大数据测试基准；然后重点讨论TPC-DS测试基准。\n\n### 大数据测试基准的选择\n\n企业在选择大数据测试基准时，首先应考虑基准与其自身业务的相关性。\n\n1. 与其自身业务的相关性\n\n它主要描述测试基准设定的应用场景是否与企业的实际业务场景类似，如基于社交网络应用的评测基准与银行系统的应用场景就没有什么相关性。不相关的基准，测试结果再好，也没有实际意义。相关性还要考虑测试基准所采用的数据模型是否代表数据仓库的发展方向，如基于星型模型的开发要比基于传统的关系模型开发更加有效。\n\n当然，一套行之有效的大数据测试基准包含许多其它要素。Jim Gray及金澈清等学者[4]已经对度量选取、模拟数据生成器、工作负载设定、审计等要素进行了详细论述。除此之外，本文还认为测试基准的健壮性、SQL标准的兼容性和通用性/可移植性也是重要的要素。\n\n2. 模拟数据生成要具有真实性\n\n它描述了测试基准是否仿真真实应用场景，所产生的模拟数据是否与真实数据相似。\n\n3. 工作负载的设定具有可扩展性\n\n它描述该评测基准是否适用于不同规模的计算机系统，许多评测基准会使用标度因子来决定模拟数据的规模，通过调整标度因子来得到不同规模的工作负载。\n\n4. 度量的选取的可理解性\n\n它衡量该评测基准是否易于为用户理解，不易为用户理解的基准的可信程度也较低。\n\n5. 客观性与公正性\n\n众所周知，在竞技比赛中，一个人不能既是运动员又是裁判员。测试基准好比竞技比赛中的裁判员，应该由中立的第三方机构制定。事实也证明，在各个领域最受欢迎的测试基准都是有第三方机构设计的。过去20多年的经历证明TPC系列基准是数据库领域最为广泛接受的基准。除此之外，第三方机构的审计也是保证证评测结果的客观性与公正性的重要手段。\n\n6. 健壮性\n\n测试基准要足够健壮，不能轻易被“hack”，这对测试结果的公平性非常重要。例如对TPC-H的前身TPC-D，通过物理化视图，Oracle的性能比Micosoft的SQLServer高100倍，这些显然是不公平的。因此TPC组织规定TPC-H测试中物理化视图是不和法的。但是除非是专业人员，一般用户很难判定测试过程中视图有没有被物理化。TPC-DS在健壮行方面要好很多，因为它的SQL本身比较复杂，也比较多，Hack起来相对困难，并且只hack几个SQL对整体性能提高有限。\n\n7. SQL标准兼容性\n\nSQL是ANSI为统一各个数据库厂商之间的编程差异定义的标准，已发布SQL86、SQL92、SQL99、SQL2003等版本。这些标准已经被主流的商用（例如Oracle、DB2、SQL server）以及开源的数据库产品（例如MySQL、mSQL和PostgreSQL）的广泛采用。对整个数据库产业的发展起到了巨大的推动作用。大数据是个新兴的领域，它的发展不能完全抛弃原有的应用。如果不能全面支持SQL标准，现有系统的移植非常困难，学习曲线就会变长。\n\n8. 通用性/可迁移性\n\n通用性描述是否可在不同数据库系统和架构上实现指定的评测基准。测试基准不应该规定实现的细节，而只需要定义测试规范。DBMS只要遵循规范得到正确的结果，就是合理的测试，无论其基于Map/Reduce、Spark还是其他的技术，也不管其底层存储是用HDFS、HBASE还是其他方式。\n\n### 大数据测试基准对比\n\n经过30几年的研究，传统数据库测试基准的研究已经相当成熟，在各个领域出现了行之有效的测试基准。随着大数据应用的发展，大数据测试基准的研究最近几年逐渐兴起，但大都是在传统的测试基准的基础进行裁剪、扩充、综合。金澈清等学者[4]对数据库基准的发展概述如图1所示。 \n\n![](/assets/images/2015/05/14/bigdata-tpc-benchmarks/1.jpg)\n\n本文重点关注被列为大数据测试基准的相关基准、BigFrame[5]以及TPC-DS，对其它的基准本文不再赘述，有兴趣的读者请参阅文[4]。\n\n1. Map/reduce性能测试\n\n如文[4]中所述，MRBench、HiBench、TestDFSIO、Sort/teraSort只是针对Map/Reduce框架，目的是评测运行Map/Reduce框架的集群的性能。CALDA基准尝试比较不同架构在数据管理方面的性能。这些测试过于简单，无法模拟复杂的应用，也不通用。\n\n2. YCSB/YCSB++/LinkBench\n\n这是一组针对网络应用的测试基准。YCSB（Yahoo! Cloud Serving Benchmark）及其扩展YCSB++测试查询回复的延时等云服务系统中云计算的特点，如查询回复的延时、纵向扩展和弹性加速比、并行性测试等。LinkBench是一个基于社交网络应用的评测基准。它仿真Facebook公司的图数据管理应用，包括数据特性、工作负载以及度量等。这些都是公司开发的针对自己特定应用场景的测试基准，很难在整个行业内进行推广。\n\n3. BigBench\n\nBigBench是一款面向商品零售业的基准，它扩展了TPC-DS，综合考虑多种数据模态，增加了半结构化数据Web Log和非结构化数据Reviews。其负载的生成是TPC-DS定制化的版本。BigBench包含30个查询。BigBench基本数据模型如图2所示：\n\n![](/assets/images/2015/05/14/bigdata-tpc-benchmarks/2.jpg)\n\n4. BigFrame\n\nBigFrame是一个测试基准生成器[5]，用户可以根据自己的需求定制专有测试基准。在目前实现中，其关系模型与BigBench类似，也是基于TPC-DS。同时它扩展了半结构化和非结构化的数据Tweets以及图形化数据Followee/Follower。BigFrame基本数据模型如图3所示：\n\n![](/assets/images/2015/05/14/bigdata-tpc-benchmarks/3.jpg)\n\n如文[5]所述，大数据与决策支持系统（DSS）并不是完全独立的，大数据也不能抛弃传统。DSS系统中，只要数据量足够大，都可以认为是大数据问题。被化为大数据测试基准的BigBench和BigFrame的大部分内容都来自于TPC-DS，从这个意义上讲，TPC-DS不但是一种结构数据的大数据测试基准，而且是其它大数据测试基准的基础。\n\n### TPC-DS\n\nTPC-DS测试基准是TPC组织推出的用于替代TPC-H的下一代决策支持系统测试基准。因此在讨论TPC-DS之前，先介绍一下TPC-H。\n\n1. TPC-H\n\nTPC-H是一款面向商品零售业的决策支持系统测试基准，它定义了8张表，22个查询，遵循SQL92。TPC-H的数据模型如图4所示。TPC-H基准的数据库模式遵循第三范式，叶晓俊教授等学者[6]认为“它的数据表数据特征单一(如数据不倾斜) ，其数据维护功能仅仅限制了潜在的对索引的过度使用，而没有测试DBMS 执行真实数据维护操作——数据提取、转换和加载(ETL) 功能的能力”。同时，新兴的数据仓库开始采用新的模型，如星型模型、雪花模型。TPC-H已经不能精准反映当今数据库系统的真实性能。为此，TPC组织推出了新一代的面向决策应用的TPC-DS 基准。\n\n![](/assets/images/2015/05/14/bigdata-tpc-benchmarks/4.jpg)\n\n2. TPC-DS\n\nTPC-DS采用星型、雪花型等多维数据模式。它包含7张事实表，17张纬度表平均每张表含有18列。其工作负载包含99个SQL查询，覆盖SQL99和2003的核心部分以及OLAP。这个测试集包含对大数据集的统计、报表生成、联机查询、数据挖掘等复杂应用，测试用的数据和值是有倾斜的，与真实数据一致。可以说TPC-DS是与真实场景非常接近的一个测试集，也是难度较大的一个测试集。\n\nTPC-DS的这个特点跟大数据的分析挖掘应用非常类似。Hadoop等大数据分析技术也是对海量数据进行大规模的数据分析和深度挖掘，也包含交互式联机查询和统计报表类应用，同时大数据的数据质量也较低，数据分布是真实而不均匀的。因此TPC-DS成为客观衡量多个不同Hadoop版本以及SQL on Hadoop技术的最佳测试集。这个基准测试有以下几个主要特点：\n\n* 一共99个测试案例，遵循SQL'99和SQL 2003的语法标准，SQL案例比较复杂\n* 分析的数据量大，并且测试案例是在回答真实的商业问题\n* 测试案例中包含各种业务模型（如分析报告型，迭代式的联机分析型，数据挖掘型等）\n* 几乎所有的测试案例都有很高的IO负载和CPU计算需求\n\n叶晓俊等学者对这些查询的分部总结如表1所示[6]。典型的Store_Sales的数据模型如图5所示。这个基准测试的完整信息请参考http://www.tpc.org/tpcds/。\n\n![](/assets/images/2015/05/14/bigdata-tpc-benchmarks/5.jpg)\n\n![](/assets/images/2015/05/14/bigdata-tpc-benchmarks/6.jpg)\n\n3. TPC-DS认证现状\n\nTPC-DS以其高标准、高要求得到大家的广泛认知，理应得到广泛的应用，但是到目前为止还没有任何厂商得到TPC官方的认证。究其原因，本文认为：\n\n* 传统的数据库厂商，DBMS系统比较成熟，SQL的支持也相当完善，但是其分布式、并行处理能力欠缺，导致其性能很差。所以传统的厂商不愿意发布测试结果。\n* 新型的计算模型如Map/Reduce、spark，具有较好的并行处理能力，但是SQL的兼容性比较差，如HiveSQL、SparkSQL只支持40个SQL，从而也无法发布TPC-DS测试报告。尽管如此，各厂商还是通过非TPC官方的途径发布TPC-DS的部分测试结果，以展现其在性能方面的提升。由此可见大家对TPC-DS的程接受度。\n\n### 结束语\n\n大数据评测基准用于公平、客观地评测不同大数据库产品/平台的功能和性能，对人们选择合适的大数据分析决策系统具有重要的参考价值。随着国内外各代表性的Hadoop发行版厂商以TPC-DS为标准测评产品，TPC-DS也就逐渐成为了业界公认的大数据系统测试基准。但是随着大数据应用在各行各业的发展，测试基准也需不断与时俱进。大数据测试基准仍然面临着诸多挑战，还需要政府、学术界和工业界的紧密合作。\n\n**编外话**：对于用户来说，产品的测试绝对不是自己可以轻易完成的事情。而为了更好地取信潜在用户，对产品做基准测试应为每个产品/服务提供商的首要工作之一。而据编者所知，国内已经有一些提供商开始从事类似方面的工作，比如星环的TPC-DS 500G的功能、性能及其兼容性测试已经得到上海市计算机软件评测实验室的认证。\n\n###参考文献\n\n* Big data: Science in the petabyte era. Nature, 2008, 455: 1-136\n* [www.tpc.org](http://www.tpc.org)\n* [www.dca.org.cn](http://www.dca.org.cn)\n* 金澈清, 钱卫宁, 周敏奇, 周傲英，数据管理系统评测基准：从传统数据库到新兴大数据，计算机学报, 2014.\n* M. Barata, etc, Survey on Big Data and Decision Support Benchmarks, LNCS 8645, 174–182, 2014.\n* 陈旦，叶晓俊，施霖, TPC-DS性能测试工具的实现, 计算机应用，第31 卷，第9期, 2011.\n\n### 关于作者：\n\n谭磊，复旦计算机学士、美国杜克计算机硕士。美国微软总部服务13年，是数据分析、数据挖掘、产品研发及管理、互联网广告和互联网营销方面的专家。《New Internet：大数据挖掘》《数据掘金：电商数据运营》两书作者。\n\n---\n\n* 原文链接：[解析大数据基准测试——TPC-H or TPC-DS](http://www.csdn.net/article/2015-05-14/2824680)\n","tags":["TPC"],"categories":["Benchmark"]},{"title":"Succinct","url":"%2F2015%2F2015-05-05-succinct%2F","content":"\nSuccinct is a data store that enables efficient queries directly on a compressed representation of the input data. Succinct uses a compression technique that achieves compression close to that of gzip and yet allows random access into the input data. In addition, Succinct natively supports a wide range of queries including count and search of arbitrary strings, range and wildcard queries.\n\n> What differentiates Succinct from previous data stores is that Succinct supports these queries without storing any secondary indexes, without requiring data scans and without decompressing the data — all the required information is embedded within the compressed representation and queries are executed directly on the compressed representation.\n\nAs a base API, Succinct exposes a simple interface that supports above queries on flat files. Applications that perform queries on semi-structured data can extend this API to build higher-level data representations.\n\nOn real-world and benchmark datasets, Succinct requires as much as an order of magnitude lower storage compared to state-of-the-art systems with similar functionality. As a result, Succinct executes more queries in faster storage, leading to lower query latency than existing systems for a much larger range of input sizes.\n\n相关链接：[Succinct](http://succinct.cs.berkeley.edu/wp/wordpress/)、\n[Succinct: Enabling Queries on Compressed Data](https://www.usenix.org/conference/nsdi15/technical-sessions/presentation/agarwal)、\n[Succinct Data Structure Library 2.0](https://github.com/simongog/sdsl-lite)、\n[CMPH - C Minimal Perfect Hashing Library](http://cmph.sourceforge.net/)\n\n---\n\n* 原文链接：[Succinct](http://succinct.cs.berkeley.edu/wp/wordpress/?page_id=127)\n","tags":["Succinct"],"categories":["Succinct"]},{"title":"YARN资源调度策略","url":"%2F2015%2F2015-04-30-yarn-resource-scheduler%2F","content":"\n公司活动写的一篇文章。这里也发下吧。\n\n介绍下YARN中资源调度相关概念和算法。以hadoop 2.2.0为准。\n\nYARN虽然是从MapReduce发展而来，但其实更偏底层，它在硬件和计算框架之间提供了一个抽象层，用户可以方便的基于YARN编写自己的分布式计算框架，而不用关心硬件的细节。由此可以看出YARN的核心功能：资源抽象、资源管理（包括调度、使用、监控、隔离等等）。从某种程度上说YARN类似于IaaS。\n\n![](/assets/images/2015/04/30/yarn-resource-scheduler/overview.png)\n\nYARN的基本概念不再赘述。一些缩写：RM = ResourceManager、NM = NodeManager、AM = ApplicationMaster。\n\n# 什么是资源？\n\n对一个资源管理系统而言，首先要定义出资源的种类，然后将每种资源量化，才能管理。这就是资源抽象的过程。\n\n先抛开YARN不谈，在一个分布式、多用户的系统中，什么是资源？\n我们通常所说的“资源”都是硬件资源，包括CPU使用/内存使用/磁盘用量/IO/网络流量等等。这是比较粗粒度的。也可以是抽象层次更高的TPS/请求数之类的。其实广义来看，时间、人力等“软件”也是资源，可惜一般很难量化。\n\n为什么要有“资源”这个概念？首先可以用来衡量系统的瓶颈，系统能否充分利用资源？什么时候应该扩容？在多用户的系统中，“资源”还额外承担着限制用户的功能。比如当总体资源紧张时，重要的用户可以优先获得资源，有更高的资源上限，普通的用户更难获得资源。\n\nYARN的资源抽象比较简单，只有两种资源：内存和CPU。而资源数量是管理员手动设置的，每个NM节点可以贡献一定数量的内存（MB）和CPU，由RM统一管理，不一定是真实的内存和CPU数。\n其中内存资源是比较关键的，直接决定任务能否成功。如果某个任务需要的内存过多，可能无法执行，或者OOM。CPU资源的限制比较弱，只限定了一台NM上能并发执行多少任务。如果并发的过多，执行的可能比较慢。\n\n# 基本概念\n\n## Container\n\nContainer是RM分配资源的基本单位。每个Container包含特定数量的CPU资源和内存资源，用户的程序运行在Container中，有点类似虚拟机。RM负责接收用户的资源请求并分配Container，NM负责启动Container并监控资源使用。如果使用的资源（目前只有内存）超出Container的限制，相应进程会被NM杀掉。\n\n可见Container这个概念不只用于资源分配，也用于资源隔离。理论上来说不同Container之间不能互相影响。可惜现阶段YARN的隔离做的还不太好。\n\nContainer的另一个特性是客户端可以要求只在特定节点上分配，这样用户的程序可以只在特定的节点上执行。这跟计算本地性有关。后面会讲到。\n\nContainer是有最大资源限制的。在我们的设置中，每个Container最多只能有8G内存，8个CPU。这是由RM端的参数yarn.scheduler.maximum-allocation-mb和yarn.scheduler.maximum-allocation-vcores决定的。\n\n## 调度器与队列\n\n在YARN中，调度器是一个可插拔的组件，常见的有FIFO，CapacityScheduler，FairScheduler。可以通过配置文件选择不同的调度器。\n\n在RM端，根据不同的调度器，所有的资源被分成一个或多个队列（queue），每个队列包含一定量的资源。用户的每个application，会被唯一的分配到一个队列中去执行。队列决定了用户能使用的资源上限。\n\n所谓资源调度，就是决定将资源分配给哪个队列、哪个application的过程。\n\n可见调度器的两个主要功能：1.决定如何划分队列；2.决定如何分配资源。此外，还有些其他的特性：ACL、抢占、延迟调度等等。\n\n后文会对这几种调度器分别介绍下。\n\n## 事件驱动\n\nYARN实现了一套基于状态机的事件驱动机制：很多对象内部有一个预先定义好的有限状态机，相应的事件会触发状态转换，状态转换的过程中触发预先定义的钩子，钩子执行的过程中又生成新的事件，继续状态转换。这种设计的好处是耦合小，但不太好理解。\n\n几个角色：\n\n* Dispatcher —— 用于分发事件，一般是异步的。内部用一个BlockingQueue暂存所有事件。\n* Event —— 事件类型。\n* Handler —— 事件的消费者。每个消费者只handle特定的事件，所有Handler要在Dispatcher上注册。\n\n这个机制在YARN的各个模块中用的非常广泛，不只用于调度器。\n\n## pull-based\n\n通俗的说，AM通过心跳向RM申请资源，但当次心跳申请的资源不能马上拿到，而是要再经过若干次心跳才能拿到。这是一种pull-based模型。\n\nAM通过RPC协议ApplicationMasterProtocol与RM通信。这个协议在服务端的实现会调用YarnScheduler的allocate方法（所有调度器都必须实现YarnScheduler接口）。allocate方法有两个作用：1.申请、释放资源；2.表示AM是否存活。超过一段时间AM没有调用这个方法，RM会认为AM挂掉并尝试重新提交。\n\nallocate方法有3个参数：<applicationid, 想要申请的资源,=\"\" 要释放的container=\"\">。调度器会暂存这个application的资源请求，同时取出上次心跳后新分配给这个application的container，包装为一个Allocation对象返回。如果上次要求的资源也还没分配，那返回的Allocation对象就不包含任何资源。</applicationid,>\n\n那真正分配container是什么时候？答案是NM的心跳时。当NM向RM发送心跳时，会触发一个NODE_UPDATE事件。schduler会handle这个事件尝试在这个node上分配container。里面有一系列判断，比如当前节点是否有足够资源、优先给哪个application分配资源。如果成功分配container，就加入一个List中，等待AM下次心跳来取。\n\n这点跟以前的JobTracker比较像，也是TaskTracker各自去拉取任务。\n\n# 常见调度器\n\n前文说过，调度器的两个主要作用：1.决定如何划分队列；2.决定如何分配资源，这里又分两种情况：为队列分配资源和为单个application分配资源。从这两方面看下常见的调度器，重点分析下FairScheduler。\n\n## FIFO\n\n最简单、也是默认的调度器。只有一个队列，所有用户共享。\n\n资源分配的过程也非常简单，先到先得，所以很容易出现一个用户占满集群所有资源的情况。\n\n可以设置ACL，但不能设置各个用户的优先级。\n\n优点是简单好理解，缺点是无法控制每个用户的资源使用。\n\n一般不能用于生产环境中。\n\n## CapacityScheduler\n\n在FIFO的基础上，增加多用户支持，最大化集群吞吐量和利用率。它基于一个很朴素的思想：每个用户都可以使用特定量的资源，但集群空闲时，也可以使用整个集群的资源。也就是说，单用户的情况下，和FIFO差不多。\n\n这种设计是为了提高整个集群的利用率，避免集群有资源但不能提交任务的情况。\n\n特点：\n\n*   划分队列使用xml文件配置，每个队列可以使用特定百分比的资源\n*   队列可以是树状结构，子队列资源之和不能超过父队列。所有叶子节点的资源之和必须是100%，只有叶子节点能提交任务\n*   可以为每个队列设置ACL，哪些用户可以提交任务，哪些用户有admin权限。ACL可以继承\n*   队列资源可以动态变化。最多可以占用100%的资源。管理员也可以手动设置上限。\n*   配置可以动态加载，但只能添加队列，不能删除\n*   可以限制整个集群或每个队列的并发任务数量\n*   可以限定AM使用的资源比例，避免所有资源用来执行AM而只能无限期等待的情况\n\n当选择队列分配资源时，CapacityScheduler会优先选择资源用量在规定量以下的。\n\n当选择一个队列中的application分配资源时，CapacityScheduler默认使用FIFO的规则，也可以设定每个app最多占用队列资源的百分比。\n\n关于CapacityScheduler一个比较重要问题就是百分比是如何计算的。默认的算法是DefaultResourceCalculator类的ratio方法，只考虑了内存。也就是说CapacityScheduler调度时是只考虑内存的。管理员也可以手动设置选择其他算法。\n\n优点：灵活、集群的利用率高\n\n缺点：也是灵活。某个用户的程序最多可以占用100%的资源，如果他一直不释放，其他用户只能等待，因为CapacityScheduler不支持抢占式调度，必须等上一个任务主动释放资源。\n\n## FairScheduler\n\n我们一直在用的调度器。设计思路和CapacityScheduler不同，优先保证“公平”，每个用户只有特定数量的资源可以用，不可能超出这个限制，即使集群整体很空闲。\n\n特点：\n\n*   使用xml文件配置，每个队列可以使用特定数量的内存和CPU\n*   队列是树状结构。只有叶子节点能提交任务\n*   可以为每个队列设置ACL\n*   可以设置每个队列的权重\n*   配置可以动态加载\n*   可以限制集群、队列、用户的并发任务数量\n*   支持抢占式调度\n\n优点：稳定、管理方便、运维成本低\n\n缺点：相对CapacityScheduler，牺牲了灵活性。经常出现某个队列资源用满，但集群整体还有空闲的情况。整体的资源利用率不高。\n\n下面重点看下资源分配的算法。\n\n### Max-min fairness算法\n\nFairScheduler主要关注“公平”，那么在一个共享的集群中，怎样分配资源才算公平？\n\n常用的是max-min fairness算法：[wiki](http://en.wikipedia.org/wiki/Max-min_fairness)。这种策略会最大化系统中一个用户收到的最小分配。如果每一个用户都有足够地请求，会给予每个用户一份均等的资源。尽量不让任何用户被“饿死”。\n\n一个例子：资源总量是10，有3个用户A/B/C，需要的资源分别是5/4/3，应该怎样分配资源？\n\n第一轮：10个资源分成3份，每个用户得到3.33\n\n第二轮：3.33超出了用户C的需求，超出了0.33，将这多余的0.33平均分给A和B，每个用户得0.16\n\n所以最后的分配结果是A=3.49，B=3.49，C=3\n\n上面的例子没有考虑权重，如果3个用户的权重分别是0.5/1/0.8，又应该如何分配资源？\n\n第一轮：将权重标准化，3个用户的权重比是5:10:8。将所有资源分成5+10+8=23份，按比例分配给各个用户。A得到`10*5/23=2.17`，B得到`10*10/23=4.35`，C得到`10*8/23=3.48`。\n\n第二轮：B和C的资源超出需求了，B超过0.25，C超过0.48。将多出资源分配给A。\n\n最后的分配结果是A=2.9，B=4，C=3\n\n由于进位的问题会有些误差。\n\n更多用户的情况下同理。\n\n### DRF\n\nMax-min fairness解决了单一资源下，多用户的公平分配。这个算法以前主要用来分配网络流量。但在现代的资源管理系统中，往往不只有一种资源。比如YARN，包含CPU和内存两种资源。多种资源的情况下，如何公平分配？Berkeley的大牛们提出了[DRF算法](http://static.usenix.org/event/nsdi11/tech/full_papers/Ghodsi.pdf)。\n\nDRF的很多细节不提了。核心概念在于让所有application的“主要资源占比”尽量均等。比如集群总共X内存，Y CPU。app1和app2是CPU密集型的，app1每次请求3个CPU，app2每次请求4个CPU；app3和app4是内存密集型的，app3每次请求10G内存，app4每次请求20G内存。设分给app1、app2、app3、app4的请求数分别是a、b、c、d。DRF算法就是希望找到一组abcd，使得3a/X=4b/X=10c/Y=20d/Y。\n\n如何判断CPU/内存密集型？如果任务需要的CPU资源/集群总的CPU资源 &gt; 需要的内存资源/集群总的内存资源，就是CPU密集型，反之是内存密集型。\n\n实际应用中一般没有最优解，而是一个不断动态调整的过程。和max-min fairness一样，也要经过多轮分配，才能达到一个公平的状态。\n\n如果考虑权重的话，算法会更复杂一点。另外在单一资源的情况下，DRF会退化为max-min fairness。\n\n### 资源分配过程\n\n了解了一些基本的算法，接下来看看FairScheduler的资源分配过程。\n\n前文说过NM的心跳会触发一个NODE_UPDATE事件，scheduler同时也是这个事件的handler，会尝试在对应的节点上分配container。\n\n在FairScheduler中，所有的queue、application都继承了Scheduable，构成一个树状结构。资源分配的过程就是从这颗树的根节点开始查找，直到找到一个合适的Scheduable对象的过程。\n\n![](/assets/images/2015/04/30/yarn-resource-scheduler/tree.png)\n\n以上图为例，共有3种对象：ParentQueue（root是一个特殊的ParentQueue）、LeafQueue、Application，只有LeafQueue才能提交app。\n\n每个Queue可以定义自己的SchedulingPolicy，这个policy主要用于Scheduable对象的排序。目前共有3种SchedulingPolicy的实现：FifoPolicy、FairSharePolicy、DominantResourceFairnessPolicy，FIFO只能用于LeafQueue，其他两种Policy可以用于任意Queue。默认是FairSharePolicy。\n\n分配Container是一次深度优先搜索：从root节点开始，首先检查当前节点资源是否用满，是则直接返回（这里会同时考虑CPU和内存）。如果当前节点是ParentQueue，就将所有子节点排序（SchedulingPolicy决定了这里的顺序），依次尝试在每个子节点上分配container；如果当前节点是LeafQueue，就将下面的app排序（也是SchedulingPolicy决定，但加入了一些app特有的判断条件），依次尝试为每个app分配资源；如果当前节点是app，会比较当前app的资源需求与节点的剩余资源，如果能满足，才真正分配container。至此整个资源分配过程才完成。如果找不到合适的app，最后会返回null。\n\n从上面的过程可以看出，每次NM心跳时，都会触发一次资源分配，而且只能分配一个container。所以NM的心跳频率会影响到整个集群的吞吐量。另外可以配置参数yarn.scheduler.fair.assignmultiple让一次心跳分配多个container，默认是false。\n\n下面看下默认的FairSharePolicy是如何排序的。这个policy只考虑内存资源，但跟max-min failness不太一样。max-min fairness关注整体资源的公平分配，而FairSharePolicy目的在于公平分配“被调度的机会”，所以最终的资源分配可能不是算法上的最优解。但目的是一样的，都是让所有app有机会运行，不会被饿死。\n\n每个Schedulable对象都有minShare、maxShare、fairShare 3个属性，其中minShare、maxShare用于排序，fairShare用于抢占式调度，后文会讲到。此外还有权重属性（weight），也会用于排序。对于queue而言，minShare、maxShare就是fair-scheduler.xml里配置的minResource和maxResource，weight也是直接配置的。对于application而言minResource直接返回0，maxResource直接返回Integer.MAX_VALUE，weight如果没有配置yarn.scheduler.fair.sizebasedweight=true就直接返回1.0，意味着所有app的权重是相同的。\n\nFairSharePolicy在比较两个Schedulable对象时，先看是否有已分配资源小于minShare的，如果是说明当前Scheduable处于饥饿状态，应该被优先满足。如果两个Schedulable都处于饥饿状态，就看谁占minShare的比例更小（谁更饿）。如果没有饥饿状态的，就比较两个Schedulable已用资源与权重的比例，这个比例越大，说明占用了越多的资源，为了公平，应该给另一个Schedulable分配资源。\n\nDominantResourceFairnessPolicy是YARN中DRF算法的实现，会考虑内存和CPU两种资源，排序逻辑会更复杂些，这里略过。\n\n### 任务分配过程\n\n任务分配过程决定一个app被分到哪个队列。相对于资源分配过程，这个过程简单的多。因为app在提交的时候一般会指定队列名。\n\n第一步：检查提交的app是否指定了队列名。如果没有指定，检查是否存在和用户同名的队列。如果还不存在，就提交到default队列。default队列可以在配置文件中指定，也可以在调度器初始化时默认创建。\n\n第二步：检查ACL，当前用户是否有向指定队列提交任务的权限。\n\n第三步：如果通过ACL检查，发出一个APP_ACCEPTED事件。app加入LeafQueue的children，开始等待资源分配。\n\nFairScheduler的一个特点是客户端可以动态创建队列，即指定一个不存在的队列。但生产环境中这一般是不允许的。\n\n### 抢占式调度\n\nFairScheduler特有的功能。当某个队列资源不足时，调度器会杀死其他队列的container以释放资源，分给这个队列。这个特性默认是关闭的。\n\n关键点有两个：1.启动抢占式调度的条件？2.选择哪些container去杀掉？\n\n前文说过每个Schedulable对象都有minShare、fairShare属性。这两个属性是抢占式调度的阈值。当一个Schedulable使用的资源小于fairShare*0.5、或者小于minShare，并且持续超过一定时间（这两种情况的超时时间不同，可以设置），就会开始抢占式调度。\n\nSchedulabe的fairShare是会不断变化的（minShare一般不会变化）。如果队列的minResource、maxResource、权重等属性变化，fairShare都要重新计算。application开始或结束，也都要重新计算fairShare。FairScheduler中有一个线程UpdateThread，默认每0.5秒调用一次update方法，就会重新计算fairShare。\n\n计算fairShare的过程就是将“上层”Schedulable的fairShare，“公平”的分配给下层的Schedulable。计算过程从root queue开始。root queue的fairShare就是整个集群的可用资源。怎样才算公平？要综合考虑各个Schedulable的权重、minShare、maxShare，算法也是由SchedulingPolicy决定的。默认是FairSharePolicy。这个计算逻辑跟max-min fairness类似。\n\n当FairScheduler决定开始抢占时，首先会计算要抢得的资源量。对于使用资源量小于minShare的，要恢复到minShare；对于使用量小于fairShare*0.5的，需要恢复到fairShare。将所有要恢复的资源量相加，得出要抢的的资源总量。然后遍历所有LeafQueue，找到所有资源用量大于fairShare的app，将他们在运行的container加入一个List，按优先级升序排列。然后遍历，优先杀死优先级低的container。当释放足够的资源后，抢占停止。\n\n如何确定container的优先级？这是由AM在申请资源的时候决定的。用一个整数表示，数字越大优先级越低。以MapReduce为例，AM Container是0，Reduce Container是10，Map Contaienr是20。意味着一个map任务更容易被杀死。\n\n抢占式调度可以一定程度上保证公平，但不可控因素比较多。如果用户的长时间任务因此失败，是不可接受的。所以生产环境一般关闭这个特性。\n\n### 计算本地性\n\n从MapReduce时代开始，“移动计算比移动数据更经济”的概念就深入人心。在YARN中，当然也继承了这一传统。这一特性主要是用来配合HDFS的，因为HDFS的多副本，任务应该尽量在选择block所在的机器上执行，可以减少网络传输的消耗。如果开启了Short-Circuit Read特性，还可以直接读本地文件，提高效率。\n\n本地性有3个级别：NODE_LOCAL、RACK_LOCAL、OFF_SWITCH，分别代表同节点、同机架、跨机架。计算效率会依次递减。\n\n根据前文所述，Container在申请时可以指定节点，但这不是强制的。只有NM心跳的时候才会分配资源，所以container无法一般确定自己在那个节点上执行，基本是随机的。scheduler能做的只是尽量满足NODE_LOCAL，尽量避免OFF_SWITCH。计算本地性更多的要AM端配合，当AM拿到资源后，优先分配给NODE_LOCAL的任务。\n\n但FairScheduler中，允许一个app错过若干次调度机会，以便能分到一个NODE_LOCAL的节点。由yarn.scheduler.fair.locality.threshold.node控制。这个参数是一个百分比，表示相对整个集群的节点数目而言，一个app可以错过多少次机会。\n\n比如yarn.scheduler.fair.locality.threshold.node为0.2，集群节点数为10。那么FairScheduler分配这个资源时，发现当前发来心跳的NM不能满足这个app的NODE_LOCAL要求，就会跳过，继续寻找下一个APP。相当于这个app错过一次调度机会，最多可以错过2次。\n\n对RACK_LOCAL而言，有一个参数yarn.scheduler.fair.locality.threshold.rack，作用差不多。\n\n# 发展趋势\n\nYARN的发展一直比较快，调度/资源相关的一些值得关注的改进：\n\nLabel based scheduling\n\n* [https://issues.apache.org/jira/browse/YARN-796](https://issues.apache.org/jira/browse/YARN-796)\n* [https://issues.apache.org/jira/browse/YARN-3214](https://issues.apache.org/jira/browse/YARN-3214)\n\n可以给不同的节点加上标签，比如某些节点CPU频率比较高、某些节点内存比较大，RM在调度的时候，可以更有针对性。甚至可以分成多个小集群供不同用户使用。\n\n管理更多资源\n\n磁盘：\n\n* [https://issues.apache.org/jira/browse/YARN-2139](https://issues.apache.org/jira/browse/YARN-2139)\n\n网络：\n\n* [https://issues.apache.org/jira/browse/YARN-2140](https://issues.apache.org/jira/browse/YARN-2140)\n\nDynamic resource configuration\n\n* [https://issues.apache.org/jira/browse/YARN-291](https://issues.apache.org/jira/browse/YARN-291)\n\n动态加载资源配置。包括自动探测实际的机器配置，而不是管理员手动设置。\n\napp级别的权重设置\n\n* [https://issues.apache.org/jira/browse/YARN-1963](https://issues.apache.org/jira/browse/YARN-1963)\n\n使用Docker做资源隔离\n\n* [https://issues.apache.org/jira/browse/YARN-1964](https://issues.apache.org/jira/browse/YARN-1964)\n\n---\n\n* Author: [foolbear](http://jxy.me/)\n* Link: [YARN资源调度策略](http://jxy.me/2015/04/30/yarn-resource-scheduler/)\n","tags":["Scheduler"],"categories":["YARN"]},{"title":"分布式配置管理平台 Disconf","url":"%2F2015%2F2015-03-27-config-center-disconf%2F","content":"\n## 摘要\n\n为了更好的解决分布式环境下多台服务实例的配置统一管理问题，本文提出了一套完整的分布式配置管理解决方案（简称为disconf[4]，下同）。首先，实现了同构系统的配置发布统一化，提供了配置服务server，该服务可以对配置进行持久化管理并对外提供restful接口，在此基础上，基于zookeeper实现对配置更改的实时推送，并且，提供了稳定有效的容灾方案，以及用户体验良好的编程模型和WEB用户管理界面。其次，实现了异构系统的配置包管理，提出基于zookeeper的全局分布式一致性锁来实现主备统一部署、系统异常时的主备自主切换。通过在百度内部以及外部等多个产品线的实践结果表明，本解决方案是有效且稳定的。\n\n## 技术背景\n\n在一个分布式环境中，同类型的服务往往会部署很多实例。这些实例使用了一些配置，为了更好地维护这些配置就产生了配置管理服务。通过这个服务可以轻松地管理成千上百个服务实例的配置问题。\n\n王阿晶提出了基于zooKeeper的配置信息存储方案的设计与实现[1], 它将所有配置存储在zookeeper上，这会导致配置的管理不那么方便，而且他们没有相关的源码实现。淘宝的diamond[2]是淘宝内部使用的一个管理持久配置的系统，它具有完整的开源源码实现，它的特点是简单、可靠、易用，淘宝内部绝大多数系统的配置都采用diamond来进行统一管理。他将所有配置文件里的配置打散化进行存储，只支持KV结构，并且配置更新的推送是非实时的。百度内部的BJF配置中心服务[3]采用了类似淘宝diamond的实现，也是配置打散化、只支持KV和非实时推送。\n\n同构系统是市场的主流，特别地，在业界大量使用部署虚拟化（如JPAAS系统，SAE，BAE）的情况下，同一个系统使用同一个部署包的情景会越来越多。但是，异构系统也有一定的存在意义，譬如，对于“拉模式”的多个下游实例，同一时间点只能只有一个下游实例在运行。在这种情景下，就存在多台实例机器有“主备机”模式的问题。目前国内并没有很明显的解决方案来统一解决此问题。\n\n## 功能特点与设计理念\n\ndisconf是一套完整的基于zookeeper的分布式配置统一解决方案。\n\n**它的功能特点是**\n\n* 支持配置（配置项+配置文件）的分布式化管理\n\n  * 配置发布统一化\n  * 配置发布、更新统一化（云端存储、发布）:配置存储在云端系统，用户统一在平台上进行发布、更新配置。\n  * 配置更新自动化：用户在平台更新配置，使用该配置的系统会自动发现该情况，并应用新配置。特殊地，如果用户为此配置定义了回调函数类，则此函数类会被自动调用。\n\n* 配置异构系统管理\n\n  * 异构包部署统一化：这里的异构系统是指一个系统部署多个实例时，由于配置不同，从而需要多个部署包（jar或war）的情况（下同）。使用Disconf后，异构系统的部署只需要一个部署包，不同实例的配置会自动分配。特别地，在业界大量使用部署虚拟化（如JPAAS系统，SAE，BAE）的情况下，同一个系统使用同一个部署包的情景会越来越多，Disconf可以很自然地与他天然契合。\n异构主备自动切换：如果一个异构系统存在主备机，主机发生挂机时，备机可以自动获取主机配置从而变成主机。\n  * 异构主备机Context共享工具：异构系统下，主备机切换时可能需要共享Context。可以使用Context共享工具来共享主备的Context。\n\n* 注解式编程，极简的使用方式：我们追求的是极简的、用户编程体验良好的编程方式。通过简单的标注+极简单的代码撰写，即可完成复杂的配置分布式化。\n* 需要Spring编程环境\n\n**它的设计理念是：**\n\n* 简单，用户体验良好：\n\n  * 摒弃了打散化配置的管理方式[2,3]，仍旧采用基于配置文件的编程方式，这和程序员以前的编程习惯（配置都是放在配置文件里）一致。特别的，为了支持较为小众的打散化配置功能，还特别支持了配置项。\n  * 采用了基于XML无代码侵入编程方式：只需要几行XML配置，即可实现配置文件发布更新统一化、自动化。\n  * 采用了基于注解式的弱代码侵入编程方式：通过编程规范，一个配置文件一个配置类，代码结构简单易懂。XML几乎没有任何更改，与原springXML配置一样。真正编程时，几乎感觉不到配置已经分布式化\n\n* 可以托管任何类型的配置文件，这与[2,3]只能支持KV结构的功能有较大的改进。\n* 配置更新实时推送\n* 提供界面良好Web管理功能，可以非常方便的查看配置被哪些实例使用了。\n\n## 详细设计\n\n### 架构设计\n\n**disconf服务集群模式**：\n\n![](/assets/images/2015/03/27/config-center-disconf/001.jpg)\n\n**disconf的模块架构图**：\n\n![](/assets/images/2015/03/27/config-center-disconf/002.jpg)\n\n每个模块的简单介绍如下：\n\n* Disconf-core\n\n  * 分布式通知模块：支持配置更新的实时化通知\n  * 路径管理模块：统一管理内部配置路径URL\n\n* Disconf-client\n\n  * 配置仓库容器模块：统一管理用户实例中本地配置文件和配置项的内存数据存储\n  * 配置reload模块：监控本地配置文件的变动，并自动reload到指定bean\n  * 扫描模块：支持扫描所有disconf注解的类和域\n  * 下载模块：restful风格的下载配置文件和配置项\n  * watch模块：监控远程配置文件和配置项的变化\n  * 主备分配模块：主备竞争结束后，统一管理主备分配与主备监控控制\n  * 主备竞争模块：支持分布式环境下的主备竞争\n\n* Disconf-web\n\n  * 配置存储模块：管理所有配置的存储和读取\n  * 配置管理模块：支持配置的上传、下载、更新\n  * 通知模块：当配置更新后，实时通知使用这些配置的所有实例\n  * 配置自检监控模块：自动定时校验实例本地配置与中心配置是否一致\n  * 权限控制：web的简单权限控制\n\n* Disconf-tools\n\n  * context共享模块：提供多实例间context的共享。\n\n### 流程设计\n\n![](/assets/images/2015/03/27/config-center-disconf/003.jpg)\n\n**运行流程详细介绍：**\n\n与2.0版本的主要区别是支持了：主备分配功能/主备切换事件。\n\n* **启动事件A**：以下按顺序发生。\n\n  * A3：扫描静态注解类数据，并注入到配置仓库里。\n  * A4+A2：根据仓库里的配置文件、配置项，去 disconf-web 平台里下载配置数据。这里会有主备竞争\n  * A5：将下载得到的配置数据值注入到仓库里。\n  * A6：根据仓库里的配置文件、配置项，去ZK上监控结点。\n  * A7+A2：根据XML配置定义，到 disconf-web 平台里下载配置文件，放在仓库里，并监控ZK结点。这里会有主备竞争。\n  * A8：A1-A6均是处理静态类数据。A7是处理动态类数据，包括：实例化配置的回调函数类；将配置的值注入到配置实体里。\n\n* **更新配置事件B**：以下按顺序发生。\n\n  * B1：管理员在 Disconf-web 平台上更新配置。\n  * B2：Disconf-web 平台发送配置更新消息给ZK指定的结点。\n  * B3：ZK通知 Disconf-cient 模块。\n  * B4：与A4一样。\n  * B5：与A5一样。\n  * B6：基本与A4一样，唯一的区别是，这里还会将配置的新值注入到配置实体里。\n\n* **主备机切换事件C**：以下按顺序发生。\n\n  * C1：发生主机挂机事件。\n  * C2：ZK通知所有被影响到的备机。\n  * C4：与A2一样。\n  * C5：与A4一样。\n  * C6：与A5一样。\n  * C7：与A6一样。\n\n### 模块实现\n\ndisconf-web提供了前后端分离的web架构，具体可见：\n\n[https://github.com/knightliao/disconf/tree/master/disconf-web](https://github.com/knightliao/disconf/tree/master/disconf-web)\n\n本部分会重点介绍disconf-client的实现方式。\n\n#### 注解式disconf实现\n\n本实现会涉及到 配置仓库容器模块、扫描模块、下载模块、watch模块，\n\n![](/assets/images/2015/03/27/config-center-disconf/004.jpg)\n\n使用AOP拦截的一个好处是可以比较轻松的实现配置控制，比如并发环境下的配置统一生效。关于这方面的讨论可以见[这里](https://github.com/knightliao/disconf/wiki/%E7%BB%86%E8%8A%82%E8%AE%A8%E8%AE%BA)。\n\n特别地，本方式提供的编程模式非常简单，例如使用以下配置类的程序在使用它时，可以直接@Autowired进来进行调用，使用它时就和平常使用普通的JavaBean一样，但其实它已经分布式化了。配置更新时，配置类亦会自动更新。\n\n```java\n    @Service\n    @DisconfFile(filename = \"redis.properties\")\n    public class JedisConfig {\n\n        // 代表连接地址\n        private String host;\n\n        // 代表连接port\n        private int port;\n\n        /**\n         * 地址, 分布式文件配置\n         * \n         * @return\n         */\n        @DisconfFileItem(name = \"redis.host\", associateField = \"host\")\n        public String getHost() {\n            return host;\n        }\n\n        public void setHost(String host) {\n            this.host = host;\n        }\n\n        /**\n         * 端口, 分布式文件配置\n         * \n         * @return\n         */\n        @DisconfFileItem(name = \"redis.port\", associateField = \"port\")\n        public int getPort() {\n            return port;\n        }\n\n        public void setPort(int port) {\n            this.port = port;\n        }\n    }\n```\n\n#### 基于XML配置disconf实现\n\n本实现提供了无任何代码侵入方式的分布式配置。\n\nReloadablePropertiesFactoryBean继承了Spring Properties文件的PropertiesFactoryBean类，管理所有当配置更新时要进行reload的配置文件。对于被管理的每一个配置文件，都会通过 配置仓库容器模块、扫描模块、下载模块、watch模块 进行配置获取至配置仓库里。\n\nReloadingPropertyPlaceholderConfigurer继承了Spring Bean配置值控制类PropertyPlaceholderConfigurer。在第一次扫描spring bean里，disconf会记录配置文件的配置与哪些bean有关联。\n\nReloadConfigurationMonitor是一个定时任务，定时check本地配置文件是否有更新。\n\n当配置中心的配置被更新时，配置文件会被下载至实例本地，ReloadConfigurationMonitor即会监控到此行为，并且通知 ReloadingPropertyPlaceholderConfigurer 对相关的bean类进行值更新。\n\n特别的，此种方式无法解决并发情况下配置统一生效的问题。\n\n#### 主备分配实现\n\n在实现中，为每个配置提供主备选择的概念。用户实例在获取配置前需要先进行全局唯一性竞争才能得到配置值。在这里，我们采用基于zookeeper的全局唯一性锁来实现。\n\n## Comparisons\n\n|   | 淘宝Diamond[2] | Disconf | 比较 |\n| - | ------------- | ------- | --- |\n| 数据持久性 | 存储在mysql上 | 存储在mysql上 | 都持久化到数据库里，都易于管理 |\n| 推拉模型 | 拉模型，每隔15s拉一次全量数据 | 基于Zookeeper的推模型，实时推送 | disconf基于分布式的Zookeeper来实时推送，在稳定性、实效性、易用性上均优于diamond |\n| 配置读写 | 支持实例对配置读写。支持某台实例写配置数据，并广播到其它实例上 | 只支持实例对配置读。通过在disconf-web上更新配置到达到广播写到所有应用实例 | 从目前的应用场景来看，实例对配置的写需求不是那么明显。disconf支持的中心化广播方案可能会与人性思考更加相似。 |\n| 容灾 | 多级容灾模式，配置数据会dump在本地，避免中心服务挂机时无法使用 | 多级容灾模式，优先读取本地配置文件。 | 双方均支持在中心服务挂机时配置实例仍然可以使用 |\n| 配置数据模型 | 只支持KV结构的数据，非配置文件模式 | 支持传统的配置文件模式（配置文件），亦支持KV结构数据(配置项) | 使用配置文件的编程方式可能与程序员的编程习惯更为相似，更易于接受和使用。 |\n| 编程模型 | 需要将配置文件拆成多个配置项，没有明显的编程模型 | 在使用配置文件的基础上，提供了注解式和基于XML的两种编程模型 | 无 |\n| 并发性 | 多条配置要同时生效时，无法解决并发同时生效的问题 | 基于注解式的配置，可以解决并发性问题 | 无 |\n\n## Reference\n\n1. 王阿晶，邹仕洪: [基于ZooKeeper的配置信息存储方案的设计与实现](http://wenku.baidu.com/view/ee86ca90daef5ef7ba0d3c7d.html)\n2. 淘宝Diamod实现：[http://code.taobao.org/p/diamond/src/](http://code.taobao.org/p/diamond/src/), 2012\n3. [百度BJF配置中心](http://wiki.babel.baidu.com/twiki/bin/view/Main/CAP-CC#%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%831.0%E5%BF%AB%E9%80%9F%E6%8E%A5%E5%85%A5%E6%8C%87%E5%8D%97.pptx), 2014\n4. Disconf github: [https://github.com/knightliao/disconf](https://github.com/knightliao/disconf), 2014\n5. [淘宝分布式配置管理服务Diamond](http://codemacro.com/2014/10/12/diamond/)\n6. [zooKeeper和Diamond有什么不同](http://jm-blog.aliapp.com/?p=2561)\n7. [diamond专题（一）-- 简介和快速使用](http://jm-blog.aliapp.com/?p=1588)\n\n---\n\n* 原文链接：[分布式配置管理平台 Disconf](http://www.liaoqiqi.com/post/219)\n","tags":["Disconf"],"categories":["Configuration"]},{"title":"常用排序算法总结（性能+代码）","url":"%2F2015%2F2015-03-13-sort-algorithm-summary%2F","content":"\n## 1. 插入排序\n\n### 1.1 性能分析\n\n时间复杂度`O(n^2)`, 空间复杂度`O(1)`\n\n排序时间与输入有关：输入的元素个数；元素已排序的程度。\n\n最佳情况，输入数组是已经排好序的数组，运行时间是`n`的线性函数； 最坏情况，输入数组是逆序，运行时间是`n`的二次函数。\n\n### 1.2 核心代码\n\n```\npublic void sort(){\n    int temp;\n    for(int i = 1; i&lt;arraytoSort.length; i++){\n        for(int j = i-1; j&gt;=0; j--){\n            if( arraytoSort[j+1] &lt; arraytoSort[j] ){\n                temp = arraytoSort[j+1];\n                arraytoSort[j+1] = arraytoSort[j];\n                arraytoSort[j] = temp;\n            }   \n        }   \n    }\n}\n```\n\n## 2.选择排序\n\n### 2.1 性能分析\n\n时间复杂度`O(n^2)`, 空间复杂度`O(1)`\n\n排序时间与输入无关，最佳情况，最坏情况都是如此, 不稳定 如 `{5,5,2}`。\n\n### 2.2核心代码\n\n```\npublic void sort(){ \n    for(int i = 0; i&lt;arraytoSort.length-1; i++){\n        int min = i;\n        int temp;\n        //find min\n        for(int j = i+1; j&lt;arraytoSort.length ;j++){\n            if(arraytoSort[j] &lt;arraytoSort[min]){\n                min = j;\n                }\n        }\n        //swap the min with the ith element\n        temp = arraytoSort[min];\n        arraytoSort[min] = arraytoSort[i];\n        arraytoSort[i] = temp;\n    }\n}\n```\n\n## 3. 归并排序\n\n### 3.1 性能分析\n\n时间复杂度 `O(nlogn)`, 空间复杂度`O(n) +O(logn)`\n\n排序时间与输入无关，最佳情况，最坏情况都是如此, 稳定。\n\n原理：\n\n可以将数组分成二组。依次类推，当分出来的小组只有一个数据时，可以认为这个小组组内已经达到了有序，然后再合并相邻的二个小组就可以了。这样通过先递归的分解数列，再合并数列就完成了归并排序\n\n归并排序的时间复杂度，合并耗费`O(n)`时间，而由完全二叉树的深度可知，整个归并排序需要进行`log_2n`次，因此，总的时间复杂度为 `O(nlogn)`，而且这是归并排序算法中最好、最坏、平均的时间性能。\n\n由于归并排序在归并过程中需要与原始记录序列同样数量的存储空间存放归并结果 以及 递归时深度为 `log_2n` 的栈空间，因此空间复杂度为`O(n+logn)`。\n\n另外，对代码进行仔细研究，发现 Merge 函数中有`if (L[i]&lt;R[j])` 语句，这就说明它需要两两比较，不存在跳跃，因此归并排序是一种稳定的排序算法。\n\n也就是说，归并排序是一种比较占用内存，但却效率高且稳定的算法。\n\n### 3.2 核心代码\n\n```\npublic int merge( int p, int q, int r ){\n    int count = 0;\n    int[] right = assignlist(p,q); \n    //赋值左半部分数组（赋值就是用for循环，还有一个哨兵：最后一个元素设置为maxvalue）\n    int[] left = assignlist(q+1,r); //赋值有半部分数组\n    int i = 0;\n    int j = 0;\n\n    for(int k = p; k&lt;=r; k++){\n        if(right[i] &lt;= left[j]){    \n            arraytoSort[k] = right[i];\n            i++;    \n        }\n        else if(right[i] &gt; left[j]){\n            arraytoSort[k] = left[j];\n            j++;\n            count = count + (q - p + 1) -i;\n        }\n    }\n    return count;\n}\n\nvoid MergeSort(int arry[],int start,int end){\n    if(start&lt;end)\n    {\n        int mid=(start+end)/2;//数组重点\n        MergeSort(arry,start,mid);//递归调用，排序前半段arry[start...mid]\n        MergeSort(arry,mid+1,end);//递归调用，排序后半段arry[mid+1,end]\n        MergeArry(arry,start,mid,end);//归并上述两段有序数组。\n    }\n}\n```\n\n### 3.3 延伸\n\n求逆序对\n\n## 4冒泡排序\n\n### 4.1 性能分析\n\n时间复杂度`O(n^2)`, 空间复杂度`O(1)`， 稳定，因为存在两两比较，不存在跳跃。\n\n排序时间与输入无关，最好，最差，平均都是`O(n^2)`\n\n### 4.2 核心代码\n\n```\nfor(int i=0;i&lt;arraytoSort.length-1;i++){    \n    for(int j=arraytoSort.length-1;j&gt;=i+1;j--){\n        int temp;\n        if(arraytoSort[j]&lt;arraytoSort[j-1])\n        {\n            temp = arraytoSort[j];\n            arraytoSort[j] = arraytoSort[j-1];\n            arraytoSort[j-1] = temp;\n        }\n    }\n}\n```\n\n### 4.3 延伸\n\n冒泡排序缺陷：\n\n1.  在排序过程中，执行完当前的第i趟排序后，可能数据已全部排序完备，但是程序无法判断是否完成排序，会继续执行剩下的`(n-1-i)`趟排序。解决方法： 设置一个`flag`位, 如果一趟无元素交换，则 `flag = 0`; 以后再也不进入第二层循环。\n\n2.  当排序的数据比较多时排序的时间会明显延长，因为会比较 `n*(n-1)/2`次。\n\n## 5. 堆排序\n\n### 5.1 性能分析\n\n时间复杂度 `O(nlogn)`, 空间复杂度`O(1)`. 从这一点就可以看出，堆排序在时间上类似归并，但是它又是一种原地排序，时间复杂度小于归并的`O(n+logn)`\n\n排序时间与输入无关，最好，最差，平均都是`O(nlogn)`. 不稳定\n\n堆排序借助了堆这个数据结构，堆类似二叉树，又具有堆积的性质（子节点的关键值总小于（大于）父节点）\n\n堆排序包括两个主要操作:\n\n1.  保持堆的性质heapify(A,i)\n\n时间复杂度`O(logn)`\n\n2.  建堆 buildmaxheap(A)\n\n时间复杂度`O(n)`线性时间建堆\n\n**对于大数据的处理**： 如果对100亿条数据选择Topk数据，选择快速排序好还是堆排序好？ 答案是只能用堆排序。 堆排序只需要维护一个k大小的空间，即在内存开辟k大小的空间。而快速排序需要开辟能存储100亿条数据的空间，which is impossible.\n\n### 5.2 核心代码\n\n```\npublic class HeapSort {\n    public void buildheap(int array[]){\n        int length = array.length;\n        int heapsize = length;\n        int nonleaf = length / 2 - 1;\n        for(int i = nonleaf; i&gt;=0;i--){\n            heapify(array,i,heapsize);\n        }\n    }\n\n    public void heapify(int array[], int i,int heapsize){\n        int smallest = i;\n        int left = 2*i+1;\n        int right = 2*i+2;\n        if(left&lt;heapsize){\n            if(array[i]&gt;array[left]){\n                smallest = left;\n            }\n            else smallest = i;\n        }\n        if(right&lt;heapsize){\n            if(array[smallest]&gt;array[right]){\n                smallest = right;\n            }\n        }\n        if(smallest != i){\n            int temp;\n            temp = array[i];\n            array[i] = array[smallest];\n            array[smallest] = temp;\n            heapify(array,smallest,heapsize);\n        }\n    }\n\n    public void heapsort(int array[]){\n        int heapsize = array.length;\n        buildheap(array);\n\n        for(int i=0;i&lt;array.length-1;i++){\n            // swap the first and the last\n            int temp;\n            temp = array[0];\n            array[0] = array[heapsize-1];\n            array[heapsize-1] = temp;\n            // heapify the array\n            heapsize = heapsize - 1;\n            heapify(array,0,heapsize);\n\n        }   \n    }\n```\n\n### 5.3 延伸\n\n堆这种数据结构的很好的应用是 优先级队列，如作业调度。\n\n## 6 快速排序\n\n### 6.1 性能分析\n\n时间复杂度 `O(nlogn)`  空间复杂度`O（logn）` 不稳定 【两个时间复杂度`O(nlogn)` 的排序算法都不稳定】\n\n时间复杂度：\n\n最坏`O（n^2）` 当**划分不均匀**时候 逆序and排好序都是最坏情况\n\n最好`O（n）` 当划分均匀`partition`的时间复杂度: `O（n）`一共需要`logn`次`partition`\n\n空间复杂度：递归造成的栈空间的使用，最好情况，递归树的深度`logn` 空间复杂的`logn`，最坏情况，需要进行`n‐1` 递归调用，其空间复杂度为 `O(n)`，平均情况，空间复杂度也为`O(log2n)`。\n\n由于关键字的比较和交换是跳跃进行的，因此，快速排序是一种不稳定的排序方法。\n\n快速排序的每一轮就是将这一轮的基准数归位，直到所有的数都归为为止，排序结束。（类似冒泡）.\n\npartition是返回一个基准值的index, index 左边都小于该index的数，右边都大于该index的数。\n\n快速排序之所比较快，因为相比冒泡排序，每次交换是跳跃式的。每次排序的时候设置一个基准点，将小于等于基准点的数全部放到基准点的左边，将大于等于基准点的数全部放到基准点的右边。这样在每次交换的时候就不会像冒泡排序一样每次只能在相邻的数之间进行交换，交换的距离就大的多了。因此总的比较和交换次数就少了，速度自然就提高了。当然在最坏的情况下，仍可能是相邻的两个数进行了交换。因此快速排序的最差时间复杂度和冒泡排序是一样的都是 `O(n^2)`，它的平均时间复杂度为 `O(nlogn)`。其实快速排序是基于 “二分” 的思想。\n\n### 6.2 核心代码\n\n```\npublic class Quicksort {\n       public int partition(int A[], int begin, int end){\n             int i = begin;\n             int j = end;\n             int q;\n             int pivot = begin;\n             int pivotnumber = A[pivot];\n             while(i!=j){\n                   int temp;\n                   while(A[j]&gt;pivotnumber &amp;&amp; i&lt;j){\n                        j--;\n\n                  }\n                   while(A[i]&lt;=pivotnumber &amp;&amp; i&lt;j)\n                  {\n                        i++;\n                  }\n                  temp = A[i];\n                  A[i] = A[j];\n                  A[j] = temp;\n            }\n\n             if(i == j){\n                   int temp;\n                  temp =A[pivot];\n                  A[pivot] = A[i];\n                  A[i] = temp;      \n            }\n             return i;\n      }\n       public void sort(int A[], int begin,int end){\n             if(begin&lt;end){\n                   int q;\n                  q = partition(A,begin, end);\n                  sort(A,begin, q-1);\n                  sort(A,q+1,end);\n            }     \n      }\n       public static void main(String[] args) {\n             int array[] = {8,7,1,6,5,4,3,2};\n            Quicksort s = new Quicksort();\n            s.sort(array, 0, 7);\n             for(int i=0;i&lt;array.length;i++){\n                  System. out.println(\"output \" + array[i]);\n            }\n      }\n}\n```\n\n**非比较排序**： ，计数排序，基数排序，桶排序，时间复杂度能够达到`O(n)`.  这些排序为了达到不比较的目的，对数据做了一些基本假设（限制）。如计数排序假设数据都`[0,n]` 范围内，且范围较小；基数排序假设数据都`[0,n]` 范围内；也是桶排序假设数据均匀独立的分布。\n\n而且，非比较排序的空间要求比较高，用空间换取时间吧。当我们的待排序数组具备一些基数排序与桶排序要求的特性，且空间上又比较富裕时，桶排序与基数排序不失为最佳选择。\n\n## 7. 计数排序\n\n我们希望能线性的时间复杂度排序，如果一个一个比较，显然是不实际的，书上也在决策树模型中论证了，比较排序的情况为`nlogn` 的复杂度。既然不能一个一个比较，我们想到一个办法，就是如果**在排序的时候就知道他的位置，那不就是扫描一遍，把他放入他应该的位置**不就可以了。 要知道**他的位置，我们只需要知道有多少不大于他不就可以了**吗？\n\n### 7.1 性能分析\n\n最好，最坏，平均的时间复杂度`O(n+k)`, 天了噜， 线性时间完成排序，且稳定。\n\n优点：不需要比较函数，利用地址偏移，对范围固定在[0,k]的整数排序的最佳选择。是排序字节串最快的排序算法。\n\n缺点：由于用来计数的数组的长度取决于待排序数组中数据的范围（等于待排序数组的最大值与最小值的差加上1），这使得计数排序对于数据范围很大的数组，需要大量时间和内存。\n\n### 7.2 核心代码\n\n```\npublic int[] countsort(int A[]){\n    int[] B = new int[A.length]; //to store result after sorting\n    int k = max(A);\n    int [] C = new int[k+1]; // to store temp\n    for(int i=0;i&lt;A.length;i++){    \n        C[A[i]] = C[A[i]] + 1;\n    }\n    // 小于等于A[i]的数的有多少个, 存入数组C\n    for(int i=1;i&lt;C.length;i++){\n        C[i] = C[i] + C[i-1];\n    }\n    //逆序输出确保稳定-相同元素相对顺序不变\n    for(int i=A.length-1;i&gt;=0;i--){\n\n        B[C[A[i]]-1] = A[i]; \n        C[A[i]] = C[A[i]]-1;\n    }\n    return B;\n}\n```\n\n### 7.3 扩展\n\n请给出一个算法，使之对给定的介于 `0`到 `k` 之间的 `n`个整数进行预处理，并能在`O(1)` 时间内回答出输入的整数中有多少个落在 `[a...b]` 区间内。你给出的算法的预处理时间为`O(n+k)`。\n\n分析：就是用计数排序中的预处理方法，获得数组 `C[0...k`]，使得`C[i]`为不大于 `i`的元素的个数。这样落入 `[a...b]` 区间内的元素个数有 `C[b]-C[a-1]`。\n\n计数排序的重要性质是他是**稳定**的。一般而言，仅当卫星数据随着被排序的元素一起移动时，稳定性才显得比较重要。而这也是计数排序作为基数排序的子过程的重要原因\n\n## 8 基数排序\n\n为什么要用基数排序 ？\n\n计数排序和桶排序都只是在研究一个关键字的排序，现在我们来讨论有多个关键字的排序问题。\n\n假设我们有一些二元组`(a,b)`，要对它们进行以`a` 为首要关键字，`b`的次要关键字的排序。我们可以先把它们先按照首要关键字排序，分成首要关键字相同的若干堆。然后，在按照次要关键值分别对每一堆进行单独排序。最后再把这些堆串连到一起，使首要关键字较小的一堆排在上面。按这种方式的基数排序称为 **MSD(Most Significant Dight) 排序**。\n\n第二种方式是从最低有效关键字开始排序，称为 **LSD(Least Significant Dight)排序** 。首先对所有的数据按照次要关键字排序，然后对所有的数据按照首要关键字排序。要注意的是，使用的排序算法必须是稳定的，否则就会取消前一次排序的结果。由于不需要分堆对每堆单独排序，LSD 方法往往比 MSD 简单而开销小。下文介绍的方法全部是基于 LSD 的。\n\n通常，基数排序要用到计数排序或者桶排序。使用计数排序时，需要的是Order数组。使用桶排序时，可以用链表的方法直接求出排序后的顺序。\n\n![](/assets/images/2015/03/13/sort-algorithm-summary/001.png)\n\n### 8.1 性能分析\n\n时间复杂度`O（n）` (实际上是`O(d(n+k))` d是位数)\n\n### 8.2 核心代码\n\n```RADIX-SORT(A,d)\n    for i = 1 to d\n        do use a stable sort to sort array A on digit i\n```\n\n### 8.3扩展\n\n问题：对`[0,n^2-1]`的`n` 个整数进行线性时间排序。\n\n思路 ： 把整数转换为n进制再排序，每个数有两位，每位的取值范围是`[0..n-1]`，再进行基数排序\n\n[http://blog.csdn.net/mishifangxiangdefeng/article/details/7685839](http://blog.csdn.net/mishifangxiangdefeng/article/details/7685839)\n\n问题： 给定一个字符串数组，其中不同的串包含的字符数可能不同，但所有串中总的字符个数为 n。说明如何在 O(n) 时间内对该数组进行排序\n\n## 9. 桶排序\n\n桶排序的思想近乎彻底的分治思想。\n\n桶排序假设待排序的一组数**均匀独立**的分布在一个范围中，并将这一范围划分成几个子范围（桶）。\n\n然后基于某种映射函数`f` ，将待排序列的关键字 `k` 映射到第`i`个桶中 (即桶数组`B` 的下标`i`) ，那么该关键字`k` 就作为 `B[i]`中的元素 (每个桶`B[i]`都是一组大小为`N/M` 的序列 )。\n\n接着将各个桶中的数据有序的合并起来 : 对每个桶`B[i]` 中的所有元素进行比较排序 (可以使用快排)。然后依次枚举输出 `B[0]....B[M]` 中的全部内容即是一个有序序列。\n\n补充： 映射函数一般是 `f = array[i] / k`; `k^2 = n`; `n`是所有元素个数\n\n![](/assets/images/2015/03/13/sort-algorithm-summary/002.png)\n\n### 9.1 性能分析\n\n平均时间复杂度为线性的 `O(n+C)` 最优情形下，桶排序的时间复杂度为`O(n)`。\n\n桶排序的空间复杂度通常是比较高的，额外开销为`O(n+m)`（因为要维护 M 个数组的引用）。\n\n就是桶越多，时间效率就越高，而桶越多，空间却就越大，由此可见时间和空间是一个矛盾的两个方面。\n\n算法稳定性 : 桶排序的稳定性依赖于桶内排序。如果我们使用了快排，显然，算法是不稳定的。\n\n[一个讲bucket排序非常好的文章](http://hxraid.iteye.com/blog/647759)\n\n桶排序利用函数的映射关系，减少了几乎所有的比较工作。实际上，桶排序的 f(k) 值的计算，其作用就相当于快排中划分，已经把大量数据分割成了基本有序的数据块 (桶)。然后只需要对桶中的少量数据做先进的比较排序即可。\n\n对 N 个关键字进行桶排序的时间复杂度分为两个部分：\n\n(1) 循环计算每个关键字的桶映射函数，这个时间复杂度是 `O(n)`。\n\n(2) 利用先进的比较排序算法对每个桶内的所有数据进行排序，其时间复杂度为  `∑ O(ni*logni)` 。其中 `ni` 为第 `i`个桶的数据量。\n\n很显然，第 (2) 部分是桶排序性能好坏的决定因素。这就是一个时间代价和空间代价的权衡问题了。\n\n### 9.2 核心代码\n\n### 9.3扩展\n\n![](/assets/images/2015/03/13/sort-algorithm-summary/003.png)\n\n## in summary\n\n![](/assets/images/2015/03/13/sort-algorithm-summary/004.png)\n\n关于稳定性：\n\n*   选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法，\n*   冒泡排序、插入排序、归并排序和基数排序是稳定的排序算法。\n*   常用时间复杂度的大小关系：`O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n2)&lt;O(n3)&lt;O(2n)&lt;O(n!)&lt;O(nn)`\n\n---\n\n* Author: [SecondLife](https://segmentfault.com/u/secondlife)\n* Source: [SegmentFault](https://segmentfault.com)\n* 原文链接：[常用排序算法总结（性能+代码）](https://segmentfault.com/a/1190000002595152)\n","tags":["Performance"],"categories":["Algorithm"]},{"title":"大数据治理：为业务提供持续的、可度量的价值","url":"%2F2015%2F2015-03-05-bigdata-governance%2F","content":"\n面对我们身边每时每刻迅速增长的庞大数据，因为其数量大、速度快、种类多和准确性的特征，如何更好地利用大数据创造出有意义的价值，一直是我们探索的重要话题。而在这之前，就需要用科学正确的方法策略对大数据进行治理。大数据治理是指制定与大数据有关的数据优化、隐私保护与数据变现的政策，是传统信息治理的延续和扩展，也是大数据分析的基础，还是连接大数据科学和应用的桥梁，因此大数据治理是大数据再创高峰的“必修课”。下面我们将与您分享新鲜出炉的大数据治理方案。\n\n### 大数据治理系列\n\n本系列共分为七个部分，围绕大数据治理统一流程参考模型，并结合实际业务问题和 IBM 相应的产品解决方案展开叙述。\n\n**[第一部分: 大数据治理统一流程模型概述和明确元数据管理策略](http://www.ibm.com/developerworks/cn/data/library/bd-1503bigdatagovernance1/index.html \"第一部分: 大数据治理统一流程模型概述和明确元数据管理策略\")**\n\n为了更好地帮助企业进行大数据治理，笔者在 IBM 数据治理统一流程模型基础上结合在电信、金融、政府等行业进行大数据治理的经验，整理出了大数据治理统一流程参考模型。本文主要介绍了大数据治理的基本概念，以及结合图文并茂的方式讲解了大数据治理统一流程参考模型的前两步：“明确元数据管理策略”和“元数据集成体系结构”内容。\n\n**[第二部分：元数据集成体系结构](http://www.ibm.com/developerworks/cn/data/library/bd-1503bigdatagovernance2/index.html \"第二部分：元数据集成体系结构\")**\n\n在明确了元数据管理策略后需要确定实现该管理策略所需的技术体系结构，即元数据集成体系结构。元数据集成体系结构涉及到多个概念，如元模型、元-元模型、公共仓库元模型（CWM）等，本部分将继续介绍大数据治理统一流程参考模型第二步“元数据集成体系结构”的相关内容。\n\n**[第三部分：实施元数据管理](http://www.ibm.com/developerworks/cn/data/library/bd-1503bigdatagovernance3/index.html \"第三部分：实施元数据管理\")**\n\n了解了元数据管理策略和元数据集成体系结构之后，企业可以根据需要选择合适的业务元数据和技术元数据管理工具，并制定相应的元数据管理制度进行全面的元数据管理。本部分主要介绍大数据治理统一流程参考模型第三步“实施元数据管理”，元数据管理成熟度模型、IBM元数据管理相关工具等内容。\n\n**[第四部分：大数据治理统一流程参考模型的第四步到第九步](http://www.ibm.com/developerworks/cn/data/library/bd-1503bigdatagovernance4/index.html \"第四部分：大数据治理统一流程参考模型的第四步到第九步\")**\n\n如果想要成功地实施大数据治理计划，需要了解信息供应链中的各个环节的数据模型、主外键关系等。本部分主要介绍大数据治理统一流程参考模型第四步“定义业务问题”、第五步“获得主管支持”、第六步“执行成熟度评估”、第七步“构建路线图”、第八步“建立组织蓝图”和第九步“了解数据”等内容。\n\n**[第五部分：定义度量值和主数据监管](http://www.ibm.com/developerworks/cn/data/library/bd-1503bigdatagovernance5/index.html \"第五部分：定义度量值和主数据监管\")**\n\n数据治理需要全面的度量值或关键业务指标（KPI）来衡量和跟踪数据治理计划的进度，考核数据治理的效果。在大数据时代，通过建立大数据与主数据之间的映射关系可以有效地提高客户关系管理水平，提高客户满意度和忠诚度，提升销售业绩。本文主要介绍大数据治理统一流程参考模型的第十步“定义度量值”、第十一步“主数据监管”。\n\n**[第六部分：大数据监管和信息单一视图监管](http://www.ibm.com/developerworks/cn/data/library/bd-1503bigdatagovernance6/index.html \"第六部分：大数据监管和信息单一视图监管\")**\n\n在大数据时代，企业更需要数据治理，只有对海量数据进行治理，使其变得可信才能帮助企业获取准确、深入的洞察力。通过使用完整、及时、准确和一致的企业单一信息视图，企业高管们可以针对不同的情况及时采取措施，为了成功实现企业信息单一视图，对其进行监管就非常重要。本文将重点介绍大数据治理统一流程参考模型的第十二步“（狭义）大数据监管”、第十三步“信息单一视图监管”。\n\n**[第七部分：分析监管、安全与隐私管理和信息生命周期监管](http://www.ibm.com/developerworks/cn/data/library/bd-1503bigdatagovernance7/index.html \"第七部分：分析监管、安全与隐私管理和信息生命周期监管\")**\n\n过度的管理数据会带来成本的极大增加，需要在满足业务需求以及法律法规的前提下制定明确的保留时间表，积极采用压缩技术进行大数据的存储从而降低存储成本。此外，如何进行个人隐私保护也是是各个行业在大数据时代面临的一个巨大挑战。本文将介绍大数据治理统一流程参考模型的第十四步“运营分析监管”、第十五步“预测分析监管”、第十六步“管理安全与隐私”、第十七步“监管信息生命周期”和第十八步“度量结果”等内容。\n\n---\n\n* 原文链接：[大数据治理：为业务提供持续的、可度量的价值](http://www.ibm.com/developerworks/cn/bigdata/governance/index.html \"大数据治理：为业务提供持续的、可度量的价值\")\n","tags":["BigData"],"categories":["Data-Governance"]},{"title":"寻找一种易于理解的一致性算法（扩展版）","url":"%2F2015%2F2015-02-06-raft-zh_cn%2F","content":"\n## 摘要\n\nRaft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能，但是它的算法结构和 Paxos 不同，使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。从一个用户研究的结果可以证明，对于学生而言，Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性。\n\n## 1 介绍\n\n一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。正因为如此，一致性算法在构建可信赖的大规模软件系统中扮演着重要的角色。在过去的 10 年里，Paxos  算法统治着一致性算法这一领域：绝大多数的实现都是基于 Paxos 或者受其影响。同时 Paxos 也成为了教学领域里讲解一致性问题时的示例。\n\n但是不幸的是，尽管有很多工作都在尝试降低它的复杂性，但是 Paxos 算法依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。这些都导致了工业界和学术界都对 Paxos 算法感到十分头疼。\n\n和 Paxos 算法进行过努力之后，我们开始寻找一种新的一致性算法，可以为构建实际的系统和教学提供更好的基础。我们的做法是不寻常的，我们的首要目标是可理解性：我们是否可以在实际系统中定义一个一致性算法，并且能够比 Paxos 算法以一种更加容易的方式来学习。此外，我们希望该算法方便系统构建者的直觉的发展。不仅一个算法能够工作很重要，而且能够显而易见的知道为什么能工作也很重要。\n\nRaft 一致性算法就是这些工作的结果。在设计 Raft 算法的时候，我们使用一些特别的技巧来提升它的可理解性，包括算法分解（Raft 主要被分成了领导人选举，日志复制和安全三个模块）和减少状态机的状态（相对于 Paxos，Raft 减少了非确定性和服务器互相处于非一致性的方式）。一份针对两所大学 43 个学生的研究表明 Raft 明显比 Paxos 算法更加容易理解。在这些学生同时学习了这两种算法之后，和 Paxos 比起来，其中 33 个学生能够回答有关于 Raft 的问题。\n\nRaft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication），但是它也有一些独特的特性：\n\n* **强领导者**：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导者发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。\n* **领导选举**：Raft 算法使用一个随机计时器来选举领导者。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。\n* **成员关系调整**：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。\n\n我们相信，Raft 算法不论出于教学目的还是作为实践项目的基础都是要比 Paxos 或者其他一致性算法要优异的。它比其他算法更加简单，更加容易理解；它的算法描述足以实现一个现实的系统；它有好多开源的实现并且在很多公司里使用；它的安全性已经被证明；它的效率和其他算法比起来也不相上下。\n\n接下来，这篇论文会介绍以下内容：复制状态机问题（第 2 节），讨论 Paxos 的优点和缺点（第 3 节），讨论我们为了理解能力而使用的方法（第 4 节），阐述 Raft 一致性算法（第 5-8 节），评价 Raft 算法（第 9 节），以及一些相关的工作（第 10 节）。\n\n## 2 复制状态机\n\n一致性算法是从复制状态机的背景下提出的（参考英文原文引用37）。在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导者，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。\n\n![图 1 ](/assets/images/2015/02/06/raft-zh_cn/001.png)\n\n> 图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。\n\n复制状态机通常都是基于复制日志实现的，如图 1。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。\n\n保证复制日志相同就是一致性算法的工作了。在一台服务器上，一致性模块接收客户端发送来的指令然后增加到自己的日志中去。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，尽管有些服务器会宕机。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成一个高可靠的状态机。\n\n实际系统中使用的一致性算法通常含有以下特性：\n\n* 安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、冗余和乱序等错误都可以保证正确。\n* 可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。他们当有稳定的存储的时候可以从状态中恢复回来并重新加入集群。\n* 不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟在可能只有在最坏情况下才会导致可用性问题。\n* 通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。\n\n## 3 Paxos算法的问题\n\n在过去的 10 年里，Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法，同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性，同时也支持集群成员关系的变更。Paxos 的正确性已经被证明，在通常情况下也很高效。\n\n不幸的是，Paxos 有两个明显的缺点。第一个缺点是 Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后，也只有少数人成功理解了这个算法。因此，有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题，但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示，很少有人对 Paxos 算法感到满意，甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后，这一过程花了近一年时间。\n\n我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的，它被划分成了两种没有简单直观解释和无法独立理解的情景。因此，这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信，在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。\n\nPaxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法，但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试，但是他们都互相不一样，和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法，但是大多数的细节并没有被公开。\n\n而且，Paxos 算法的结构也不是十分易于构建实践的系统；单决策分解也会产生其他的结果。例如，独立的选择一组日志条目然后合并成一个序列化的日志并没有带来太多的好处，仅仅增加了不少复杂性。围绕着日志来设计一个系统是更加简单高效的；新日志条目以严格限制的顺序增添到日志中去。另一个问题是，Paxos 使用了一种对等的点对点的方式作为它的核心（尽管它最终提议了一种弱领导人的方法来优化性能）。在只有一个决策会被制定的简化世界中是很有意义的，但是很少有现实的系统使用这种方式。如果有一系列的决策需要被制定，首先选择一个领导人，然后让他去协调所有的决议，会更加简单快速。\n\n因此，实际的系统中很少有和 Paxos 相似的实践。每一种实现都是从 Paxos 开始研究，然后发现很多实现上的难题，再然后开发了一种和 Paxos 明显不一样的结构。这样非常费时和容易出错的，并且理解 Paxos 的难度是的这个问题更加糟糕。Paxos 算法在理论上被证明是正确可行的，但是现实的系统和 Paxos 差别是如此的大，以至于这些证明没有什么太大的价值。下面来自 Chubby 实现非常典型：\n\n> 在Paxos算法描述和实现现实系统中间有者巨大的鸿沟。最终的系统建立在一种没有经过证明的算法之上。\n\n由于以上问题，我们认为 Paxos 算法既没有提供一个良好的基础给实践的系统，也没有给教学很好的帮助。基于一致性问题在大规模软件系统中的重要性，我们决定看看我们是否可以设计一个拥有更好特性的替代 Paxos 的一致性算法。Raft算法就是这次实验的结果。\n\n## 4 为了可理解性的设计\n\n设计 Raft 算法我们有几个初衷：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在大多数的情况下都是可用的；并且它的大部分操作必须是高效的。但是我们最重要也是最大的挑战是可理解性。它必须保证对于普遍的人群都可以十分容易的去理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行必然的扩展。\n\n在设计 Raft 算法的时候，有很多的点需要我们在各种备选方案中进行选择。在这种情况下，我们评估备选方案基于可理解性原则：解释各个备选方案有多大的难度（例如，Raft 的状态空间有多复杂，是否有微妙的暗示）？对于一个读者而言，完全理解这个方案和暗示是否容易？\n\n我们意识到对这种可理解性分析上具有高度的主观性；尽管如此，我们使用了两种通常适用的技术来解决这个问题。第一个技术就是众所周知的问题分解：只要有可能，我们就将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成领导人选举，日志复制，安全性和角色改变几个部分。\n\n我们使用的第二个方法是通过减少状态的数量来简化需要考虑的状态空间，使得系统更加连贯并且在可能的时候消除不确定性。特别的，所有的日志是不允许有空洞的，并且 Raft 限制了日志之间变成不一致状态的可能。尽管在大多数情况下我们都试图去消除不确定性，但是也有一些情况下不确定性可以提升可理解性。尤其是，随机化方法增加了不确定性，但是他们有利于减少状态空间数量，通过处理所有可能选择时使用相似的方法。我们使用随机化去简化 Raft 中领导人选举算法。\n\n## 5 Raft 一致性算法\n\nRaft 是一种用来管理章节 2 中描述的复制日志的算法。图 2 为了参考之用，总结这个算法的简略版本，图 3 列举了这个算法的一些关键特性。图中的这些元素会在剩下的章节逐一介绍。\n\nRaft 通过选举一个高贵的领导人，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目，把日志条目复制到其他服务器上，并且当保证安全性的时候告诉其他的服务器应用日志条目到他们的状态机中。拥有一个领导人大大简化了对复制日志的管理。例如，领导人可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从领导人流向其他服务器。一个领导人可以宕机，可以和其他服务器失去连接，这时一个新的领导人会被选举出来。\n\n通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题会在接下来的子章节中进行讨论：\n\n* **领导选举**：一个新的领导人需要被选举出来，当现存的领导人宕机的时候（章节 5.2）\n* **日志复制**：领导人必须从客户端接收日志然后复制到集群中的其他节点，并且强制要求其他节点的日志保持和自己相同。\n* **安全性**：在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；这个解决方案涉及到一个额外的选举机制（5.2 节）上的限制。\n\n在展示一致性算法之后，这一章节会讨论可用性的一些问题和系统中的候选人角色的问题。\n\n**状态**：\n\n|状态|所有服务器上持久存在的|\n|-------|------|\n|currentTerm | 服务器最后一次知道的任期号（初始化为 0，持续递增）|\n|votedFor | 在当前获得选票的候选人的 Id|\n| log[] | 日志条目集；每一个条目包含一个用户状态机执行的指令，和收到时的任期号 |\n\n|状态|所有服务器上经常变的|\n|-------|------|\n| commitIndex| 已知的最大的已经被提交的日志条目的索引值|\n| lastApplied| 最后被应用到状态机的日志条目索引值（初始化为 0，持续递增）|\n\n| 状态 | 在领导人里经常改变的 （选举后重新初始化）|\n|----|--------|\n| nextIndex[] | 对于每一个服务器，需要发送给他的下一个日志条目的索引值（初始化为领导人最后索引值加一）|\n| matchIndex[] | 对于每一个服务器，已经复制给他的日志的最高索引值|\n\n\n**附加日志 RPC**：\n\n由领导人负责调用来复制日志指令；也会用作heartbeat\n\n| 参数 | 解释 |\n|----|----|\n|term| 领导人的任期号|\n|leaderId| 领导人的 Id，以便于跟随者重定向请求|\n|prevLogIndex|新的日志条目紧随之前的索引值|\n|prevLogTerm|prevLogIndex 条目的任期号|\n|entries[]|准备存储的日志条目（表示心跳时为空；一次性发送多个是为了提高效率）\n|leaderCommit|领导人已经提交的日志的索引值|\n\n| 返回值| 解释|\n|---|---|\n|term|当前的任期号，用于领导人去更新自己|\n|success|跟随者包含了匹配上 prevLogIndex 和 prevLogTerm 的日志时为真|\n\n接收者实现：\n\n1. 如果 `term < currentTerm` 就返回 false （5.1 节）\n2. 如果日志在 prevLogIndex 位置处的日志条目的任期号和 prevLogTerm 不匹配，则返回 false （5.3 节）\n3. 如果已经存在的日志条目和新的产生冲突（索引值相同但是任期号不同），删除这一条和之后所有的 （5.3 节）\n4. 附加任何在已有的日志中不存在的条目\n5. 如果 `leaderCommit > commitIndex`，令 commitIndex 等于 leaderCommit 和 新日志条目索引值中较小的一个\n\n**请求投票 RPC**：\n\n由候选人负责调用用来征集选票（5.2 节）\n\n| 参数 | 解释|\n|---|---|\n|term| 候选人的任期号|\n|candidateId| 请求选票的候选人的 Id |\n|lastLogIndex| 候选人的最后日志条目的索引值|\n|lastLogTerm| 候选人最后日志条目的任期号|\n\n| 返回值| 解释|\n|---|---|\n|term| 当前任期号，以便于候选人去更新自己的任期号|\n|voteGranted| 候选人赢得了此张选票时为真|\n\n接收者实现：\n\n1. 如果`term < currentTerm`返回 false （5.2 节）\n2. 如果 votedFor 为空或者就是 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他（5.2 节，5.4 节）\n\n**所有服务器需遵守的规则**：\n\n所有服务器：\n\n* 如果`commitIndex > lastApplied`，那么就 lastApplied 加一，并把`log[lastApplied]`应用到状态机中（5.3 节）\n* 如果接收到的 RPC 请求或响应中，任期号`T > currentTerm`，那么就令 currentTerm 等于 T，并切换状态为跟随者（5.1 节）\n\n跟随者（5.2 节）：\n\n* 响应来自候选人和领导者的请求\n* 如果在超过选举超时时间的情况之前都没有收到领导人的心跳，或者是候选人请求投票的，就自己变成候选人\n\n候选人（5.2 节）：\n\n* 在转变成候选人后就立即开始选举过程\n\t* 自增当前的任期号（currentTerm）\n\t* 给自己投票\n\t* 重置选举超时计时器\n\t* 发送请求投票的 RPC 给其他所有服务器\n* 如果接收到大多数服务器的选票，那么就变成领导人\n* 如果接收到来自新的领导人的附加日志 RPC，转变成跟随者\n* 如果选举过程超时，再次发起一轮选举\n\n领导人：\n\n* 一旦成为领导人：发送空的附加日志 RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以阻止跟随者超时（5.2 节）\n*  如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端（5.3 节）\n*  如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex，那么：发送从 nextIndex 开始的所有日志条目：\n\t* 如果成功：更新相应跟随者的 nextIndex 和 matchIndex\n\t* 如果因为日志不一致而失败，减少 nextIndex 重试\n* 如果存在一个满足`N > commitIndex`的 N，并且大多数的`matchIndex[i] ≥ N`成立，并且`log[N].term == currentTerm`成立，那么令 commitIndex 等于这个 N （5.3 和 5.4 节）\n\n> 图 2：一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）。\n\n| 特性| 解释|\n|---|---|\n|选举安全特性| 对于一个给定的任期号，最多只会有一个领导人被选举出来（5.2 节）|\n|领导人只附加原则| 领导人绝对不会删除或者覆盖自己的日志，只会增加（5.3 节）|\n|日志匹配原则| 如果两个日志在相同的索引位置的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置之间全部完全相同（5.3 节）\n|领导人完全特性|如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（5.4 节）|\n|状态机安全特性| 如果一个领导人已经在给定的索引值位置的日志条目应用到状态机中，那么其他任何的服务器在这个索引位置不会提交一个不同的日志（5.4.3 节）|\n\n> 图 3：Raft 在任何时候都保证以上的各个特性。\n\n\n### 5.1 Raft 基础\n\n一个 Raft 集群包含若干个服务器节点；通常是 5 个，这允许整个系统容忍 2 个节点的失效。在任何时刻，每一个服务器节点都处于这三个状态之一：领导人、跟随者或者候选人。在通常情况下，系统中只有一个领导人并且其他的节点全部都是跟随者。跟随者都是被动的：他们不会发送任何请求，只是简单的响应来自领导者或者候选人的请求。领导人处理所有的客户端请求（如果一个客户端和跟随者联系，那么跟随者会把请求重定向给领导人）。第三种状态，候选人，是用来在 5.2 节描述的选举新领导人时使用。图 4 展示了这些状态和他们之前转换关系；这些转换关系会在接下来进行讨论。\n\n![图 4 ](/assets/images/2015/02/06/raft-zh_cn/002.png)\n\n> 图 4：服务器状态。跟随者只响应来自其他服务器的请求。如果跟随者接收不到消息，那么他就会变成候选人并发起一次选举。获得集群中大多数选票的候选人将成为领导者。在一个任期内,领导人一直都会是领导人直到自己宕机了。\n\n![图 5](/assets/images/2015/02/06/raft-zh_cn/003.png)\n\n> 图 5：时间被划分成一个个的任期，每个任期开始都是一次选举。在选举成功后，领导人会管理整个集群直到任期结束。有时候选举会失败，那么这个任期就会没有领导人而结束。任期之间的切换可以在不同的时间不同的服务器上观察到。\n\nRaft 把时间分割成任意长度的**任期**，如图 5。任期用连续的整数标记。每一段任期从一次**选举**开始，就像章节 5.2 描述的一样，一个或者多个候选人尝试成为领导者。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人的职责。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导者。\n\n不同的服务器节点可能多次观察到任期之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用，这会允许服务器节点查明一些过期的信息比如陈旧的领导者。每一个节点存储一个当前任期号，这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。如果一个候选人或者领导者发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。\n\nRaft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起（章节  5.2），然后附加条目（AppendEntries）RPCs 由领导人发起，用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPCs 来获得最佳的性能。\n\n### 5.2 领导人选举\n\nRaft 使用一种心跳机制来触发领导人选举。当服务器程序启动时，他们都是跟随者身份。一个服务器节点继续保持着跟随者状态如果他从领导人或者候选者处接收到有效的 RPCs。领导者周期性的向所有跟随者发送心跳包（不包含日志项内容的附加日志项 RPCs）来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息，也就是**选举超时**，然后他就会认为系统中没有可用的领导者然后开始进行选举以选出新的领导者。\n\n要开始一次选举过程，跟随者先要增加自己的当前任期号并且转换到候选人状态。然后他会并行的向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生：(a) 他自己赢得了这次的选举，(b) 其他的服务器成为领导者，(c) 一段时间之后没有任何一个获胜的人。这些结果会分别的在下面的段落里进行讨论。\n\n当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票，那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则（注意：5.4 节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举（图 3 中的选举安全性）。一旦候选人赢得选举，他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止新的领导人的产生。\n\n在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加日志项 RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。\n\n第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。\n\nRaft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在下次选举之前一直等待；这样减少了在新的选举中另外的选票瓜分的可能性。9.3 节展示了这种方案能够快速的选出一个领导人。\n\n选举是一个用来展示在选择设计替代方案的时候可理解性是如何指导我们的例子。起初我们计划使用一种排名系统：每一个候选人都被赋予一个唯一的排名，排名用来在候选人之间竞争时进行选择。如果一个候选人发现另一个候选人拥有更高的排名，那么他就会回到跟随者状态，这样高排名的候选人能够更加容易的赢得下一次选举。但是我们发现这种方法在可用性方面会有一点问题（一个低排名的服务器可能会再次的超时并成为候选人当高排名的服务器宕机时，但是如果他这么做太快，他会重置掉一个选举过程）。我们针对算法进行了多次调整，但是每次调整之后都会有新的问题。最终我们认为随机重试的方法是更加明显和易于理解的。\n\n### 5.3 日志复制\n\n一旦一个领导人被选举出来，他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导人把这条指令作为一条新的日志条目附加到日志中去，然后并行的发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当这条日志条目被安全的复制（下面会介绍），领导人会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。\n\n![图 6](/assets/images/2015/02/06/raft-zh_cn/004.png)\n\n> 图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全的被应用到状态机中去的时候，就认为是可以提交了。\n\n日志以图 6 展示的方式组织。每一个日志条目存储一条状态机指令和从领导人收到这条指令时的任期号。在日志中的任期号是用来检查不一致情况，同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。\n\n领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为**已提交**。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。在领导人将创建的日志条目复制到大多数的服务器上的时候，日志条目就会被提交（例如在图 6 中的条目 7）。同时，领导人的日志中之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。5.4 节会讨论某些当在领导人改变之后应用这条规则的隐晦内容，同时他也展示了这种提交的定义是安全的。领导人跟踪了最大的将会被提交的日志项的索引，并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包），这样其他的服务器才能最终知道领导人的提交位置。一旦跟随者知道一条日志条目已经被提交，那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。\n\n我们设计了 Raft 的日志机制来维护一个不同服务器的日志之间的高层次的一致性。这么做不仅简化了系统的行为也使得更加可预计，同时他也是安全性保证的一个重要组件。Raft 维护着以下的特性，这些同时也组成了图 3 中的日志匹配特性：\n\n* 如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。\n* 如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。\n\n第一个特性来自这样的一个事实，领导人最多在一个任期里在指定的一个日志索引位置创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候，领导人会把新的日志条目紧接着之前的条目的索引位置和任期号包含在里面。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝接收新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查保护了日志匹配特性当日志扩展的时候。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的了。\n\n![图 7](/assets/images/2015/02/06/raft-zh_cn/005.png)\n\n> 图 7：当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能这样发生，那个服务器在任期 2 的时候是领导人，附加了一些日志条目到自己的日志中，在提交之前就崩溃了；很快这个机器就重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在这些任期 2 和任期 3 重点日志被提交之前，这个服务器又宕机了，然后的几个任期里一直处于宕机状态。\n\n在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在一系列的领导人和跟随者崩溃的情况下加剧。图 7 展示了跟随者的日志可能和新的领导人不同的方式。跟随者可能会丢失一些在新的领导人中有的日志条目，他也可能拥有一些领导人没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。\n\n在 Raft 算法中，领导人处理不一致是通过强制跟随者直接复制自己的日志来解决了。这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。5.4 节会阐述如何通过增加一些限制来使得这样的操作是安全的。\n\n要使得跟随者的日志进入和自己一致的状态，领导人必须找到最后两者达成一致的地方，然后删除从那个点之后的所有日志条目，发送自己的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导人针对每一个跟随者维护了一个 **nextIndex**，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候，他初始化所有的 nextIndex 值为自己的最后一条日志的index加1（图 7 中的 11）。如果一个跟随者的日志和领导人不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。\n\n如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以包含冲突的条目的任期号和自己存储的那个任期的最早的索引地址。借助这些信息，领导人可以减小 nextIndex 越过所有那个任期冲突的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。\n\n通过这种机制，领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作，然后日志就能自动的在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导人从来不会覆盖或者删除自己的日志（图 3 的领导人只附加特性）。\n\n日志复制机制展示出了第 2 节中形容的一致性特性：Raft 能够接受，复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下，新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。\n\n### 5.4 安全性\n\n前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而，到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。\n\n这一节通过在领导选举的时候增加一些限制来完善了 Raft 算法。这一限制保证了任何的领导人对于给定的任期号，都拥有了之前任期的所有被提交的日志条目（图 3 中的领导人完整特性）。增加这一选举时的限制，我们对于提交时的规则也更加清晰。最终，我们展示对于领导人完整特性的简要证明并且说明领导人是如何领导复制状态机的正确行为的。\n\n#### 5.4.1 选举限制\n\n在任何基于领导人的一致性算法中，领导人都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication，一个人可以被选举为领导人即使他一开始并没有包含所有已经提交的日志条目。这种算法包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导人，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证所有之前的任期号中已经提交的日志条目在选举的时候都会出现在新的领导人中，不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的，只从领导人传给跟随者，并且领导人从不会覆盖本地日志中已经存在的条目。\n\nRaft 使用投票的方式来阻止候选人赢得选举除非这个候选人包含了所有已经提交的日志条目。候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目肯定在这些服务器节点中至少存在一个上面。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。请求投票 RPC 实现了这样的限制： RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。\n\nRaft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。\n\n#### 5.4.2 提交之前任期内的日志条目\n\n如同 5.3 节介绍的那样，领导人知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况，一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导人覆盖掉。\n\n![图 8](/assets/images/2015/02/06/raft-zh_cn/006.png)\n\n> 图 8：如图的时间序列展示了为什么领导人无法通过老的日志的任期号来判断其提交状态。在 (a) 中，S1 是领导者，部分的复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。但是，在崩溃之前，如果 S1 在自己的任期里复制了日志条目到大多数机器上，如 (e) 中，然后这个条目就会被提交（S5 就不可能选举成功）。 在这个时候，之前的所有日志就会被正常提交处理。\n\n为了消除图 8 里描述的情况，Raft 通过计算副本数目的方式，使得永远不会提交一个之前任期内的日志条目。通过计算副本数目，只有领导人当前任期里的日志条目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。\n\n当领导人复制之前任期里的日志时，Raft 会在提交规则上产生额外的复杂性是因为所有的日志条目都保留原始的任期号。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易判断出日志，因为他们全程都使用同一个任期号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来给他们重新编号）。\n\n#### 5.4.3 安全性论证\n\n在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到该领导人未来某个任期的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。\n\n![图 9](/assets/images/2015/02/06/raft-zh_cn/006.png)\n\n> 图 9：如果 S1 （任期 T 的领导者）提交了一条新的日志在它的任期里，然后 S5 在之后的任期 U 里被选举为领导人，然后至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。\n\n1. 在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。\n2. 领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人T 的日志条目，并且给领导人U 投票了，如图 9。这个投票者是产生这个矛盾的关键。\n3. 这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。\n4. 投票者在给领导人 U 投票时依然保有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有和领导人冲突的时候才会删除条目。\n5. 投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。\n6. 首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。\n7. 除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交当然日志，这里产生矛盾。\n8. 这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。\n9. 日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (d) 中的索引 2。\n\n通过领导人完全特性，我们就能证明图 3 中的状态机安全特性，即如果已经服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。\n\n最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。\n\n### 5.5 跟随者和候选人崩溃\n\n到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单的通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。\n\n### 5.6 时间和可用性\n\nRaft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换在服务器崩溃时花费更多的时间，候选人将不会等待太长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。\n\n领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举出并维持一个稳定的领导人除非整个系统满足下面的时间要求：\n\n> 广播时间（broadcastTime）  <<  选举超时时间（electionTimeout） <<  平均故障间隔时间（MTBF）\n\n在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统上是很小的情况。\n\n广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。\n\n## 6 集群成员变化\n\n到目前为止，我们都假设集群的配置（加入到一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔是会改变集群的配置的，例如替换那些宕机的机器或者改变复制级别。尽管可以通过暂停整个集群，更新所有配置，然后重启整个集群的方式来实现，但是在更改的时候集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定自动化配置改变并且将其纳入到 Raft 一致性算法中来。\n\n为了让配置修改机制能够安全，那么在转换的过程中不能够存在任何时间点使得两个领导人同时被选举成功在同一个任期里。不幸的是，任何服务器直接从旧的配置直接转换到新的配置的方案都是不安全的。一次性自动的转换所有服务器是不可能的，所以在转换期间整个集群存在划分成两个独立的大多数群体的可能性（见图 10）。\n\n![图 10](/assets/images/2015/02/06/raft-zh_cn/007.png)\n\n> 图 10：直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。\n\n为了保证安全性，配置更改必须使用两阶段方法。目前有很多种两阶段的实现。例如，有些系统在第一阶段停掉旧的配置所以集群就不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合：\n\n* 日志条目被复制给集群中新、老配置的所有服务器。\n* 新、旧配置的服务器都可以成为领导人。\n* 达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。\n\n共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程人依然响应服务器请求。\n\n集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置转换的过程。当一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论他是否已经被提交）。这意味着领导人要使用  C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。如果领导人崩溃了，被选出来的新领导人可能是使用 C-old 配置也可能是 C-old,new 配置，这取决于赢得选举的候选人是否已经接收到了 C-old,new 配置。在任何情况下， C-new 配置在这一时期都不会单方面的做出决定。\n\n一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new，在没有经过他人批准的情况下都不可能做出决定，并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。这个时候，领导人创建一条关于 C-new 配置的日志条目并复制给集群就是安全的了。再者，每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新的配置的服务器就可以被关闭了。如图 11，C-old 和 C-new 没有任何机会同时做出单方面的决定；这保证了安全性。\n\n![图 11](/assets/images/2015/02/06/raft-zh_cn/008.png)\n\n> 图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的条目，实线表示最后被提交的日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old,new 的大多数和  C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在  C-new 和 C-old 可以同时做出决定的时间点。\n\n在关于重新配置还有三个问题需要提出。第一个问题是，新的服务器可能初始化没有存储任何的日志条目。当这些服务器以这种状态加入到集群中，那么他们需要一段时间来更新追赶，这时还不能提交新的日志条目。为了避免这种可用性的间隔时间，Raft 在配置更新的时候使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们，但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器，重新配置可以像上面描述的一样处理。\n\n第二个问题是，集群的领导人可能不是新配置的一员。在这种情况下，领导人就会在提交了 C-new 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间，领导人管理着集群，但是不包括他自己；他复制日志但是不把他自己算作是大多数之一。当 C-new 被提交时，会发生领导人过渡，因为这时是最早新的配置可以独立工作的时间点（将总是能够在 C-new 配置下选出新的领导人）。在此之前，可能只能从 C-old 中选出领导人。\n\n第三个问题是，移除不在 C-new 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时，他们就会进行新的选举过程。他们会发送拥有新的任期号的请求投票 RPCs，这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致整体可用性大幅降低。\n\n为了避免这个问题，当服务器确认当前领导人存在时，服务器会忽略请求投票 RPCs。特别的，当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群，那么他就不会被更大的任期号废黜。\n\n## 7 日志压缩\n\nRaft 的日志在正常操作中不断的增长，但是在实际的系统中，日志不能无限制的增长。随着日志不断增长，他会占用越来越多的空间，花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息，那么会带来可用性问题。\n\n快照是最简单的压缩方法。在快照系统中，整个系统的状态都以快照的形式写入到稳定的持久化存储中，然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。\n\n增量压缩的方法，例如日志清理或者日志结构合并树，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口，但是日志清除方法就需要修改 Raft 了。\n\n![图 12](/assets/images/2015/02/06/raft-zh_cn/009.png)\n\n> 图 12：一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。\n\n图 12 展示了 Raft 中快照的基础思想。每个服务器独立的创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：**最后被包含索引**指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），**最后被包含的任期**指的是该条目的任期号。保留这些数据是为了支持快照前的第一个条目的附加日志请求时的一致性检查，因为这个条目需要最后的索引值和任期号。为了支持集群成员更新（第 6 节），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。\n\n尽管通常服务器都是独立的创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。\n\n**安装快照 RPC**：\n\n在领导人发送快照给跟随者时使用到。领导人总是按顺序发送。\n\n| 参数 | 解释 |\n|----|----|\n| term | 领导人的任期号 |\n| leaderId | 领导人的 Id，以便于跟随者重定向请求 |\n| lastIncludedIndex | 快照中包含的最后日志条目的索引值 |\n| lastIncludedTerm | 快照中包含的最后日志条目的任期号 |\n| offset | 分块在快照中的偏移量 |\n| data[] | 原始数据 |\n| done | 如果这是最后一个分块则为 true |\n\n| 结果 | 解释 |\n|----|----|\n| term | 当前任期号，便于领导人更新自己 |\n\n**接收者实现**：\n\n1. 如果`term < currentTerm`就立即回复\n2. 如果是第一个分块（offset 为 0）就创建一个新的快照\n3. 在指定偏移量写入数据\n4. 如果 done 是 false，则继续等待更多的数据\n5. 保存快照文件，丢弃索引值小于快照的日志\n6. 如果现存的日志拥有相同的最后任期号和索引值，则后面的数据继续保持\n7. 丢弃整个日志\n8. 使用快照重置状态机\n\n> 图 13：一个关于安装快照的简要概述。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生命的迹象，所以跟随者可以重置选举超时计时器。\n\n\n在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种  RPC 接收到快照时，他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者直接丢弃他所有的日志；这些会被快照所取代，但是可能会和没有提交的日志产生冲突。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照之后的条目必须正确和保留。\n\n这种快照的方式背离了 Raft 的强领导人原则，因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织他们的数据了。\n\n我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。\n\n还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，他就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。\n\n第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。\n\n## 8 客户端交互\n\n这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。\n\nRaft 中的客户端发送所有请求给领导人。当客户端启动的时候，他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。\n\n我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在他调用和收到回复之间）。但是，如上述，Raft 是可以执行同一条命令多次的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。\n\n只读的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回脏数据的风险，因为领导人响应客户端请求时可能已经被新的领导人作废了，但是他还不知道。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候，他可能不知道那些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。可选的，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。\n\n## 9 算法实现和评估\n\n我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分，并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码，其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现，针对不同的开发场景。同时，很多公司已经部署了基于 Raft 的系统。\n\n这一节会从三个方面来评估 Raft 算法：可理解性、正确性和性能。\n\n### 9.1 可理解性\n\n为了和 Paxos 比较 Raft 算法的可理解能力，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程，并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文的所有内容除了日志压缩；Paxos 讲课包含了足够的资料来创建一个等价的复制状态机，包括单决策 Paxos，多决策 Paxos，重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些边角的示例。每个学生都是看完第一个视频，回答相应的测试，再看第二个视频，回答相应的测试。大约有一半的学生先进行 Paxos 部分，然后另一半先进行 Raft 部分，这是为了说明两者独立的区别从第一个算法处学来的经验。我们计算参加人员的每一个小测验的得分来看参与者是否在 Raft 算法上更加容易理解。\n\n我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些  Paxos 的经验，并且 Paxos 的视频要长 14%。如表格 1 总结的那样，我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。\n\n| 关心 | 缓和偏见采取的手段 | 可供查看的材料 |\n|----|----|----|\n| 相同的讲课质量 | 两者使用同一个讲师。Paxos 使用的是现在很多大学里经常使用的。Paxos 会长 14%。 | 视频 |\n| 相同的测验难度 | 问题以难度分组，在两个测验里成对出现。| 小测验 |\n| 公平评分 | 使用红字标题。随机顺序打分，两个测验交替进行。 | 红字标题 |\n\n> 表 1：考虑到可能会存在的偏见，对于每种情况的解决方法，和相应的材料。\n\n参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60，那么 Raft 的平均得分是 25.7，而 Paxos 是 20.8）；图 14 展示了每个参与者的得分。一对 t -测试表明，拥有 95% 的可信度，真实的 Raft 分数分布至少比 Paxos 高 2.5 分。\n\n![图 14](/assets/images/2015/02/06/raft-zh_cn/010.png)\n\n> 图 14：一个散点图表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩。在对角线之上的点表示在 Raft 获得了更高分数的学生。\n\n我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，基于以下三个因素：他们使用的是哪个小测验，之前对 Paxos 的经验，和学习算法的顺序。模型显示，对小测验的选择会产生 12.5 分的差别在对  Raft 的好感度上。这显著的高于之前的 4.9 分，因为很多学生在之前都已经有了对于   Paxos 的经验，这相当明显的帮助 Paxos，对 Raft 就没什么太大影响了。但是奇怪的是，模型预测对于先进性 Paxos 小测验的人而言，Raft 的小测验得分会比 Paxos 低 6.3 分；我们不知道为什么，但这在统计学上是这样的。\n\n我们同时也在测验之后调查了参与者，他们认为哪个算法更加容易实现和解释；这个的结果在图 15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是，这种自己报告的结果不如参与者的成绩更加可信，并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。\n\n![图 15](/assets/images/2015/02/06/raft-zh_cn/011.png)\n\n> 图 15：通过一个 5 分制的问题，参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现，右边被问哪个更容易向学生解释。\n\n关于 Raft 用户学习有一个更加详细的讨论。\n\n### 9.2 正确性\n\n在第 5 节，我们已经进行了一个正式的说明，和对一致性机制的安全性证明。这个正式说明让图 2 中的信息非常清晰通过 TLA+ 说明语言。大约 400 行说明充当了证明的主题。同时对于任何想实现的人也是十分有用的。我们非常机械的证明了日志完全特性通过 TLA 证明系统。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明这个说明中的类型安全）。而且，我们已经写了一个非正式的证明关于状态机安全性质是完备的，并且是相当清晰的（大约 3500 个词）。\n\n### 9.3 性能\n\nRaft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面，最重要的关注点是，当领导人被选举成功时，什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时，进一步提升 Raft 的性能也是可行的。例如，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来，但是我们暂时把这个问题放到未来的工作中去。\n\n我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答两个问题。首先，领导人选举的过程收敛是否快速？第二，在领导人宕机之后，最小的系统宕机时间是多久？\n\n![图 16](/assets/images/2015/02/06/raft-zh_cn/012.png)\n\n> 图 16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度，下面的图考察了最小超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次），和相应的确定的选举超时时间。例如，150-155 毫秒意思是，选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行，其广播时延大约是 15 毫秒。对于 9 个节点的集群，结果也差不多。\n\n为了衡量领导人选举，我们反复的使一个拥有五个节点的服务器集群的领导人宕机，并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图 16）。为了构建一个最坏的场景，在每一的尝试里，服务器都有不同长度的日志，意味着有些候选人是没有成为领导人的资格的。另外，为了促成选票瓜分的情况，我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机，也就是最小选举超时时间的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。\n\n图 16 上面的图表表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。\n\n图 16 中下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性。\n\n## 10 相关工作\n\n已经有很多关于一致性算法的工作被发表出来，其中很多都可以归到下面的类别中：\n\n* Lamport 关于 Paxos 的原始描述，和尝试描述的更清晰。\n* 关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础。\n* 实现一致性算法的系统，例如 Chubby，ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 着实有着很大的差别。\n* Paxos 可以应用的性能优化。\n* Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起，但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法，和 Raft 有很多相似之处。\n\nRaft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如，在 Paxos 中，领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求的。但是，这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言，Raft 就直接将领导人选举纳入到一致性算法中，并作为两阶段一致性的第一步。这样就减少了很多机制。\n\n像 Raft 一样，VR 和 ZooKeeper 也是基于领导人的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。\n\n和上述我们提及的其他基于一致性的日志复制算法中，Raft 的消息类型更少。例如，我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 中不同的消息类型，相对的，Raft 只有 4 中消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。\n\nRaft 的强领导人模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。\n\n一些集群成员变换的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论，VR 和 SMART。我们选择使用共同一致的方法因为他对一致性协议的其他部分影响很小，这样我们只需要很少的一些机制就可以实现成员变换。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较的，VR 需要停止所有的处理过程，SMART 引入了一个和 α 类似的方法，限制了请求处理的数量。Raft 的方法同时也需要更少的额外机制来实现，和 VR、SMART 比较而言。\n\n## 11 结论\n\n算法的设计通常会把正确性，效率或者简洁作为主要的目标。尽管这些都是很有意义的目标，但是我们相信，可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前，这些目标没有一个会被实现，这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉，否则将会对他们而言很难在实现的时候保持原有期望的特性。\n\n在这篇论文中，我们尝试解决分布式一致性问题，但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft，显而易见的比 Paxos 要容易理解。我们同时也相信，Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；这个过程是我们发现我们最终很少有技术上的重复，例如问题分解和简化状态空间。这些技术不仅提升了 Raft 的可理解性，同时也使我们坚信其正确性。\n\n## 12 感谢\n\n这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie`res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。\n\n## 参考\n\n略\n\n---\n\n* Author: [maemual](https://github.com/maemual)\n* Link: [寻找一种易于理解的一致性算法（扩展版）](https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md)\n","tags":["Paxos"],"categories":["Distributed"]},{"title":"美团推荐算法实践","url":"%2F2015%2F2015-01-22-meituan-recommendation-algorithm-practice%2F","content":"\n## 前言\n\n推荐系统并不是新鲜的事物，在很久之前就存在，但是推荐系统真正进入人们的视野，并且作为一个重要的模块存在于各个互联网公司，还是近几年的事情。\n\n随着互联网的深入发展，越来越多的信息在互联网上传播，产生了严重的信息过载。如果不采用一定的手段，用户很难从如此多的信息流中找到对自己有价值的信息。\n\n解决信息过载有几种手段：一种是搜索，当用户有了明确的信息需求意图后，将意图转换为几个简短的词或者短语的组合（即query），然后将这些词或短语组合提交到相应的搜索引擎，再由搜索引擎在海量的信息库中检索出与query相关的信息返回给用户；另外一种是推荐，很多时候用户的意图并不是很明确，或者很难用清晰的语义表达，有时甚至连用户自己都不清楚自己的需求，这种情况下搜索就显得捉襟见肘了。尤其是近些年来，随着电子商务的兴起，用户并非一定是带着明确的购买意图去浏览，很多时候是去“逛”的，这种情景下解决信息过载，理解用户意图，为用户推送个性化的结果，推荐系统便是一种比较好的选择。\n\n美团作为国内发展较快的o2o网站，有着大量的用户和丰富的用户行为，这些为推荐系统的应用和优化提供了不可或缺的条件，接下来介绍我们在推荐系统的构建和优化过程中的一些做法，与大家共享。\n\n## 框架\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec1.jpg)\n\n从框架的角度看，推荐系统基本可以分为数据层、触发层、融合过滤层和排序层。数据层包括数据生成和数据存储，主要是利用各种数据处理工具对原始日志进行清洗，处理成格式化的数据，落地到不同类型的存储系统中，供下游的算法和模型使用。候选集触发层主要是从用户的历史行为、实时行为、地理位置等角度利用各种触发策略产生推荐的候选集。候选集融合和过滤层有两个功能，一是对出发层产生的不同候选集进行融合，提高推荐策略的覆盖度和精度；另外还要承担一定的过滤职责，从产品、运营的角度确定一些人工规则，过滤掉不符合条件的item。排序层主要是利用机器学习的模型对触发层筛选出来的候选集进行重排序。\n\n同时，对与候选集触发和重排序两层而言，为了效果迭代是需要频繁修改的两层，因此需要支持ABtest。为了支持高效率的迭代，我们对候选集触发和重排序两层进行了解耦，这两层的结果是正交的，因此可以分别进行对比试验，不会相互影响。同时在每一层的内部，我们会根据用户将流量划分为多份，支持多个策略同时在线对比。\n\n## 数据应用\n\n数据乃算法、模型之本。美团作为一个交易平台，同时具有快速增长的用户量，因此产生了海量丰富的用户行为数据。当然，不同类型的数据的价值和反映的用户意图的强弱也有所不同。\n\n\n| 行为类别 | 行为详情 |\n| ------- | ------ |\n| 主动行为数据 | 搜索、筛选、点击、收藏、下单、支付、评分 |\n| UGC | 文本评价、上传图片 |\n| 负反馈数据 | 左滑删除、取消收藏、取消订单、退款、负评、低评 |\n| 用户画像 | 用户人口属性、美团DNA、品类偏好、消费水平、工作地与居住地 |\n\n1. 用户主动行为数据记录了用户在美团平台上不同的环节的各种行为，这些行为一方面用于候选集触发算法（在下一部分介绍）中的离线计算（主要是浏览、下单），另外一方面，这些行为代表的意图的强弱不同，因此在训练重排序模型时可以针对不同的行为设定不同的回归目标值，以更细地刻画用户的行为强弱程度。此外，用户对deal的这些行为还可以作为重排序模型的交叉特征，用于模型的离线训练和在线预测。\n\n2. 负反馈数据反映了当前的结果可能在某些方面不能满足用户的需求，因此在后续的候选集触发过程中需要考虑对特定的因素进行过滤或者降权，降低负面因素再次出现的几率，提高用户体验；同时在重排序的模型训练中，负反馈数据可以作为不可多得的负例参与模型训练，这些负例要比那些展示后未点击、未下单的样本显著的多。\n\n3. 用户画像是刻画用户属性的基础数据，其中有些是直接获取的原始数据，有些是经过挖掘的二次加工数据，这些属性一方面可以用于候选集触发过程中对deal进行加权或降权，另外一方面可以作为重排序模型中的用户维度特征。\n\n4. 通过对UGC数据的挖掘可以提取出一些关键词，然后使用这些关键词给deal打标签，用于deal的个性化展示。\n\n### 策略触发\n\n上文中我们提到了数据的重要性，但是数据的落脚点还是算法和模型。单纯的数据只是一些字节的堆积，我们必须通过对数据的清洗去除数据中的噪声，然后通过算法和模型学习其中的规律，才能将数据的价值最大化。在本节中，将介绍推荐候选集触发过程中用到的相关算法。\n\n#### 1. 协同过滤\n\n提到推荐，就不得不说协同过滤，它几乎在每一个推荐系统中都会用到。基本的算法非常简单，但是要获得更好的效果，往往需要根据具体的业务做一些差异化的处理。\n\n* 清除作弊、刷单、代购等噪声数据。这些数据的存在会严重影响算法的效果，因此要在第一步的数据清洗中就将这些数据剔除。\n\n* 合理选取训练数据。选取的训练数据的时间窗口不宜过长，当然也不能过短。具体的窗口期数值需要经过多次的实验来确定。同时可以考虑引入时间衰减，因为近期的用户行为更能反映用户接下来的行为动作。\n\n* user-based与item-based相结合。\n\n| 群体/个体 | 计算代价 | 适用场景 | 冷启动 | 可解释性 | 实时性 |\n| -------- | ------ | ------- | ---- | ------- | ----- |\n| user-based | 更依赖于当前用户相近的用户群体的社会化行为 | 适用于用户数较少的场合 | 时效性强，用户个性化兴趣不太显著的场合 | 新加入的物品能很快进入推荐列表 | 弱 | 用户新的行为不一定导致推荐结果的变化 |\n| item-based | 更侧重用户自身的个体行为 | 适用于物品数较少的场合 | 长尾物品丰富，用户个性化需求强烈的场合 | 新加入的用户能很快得到推荐 | 强 | 用户新的行为一定导致推荐结果的变化 |\n\n尝试不同的相似度计算方法。在实践中，我们采用了一种称作loglikelihood ratio[1]的相似度计算方法。在mahout中，loglikelihood ratio也作为一种相似度计算方法被采用。\n\n下表表示了Event A和Event B之间的相互关系，其中：\n\n    k11 ：Event A和Event B共现的次数\n    k12 ：Event B发生，Event A未发生的次数\n    k21 ：Event A发生，Event B未发生的次数\n    k22 ：Event A和Event B都不发生的次数\n\n|    | Event A | Everything but A |\n| -- | ------- | ---------------- |\n| Event B | A and B together (k_11) | B, but not A (k_12)\n| Everything but B | A without B (k_21) | Neither A nor B (k_22)\n\n则：logLikelihoodRatio=2 * (matrixEntropy - rowEntropy - columnEntropy)\n\n其中(entropy为几个元素组成的系统的香农熵)：\n\n    rowEntropy = entropy(k11, k12) + entropy(k21, k22)\n    columnEntropy = entropy(k11, k21) + entropy(k12, k22)\n    matrixEntropy = entropy(k11, k12, k21, k22)\n\n#### 2. location-based\n\n对于移动设备而言，与PC端最大的区别之一是移动设备的位置是经常发生变化的。不同的地理位置反映了不同的用户场景，在具体的业务中可以充分利用用户所处的地理位置。在推荐的候选集触发中，我们也会根据用户的实时地理位置、工作地、居住地等地理位置触发相应的策略。\n\n* 根据用户的历史消费、历史浏览等，挖掘出某一粒度的区域（比如商圈）内的区域消费热单和区域购买热单\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec3.jpg)\n\n区域消费热单\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec4.jpg)\n\n区域购买热单\n\n* 当新的线上用户请求到达时，根据用户的几个地理位置对相应地理位置的区域消费热单和区域购买热单进行加权，最终得到一个推荐列表。\n\n* 此外，还可以根据用户出现的地理位置，采用协同过滤的方式计算用户的相似度。\n\n#### 3. query-based\n\n搜索是一种强用户意图，比较明确的反应了用户的意愿，但是在很多情况下，因为各种各样的原因，没有形成最终的转换。尽管如此，我们认为，这种情景还是代表了一定的用户意愿，可以加以利用。具体做法如下：\n\n* 对用户过去一段时间的搜索无转换行为进行挖掘，计算每一个用户对不同query的权重。\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec5.jpg)\n\n* 计算每个query下不同deal的权重。\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec6.jpg)\n\n* 当用户再次请求时，根据用户对不同query的权重及query下不同deal的权重进行加权，取出权重最大的TopN进行推荐。\n\n#### 4. graph-based\n\n对于协同过滤而言，user之间或者deal之间的图距离是两跳，对于更远距离的关系则不能考虑在内。而图算法可以打破这一限制，将user与deal的关系视作一个二部图，相互间的关系可以在图上传播。Simrank[2]是一种衡量对等实体相似度的图算法。它的基本思想是，如果两个实体与另外的相似实体有相关关系，那它们也是相似的，即相似性是可以传播的。\n\n* Let s(A,B) denote the similarity between persons A and B, for A != B\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec7.jpg)\n\nLet s(c,d) denote the similarity between items c and d, for c != d\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec8.jpg)\n\nO(A),O(B): the set of out-neighbors for node A or node B\n\nI(c),I(d): the set of in-neighbors for node c or node d\n\n* simrank的计算（采用矩阵迭代的方式）\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec9.jpg)\n\n* 计算得出相似度矩阵后，可以类似协同过滤用于线上推荐。\n\n#### 5. 实时用户行为\n\n目前我们的业务会产生包括搜索、筛选、收藏、浏览、下单等丰富的用户行为，这些是我们进行效果优化的重要基础。我们当然希望每一个用户行为流都能到达转化的环节，但是事实上远非这样。\n\n当用户产生了下单行为上游的某些行为时，会有相当一部分因为各种原因使行为流没有形成转化。但是，用户的这些上游行为对我们而言是非常重要的先验知识。很多情况下，用户当时没有转化并不代表用户对当前的item不感兴趣。当用户再次到达我们的推荐展位时，我们根据用户之前产生的先验行为理解并识别用户的真正意图，将符合用户意图的相关deal再次展现给用户，引导用户沿着行为流向下游行进，最终达到下单这个终极目标。\n\n目前引入的实时用户行为包括：实时浏览、实时收藏。\n\n#### 6. 替补策略\n\n虽然我们有一系列基于用户历史行为的候选集触发算法，但对于部分新用户或者历史行为不太丰富的用户，上述算法触发的候选集太小，因此需要使用一些替补策略进行填充。\n\n* 热销单：在一定时间内销量最多的item，可以考虑时间衰减的影响等。\n\n* 好评单：用户产生的评价中，评分较高的item。\n\n* 城市单：满足基本的限定条件，在用户的请求城市内的。\n\n### 子策略融合\n\n为了结合不同触发算法的优点，同时提高候选集的多样性和覆盖率，需要将不同的触发算法融合在一起。常见的融合的方法有以下几种[3]：\n\n1. 加权型：最简单的融合方法就是根据经验值对不同算法赋给不同的权重，对各个算法产生的候选集按照给定的权重进行加权，然后再按照权重排序。\n\n2. 分级型：优先采用效果好的算法，当产生的候选集大小不足以满足目标值时，再使用效果次好的算法，依此类推。\n\n3. 调制型：不同的算法按照不同的比例产生一定量的候选集，然后叠加产生最终总的候选集。\n\n4. 过滤型：当前的算法对前一级算法产生的候选集进行过滤，依此类推，候选集被逐级过滤，最终产生一个小而精的候选集合。\n\n目前我们使用的方法集成了调制和分级两种融合方法，不同的算法根据历史效果表现给定不同的候选集构成比例，同时优先采用效果好的算法触发，如果候选集不够大，再采用效果次之的算法触发，依此类推。\n\n### 候选集重排序\n\n如上所述，对于不同算法触发出来的候选集，只是根据算法的历史效果决定算法产生的item的位置显得有些简单粗暴，同时，在每个算法的内部，不同item的顺序也只是简单的由一个或者几个因素决定，这些排序的方法只能用于第一步的初选过程，最终的排序结果需要借助机器学习的方法，使用相关的排序模型，综合多方面的因素来确定。\n\n#### 1. 模型\n\n非线性模型能较好的捕捉特征中的非线性关系，但训练和预测的代价相对线性模型要高一些，这也导致了非线性模型的更新周期相对要长。反之，线性模型对特征的处理要求比较高，需要凭借领域知识和经验人工对特征做一些先期处理，但因为线性模型简单，在训练和预测时效率较高。因此在更新周期上也可以做的更短，还可以结合业务做一些在线学习的尝试。在我们的实践中，非线性模型和线性模型都有应用。\n\n* 非线性模型\n\n目前我们主要采用了非线性的树模型Additive Groves[4]（简称AG），相对于线性模型，非线性模型可以更好的处理特征中的非线性关系，不必像线性模型那样在特征处理和特征组合上花费比较大的精力。AG是一个加性模型，由很多个Grove组成，不同的Grove之间进行bagging得出最后的预测结果，由此可以减小过拟合的影响。\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec10.jpg)\n\n每一个Grove有多棵树组成，在训练时每棵树的拟合目标为真实值与其他树预测结果之和之间的残差。当达到给定数目的树时，重新训练的树会逐棵替代以前的树。经过多次迭代后，达到收敛。\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec10a.jpg)\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec10b.jpg)\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec10c.jpg)\n\n\n* 线性模型\n\n目前应用比较多的线性模型非Logistic Regression莫属了。为了能实时捕捉数据分布的变化，我们引入了online learning，接入实时数据流，使用google提出的FTRL[5]方法对模型进行在线更新。\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec11.jpg)\n\n主要的步骤如下：\n\n* 在线写特征向量到HBase\n\n* Storm解析实时点击和下单日志流，改写HBase中对应特征向量的label\n\n* 通过FTRL更新模型权重\n\n* 将新的模型参数应用于线上\n\n#### 2. 数据\n\n* 采样：对于点击率预估而言，正负样本严重不均衡，所以需要对负例做一些采样。\n\n* 负例：正例一般是用户产生点击、下单等转换行为的样本，但是用户没有转换行为的样本是否就一定是负例呢？其实不然，很多展现其实用户根本没有看到，所以把这样样本视为负例是不合理的，也会影响模型的效果。比较常用的方法是skip-above，即用户点击的item位置以上的展现才可能视作负例。当然，上面的负例都是隐式的负反馈数据，除此之外，我们还有用户主动删除的显示负反馈数据，这些数据是高质量的负例。\n\n* 去噪：对于数据中混杂的刷单等类作弊行为的数据，要将其排除出训练数据，否则会直接影响模型的效果。\n\n#### 3. 特征\n\n在我们目前的重排序模型中，大概分为以下几类特征：\n\n* deal(即团购单，下同)维度的特征：主要是deal本身的一些属性，包括价格、折扣、销量、评分、类别、点击率等\n\n* user维度的特征：包括用户等级、用户的人口属性、用户的客户端类型等\n\n* user、deal的交叉特征：包括用户对deal的点击、收藏、购买等\n\n* 距离特征：包括用户的实时地理位置、常去地理位置、工作地、居住地等与poi的距离\n\n对于非线性模型，上述特征可以直接使用；而对于线性模型，则需要对特征值做一些分桶、归一化等处理，使特征值成为0~1之间的连续值或01二值。\n\n### 总结\n\n以数据为基础，用算法去雕琢，只有将二者有机结合，才会带来效果的提升。对我们而言，以下两个节点是我们优化过程中的里程碑：\n\n* 将候选集进行融合：提高了推荐的覆盖度、多样性和精度\n\n* 引入重排序模型：解决了候选集增加以后deal之间排列顺序的问题\n\n![](/assets/images/2015/01/22/meituan-recommendation-algorithm-practice/rec13.jpg)\n\n以上是我们在实践中的一点总结，当然我们还有还多事情要做。we are still on the way!\n\n注：本文为美团推荐与个性化团队集体智慧的结晶，感谢为此辛苦付出的每一个成员。同时，团队长期招聘算法工程师与平台研发工程师，感兴趣的同学请联系 hr.tech@meituan.com ，邮件标题注明“应聘推荐系统工程师”。\n\n### Reference\n\n* [http://en.wikipedia.org/wiki/Likelihood-ratio_test](http://en.wikipedia.org/wiki/Likelihood-ratio_test)\n* [SimRank: a measure of structural-context similarity](http://ilpubs.stanford.edu:8090/508/1/2001-41.pdf)\n* [http://www.52ml.net/318.html](http://www.52ml.net/318.html)\n* [http://additivegroves.net/](http://additivegroves.net/)\n* [Ad Click Prediction: a View from the Trenches](http://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf)\n\n---\n\n* 原文链接：[美团推荐算法实践](http://tech.meituan.com/mt-recommend-practice.html)\n","tags":["Recommendation"],"categories":["Machine-Learning"]},{"title":"数据压缩的历史、原理及常用算法","url":"%2F2015%2F2015-01-21-history-and-principle-data-compression-algorithm%2F","content":"\n压缩，是为了减少存储空间而把数据转换成比原始格式更紧凑形式的过程。数据压缩的概念相当古老，可以追溯到发明了摩尔斯码的19世纪中期。\n\n摩尔斯码的发明，是为了使电报员能够通过电报系统，利用一系列可听到的脉冲信号传递字母信息，从而实现文字消息的传输。摩尔斯码的发明者意识到，某些字母比其他字母使用地更频繁（例如E比X更常见），因此决定使用短的脉冲信号来表示常用字母，而使用较长的脉冲信号表示非常用字母。这个基本的压缩方案有效地改善了系统的整体效率，因为它使电报员在更短的时间内传输了更多的信息。\n\n虽然现代的压缩流程比摩尔斯码要复杂地多，但是它们仍然使用着相同的基本原理，也就是我们这篇文章中将要讲述的内容。这些概念对我们如今的计算机世界高效运行至关重要——互联网上从本地与云端存储到数据流的一切东西都严重依赖压缩算法，离开了它很可能会变得非常低效。\n\n### 压缩管道\n\n下图展示了压缩方案的通用流程。原始的输入数据包含我们需要压缩或减小尺寸的符号序列。这些符号被压缩器编码，输出结果是编码过的数据。需要注意的是，虽然通常编码后的数据要比原始输入数据小，但是也有例外情况（我们后面会讲到）。\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/1.png)\n\n通常在之后的某个时间，编码后的数据会被输入到一个解压缩器，在这里数据被解码、重建，并以符号序列的形式输出原始数据。注意，本文我们会交替地使用“序列”和“串”来指一个符号序列集。\n\n如果输出数据和输入数据始终完全相同，那么这个压缩方案被称为_无损的_，也称无损编码器。否则，它就是一个_有损的_压缩方案。\n\n无损压缩方案通常被用来压缩文本，可执行程序，或者其他任何需要完全重建数据的地方。有损压缩方案在图像，音频，视频，或者其他为了提高压缩效率而可以接受某些程度信息丢失的场合很有用处。\n\n### 数据模型\n\n信息的定义是度量一个数据片段复杂度的量。一个数据集拥有越多的信息，它就越难被压缩。稀有的概念和信息的概念是相关的，因为稀有符号的出现比常见符号的出现提供了更多的信息。\n\n例如，“日本的一次地震”的出现比“月球的一次地震”提供的信息号少，因为月球上的地震很不常见。我们可以预期，大多数压缩算法在压缩一个符号时，能够仔细地考虑它出现的频率或几率。\n\n我们把压缩算法降低信息负载的有效性，称为它的_效率_。一个效率更高的压缩算法相比效率低的压缩算法，能够更多地降低特定数据集的大小。\n\n### 概率模型\n\n设计一个压缩方案的最重要一步，是为数据创建一个概率模型。这个模型允许我们测量数据的特征，达到有效的适应压缩算法的目的。为了使它更加清晰一些，让我们浏览一下建模过程的部分环节。\n\n假设我们有一个字母表G，它由数据集中所有可能出现的字符组成。在我们的例子中，G包含4个字符：从A到D。\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/2.png)\n\n我们还有一个概率统计函数P，它定义了在输入数据串中，G中每个字符出现的概率。在输入数据串中，概率高的符号比概率低的符号更有可能出现。\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/3.png)\n\n在这个例子中，我们假定符号是[独立同分布](http://bertolami.com/index.php?engine=blog&amp;content=posts&amp;detail=fundamentals-of-data-compression)的。在源数据串中，一个符号的出现与其他任何符号没有相关性。\n\n### 最小编码率\n\nB是最常见的符号，出现的概率是40%；而C是最不常见的符号，它的出现概率只有10%。我们的目标是设计一个压缩方案，它对于常见符号使所需存储空间最小化，同时它支持使用更多的必要空间来存储不常见符号。这个折衷是压缩的基本原理，并且已经存在于几乎所有的压缩算法中。\n\n有了字母表，我们可以小试身手，来定义一个基本的压缩方案。如果我们简单地把一个符号编码为8比特的ASCII值，那么我们的压缩效率，即编码率，将是8比特/符号。假定我们对只包含4个符号的字母表改进这个方案。如果我们为每个符号分配2个比特，我们仍然能够完全重建编码过的数据串，而只需要1/4的空间。\n\n这时候，我们已经显著地提升了编码率（从8到2比特/符号），但是完全忽视了我们的概率模型。正如前面提到的，我们可以结合模型发明一个策略，通过对常见符号（B和D）使用更少的比特，对不常见符号（A和C）使用更多的比特，以提高编码效率。\n\n这提出了一个在[香农开创性论文](http://cm.bell-labs.com/cm/ms/what/shannonday/shannon1948.pdf)中描述的重要观点——我们可以简单地基于符号（或事件）的概率，定义它的理论最小存储空间。我们如下定义一个符号的_最小编码率_：\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/4.png)\n\n例如，如果一个符号出现的概率是50%，那么它绝对最少需要一个字节来存储。\n\n### 熵和冗余\n\n更进一步，如果我们为字母表中的字符计算最小编码率的加权平均值，我们得到一个被称作_香农熵_的值，简单地称作模型的_熵_。熵被定义为给定模型的最小编码率。它建立在字母表和它的概率模型之上，如下描述。\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/5.png)\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/6.png)\n\n正如你预料的一样，拥有更多罕见符号的模型，比拥有较少并且常见符号的模型的熵要高。更进一步，熵值更高的模型比熵值低的模型更难压缩。\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/7.png)\n\n在我们当前的例子中，我们模型的熵值是1.85比特/符号。编码率（2）和熵值（1.85）的差值被称作压缩方案的_冗余_。\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/8.png)\n\n在众多诸如加密和人工智能等不同的子领域，熵都是一个非常有用的话题。完整地讨论熵不在本文的范围内，但是有兴趣的读者可以在[这里](http://en.wikipedia.org/wiki/Entropy_%28information_theory%29)获得更多的信息。\n\n### 编码模型\n\n到目前为止，我们采取了一点点自由措施：自动地给出了我们符号的概率。在现实中，模型通常并不是容易得到的，我们可能通过分析源数据串（如在样例数据汇总统计符号概率），或者在压缩过程中自适应地学习，以得到这些概率值。不管是哪种情形，真实数据串的概率值不会完美地与模型匹配，而且我们会与这个差别正比例地损失压缩效率。基于这个原因，推导出（或恒定地保持）一个尽可能精确的模型是至关重要的。\n\n### 常见算法\n\n当我们为数据集定义了概率模型之后，我们就能够适当地利用这个模型设计出一个压缩方案。虽然开发一个新压缩算法的过程超出了本文的范围，但是我们可以利用已经存在的算法。下面我们回顾一些最流行的算法。\n\n下面的每一个算法都是一个顺序处理器，这就是说如果要重建已编码序列的第n个符号，必须先对第0..(n-1)个符号进行解码。由于编码后数据的不定长特性，寻找操作是不可能的——解码器在不解码前面的符号的情况下，无法直接跳转到符号n的正确偏移位置。另外，一些编码方案依赖于顺序处理每个符号时保持的内部历史状态。\n\n**• 霍夫曼编码**\n\n这是一个最为广泛知晓的压缩方案。它能够追溯到19世纪50年代，David Huffman在他的论文“[一种构建极小多余编码的方法](https://www.ic.tu-berlin.de/fileadmin/fg121/Source-Coding_WS12/selected-readings/10_04051119.pdf)”中第一次描述了这种方法。霍夫曼编码通过得到给定字母表的最优前缀码工作。\n\n一个前缀码代表一个数值，并使字母表中的每个符号的前缀码不会成为另一个符号前缀码的前缀。例如，如果0是我们第一个符号A的前缀码，那么字母表中的其他符号都不能以0开始。由于前缀码使比特流解码变得清晰明确，因此很有用。\n\n对给定字母表得到最优前缀码的过程（霍夫曼编码的真髓）不在本文的范围之内，但是我们可以计算一下例子中字母表G的前缀码的效率。假设我们已经对字母表中每个符号做了如下编码。注意我们对常见符号赋予了更短的编码，对不常见符号赋予更长的编码。\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/9.png)\n\n使用这个系统，我们的平均编码率显著地降低到了1.9比特/符号，相比之前最好的编码率2，而冗余也降低到了0.05比特/符号（相比0.15）。\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/10.png)\n\n**• 字典方法**\n\n这种类型的编码器使用一个字典来保存最近发现的符号。当遇到一个符号时，首先会在字典中查找它，检查是否已经存储过了。如果是，那么输出将只包含字典入口的引用（通常是一个偏移量），而不是整个符号。\n\n使用字典方法的压缩方案包括[LZ77 and LZ78](http://en.wikipedia.org/wiki/LZ77_and_LZ78)，它们是很多不同的无损压缩方案的基础。\n\n在一些情况下，会使用一个滑动窗口来自适应地追踪最近发现的符号。这种情况下，一个符号只在相对较近发现时才会保存在字典中。否则，符号被剔除（之后再出现可能会重新加入字典）。这个过程防止符号字典变得过大，并利用了一个事实，即序列中的符号会在相对短的窗口内重复出现。\n\n**• 哥伦布指数编码**\n\n假设你有一个由0到255范围内的整数组成的字母表，并且一个符号的出现概率与它到0的距离有关。这样，比较小的值是最常见的，而值越大出现的概率越小。\n\n对于这种情形，[哥伦布指数编码器](http://en.wikipedia.org/wiki/Exponential-Golomb_coding)会很有用处。哥伦布编码使用一个特定的前缀码，它优先考虑较小的值，而使大值付出高的代价。下面的表说明了最开始的几个值：\n\n![](/assets/images/2015/01/21/history-and-principle-data-compression-algorithm/11.png)\n\n对一个整数进行编码的过程是很直接的。首先，递增这个整数的值，并计算存储递增后的值所需的比特数。然后，将比特数减一，并把减一后相等数量的0输出到结果流。最后，输出递增后的值（第一步中计算得到的）按比特输出到结果流。\n\n例如，4递增后是5，即二进制的101。它需要3个比特来存储，因此我们输出2个0到结果流，然后输出二进制的值101。结果就是00101。\n\n和大多数压缩方案一样，哥伦布编码的效率非常依赖于输入序列中的特定符号。包含很多大值的序列与包含较少大值的序列相比，压缩效果更差一些；在某些情况下，经过哥伦布编码后的序列甚至可能比原始输入串的尺寸更大。\n\n**• 算术编码**\n\n[算数编码](http://en.wikipedia.org/wiki/Arithmetic_coding)是一个比较新的压缩算法，在最近（过去的15年里）得到了极大的普及，特别是媒体压缩方面。算数编码器是一种高效率，计算密集型，具有时序性的编码器。\n\n一个常见的算数编码变种，二进制算数编码，使用只包含两个符号（0和1）的字母表。这个变种特别有用处，因为它简化了编码器的设计，降低了运行时的计算代价，并且在编码器和解码器处理一个字母表和模型时，不需要任何显式的通讯。\n\n要获得更多关于算数编码的信息，请关注我即将发表的文章，Context Adaptive Binary Arithmetic Coding。\n\n**• 行程长度编码（RLE）**\n\n到现在为止，我们已经假设源符号是_独立同分布_的。我们的概率模型和编码率与熵的计算方法都依赖于这个事实。但是，如果我们的符号序列不满足这个要求呢？\n\n假设我们序列中符号的重复度很高，并且一个特定符号的出现有力地表明，它的重复实例即将跟随出现。这种情况下，我们可以选择使用另一个称作行程长度编码的编码方案。这种技术在符号重复度很高时表现良好，而在重复度低时表现较差。\n\n[行程长度编码器](http://en.wikipedia.org/wiki/Run-length_encoding)预测数据串中连续重复符号的长度，并使用这个符号和重复次数来替代它们。\n\n例如，序列AABBBBBBBDDD包含重复的A，B和D，使用行程长度编码后的序列为A2B7D3，因为A被重复2次，B被重复7次，而D被重复3次。重建时，解码器会根据数据串中的重复次数来重复每个符号，从而得到原始的输入串。\n\n正如我们前面提到的，这个算法适合重复度高的数据串。但是要注意当对很少重复的序列编码时会发生什么：ABCDABCD会变成A1B1C1D1A1B1C1D1，与原始数据相比更差了。和其他大多数压缩算法相同，行程长度编码的效率严重依赖与原始数据串与算法模型的符合程度。在一些极端情形下，行程长度编码可能产生2倍与原始输入数据长度的压缩结果。\n\n### 有损压缩\n\n虽然有损压缩不在本文中的讨论范围内，但是需要重点指出的是，有损压缩经常把无损压缩作为压缩管道的一部分。有损压缩可能通过2个过程来完成：首先大幅度压缩数据（抛弃不需要或者多余的信息），然后再通过无损压缩算法进行压缩。流行的图形和视频编码，如JPEG和H.264，都是这样做的，依赖无损压缩算法如霍夫曼编码或者算数编码来达到高效压缩的效果。\n\n### 总结\n\n本文聚焦于无损压缩技术，并对一些最流行的技术提供了一个简明的介绍。希望它已经激起了你对于数据压缩重要领域的兴趣，并为这个主题的进一步阅读提供方向。\n\n---\n\n* Author: [JOE BERTOLAMI](http://bertolami.com/index.php)\n* 翻译：[Sheng Gordon](http://www.jobbole.com/members/shenggordon/)\n* Source: [伯乐在线](http://jobbole.com)\n* Link: [数据压缩的历史、原理及常用算法](http://blog.jobbole.com/83422/)\n* 原文：[Fundamentals of Compression](http://bertolami.com/index.php?engine=blog&content=posts&detail=fundamentals-of-data-compression)","tags":["Compression"],"categories":["Compression"]},{"title":"Hadoop Best Practices: Scheduling in YARN","url":"%2F2014%2F2014-12-27-hadoop-best-practices-scheduling-in-yarn%2F","content":"\n这篇文章基本上是对[《Hadoop: The Definitive Guide, 4th Edition》第 4 章](https://www.safaribooksonline.com/library/view/hadoop-the-definitive/9781491901687/ch04.html#YARNScheduling)的转述，版权归作者所有。\n\nYARN 提供了三种任务调度策略：FIFO Scheduler，Capacity Scheduler 和 Fair Scheduler，下面会分别详细介绍。\n\n# FIFO Scheduler\n\n顾名思义，FIFO Scheduler 就是将所有 application 按照提交顺序来执行，这些 application 都放在一个队列里，只有在执行完一个之后，才会继续执行下一个。\n\n这种调度策略很容易理解，但缺点也很明显。耗时的长任务会导致后提交的任务一直处于等待状态，如果这个集群是多人共享的，显然不太合理。因此 YARN 提供了另外两种调度策略，更加适合共享集群。下图是 FIFO Scheduler 执行过程的示意图：\n\n![](/assets/images/2014/12/27/hadoop-best-practices-scheduling-in-yarn/001.png)\n\n# Capacity Scheduler\n\n既然需要多人共享，那 Capacity Scheduler 就为每个人分配一个队列，每个队列占用的集群资源是固定的，但是可以不同，队列内部还是采用 FIFO 调度的策略。下图是 Capacity Scheduler 执行过程的示意图：\n\n![](/assets/images/2014/12/27/hadoop-best-practices-scheduling-in-yarn/002.png)\n\n可以看到，队列 A 和 B 享有独立的资源，但是 A 所占的资源比重更多。如果任务在被执行的时候，集群恰好有空闲资源，比如队列 B 为空，那么调度器就可能分配更多的资源给队列 A，以更好地利用空闲资源。这种处理方式被叫做「queue elasticity」（弹性队列）。\n\n但是弹性队列也有一些副作用，如果此时队列 B 有了新任务，之前被队列 A 占用的资源并不会立即释放，只能等到队列 A 的任务执行完。为了防止某个队列过多占用集群资源，YARN 提供了一个设置可以控制某个队列能够占用的最大资源。但这其实又是跟弹性队列冲突的，因此这里有一个权衡的问题，这个最大值设为多少需要不断试验和尝试。\n\nCapacity Scheduler 的队列是支持层级关系的，即有子队列的概念。下面是一个示例配置文件：\n\n```xml\n<?xml version=\"1.0\"?>\n<configuration>\n  <property>\n    <name>yarn.scheduler.capacity.root.queues</name>\n    <value>prod,dev</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.capacity.root.dev.queues</name>\n    <value>eng,science</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.capacity.root.prod.capacity</name>\n    <value>40</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.capacity.root.dev.capacity</name>\n    <value>60</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.capacity.root.dev.maximum-capacity</name>\n    <value>75</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.capacity.root.dev.eng.capacity</name>\n    <value>50</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.capacity.root.dev.science.capacity</name>\n    <value>50</value>\n  </property>\n</configuration>\n```\n\n所有队列的根队列叫做 root，这里一共有两个队列：dev 和 prod，dev 队列之下又有两个子队列：eng 和 science。dev 和 prod 分别占用了 60% 和 40% 的资源比重，同时限制了 dev 队列能够伸缩到的最大资源比重是 75%，换句话说，prod 队列至少能有 25% 的资源分配。eng 和 science 队列各占 50%，但因为没有设置最大值，所以有可能出现某个队列占用整个父队列资源的情况。\n\n除了设置队列层级关系和资源分配比重之外，Capacity Scheduler 还提供了诸如控制每个用户或者任务最大占用资源、同时执行的最大任务数，以及队列的 ACL 等配置，详细请参考[官方文档](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html)。\n\n## 队列放置\n\n分配好了队列，要怎么控制任务在指定队列执行呢？如果是 MapReduce 程序，那么可以通过 mapreduce.job.queuename 来设置执行队列，默认情况是在 default 队列执行。注意指定的队列名不需要包含父队列，即不能写成 root.dev.eng，而应该写 eng。\n\n# Fair Scheduler\n\nFair Scheduler 试图为每个任务均匀分配资源，比如当前只有任务 1 在执行，那么它拥有整个集群资源，此时任务 2 被提交，那任务 1 和任务 2 将平分集群资源，以此类推。\n\n当然 Fair Scheduler 也支持队列的概念，下图是执行过程的示意图：\n\n![]()\n\n队列 A 首先执行任务，任务 1 拥有整个集群资源，随后队列 B 增加任务 2，这两个队列均分资源，接着任务 3 被提交到队列 B，但这并不会影响队列 A，任务 3 将会跟任务 2 一起均分资源。\n\n## 开启 Fair Scheduler\n\n设置 yarn.resourcemanager.scheduler.class 为 org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler（在 yarn-site.xml），如果你使用的是 CDH，那默认就是 Fair Scheduler~~（事实上，CDH 也不支持 Capacity Scheduler）~~。\n\n## 队列设置\n\nFair Scheduler 通过 fair-scheduler.xml 文件来进行各种设置，这个文件的位置可以通过 yarn.scheduler.fair.allocation.file 属性来控制（在 yarn-site.xml）。如果没有这个文件，Fair Scheduler 采取的策略将是：每个任务都放在以当前用户命名的队列中，如果这个队列不存在，将会自动创建。\n\nFair Scheduler 也支持显式定义队列，就像 Capacity Scheduler 那样，下面是示例文件：\n\n```xml\n<?xml version=\"1.0\"?>\n<allocations>\n  <defaultQueueSchedulingPolicy>fair</defaultQueueSchedulingPolicy>\n\n  <queue name=\"prod\">\n    <weight>40</weight>\n    <schedulingPolicy>fifo</schedulingPolicy>\n  </queue>\n\n  <queue name=\"dev\">\n    <weight>60</weight>\n    <queue name=\"eng\" />\n    <queue name=\"science\" />\n  </queue>\n\n  <queuePlacementPolicy>\n    <rule name=\"specified\" create=\"false\" />\n    <rule name=\"primaryGroup\" create=\"false\" />\n    <rule name=\"default\" queue=\"dev.eng\" />\n  </queuePlacementPolicy>\n</allocations>\n```\n\n这里自定义了两个队列：prod 和 dev，权重比是 40:60，也就是说不采用均分的策略。每个队列可以有不同的调度策略，默认都是 fair，此外还有 FIFO、Dominant Resource Fairness（drf，后面会讲到）。详细的配置信息可以查看[官方文档](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html)。\n\n## 队列放置\n\n不同于 Capacity Scheduler，Fair Scheduler 是通过规则来决定放置的队列，即前面配置文件中的 queuePlacementPolicy 设置。第一个规则 specified 代表如果任务自己指定了队列，就放置到这个队列，如果没有指定，或者指定的队列不存在，就采用下一条规则。primaryGroup 规则的意思是试图将任务放置到当前用户的主要 Unix 组，如果这个队列不存在则继续下一条规则。default 规则会匹配所有任务，示例文件的意思是放置到 dev.eng 队列中。\n\nqueuePlacementPolicy 可以省略，如果不设置，那么默认的规则如下：\n\n```xml\n<queuePlacementPolicy>\n  <rule name=\"specified\" />\n  <rule name=\"user\" />\n</queuePlacementPolicy>\n```\n也就是说除非显式指定队列，那么将会使用当前用户名作为队列，并且如果队列不存在将会自动创建。\n\n## 中断（Preempt）\n\n当一个任务被提交到一个空队列，但是集群不太空闲的时候，这个任务不会被立即执行，需要等待其它任务执行完毕让出资源。为了等待时间更加可控，Fair Scheduler 支持「中断」（preemption）。\n\n中断的意思是调度器会通过强行结束 container 执行的方式来释放资源，在满足某些条件的情况下。注意中断是以牺牲集群性能为代价的一种做法，因为被强行结束的 container 需要重新执行。\n\n通过设置 yarn.scheduler.fair.preemption 为 true 来开启中断（在 yarn-site.xml），同时还需要设置另外两个超时属性中的至少一个（在 fair-scheduler.xml），超时的单位都是秒。\n\ndefaultMinSharePreemptionTimeout 或 minSharePreemptionTimeout：如果一个队列等待当前设置的超时时间之后还是没有分配到应该分配的最小资源，那么调度器就会去中断其它 container。\ndefaultFairSharePreemptionTimeout 或 fairSharePreemptionTimeout：如果一个队列等待当前设置的超时时间之后还是没有分配到应该分配的资源的一半以上，那么调度器就会去中断其它 container。defaultFairSharePreemptionThreshold 或 fairSharePreemptionThreshold 可以用来调节阈值，默认是 0.5。\n\n# 延迟调度\n\n以上三种调度都遵从 locality 原则。在一个繁忙的集群里，当一个任务请求一个节点的时候有很大概率这个节点正被其它 container 占用，比较显而易见的做法可能是立即寻找同一机柜里的其它节点。但是经过实际观察，如果稍微等待一段时间（秒级），分配到当前请求节点的概率将显著增加。这种策略叫做「延迟调度」（delay scheduling），Capacity Scheduler 和 Fair Scheduler 都支持这种策略。\n\n每一个 node manager 会定期发送心跳给 resource manager，这其中就包含了该 node manager 正在运行的 container 数量以及可以分配给新 container 的资源。当采用延迟调度策略时，调度器并不会立即使用收集到的信息，而会等待一段时间，以达到遵从 locality 的目的。\n\nCapacity Scheduler 的延迟调度通过 yarn.scheduler.capacity.node-locality-delay 来配置，这是一个正整数，假设是 n，表示调度器将会放弃前 n 条心跳信息。\n\nFair Scheduler 的延迟调度通过 yarn.scheduler.fair.locality.threshold.node 来设置，这是一个 0~1 之间的浮点数，例如是 0.5，表示调度器将会等待超过一半的节点发送心跳信息之后再决定。\n\n# Dominant Resource Fairness (DRF)\n\n如果只有一种资源类型需要调度，例如内存，那资源容量的概念将会很简单，比如均分资源，就代表均分内存。但是如果有多种资源类型，例如再加上 CPU，事情就变得复杂了。如果一个任务需要很多的 CPU，但是很少的内存，而另一个任务需要很少的 CPU，很多的内存，这两个任务要如何比较呢？\n\nDominant Resource Fairness（DRF）就是用来干这种事情的，下面举例说明是什么意思。\n\n假设一个集群总共有 100 个 CPU，10 TB 内存。任务 A 需要 2 个 CPU，300 GB 内存。任务 B 需要 6 个 CPU，100 GB 内存。那么 A 所需资源占集群的比重是 2% 和 3%，因为内存的比重更大，那么就可以以 3% 这个比重来整体衡量 A。同理，比较之后 B 的最终比重是 6%。因此任务 B 需要两倍于任务 A 的资源（6% 比 3%），如果是均分（fair）策略，那么 B 的 container 数量将会是 A 的一半。\n\nDRF 没有默认使用，因此在计算资源的时候只考虑了内存，而忽略了 CPU。Capacity Scheduler 需要设置 yarn.scheduler.capacity.resource-calculator 为 org.apache.hadoop.yarn.util.resource.DominantResourceCalculator（在 capacity-scheduler.xml）；Fair Scheduler 需要设置 defaultQueueSchedulingPolicy 为 drf。\n\n# 总结\n\nFIFO Scheduler 显然不适用于生产环境；Capacity Scheduler 概念简单，但缺乏灵活性；Fair Scheduler 最复杂，但具有足够的灵活性以及更好的资源利用率。\n\n---\n\n* Author: [Freedom](http://blog.xiaogaozi.org/)\n* Link: [Hadoop Best Practices: Scheduling in YARN](http://blog.xiaogaozi.org/2014/12/27/hadoop-best-practices-scheduling-in-yarn/)\n","tags":["HADOOP"],"categories":["Scheduling"]},{"title":"虚拟化性能分析（XEN/KVM/LXC) ","url":"%2F2014%2F2014-09-30-virtualization-performance-analysis-xen-kvm-lxc%2F","content":"\n## 1 测试环境\nPowerEdge C6220 II服务器的一个刀片，64G内存，32颗CPU。\n\n   千兆网卡\n   百兆交换机\n   Dom0 8G 32vcpu\n   Dom1 8G 8vcpu\n\n## 2 虚拟化的类型\n\nXEN和KVM实现了真正的虚拟化方案；LXC确切来说应该是资源隔离（namespace），并不能提供完整的物理隔离功能。\n\nXEN虚拟化是相对于KVM来说更加成熟的虚拟化方案，像AWS、Azure等公有云都是使用的XEN作为虚拟化方案；而随着最近几年KVM的发展以及KVM较好的性能，国内的部分虚拟化厂商开始选择KVM作为新的虚拟化方案，像百度、Intel中国、阿里云等开始逐步向KVM迁移。\n\nLXC通过资源隔离和命名空间实现了伪虚拟化功能，由于LXC较高的性能和不彻底的隔离，越来越多的应用到私有云上。\n\n## 3 磁盘IO性能\n\n### 3.1 XEN磁盘性能\n\n我们知道XEN 虚机中磁盘操作会经过Dom0来中转，那么中转带来的效率损坏有多少呢？这里测试raw和LVM两种情况。\n\n#### 3.1.1 Dom0\n\n##### 3.1.1.1 随机读\n\n```shell\nfio -filename=/dev/vg0/root-disk -direct=1 -iodepth 1 -thread -rw=randread -ioengine=sync -bs=2M -size=50G -numjobs=1 -runtime=60 -group_reporting -name=mytest\n```\n\n![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/001.png)\n\n##### 3.1.1.2 随机写\n\n```shell\nfio -filename=/dev/vg0/root-disk -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=sync -bs=2M -size=50G -numjobs=1 -runtime=60 -group_reporting -name=mytest\n```\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/002.png)\n\n#### 3.1.2 DomU使用LVM\n\n##### 3.1.2.1 随机读\n\n```shell\nfio -filename=/dev/xvda1 -direct=1 -iodepth 1 -thread -rw=randread -ioengine=sync -bs=2M -size=50G -numjobs=1 -runtime=60 -group_reporting -name=mytest\n```\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/003.png)\n\n##### 3.1.2.2 随机写\n\n```shell\nfio -filename=/dev/xvda1 -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=sync -bs=2M -size=50G -numjobs=1 -runtime=60 -group_reporting -name=mytest\n```\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/004.png)\n \n#### 3.1.3 DomU使用RAW\n\n##### 3.1.3.1 随机读\n\n```shell\nfio -filename=/dev/xvda1 -direct=1 -iodepth 1 -thread -rw=randread -ioengine=sync -bs=2M -size=50G -numjobs=1 -runtime=60 -group_reporting -name=mytest\n```\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/005.png)\n\n##### 3.1.3.2 随机写\n\n```shell\nfio -filename=/dev/xvda1 -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=sync -bs=2M -size=50G -numjobs=1 -runtime=60 -group_reporting -name=mytest\n```\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/006.png)\n\n#### 3.1.4 总结\n\n从测试数据可以看出，LVM DomU相较于Dom0，随机读取的吞吐量、IOPS下降10%，时延增加12%；随机写的的吞吐量、IOPS下降22%，时延增加33%。\n\n与之相比RAW的性能下降更加明显。XEN虚拟化环境中采用LVM作为存储方案。\n\n### 3.2 KVM磁盘性能\n\nKVM的磁盘性能由于受到virtio的影响，每次测试结果偏差较大，不在此罗列。\n\n### 3.3 LXC磁盘性能\n\n根据LXC实现原理，其磁盘操作性能与物理机一致。\n\n## 4 网卡性能\n\n根据前段时间现场出现的问题和提供解决方案后的效果，以及理论数据来看，网卡需要采用pci-passthrough或者SR-IOV的模式。\n\n## 5 OS性能\n\n### 5.1 benchmark测试\n\n采用lmbench对操作系统进行整体性能测试，包括非虚拟化场景、虚拟化Dom0且不绑定CPU场景、虚拟化Dom0绑定CPU场景、虚拟化DomU不绑定CPU场景、虚拟化DomU绑定CPU场景、KVM场景、LXC场景。分别对应physical-host、dom0-nopin---、dom0-pin8core、domU-nopin--8、domU-pin8core、kvm-8core----、lxc-32core---。\n\n具体测试数据参见附件benchmark-real.result。\n\n#### 5.1.1 虚机的系统调用性能下降明显\n\n由于虚机中的系统调用路径边长，XEN系统调用的性能下降明显，KVM由于是内核嵌入式虚拟化，性能明显高于XEN。\n\n而LXC由于与physical-host一样，使用同一个内核，所以LXC的性能与物理机基本相同。\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/007.png)\n\n#### 5.1.2 CPU计算能力无差别\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/008.png)\n\n#### 5.1.3 绑定CPU后的内存读写效率较高\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/009.png)\n\n绑定CPU后，由于cache命中增多，I/O相关的操作效率明显提升。\n\n### 5.2 总结\n\n要想获得较好的CPU计算性能，对于关键业务的虚机，需要给虚机绑定CPU，一方面可以防止VCPU漂移导致的缓存失效问题，另一方面可以防止由于VCPU调度不均衡导致的部分物理CPU过载的情况。\n\n#### 5.2.1 Dom0绑定cpu\n\nDom0负责处理DomU与外设的交互，Dom0的性能直接影响DomU的性能，推荐Dom0的vcpu不少于4个。\n\n启动参数中添加“dom0_max_vcpus=4 dom0_vcpus_pin”\n\n#### 5.2.2 DomU绑定cpu\n\nDomU中绑定CPU时要尽量将一个虚机的物理CPU放到同一个socket上，提高最后一级cache的命中率，同时也可以降低numa访问不同距离内存带来的负面影响。\n\n对于开启超线程的CPU，一定要将两个逻辑CPU分配给同一个DomU，否则可能会因为CPU内硬件争用导致不同DomU之间互相影响。\n\n查看CPU逻辑拓扑的方法可以通过xm info -n或者在Dom0中取消cpu绑定的情况下，通过hitvsupport中的likwid-topology命令。\n\nDomU中指定CPU的方法如下：\n\n```\nvcpus=8\ncpus = [\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"]\n```\n\n## 6. 虚拟化安装\n\n### 6.1 XEN\n\nSLES安装XEN PV内核\n\n#### 6.1.1 安装xen和dom0\n\n```\nyast2->virtualization->install hypervisor and tools\n```\n\n自动安装xen和dom0,重启并选择XEN启动项。\n\n安装虚拟机\n\n```\nyast2->virtualization->create virtual machines\n```\n\n根据步骤创建虚拟机，这里创建出来的虚拟机就是domU\n\n#### 6.1.2 常用操作\n\n查看主机上的虚拟机\n\n```\n#xm list\n```\n\n停止虚拟机\n\n```\n#xm destroy virtualname\n```\n\n虚拟机的配置存储在Xend store中，磁盘镜像文件默认存储在/var/lib/xen/images目录下。\n导出虚拟机配置\n\n```\n#xm list -l virtualname > virtualname.cfg\n```\n\n删除一个虚拟机\n\n```\n#xm delete virtualname\n```\n\n根据配置文件添加一个虚拟机\n\n```\n#xm new -F virtualname.cfg\n```\n\n虚拟机clone\n\n```\n#virt-clone -o originalvirutal -n newvirtual -f /var/lib/xen/images/newvirtual.disk\n```\n\n进入虚拟机操作\n\n```\n#xm console virtualname\n#退出时用ctrl+]\n```\n\n保存(暂停)虚拟机\n\n```\n#virsh save virutalname /var/virtualname.img\n```\n\n恢复虚拟机\n\n```\n#virsh restore /var/virtualname.img\n```\n\n### 6.2 KVM\n\n在SUSE下KVM的安装于XEN类似，可以通过yast2图形化界面安装。\n\n#### 6.3 LXC\n\n##### 6.3.1 LXC环境安装\n\nlxc不支持图形化操作，只能通过命令行进行。\n\n安装lxc相关工具包\n\n```\n#zypper install lxc\n```\n\nlxc依赖内核cgroup，需要设置默认启动\n\n```\n#insserv boot.cgroup\n```\n\n手动启动cgroup\n\n```\n#/etc/init.d/boot.cgroup start\n```\n\n##### 6.3.2 LXC虚机安装\n\n这里以创建一个sles虚机为例讲解虚机的安装过程。\n\n（1）编写lxc配置文件，配置文件一般存放在/etc/lxc目录下\n\n```\n#cat /etc/lxc/c2.conf\n```\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/010.png)\n\n（2）以该配置文件创建一个sles虚机\n\n```\n#lxc-create -t sles -f c2.conf -n c2\n```\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/011.png)\n\n本质上进行的操作就是copy一个rootfs到目录/var/lib/lxc目录下\n\n（3）启动虚机c2\n\n```\n#lxc-start -n c2\n```\n\n（4）进入虚机\n\n```\n#lxc-console -n c2\n```\n\n（5）查看虚机状态\n\n```\n#lxc-info -n c2\n```\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/012.png)\n\n（6）设置虚机可使用的内存\n\n设置C1可以使用的内存为2G\n\n```\n#lxc-cgroup -n c1 memory.limit_in_bytes 2G\n```\n\n设置C1超过使用内存后诱发oom\n\n```\n#lxc-cgropu -n c1 memory.oom_control 0\n```\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/013.png)\n\n如果有swap空间，当C1的内存使用2G后会使用swap，直到swap用光才会被kill。\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/014.png)\n\n如果关闭swap后，当C1的内存使用达到2G，再次申请空间就会被kill。\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/015.png)\n\n说明：由于memsw control的稳定性问题，sles11sp2默认关闭了对虚机使用memory和swap总和的限制。\n\n ![](/assets/images/2014/09/30/virtualization-performance-analysis-xen-kvm-lxc/016.png)\n\n## 7. 总结\n\n三种虚拟化性能比较：LXC>>KVM>>XEN；由于LXC使用cgroup机制，其性能损坏基本为0。\n\n三种虚拟化隔离比较：XEN>>KVM>>LXC；LXC只能虚拟化linux。\n\n三种虚拟化内存利用率：LXC>>KVM>>XEN；由于LXC共用内核，内存利用率最高；其他两种方案每个虚机都需要单独的操作系统占用一部分内存空间。\n\n---\n\n* Author: [瀚海书香](http://blog.chinaunix.net/uid/20662820.html)\n* 原文链接：[虚拟化性能分析（XEN/KVM/LXC)](http://blog.chinaunix.net/uid-20662820-id-4514947.html)\n","tags":["LXC"],"categories":["Virtualization"]},{"title":"JDBC 操作 Spark Thrift Server","url":"%2F2014%2F2014-09-29-jdbc-spark-thrift-server%2F","content":"\n### 介绍\n\n可使用不同语言(Java、Scala、Python)，以 JDBC 或 Thrift 方式，操作 Spark SQL。\n\n下面的示例项目展示了以JDBC 方式，通过 Spark Thrift Server 进行的基础操作。\n\n项目包含多种语言的示例：Java、Scala、Python\n\n### 注意\n\nPython使用到了pyhs2、pyhive、impyla\n\n可通过pip或easy_install安装\n\n安装中需要c++环境，依赖thrift和thrift sasl\n\nsasl可通过sasl-0.1.3-cp27-none-win_amd64.whl安装\n\n### 参考：\n\n* [https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2](https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2)\n* [https://github.com/BradRuderman/pyhs2](https://github.com/BradRuderman/pyhs2)\n* [https://github.com/dropbox/PyHive](https://github.com/dropbox/PyHive)\n* [https://github.com/cloudera/impyla](https://github.com/cloudera/impyla)\n\n### 示例\n\n* 项目地址：[JDBC-Spark-Thrift-Server](https://github.com/HyperJ/JDBC-Spark-Thrift-Server \"JDBC-Spark-Thrift-Server\")\n\n### 链接：\n\n* [Spark SQL: Distributed SQL Engine](http://spark.apache.org/docs/latest/sql-programming-guide.html#distributed-sql-engine \"Spark SQL: Distributed SQL Engine\")、\n* [HiveServer2 Clients](https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients \"HiveServer2 Clients\")、\n* [Setting Up HiveServer2](https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2 \"Setting Up HiveServer2\")、\n* [pyhs2](https://github.com/BradRuderman/pyhs2 \"pyhs2\")、\n* [PyHive: Python interface to Hive and Presto.](https://github.com/dropbox/PyHive \"PyHive: Python interface to Hive and Presto.\")、\n* [impyla: Python DB API 2.0 client for Impala and Hive (HiveServer2 protocol)](https://github.com/cloudera/impyla \"impyla: Python DB API 2.0 client for Impala and Hive (HiveServer2 protocol)\")\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[JDBC 操作 Spark Thrift Server](http://blog.hyperj.net/2014/2014-09-29-jdbc-spark-thrift-server/)","tags":["HyperJ"],"categories":["Spark"]},{"title":"画图解释 SQL JOIN 语句","url":"%2F2014%2F2014-08-19-sql-join-statement-paint%2F","content":"\n我认为 Ligaya Turmelle 的关于SQL联合（join）语句的帖子对于新手开发者来说是份很好的材料。SQL 联合语句好像是基于集合的，用韦恩图来解释咋一看是很自然而然的。不过正如在她的帖子的回复中所说的，在测试中我发现韦恩图并不是十分的匹配SQL联合语法。\n\n不过我还是喜欢这个观点，所以我们来看看能不能用上韦恩图。假设我们有下面两张表。表A在左边，表B在右边。我们给它们各四条记录。\n\n```sql\nid name       id  name\n-- ----       --  ----\n1  Pirate     1   Rutabaga\n2  Monkey     2   Pirate\n3  Ninja      3   Darth Vader\n4  Spaghetti  4   Ninja\n```\n \n我们用过name字段用几种不同方式把这些表联合起来，看能否得到和那些漂亮的韦恩图在概念上的匹配。\n\n```sql\nSELECT * FROM TableA\nINNER JOIN TableB\nON TableA.name = TableB.name\n\nid  name       id   name\n--  ----       --   ----\n1   Pirate     2    Pirate\n3   Ninja      4    Ninja\n```\n\n内联合（inner join）只生成同时匹配表A和表B的记录集。（如下图）\n\n![](/assets/images/2014/08/19/sql-join-statement-paint/iinner-join.png)\n\n```sql\nSELECT * FROM TableA\nFULL OUTER JOIN TableB\nON TableA.name = TableB.name\n\nid    name       id    name\n--    ----       --    ----\n1     Pirate     2     Pirate\n2     Monkey     null  null\n3     Ninja      4     Ninja\n4     Spaghetti  null  null\nnull  null       1     Rutabaga       \nnull  null       3     Darth Vader\n```\n\n全外联合（full outer join）生成表A和表B里的记录全集，包括两边都匹配的记录。如果有一边没有匹配的，缺失的这一边为null。（如下图）\n\n![](/assets/images/2014/08/19/sql-join-statement-paint/Full-outer-join.png)\n\n```sql\nSELECT * FROM TableA\nLEFT OUTER JOIN TableB\nON TableA.name = TableB.name\n\nid  name       id    name\n--  ----       --    ----\n1   Pirate     2     Pirate\n2   Monkey     null  null\n3   Ninja      4     Ninja\n4   Spaghetti  null  null\n```\n\n左外联合（left outer join）生成表A的所有记录，包括在表B里匹配的记录。如果没有匹配的，右边将是null。（如下图）\n\n![](/assets/images/2014/08/19/sql-join-statement-paint/Left-outer-join.png)\n\n```sql\nSELECT * FROM TableA\nLEFT OUTER JOIN TableB\nON TableA.name = TableB.name\nWHERE TableB.id IS null\n\nid  name       id     name\n--  ----       --     ----\n2   Monkey     null   null\n4   Spaghetti  null   null\n```\n\n为了生成只在表A里而不在表B里的记录集，我们用同样的左外联合，然后用where语句排除我们不想要的记录。（如下图）\n\n![](/assets/images/2014/08/19/sql-join-statement-paint/WHERE-TableB.id-IS-nul.png)\n\n```sql\nSELECT * FROM TableA\nFULL OUTER JOIN TableB\nON TableA.name = TableB.name\nWHERE TableA.id IS null \nOR TableB.id IS null\n\nid    name       id    name\n--    ----       --    ----\n2     Monkey     null  null\n4     Spaghetti  null  null\nnull  null       1     Rutabaga\nnull  null       3     Darth Vader\n```\n\n为了生成对于表A和表B唯一的记录集，我们用同样的全外联合，然后用where语句排除两边都不想要的记录。（如下图）\n\n![](/assets/images/2014/08/19/sql-join-statement-paint/WHERE-TableA.id-IS-null.png)\n\n还有一种笛卡尔积或者交叉联合（cross join），据我所知不能用韦恩图表示：\n\n```sql\nSELECT * FROM TableA\nCROSS JOIN TableB\n```\n\n这个把“所有”联接到“所有”，产生4乘4=16行，远多于原始的集合。如果你学过数学，你便知道为什么这个联合遇上大型的表很危险。\n\n【2013-06-17 更新】下图由 Moffatt 在 2008 年制作（点击可查看大图）。PS：Jeff Atwood 的文章写于 2007 年。\n\n![](/assets/images/2014/08/19/sql-join-statement-paint/SQL-Joins.jpg)\n\n---\n\n* 原文链接：[画图解释 SQL join 语句](http://blog.jobbole.com/40443/)\n","tags":["JOIN"],"categories":["SQL"]},{"title":"Apache Twill 入门","url":"%2F2014%2F2014-07-07-apache-twill-introduction%2F","content":"\n### Apache Twill 介绍\n\nApache Twill 抽象了 Apache Hadoop® Yarn 开发的编程接口，减少了开发分布式应用程序的复杂性，让开发者将更多的注意力放在他们的应用程序的业务逻辑上。\nApache Twill 允许您通过Yarn的分布式编程模型运行类似于的单机的线程开发。\n\n### Apache Twill 开发\n\n- 创建Maven工程并添加依赖\n\n  主要是Hadoop和Twill相关依赖\n\n- 添加Hadoop配置文件\n\n  core-default.xml、hdfs-default.xml、yarn-default.xml\n\n- 编写业务程序\n\n  继承AbstractTwillRunnable，实现run方法，写业务逻辑\n\n- 编写运行程序\n\n  初始化配置信息，主要是Zookeeper信息和资源配置信息，通过TwillRunnerService方式运行程序\n\n- 运行测试代码\n\n  需配置HADOOP_HOME或hadoop.home.dir\n\n相关链接：[Apache Twill](http://twill.incubator.apache.org \"Apache Twill\")、\n[Apache Twill Getting Started](http://twill.incubator.apache.org/GettingStarted.html \"Apache Twill Getting Started\")、\n[Apache Twill—YARN上应用程序开发包](http://dongxicheng.org/mapreduce-nextgen/apache-twill-for-yarn/ \"Apache Twill—YARN上应用程序开发包\")\n\n---\n\n* 项目地址：[Yarn-Demo-by-Twill](https://github.com/HyperJ/Yarn-Demo-by-Twill \"Yarn-Demo-by-Twill\")\n","tags":["YARN"],"categories":["Twill"]},{"title":"Presto实现原理和美团的使用实践","url":"%2F2014%2F2014-06-16-presto%2F","content":"\nFacebook的数据仓库存储在少量大型Hadoop/HDFS集群。Hive是Facebook在几年前专为Hadoop打造的一款数据仓库工具。在以前，Facebook的科学家和分析师一直依靠Hive来做数据分析。但Hive使用MapReduce作为底层计算框架，是专为批处理设计的。但随着数据越来越多，使用Hive进行一个简单的数据查询可能要花费几分到几小时，显然不能满足交互式查询的需求。Facebook也调研了其他比Hive更快的工具，但它们要么在功能有所限制要么就太简单，以至于无法操作Facebook庞大的数据仓库。\n\n2012年开始试用的一些外部项目都不合适，他们决定自己开发，这就是Presto。2012年秋季开始开发，目前该项目已经在超过 1000名Facebook雇员中使用，运行超过30000个查询，每日数据在1PB级别。Facebook称Presto的性能比Hive要好上10倍多。2013年Facebook正式宣布开源Presto。\n\n本文首先介绍Presto从用户提交SQL到执行的这一个过程，然后尝试对Presto实现实时查询的原理进行分析和总结，最后介绍Presto在美团的使用情况。\n\n### Presto架构\n\n![](/assets/images/2014/06/16/presto/image1.png)\n\nPresto查询引擎是一个Master-Slave的架构，由一个Coordinator节点，一个Discovery Server节点，多个Worker节点组成，Discovery Server通常内嵌于Coordinator节点中。Coordinator负责解析SQL语句，生成执行计划，分发执行任务给Worker节点执行。Worker节点负责实际执行查询任务。Worker节点启动后向Discovery Server服务注册，Coordinator从Discovery Server获得可以正常工作的Worker节点。如果配置了Hive Connector，需要配置一个Hive MetaStore服务为Presto提供Hive元信息，Worker节点与HDFS交互读取数据。\n\n### Presto执行查询过程简介\n\n既然Presto是一个交互式的查询引擎，我们最关心的就是Presto实现低延时查询的原理，我认为主要是下面几个关键点，当然还有一些传统的SQL优化原理，这里不介绍了。\n\n* 完全基于内存的并行计算\n\n* 流水线\n\n* 本地化计算\n\n* 动态编译执行计划\n\n* 小心使用内存和数据结构\n\n* 类BlinkDB的近似查询\n\n* GC控制\n\n为了介绍上述几个要点，这里先介绍一下Presto执行查询的过程\n\n#### 提交查询\n\n用户使用Presto Cli提交一个查询语句后，Cli使用HTTP协议与Coordinator通信，Coordinator收到查询请求后调用SqlParser解析SQL语句得到Statement对象，并将Statement封装成一个QueryStarter对象放入线程池中等待执行。\n\n![](/assets/images/2014/06/16/presto/image2.jpg)\n\n#### SQL编译过程\n\nPresto与Hive一样，使用Antlr编写SQL语法，语法规则定义在Statement.g和StatementBuilder.g两个文件中。\n\n如下图中所示从SQL编译为最终的物理执行计划大概分为5部，最终生成在每个Worker节点上运行的LocalExecutionPlan，这里不详细介绍SQL解析为逻辑执行计划的过程，通过一个SQL语句来理解查询计划生成之后的计算过程。\n\n![](/assets/images/2014/06/16/presto/image3.png)\n\n样例SQL：\n\n```sql\nselect c1.rank, count(*) from dim.city c1 join dim.city c2 on c1.id = c2.id where c1.id > 10 group by c1.rank limit 10;\n```\n\n![](/assets/images/2014/06/16/presto/image4.jpg)\n\n上面的SQL语句生成的逻辑执行计划Plan如上图所示。那么Presto是如何对上面的逻辑执行计划进行拆分以较高的并行度去执行完这个计划呢，我们来看看物理执行计划。\n\n#### 物理执行计划\n\n逻辑执行计划图中的虚线就是Presto对逻辑执行计划的切分点，逻辑计划Plan生成的SubPlan分为四个部分，每一个SubPlan都会提交到一个或者多个Worker节点上执行。\n\nSubPlan有几个重要的属性planDistribution、outputPartitioning、partitionBy属性。\n\n* PlanDistribution表示一个查询Stage的分发方式，逻辑执行计划图中的4个SubPlan共有3种不同的PlanDistribution方式：Source表示这个SubPlan是数据源，Source类型的任务会按照数据源大小确定分配多少个节点进行执行；Fixed表示这个SubPlan会分配固定的节点数进行执行（Config配置中的query.initial-hash-partitions参数配置，默认是8）；None表示这个SubPlan只分配到一个节点进行执行。在下面的执行计划中，SubPlan1和SubPlan0 PlanDistribution=Source，这两个SubPlan都是提供数据源的节点，SubPlan1所有节点的读取数据都会发向SubPlan0的每一个节点；SubPlan2分配8个节点执行最终的聚合操作；SubPlan3只负责输出最后计算完成的数据。\n\n* OutputPartitioning属性只有两个值HASH和NONE，表示这个SubPlan的输出是否按照partitionBy的key值对数据进行Shuffle。在下面的执行计划中只有SubPlan0的OutputPartitioning=HASH，所以SubPlan2接收到的数据是按照rank字段Partition后的数据。\n\n![](/assets/images/2014/06/16/presto/image5.jpg)\n\n#### 完全基于内存的并行计算\n\n##### 查询的并行执行流程\n\nPresto SQL的执行流程如下图所示\n\n* Cli通过HTTP协议提交SQL查询之后，查询请求封装成一个SqlQueryExecution对象交给Coordinator的SqlQueryManager#queryExecutor线程池去执行\n\n* 每个SqlQueryExecution线程（图中Q-X线程）启动后对查询请求的SQL进行语法解析和优化并最终生成多个Stage的SqlStageExecution任务，每个SqlStageExecution任务仍然交给同样的线程池去执行\n\n* 每个SqlStageExecution线程（图中S-X线程）启动后每个Stage的任务按PlanDistribution属性构造一个或者多个RemoteTask通过HTTP协议分配给远端的Worker节点执行\n\n* Worker节点接收到RemoteTask请求之后，启动一个SqlTaskExecution线程（图中T-X线程）将这个任务的每个Split包装成一个PrioritizedSplitRunner任务（图中SR-X）交给Worker节点的TaskExecutor#executor线程池去执行\n\n![](/assets/images/2014/06/16/presto/image6.png)\n\n上面的执行计划实际执行效果如下图所示。\n\n* Coordinator通过HTTP协议调用Worker节点的 /v1/task 接口将执行计划分配给所有Worker节点（图中蓝色箭头）\n\n* SubPlan1的每个节点读取一个Split的数据并过滤后将数据分发给每个SubPlan0节点进行Join操作和Partial Aggr操作\n\n* SubPlan1的每个节点计算完成后按GroupBy Key的Hash值将数据分发到不同的SubPlan2节点\n\n* 所有SubPlan2节点计算完成后将数据分发到SubPlan3节点\n\n* SubPlan3节点计算完成后通知Coordinator结束查询，并将数据发送给Coordinator\n\n![](/assets/images/2014/06/16/presto/image7.png)\n\n##### 源数据的并行读取\n\n在上面的执行计划中SubPlan1和SubPlan0都是Source节点，其实它们读取HDFS文件数据的方式就是调用的HDFS InputSplit API，然后每个InputSplit分配一个Worker节点去执行，每个Worker节点分配的InputSplit数目上限是参数可配置的，Config中的query.max-pending-splits-per-node参数配置，默认是100。\n\n##### 分布式的Hash聚合\n\n上面的执行计划在SubPlan0中会进行一次Partial的聚合计算，计算每个Worker节点读取的部分数据的部分聚合结果，然后SubPlan0的输出会按照group by字段的Hash值分配不同的计算节点，最后SubPlan3合并所有结果并输出\n\n#### 流水线\n\n##### 数据模型\n\nPresto中处理的最小数据单元是一个Page对象，Page对象的数据结构如下图所示。一个Page对象包含多个Block对象，每个Block对象是一个字节数组，存储一个字段的若干行。多个Block横切的一行是真实的一行数据。一个Page最大1MB，最多16*1024行数据。\n\n![](/assets/images/2014/06/16/presto/image8.png)\n\n##### 节点内部流水线计算\n\n下图是一个Worker节点内部的计算流程图，左侧是任务的执行流程图。\n\nWorker节点将最细粒度的任务封装成一个PrioritizedSplitRunner对象，放入pending split优先级队列中。每个\n\nWorker节点启动一定数目的线程进行计算，线程数task.shard.max-threads=availableProcessors() * 4，在config中配置。\n\n每个空闲的线程从队列中取出一个PrioritizedSplitRunner对象执行，如果执行完成一个周期，超过最大执行时间1秒钟，判断任务是否执行完成，如果完成，从allSplits队列中删除，如果没有，则放回pendingSplits队列中。\n\n每个任务的执行流程如下图右侧，依次遍历所有Operator，尝试从上一个Operator取一个Page对象，如果取得的Page不为空，交给下一个Operator执行。\n\n![](/assets/images/2014/06/16/presto/image9.png)\n\n##### 节点间流水线计算\n\n下图是ExchangeOperator的执行流程图，ExchangeOperator为每一个Split启动一个HttpPageBufferClient对象，主动向上一个Stage的Worker节点拉数据，数据的最小单位也是一个Page对象，取到数据后放入Pages队列中\n\n![](/assets/images/2014/06/16/presto/image10.png)\n\n#### 本地化计算\n\nPresto在选择Source任务计算节点的时候，对于每一个Split，按下面的策略选择一些minCandidates\n\n* 优先选择与Split同一个Host的Worker节点\n\n* 如果节点不够优先选择与Split同一个Rack的Worker节点\n\n* 如果节点还不够随机选择其他Rack的节点\n\n对于所有Candidate节点，选择assignedSplits最少的节点。\n\n#### 动态编译执行计划\n\nPresto会将执行计划中的ScanFilterAndProjectOperator和FilterAndProjectOperator动态编译为Byte Code，并交给JIT去编译为native代码。Presto也使用了Google Guava提供的LoadingCache缓存生成的Byte Code。\n\n![](/assets/images/2014/06/16/presto/image11.png)\n\n![](/assets/images/2014/06/16/presto/image12.png)\n\n上面的两段代码片段中，第一段为没有动态编译前的代码，第二段代码为动态编译生成的Byte Code反编译之后还原的优化代码，我们看到这里采用了循环展开的优化方法。\n\n循环展开最常用来降低循环开销，为具有多个功能单元的处理器提供指令级并行。也有利于指令流水线的调度。\n\n#### 小心使用内存和数据结构\n\n使用Slice进行内存操作，Slice使用Unsafe#copyMemory实现了高效的内存拷贝，Slice仓库参考：https://github.com/airlift/slice\n\nFacebook工程师在另一篇介绍ORCFile优化的文章中也提到使用Slice将ORCFile的写性能提高了20%~30%，参考：https://code.facebook.com/posts/229861827208629/scaling-the-facebook-data-warehouse-to-300-pb/\n\n#### 类BlinkDB的近似查询\n\n为了加快avg、count distinct、percentile等聚合函数的查询速度，Presto团队与BlinkDB作者之一Sameer Agarwal合作引入了一些近似查询函数approx_avg、approx_distinct、approx_percentile。approx_distinct使用HyperLogLog Counting算法实现。\n\n#### GC控制\n\nPresto团队在使用hotspot java7时发现了一个JIT的BUG，当代码缓存快要达到上限时，JIT可能会停止工作，从而无法将使用频率高的代码动态编译为native代码。\n\nPresto团队使用了一个比较Hack的方法去解决这个问题，增加一个线程在代码缓存达到70%以上时进行显式GC，使得已经加载的Class从perm中移除，避免JIT无法正常工作的BUG。\n\n#### Presto TPCH benchmark测试\n\n介绍了上述这么多点，我们最关心的还是Presto性能测试，Presto中实现了TPCH的标准测试，下面的表格给出了Presto 0.60 TPCH的测试结果。直接运行presto-main/src/test/java/com/facebook/presto/benchmark/BenchmarkSuite.java。\n\n```\nbenchmarkName cpuNanos(MILLISECONDS) inputRows inputBytes inputRows/s inputBytes/s outputRows outputBytes outputRows/s outputBytes/s\n                      count_agg     2.055ms   1.5M  12.9MB    730M/s  6.12GB/s      1      9B     486/s  4.28KB/s\n                 double_sum_agg    14.792ms   1.5M  12.9MB    101M/s   870MB/s      1      9B      67/s    608B/s\n                       hash_agg   174.576ms   1.5M  21.5MB   8.59M/s   123MB/s      3     45B      17/s    257B/s\n               predicate_filter    68.387ms   1.5M  12.9MB   21.9M/s   188MB/s  1.29M  11.1MB   18.8M/s   162MB/s\n                     raw_stream     1.899ms   1.5M  12.9MB    790M/s  6.62GB/s   1.5M  12.9MB    790M/s  6.62GB/s\n                         top100    58.735ms   1.5M  12.9MB   25.5M/s   219MB/s    100    900B    1.7K/s    15KB/s\n         in_memory_orderby_1.5M  1909.524ms   1.5M  41.5MB    786K/s  21.7MB/s   1.5M  28.6MB    786K/s    15MB/s\n                     hash_build   588.471ms   1.5M  25.7MB   2.55M/s  43.8MB/s   1.5M  25.7MB   2.55M/s  43.8MB/s\n                      hash_join  2400.006ms     6M   103MB    2.5M/s  42.9MB/s     6M   206MB    2.5M/s  85.8MB/s\n            hash_build_and_join  2996.489ms   7.5M   129MB    2.5M/s    43MB/s     6M   206MB      2M/s  68.8MB/s\n              hand_tpch_query_1  3146.931ms     6M   361MB   1.91M/s   115MB/s      4    300B       1/s     95B/s\n              hand_tpch_query_6   345.960ms     6M   240MB   17.3M/s   695MB/s      1      9B       2/s     26B/s\nsql_groupby_agg_with_arithmetic  1211.444ms     6M   137MB   4.95M/s   113MB/s      2     30B       1/s     24B/s\n                  sql_count_agg     3.635ms   1.5M  12.9MB    413M/s  3.46GB/s      1      9B     275/s  2.42KB/s\n             sql_double_sum_agg    16.960ms   1.5M  12.9MB   88.4M/s   759MB/s      1      9B      58/s    530B/s\n          sql_count_with_filter    81.641ms   1.5M  8.58MB   18.4M/s   105MB/s      1      9B      12/s    110B/s\n                sql_groupby_agg   169.748ms   1.5M  21.5MB   8.84M/s   126MB/s      3     45B      17/s    265B/s\n           sql_predicate_filter    46.540ms   1.5M  12.9MB   32.2M/s   277MB/s  1.29M  11.1MB   27.7M/s   238MB/s\n                 sql_raw_stream     3.374ms   1.5M  12.9MB    445M/s  3.73GB/s   1.5M  12.9MB    445M/s  3.73GB/s\n                    sql_top_100    60.663ms   1.5M  12.9MB   24.7M/s   212MB/s    100    900B   1.65K/s  14.5KB/s\n                  sql_hash_join  4421.159ms   7.5M   129MB    1.7M/s  29.1MB/s     6M   206MB   1.36M/s  46.6MB/s\n        sql_join_with_predicate  1008.909ms   7.5M   116MB   7.43M/s   115MB/s      1      9B       0/s      8B/s\n              sql_varbinary_max   224.510ms     6M  97.3MB   26.7M/s   433MB/s      1     21B       4/s     93B/s\n             sql_distinct_multi   257.958ms   1.5M    32MB   5.81M/s   124MB/s      5    112B      19/s    434B/s\n            sql_distinct_single   112.849ms   1.5M  12.9MB   13.3M/s   114MB/s      1      9B       8/s     79B/s\n               sql_tpch_query_1  3168.782ms     6M   361MB   1.89M/s   114MB/s      4    336B       1/s    106B/s\n               sql_tpch_query_6   286.281ms     6M   240MB     21M/s   840MB/s      1      9B       3/s     31B/s\n                       sql_like  3497.154ms     6M   232MB   1.72M/s  66.3MB/s  1.15M  9.84MB    328K/s  2.81MB/s\n                         sql_in    80.267ms     6M  51.5MB   74.8M/s   642MB/s     25    225B     311/s  2.74KB/s\n                sql_semijoin_in  1945.074ms   7.5M  64.4MB   3.86M/s  33.1MB/s     3M  25.8MB   1.54M/s  13.2MB/s\n                sql_regexp_like  2233.004ms   1.5M  76.6MB    672K/s  34.3MB/s      1      9B       0/s      4B/s\n     sql_approx_percentile_long   587.748ms   1.5M  12.9MB   2.55M/s  21.9MB/s      1      9B       1/s     15B/s\n               sql_between_long    53.433ms   1.5M  12.9MB   28.1M/s   241MB/s      1      9B      18/s    168B/s\nsampled_sql_groupby_agg_with_arithmetic  1369.485ms    6M   189MB   4.38M/s   138MB/s      2     30B       1/s     21B/s\n          sampled_sql_count_agg    11.367ms   1.5M  12.9MB    132M/s  1.11GB/s      1      9B      87/s    791B/s\nsampled_sql_join_with_predicate  1338.238ms   7.5M   180MB   5.61M/s   135MB/s      1      9B       0/s      6B/s\n     sampled_sql_double_sum_agg    24.638ms   1.5M  25.7MB   60.9M/s  1.02GB/s      1      9B      40/s    365B/s\n             stat_long_variance    26.390ms   1.5M  12.9MB   56.8M/s   488MB/s      1      9B      37/s    341B/s\n         stat_long_variance_pop    26.583ms   1.5M  12.9MB   56.4M/s   484MB/s      1      9B      37/s    338B/s\n           stat_double_variance    26.601ms   1.5M  12.9MB   56.4M/s   484MB/s      1      9B      37/s    338B/s\n       stat_double_variance_pop    26.371ms   1.5M  12.9MB   56.9M/s   488MB/s      1      9B      37/s    341B/s\n               stat_long_stddev    26.266ms   1.5M  12.9MB   57.1M/s   490MB/s      1      9B      38/s    342B/s\n           stat_long_stddev_pop    26.350ms   1.5M  12.9MB   56.9M/s   489MB/s      1      9B      37/s    341B/s\n             stat_double_stddev    26.316ms   1.5M  12.9MB     57M/s   489MB/s      1      9B      38/s    342B/s\n         stat_double_stddev_pop    26.360ms   1.5M  12.9MB   56.9M/s   488MB/s      1      9B      37/s    341B/s\n sql_approx_count_distinct_long    35.763ms   1.5M  12.9MB   41.9M/s   360MB/s      1      9B      27/s    251B/s\nsql_approx_count_distinct_double    37.198ms   1.5M  12.9MB   40.3M/s   346MB/s      1      9B      26/s    241B/s\n```\n\n### 美团如何使用Presto\n\n#### 选择presto的原因\n\n2013年我们也用过一段时间的impala，当时impala不支持线上1.x的hadoop社区版，所以搭了一个CDH的小集群，每天将大集群的热点数据导入小集群。但是hadoop集群年前完成升级2.2之后，当时的impala还不支持2.2 hadoop版本。而Presto刚好开始支持2.x hadoop社区版，并且Presto在Facebook 300PB大数据量的环境下可以成功的得到大量使用，我们相信它在美团也可以很好的支撑我们实时分析的需求，于是决定先上线测试使用一段时间。\n\n#### 部署和使用形式\n\n考虑到两个原因：1、由于Hadoop集群主要是夜间完成昨天的计算任务，白天除了日志写入外，集群的计算负载较低。2、Presto Worker节点与DataNode节点布置在一台机器上可以本地计算。因此我们将Presto部署到了所有的DataNode机器上，并且夜间停止Presto服务，避免占用集群资源，夜间基本也不会有用户查询数据。\n\n#### Presto二次开发和BUG修复\n\n年后才正式上线Presto查询引擎，0.60版本，使用的时间不长，但是也遇到了一些问题：\n\n* 美团的Hadoop使用的是2.2版本，并且开启了Security模式，但是Presto不支持Kerberos认证，我们修改了Presto代码，增加了Kerberos认证的功能。\n\n* Presto还不支持SQL的隐式类型转换，而Hive支持，很多自助查询的用户习惯了Hive，导致使用Presto时都会出现表达式中左右变量类型不匹配的问题，我们增加了隐式类型转换的功能，大大减小了用户SQL出错的概率。\n\n* Presto不支持查询lzo压缩的数据，需要修改hadoop-lzo的代码。\n\n* 解决了一个having子句中有distinct字段时查询失败的BUG，并反馈了Presto团队 https://github.com/facebook/presto/pull/1104\n\n所有代码的修改可以参考我们在github上的仓库 https://github.com/MTDATA/presto/commits/mt-0.60\n\n#### 实际使用效果\n\n这里给出一个公司内部开放给分析师、PM、工程师进行自助查询的查询中心的一个测试报告。这里选取了平时的5000个Hive查询，通过Presto查询的对比见下面的表格。\n\n| 自助查询sql数 | hive | presto | presto/hive |\n| ----------- | ---- | ------ | ----------- |\n| 1424 | 154427s | 27708s | 0.179424582489 |\n\n### 参考\n\n* Presto官方文档 http://prestodb.io/\n\n* Facebook Presto团队介绍Presto的文章\n   \n   https://www.facebook.com/notes/facebook-engineering/presto-interacting-with-petabytes-of-data-at-facebook/10151786197628920\n\n* SlideShare两个分享Presto 的PPT\n   \n   http://www.slideshare.net/zhusx/presto-overview?from_search=1\n   \n   http://www.slideshare.net/frsyuki/hadoop-source-code-reading-15-in-japan-presto\n\n---\n\n* 原文链接：[Presto实现原理和美团的使用实践](http://succinct.cs.berkeley.edu/wp/wordpress/?page_id=127)\n","tags":["OLAP"],"categories":["Presto"]},{"title":"一致性哈希算法(Consistent Hashing)","url":"%2F2014%2F2014-04-11-consistent-hashing%2F","content":"\n### 介绍\n\n一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。\n\n一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：\n\n1. **平衡性(Balance)**：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。\n2. **单调性(Monotonicity)**：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。\n3. **分散性(Spread)**：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。\n4. **负载(Load)**：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。\n\n在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。接下来主要讲解一下一致性哈希算法是如何设计的：\n\n### 环形Hash空间\n\n按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图:\n\n![](/assets/images/2014/04/11/consistent-hashing/001.png)\n\n### 把数据通过一定的hash算法处理后映射到环上\n\n现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。如下图：\n\n```\n    Hash(object1) = key1;\n    Hash(object2) = key2;\n    Hash(object3) = key3;\n    Hash(object4) = key4;\n```\n\n![](/assets/images/2014/04/11/consistent-hashing/002.png)\n\n### 将机器通过hash算法映射到环上\n\n在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。\n\n假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中，其示意图如下：\n\n```\nHash(NODE1) = KEY1;\nHash(NODE2) = KEY2;\nHash(NODE3) = KEY3;\n```\n\n![](/assets/images/2014/04/11/consistent-hashing/003.png)\n\n通过上图可以看出对象与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。\n\n### 机器的删除与添加\n\n普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。\n\n1. 节点（机器）的删除\n\n以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图：\n\n![](/assets/images/2014/04/11/consistent-hashing/004.png)\n\n2. 节点（机器）的添加\n\n如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图：\n\n![](/assets/images/2014/04/11/consistent-hashing/005.png)\n\n通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。\n\n### 平衡性\n\n根据上面的图解分析，一致性哈希算法满足了单调性和负载均衡的特性以及一般hash算法的分散性，但这还并不能当做其被广泛应用的原由，因为还缺少了平衡性。下面将分析一致性哈希算法是如何满足平衡性的。hash算法是不保证平衡的，如上面只部署了NODE1和NODE3的情况（NODE2被删除的图），object1存储到了NODE1中，而object2、object3、object4都存储到了NODE3中，这样就照成了非常不平衡的状态。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。\n\n“虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。\n\n以上面只部署了NODE1和NODE3的情况（NODE2被删除的图）为例，之前的对象在机器上的分布很不均衡，现在我们以2个副本（复制个数）为例，这样整个hash环中就存在了4个虚拟节点，最后对象映射的关系图如下：\n\n![](/assets/images/2014/04/11/consistent-hashing/006.png)\n\n根据上图可知对象的映射关系：object1->NODE1-1，object2->NODE1-2，object3->NODE3-2，object4->NODE3-1。通过虚拟节点的引入，对象的分布就比较均衡了。那么在实际操作中，正真的对象查询是如何工作的呢？对象从hash到虚拟节点到实际节点的转换如下图：\n\n![](/assets/images/2014/04/11/consistent-hashing/007.png)\n\n“虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值：\n\n```\nHash(“192.168.1.100”);\n```\n\n引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值：\n\n```\nHash(“192.168.1.100#1”); // NODE1-1\nHash(“192.168.1.100#2”); // NODE1-2\n```\n\n---\n\n* 参考链接：[一致性hash算法简介](http://blog.huanghao.me/?p=14)\n* 原文链接：[五分钟理解一致性哈希算法(consistent hashing)](http://blog.csdn.net/cywosp/article/details/23397179/)\n","tags":["Consistent-Hashing"],"categories":["Algorithm"]},{"title":"美团数据仓库-数据脱敏","url":"%2F2014%2F2014-04-08-data-mask%2F","content":"\n## 背景与目标\n\n在数据仓库建设过程中，数据安全扮演着重要角色，因为隐私或敏感数据的泄露，会对数据主体（客户，员工和公司）的财产、名誉、人身安全、以及合法利益造成严重损害。因此我们需要严格控制对仓库中的数据访问，即什么样的人员或者需求才可以访问到相关的数据。这就要求对数据本身的敏感程度进行安全级别划分。数据有了安全等级的划分，才能更好管理对数据访问控制，以此来保护好数据安全。\n\n举个例子简单的说明下，例如我们仓库中有一张关于注册用户的基本信息表User，其中有手机号mobile，昵称username两个字段。我们在划分数据安全层级的时，将用户mobile的安全等级划分为L2要高于username的等级L1，并规定只有访问权限达到L2的运营部门才能访问mobile字段。这样在公司各个部门需要访问注册用户基本信息表User时，我们只需检查访问者是否来自运营部门，如果是运营部可以访问mobile，如果不是只能访问username信息了。这样就有效的防止用户手机号被不相关工作人员泄露出去，同时也不影响查询用户username的需求。\n\n但是往往在实际生产过程中，应用场景会更加复杂，仅靠类似这样的访问控制，满足不了生产的需要，还需要结合其它的途径，而数据脱敏就是一种有效的方式，既能满足日常生产的需要，又能保护数据安全。\n\n数据脱敏，具体指对某些敏感信息通过脱敏规则进行数据的变形，实现敏感隐私数据的可靠保护。这样可以使数据本身的安全等级降级，就可以在开发、测试和其它非生产环境以及外包或云计算环境中安全地使用脱敏后的真实数据集。借助数据脱敏技术，屏蔽敏感信息，并使屏蔽的信息保留其原始数据格式和属性，以确保应用程序可在使用脱敏数据的开发与测试过程中正常运行。\n\n## 敏感数据梳理\n\n在数据脱敏进行之前，我们首先要确定哪些数据要作为脱敏的目标。我们根据美团特有的业务场景和数据安全级别划分（绝密、高保密、保密、可公开，四个级别）， 主要从“高保密”等级的敏感数据，开始进行梳理。\n\n这里我们把敏感数据分成四个维度进行梳理，用户、商家、终端、公司。\n\n* 从用户维度进行梳理可能有这些敏感字段如下：手机号码、邮件地址、账号、地址、固定电话号码等信息（此外个人隐私数据相关还有如：种族、政治观点、宗教信仰、基因等）\n\n* 从商家维度进行梳理：合同签订人，合同签订人电话等（不排除全局敏感数据：如商家团购品类等）\n\n* 从用户终端维度进行梳理：能够可能标识终端的唯一性字段，如设备id。\n\n* 从公司角度进行梳理：交易金额、代金卷密码、充值码等\n\n## 确定脱敏处理方法\n\n梳理出了敏感数据字段，我们接下来的工作就是如何根据特定的应用场景对敏感字段实施具体的脱敏处理方法。\n\n常见的处理方法如下几种有：\n\n* 替换：如统一将女性用户名替换为F，这种方法更像“障眼法”，对内部人员可以完全保持信息完整性，但易破解。\n\n* 重排：序号12345重排为54321，按照一定的顺序进行打乱，很像“替换”， 可以在需要时方便还原信息，但同样易破解。\n\n* 加密：编号12345加密为23456，安全程度取决于采用哪种加密算法，一般根据实际情况而定。\n\n* 截断：13811001111截断为138，舍弃必要信息来保证数据的模糊性，是比较常用的脱敏方法，但往往对生产不够友好。\n\n* 掩码: 123456 -> 1xxxx6，保留了部分信息，并且保证了信息的长度不变性，对信息持有者更易辨别， 如火车票上得身份信息。\n\n* 日期偏移取整：20130520 12:30:45 -> 20130520 12:00:00，舍弃精度来保证原始数据的安全性，一般此种方法可以保护数据的时间分布密度。\n\n但不管哪种手段都要基于不同的应用场景，遵循下面两个原则：\n\n1．remain meaningful for application logic(尽可能的为脱敏后的应用,保留脱敏前的有意义信息)\n\n2．sufficiently treated to avoid reverse engineer(最大程度上防止黑客进行破解)\n\n以这次脱敏一个需求为例：\n\n美团一般的业务场景是这样的，用户在网站上付款一笔团购单之后，我们会将团购密码，发到用户对应的手机号上。这个过程中，从用户的角度来看团购密码在未被用户消费之前，对用户来说是要保密的，不能被公开的，其次美团用户的手机号也是要保密的，因为公开之后可能被推送一些垃圾信息，或者更严重的危害。从公司内部数据分析人员来看，他们有时虽然没有权限知道用户团购密码，但是他们想分析公司发送的团购密码数量情况，这是安全允许；再有数据分析人员虽然没有权限知道用户具体的手机号码，但是他们需要统计美团用户手机的地区分布情况，或者运营商分布差异，进而为更上层的决策提供支持。\n\n根据这样的需求，我们可以对团购密码做加密处理保证其唯一性，也保留其原有的数据格式，在保密的同时不影响数据分析的需求。同样，我们将用户的手机号码的前7位，关于运营商和地区位置信息保留，后四位进行模糊化处理。这样同样也达到了保护和不影响统计的需求。\n\n因此从实际出发遵循上面的两个处理原则，第一阶段我们在脱敏工具集中，确定了如下4种基本类型的脱敏方案（对应4个udf）：\n\n| 字段名称 | 脱敏方法 | 举例 | 脱敏原则 |\n| ------ | ------- | --- | ------- |\n| 电话号码（moblie） | 掩码 | 13812345678-> 13812340000 | 防止号码泄露，但保留运营商和地区信息 (唯一性，由前端绑定或者注册时约束) |\n| 邮件（email） | 截断+ 加密 | hxs@163.com -> 6225888e3a1d4a139f5f5db98d846102b2cd0d@163.com | 保留邮件域信息 |\n| 团购密码（code） | 加密 | 4023926843399219 -> 1298078978 | 加密后在一定精度上保持唯一性，并与数据类型一致 |\n| 设备号（deviceid） | 加密 | ffbacff42826302d9e832b7e907a212a -> b9c2a61972a19bf21b06b0ddb8ba642d | 加密后保持唯一性 |\n\n## 确定实施范围与步骤\n\n通过上面字段的梳理和脱敏方案的制定，我们对美团数据仓库中涉及到得敏感字段的表进行脱敏处理。在数据仓库分层理论中，数据脱敏往往发生在上层，最直接的是在对外开放这一层面上。在实际应用中，我们既要参考分层理论，又要从美团现有数据仓库生产环境的体系出发，主要在数据维度层（dim），以及基础服务数据层（fact）上实施脱敏。这样，我们可以在下游相关数据报表以及衍生数据层的开发过程中使用脱敏后的数据，从而避免出现数据安全问题。\n\n确认处理的表和字段后，我们还要确保相关上下游流程的正常运行, 以及未脱敏的敏感信息的正常产出与存储（通过更严格的安全审核来进行访问）。\n\n以用户信息表user为例，脱敏步骤如下：\n\n1．首先生产一份ndm_user未脱敏数据，用于未脱敏数据的正常产出。\n\n2．对下游涉及的所有依赖user生产流程进行修改，来确保脱敏后的正常运行，这里主要是确认数据格式，以及数据源的工作。\n\n3．根据对应的脱敏方法对user表中对应的字段进行脱敏处理。\n\n## 总结\n\n通过上面的几个步骤的实施，我们完成了第一阶段的数据脱敏工作。在数据脱敏方案设计与实施过程中， 我们觉得更重要的还是从特定的应用场景出发进行整体设计，兼顾了数据仓库建设这一重要考量维度。数据脱敏实施为公司数据安全的推进，提供了有力支持。当然，我们第一阶段脱敏的工具集还相对较少，需要补充。 脱敏的技术架构还有待完善和更加自动化。\n\n本文关于数据安全和数据访问隔离的控制阐述较少，希望通过以后的生产实践，继续为大家介绍。\n\n## 参考\n\n参考文献如下：\n\n* http://en.wikipedia.org/wiki/Data_masking\n* http://www.prnews.cn/press_release/51034.htm\n\n---\n\n* Author：song\n* Source：[美团点评技术团队](https://tech.meituan.com)\n* Link：[美团数据仓库-数据脱敏](http://tech.meituan.com/data-mask.html)\n","tags":["DataMasking"],"categories":["DataMasking"]},{"title":"伸展树Java实现","url":"%2F2014%2F2014-04-01-splay-tree-java-implementation%2F","content":"\n## 概要\n\n前面分别通过C和C++实现了伸展树，本章给出伸展树的Java版本。基本算法和原理都与前两章一样。\n\n1. 伸展树的介绍\n2. 伸展树的Java实现(完整源码)\n3. 伸展树的Java测试程序 \n\n## 伸展树的介绍\n\n伸展树(Splay Tree)是特殊的二叉查找树。\n\n它的特殊是指，它除了本身是棵二叉查找树之外，它还具备一个特点: 当某个节点被访问时，伸展树会通过旋转使该节点成为树根。这样做的好处是，下次要访问该节点时，能够迅速的访问到该节点。 \n\n## 伸展树的Java实现\n\n### 1. 基本定义\n\n```java\npublic class SplayTree<T extends Comparable<T>> {\n    private SplayTreeNode<T> mRoot;    // 根结点\n    public class SplayTreeNode<T extends Comparable<T>> {\n        T key;                // 关键字(键值)\n        SplayTreeNode<T> left;    // 左孩子\n        SplayTreeNode<T> right;    // 右孩子\n        public SplayTreeNode() {\n            this.left = null;\n            this.right = null;\n        }\n        public SplayTreeNode(T key, SplayTreeNode<T> left, SplayTreeNode<T> right) {\n            this.key = key;\n            this.left = left;\n            this.right = right;\n        }\n    }\n    ...\n}\n```\n\nSplayTree是伸展树，而SplayTreeNode是伸展树节点。在此，我将SplayTreeNode定义为SplayTree的内部类。在伸展树SplayTree中包含了伸展树的根节点mRoot。SplayTreeNode包括的几个组成元素:\n\n   (01) key -- 是关键字，是用来对伸展树的节点进行排序的。\n   (02) left -- 是左孩子。\n   (03) right -- 是右孩子。\n\n### 2. 旋转\n\n旋转是伸展树中需要重点关注的，它的代码如下：\n\n```java\n/* \n * 旋转key对应的节点为根节点，并返回根节点。\n * 注意：\n *   (a)：伸展树中存在\"键值为key的节点\"。\n *          将\"键值为key的节点\"旋转为根节点。\n *   (b)：伸展树中不存在\"键值为key的节点\"，并且key < tree.key。\n *      b-1 \"键值为key的节点\"的前驱节点存在的话，将\"键值为key的节点\"的前驱节点旋转为根节点。\n *      b-2 \"键值为key的节点\"的前驱节点存在的话，则意味着，key比树中任何键值都小，那么此时，将最小节点旋转为根节点。\n *   (c)：伸展树中不存在\"键值为key的节点\"，并且key > tree.key。\n *      c-1 \"键值为key的节点\"的后继节点存在的话，将\"键值为key的节点\"的后继节点旋转为根节点。\n *      c-2 \"键值为key的节点\"的后继节点不存在的话，则意味着，key比树中任何键值都大，那么此时，将最大节点旋转为根节点。\n */\nprivate SplayTreeNode<T> splay(SplayTreeNode<T> tree, T key) {\n    if (tree == null) \n        return tree;\n    SplayTreeNode<T> N = new SplayTreeNode<T>();\n    SplayTreeNode<T> l = N;\n    SplayTreeNode<T> r = N;\n    SplayTreeNode<T> c;\n    for (;;) {\n        int cmp = key.compareTo(tree.key);\n        if (cmp < 0) {\n            if (tree.left == null)\n                break;\n            if (key.compareTo(tree.left.key) < 0) {\n                c = tree.left;                           /* rotate right */\n                tree.left = c.right;\n                c.right = tree;\n                tree = c;\n                if (tree.left == null) \n                    break;\n            }\n            r.left = tree;                               /* link right */\n            r = tree;\n            tree = tree.left;\n        } else if (cmp > 0) {\n            if (tree.right == null) \n                break;\n            if (key.compareTo(tree.right.key) > 0) {\n                c = tree.right;                          /* rotate left */\n                tree.right = c.left;\n                c.left = tree;\n                tree = c;\n                if (tree.right == null) \n                    break;\n            }\n            l.right = tree;                              /* link left */\n            l = tree;\n            tree = tree.right;\n        } else {\n            break;\n        }\n    }\n    l.right = tree.left;                                /* assemble */\n    r.left = tree.right;\n    tree.left = N.right;\n    tree.right = N.left;\n    return tree;\n}\npublic void splay(T key) {\n    mRoot = splay(mRoot, key);\n}\n```\n\n上面的代码的作用：将\"键值为key的节点\"旋转为根节点，并返回根节点。它的处理情况共包括：\n\n(a)：伸展树中存在\"键值为key的节点\"。\n   将\"键值为key的节点\"旋转为根节点。\n\n(b)：伸展树中不存在\"键值为key的节点\"，并且key < tree->key。\n   b-1) \"键值为key的节点\"的前驱节点存在的话，将\"键值为key的节点\"的前驱节点旋转为根节点。\n   b-2) \"键值为key的节点\"的前驱节点存在的话，则意味着，key比树中任何键值都小，那么此时，将最小节点旋转为根节点。\n\n(c)：伸展树中不存在\"键值为key的节点\"，并且key > tree->key。\n   c-1) \"键值为key的节点\"的后继节点存在的话，将\"键值为key的节点\"的后继节点旋转为根节点。\n   c-2) \"键值为key的节点\"的后继节点不存在的话，则意味着，key比树中任何键值都大，那么此时，将最大节点旋转为根节点。\n\n下面列举个例子分别对a进行说明。\n\n在下面的伸展树中查找10，，共包括\"右旋\" --> \"右链接\" --> \"组合\"这3步。\n\n![](/assets/images/2014/04/01/splay-tree-java-implementation/001.jpg)\n\n#### 01, 右旋\n\n对应代码中的\"rotate right\"部分\n\n![](/assets/images/2014/04/01/splay-tree-java-implementation/002.jpg)\n\n#### 02, 右链接\n\n对应代码中的\"link right\"部分\n\n![](/assets/images/2014/04/01/splay-tree-java-implementation/003.jpg)\n\n#### 03. 组合\n\n对应代码中的\"assemble\"部分\n\n![](/assets/images/2014/04/01/splay-tree-java-implementation/004.jpg)\n\n提示：如果在上面的伸展树中查找\"70\"，则正好与\"示例1\"对称，而对应的操作则分别是\"rotate left\", \"link left\"和\"assemble\"。\n\n其它的情况，例如\"查找15是b-1的情况，查找5是b-2的情况\"等等，这些都比较简单，大家可以自己分析。\n\n### 3. 插入\n\n插入代码\n\n```java\n/* \n * 将结点插入到伸展树中，并返回根节点\n * 参数说明：\n *     tree 伸展树的\n *     z 插入的结点\n */\nprivate SplayTreeNode<T> insert(SplayTreeNode<T> tree, SplayTreeNode<T> z) {\n    int cmp;\n    SplayTreeNode<T> y = null;\n    SplayTreeNode<T> x = tree;\n    // 查找z的插入位置\n    while (x != null) {\n        y = x;\n        cmp = z.key.compareTo(x.key);\n        if (cmp < 0)\n            x = x.left;\n        else if (cmp > 0)\n            x = x.right;\n        else {\n            System.out.printf(\"不允许插入相同节点(%d)!\\n\", z.key);\n            z=null;\n            return tree;\n        }\n    }\n    if (y==null)\n        tree = z;\n    else {\n        cmp = z.key.compareTo(y.key);\n        if (cmp < 0)\n            y.left = z;\n        else\n            y.right = z;\n    }\n    return tree;\n}\npublic void insert(T key) {\n    SplayTreeNode<T> z=new SplayTreeNode<T>(key,null,null);\n    // 如果新建结点失败，则返回。\n    if ((z=new SplayTreeNode<T>(key,null,null)) == null)\n        return ;\n    // 插入节点\n    mRoot = insert(mRoot, z);\n    // 将节点(key)旋转为根节点\n    mRoot = splay(mRoot, key);\n}\n```\n\ninsert(key)是提供给外部的接口，它的作用是新建节点(节点的键值为key)，并将节点插入到伸展树中；然后，将该节点旋转为根节点。\n\ninsert(tree, z)是内部接口，它的作用是将节点z插入到tree中。insert(tree, z)在将z插入到tree中时，仅仅只将tree当作是一棵二叉查找树，而且不允许插入相同节点。\n\n### 4. 删除\n\n删除代码\n\n```\n/* \n * 删除结点(z)，并返回被删除的结点\n * 参数说明：\n *     bst 伸展树\n *     z 删除的结点\n */\nprivate SplayTreeNode<T> remove(SplayTreeNode<T> tree, T key) {\n    SplayTreeNode<T> x;\n    if (tree == null) \n        return null;\n    // 查找键值为key的节点，找不到的话直接返回。\n    if (search(tree, key) == null)\n        return tree;\n    // 将key对应的节点旋转为根节点。\n    tree = splay(tree, key);\n    if (tree.left != null) {\n        // 将\"tree的前驱节点\"旋转为根节点\n        x = splay(tree.left, key);\n        // 移除tree节点\n        x.right = tree.right;\n    }\n    else\n        x = tree.right;\n    tree = null;\n    return x;\n}\npublic void remove(T key) {\n    mRoot = remove(mRoot, key);\n}\n```\n\nremove(key)是外部接口，remove(tree, key)是内部接口。\n\nremove(tree, key)的作用是：删除伸展树中键值为key的节点。\n\n它会先在伸展树中查找键值为key的节点。若没有找到的话，则直接返回。若找到的话，则将该节点旋转为根节点，然后再删除该节点。\n\n关于\"前序遍历\"、\"中序遍历\"、\"后序遍历\"、\"最大值\"、\"最小值\"、\"查找\"、\"打印伸展树\"、\"销毁伸展树\"等接口就不再单独介绍了，Please RTFSC(Read The Fucking Source Code)！这些接口，与前面介绍的\"二叉查找树\"、\"AVL树\"的相关接口都是类似的。\n\n## 伸展树的Java实现(完整源码)\n\n伸展树的实现文件(SplayTree.java)\n\n```java\n/**\n * Java 语言: 伸展树\n *\n * @author skywang\n * @date 2014/02/03\n */\n\npublic class SplayTree<T extends Comparable<T>> {\n\n    private SplayTreeNode<T> mRoot;    // 根结点\n\n    public class SplayTreeNode<T extends Comparable<T>> {\n        T key;                // 关键字(键值)\n        SplayTreeNode<T> left;    // 左孩子\n        SplayTreeNode<T> right;    // 右孩子\n\n        public SplayTreeNode() {\n            this.left = null;\n            this.right = null;\n        }\n\n        public SplayTreeNode(T key, SplayTreeNode<T> left, SplayTreeNode<T> right) {\n            this.key = key;\n            this.left = left;\n            this.right = right;\n        }\n    }\n\n    public SplayTree() {\n        mRoot=null;\n    }\n\n    /*\n     * 前序遍历\"伸展树\"\n     */\n    private void preOrder(SplayTreeNode<T> tree) {\n        if(tree != null) {\n            System.out.print(tree.key+\" \");\n            preOrder(tree.left);\n            preOrder(tree.right);\n        }\n    }\n\n    public void preOrder() {\n        preOrder(mRoot);\n    }\n\n    /*\n     * 中序遍历\"伸展树\"\n     */\n    private void inOrder(SplayTreeNode<T> tree) {\n        if(tree != null) {\n            inOrder(tree.left);\n            System.out.print(tree.key+\" \");\n            inOrder(tree.right);\n        }\n    }\n\n    public void inOrder() {\n        inOrder(mRoot);\n    }\n\n\n    /*\n     * 后序遍历\"伸展树\"\n     */\n    private void postOrder(SplayTreeNode<T> tree) {\n        if(tree != null)\n        {\n            postOrder(tree.left);\n            postOrder(tree.right);\n            System.out.print(tree.key+\" \");\n        }\n    }\n\n    public void postOrder() {\n        postOrder(mRoot);\n    }\n\n\n    /*\n     * (递归实现)查找\"伸展树x\"中键值为key的节点\n     */\n    private SplayTreeNode<T> search(SplayTreeNode<T> x, T key) {\n        if (x==null)\n            return x;\n\n        int cmp = key.compareTo(x.key);\n        if (cmp < 0)\n            return search(x.left, key);\n        else if (cmp > 0)\n            return search(x.right, key);\n        else\n            return x;\n    }\n\n    public SplayTreeNode<T> search(T key) {\n        return search(mRoot, key);\n    }\n\n    /*\n     * (非递归实现)查找\"伸展树x\"中键值为key的节点\n     */\n    private SplayTreeNode<T> iterativeSearch(SplayTreeNode<T> x, T key) {\n        while (x!=null) {\n            int cmp = key.compareTo(x.key);\n\n            if (cmp < 0) \n                x = x.left;\n            else if (cmp > 0) \n                x = x.right;\n            else\n                return x;\n        }\n\n        return x;\n    }\n\n    public SplayTreeNode<T> iterativeSearch(T key) {\n        return iterativeSearch(mRoot, key);\n    }\n\n    /* \n     * 查找最小结点：返回tree为根结点的伸展树的最小结点。\n     */\n    private SplayTreeNode<T> minimum(SplayTreeNode<T> tree) {\n        if (tree == null)\n            return null;\n\n        while(tree.left != null)\n            tree = tree.left;\n        return tree;\n    }\n\n    public T minimum() {\n        SplayTreeNode<T> p = minimum(mRoot);\n        if (p != null)\n            return p.key;\n\n        return null;\n    }\n     \n    /* \n     * 查找最大结点：返回tree为根结点的伸展树的最大结点。\n     */\n    private SplayTreeNode<T> maximum(SplayTreeNode<T> tree) {\n        if (tree == null)\n            return null;\n\n        while(tree.right != null)\n            tree = tree.right;\n        return tree;\n    }\n\n    public T maximum() {\n        SplayTreeNode<T> p = maximum(mRoot);\n        if (p != null)\n            return p.key;\n\n        return null;\n    }\n\n    /* \n     * 旋转key对应的节点为根节点，并返回根节点。\n     *\n     * 注意：\n     *   (a)：伸展树中存在\"键值为key的节点\"。\n     *          将\"键值为key的节点\"旋转为根节点。\n     *   (b)：伸展树中不存在\"键值为key的节点\"，并且key < tree.key。\n     *      b-1 \"键值为key的节点\"的前驱节点存在的话，将\"键值为key的节点\"的前驱节点旋转为根节点。\n     *      b-2 \"键值为key的节点\"的前驱节点存在的话，则意味着，key比树中任何键值都小，那么此时，将最小节点旋转为根节点。\n     *   (c)：伸展树中不存在\"键值为key的节点\"，并且key > tree.key。\n     *      c-1 \"键值为key的节点\"的后继节点存在的话，将\"键值为key的节点\"的后继节点旋转为根节点。\n     *      c-2 \"键值为key的节点\"的后继节点不存在的话，则意味着，key比树中任何键值都大，那么此时，将最大节点旋转为根节点。\n     */\n    private SplayTreeNode<T> splay(SplayTreeNode<T> tree, T key) {\n        if (tree == null) \n            return tree;\n\n        SplayTreeNode<T> N = new SplayTreeNode<T>();\n        SplayTreeNode<T> l = N;\n        SplayTreeNode<T> r = N;\n        SplayTreeNode<T> c;\n\n        for (;;) {\n\n            int cmp = key.compareTo(tree.key);\n            if (cmp < 0) {\n\n                if (tree.left == null)\n                    break;\n\n                if (key.compareTo(tree.left.key) < 0) {\n                    c = tree.left;                           /* rotate right */\n                    tree.left = c.right;\n                    c.right = tree;\n                    tree = c;\n                    if (tree.left == null) \n                        break;\n                }\n                r.left = tree;                               /* link right */\n                r = tree;\n                tree = tree.left;\n            } else if (cmp > 0) {\n\n                if (tree.right == null) \n                    break;\n\n                if (key.compareTo(tree.right.key) > 0) {\n                    c = tree.right;                          /* rotate left */\n                    tree.right = c.left;\n                    c.left = tree;\n                    tree = c;\n                    if (tree.right == null) \n                        break;\n                }\n\n                l.right = tree;                              /* link left */\n                l = tree;\n                tree = tree.right;\n            } else {\n                break;\n            }\n        }\n\n        l.right = tree.left;                                /* assemble */\n        r.left = tree.right;\n        tree.left = N.right;\n        tree.right = N.left;\n\n        return tree;\n    }\n\n    public void splay(T key) {\n        mRoot = splay(mRoot, key);\n    }\n\n    /* \n     * 将结点插入到伸展树中，并返回根节点\n     *\n     * 参数说明：\n     *     tree 伸展树的\n     *     z 插入的结点\n     */\n    private SplayTreeNode<T> insert(SplayTreeNode<T> tree, SplayTreeNode<T> z) {\n        int cmp;\n        SplayTreeNode<T> y = null;\n        SplayTreeNode<T> x = tree;\n\n        // 查找z的插入位置\n        while (x != null) {\n            y = x;\n            cmp = z.key.compareTo(x.key);\n            if (cmp < 0)\n                x = x.left;\n            else if (cmp > 0)\n                x = x.right;\n            else {\n                System.out.printf(\"不允许插入相同节点(%d)!\\n\", z.key);\n                z=null;\n                return tree;\n            }\n        }\n\n        if (y==null)\n            tree = z;\n        else {\n            cmp = z.key.compareTo(y.key);\n            if (cmp < 0)\n                y.left = z;\n            else\n                y.right = z;\n        }\n\n        return tree;\n    }\n\n    public void insert(T key) {\n        SplayTreeNode<T> z=new SplayTreeNode<T>(key,null,null);\n\n        // 如果新建结点失败，则返回。\n        if ((z=new SplayTreeNode<T>(key,null,null)) == null)\n            return ;\n\n        // 插入节点\n        mRoot = insert(mRoot, z);\n        // 将节点(key)旋转为根节点\n        mRoot = splay(mRoot, key);\n    }\n\n    /* \n     * 删除结点(z)，并返回被删除的结点\n     *\n     * 参数说明：\n     *     bst 伸展树\n     *     z 删除的结点\n     */\n    private SplayTreeNode<T> remove(SplayTreeNode<T> tree, T key) {\n        SplayTreeNode<T> x;\n\n        if (tree == null) \n            return null;\n\n        // 查找键值为key的节点，找不到的话直接返回。\n        if (search(tree, key) == null)\n            return tree;\n\n        // 将key对应的节点旋转为根节点。\n        tree = splay(tree, key);\n\n        if (tree.left != null) {\n            // 将\"tree的前驱节点\"旋转为根节点\n            x = splay(tree.left, key);\n            // 移除tree节点\n            x.right = tree.right;\n        }\n        else\n            x = tree.right;\n\n        tree = null;\n\n        return x;\n    }\n\n    public void remove(T key) {\n        mRoot = remove(mRoot, key);\n    }\n\n    /*\n     * 销毁伸展树\n     */\n    private void destroy(SplayTreeNode<T> tree) {\n        if (tree==null)\n            return ;\n\n        if (tree.left != null)\n            destroy(tree.left);\n        if (tree.right != null)\n            destroy(tree.right);\n\n        tree=null;\n    }\n\n    public void clear() {\n        destroy(mRoot);\n        mRoot = null;\n    }\n\n    /*\n     * 打印\"伸展树\"\n     *\n     * key        -- 节点的键值 \n     * direction  --  0，表示该节点是根节点;\n     *               -1，表示该节点是它的父结点的左孩子;\n     *                1，表示该节点是它的父结点的右孩子。\n     */\n    private void print(SplayTreeNode<T> tree, T key, int direction) {\n\n        if(tree != null) {\n\n            if(direction==0)    // tree是根节点\n                System.out.printf(\"%2d is root\\n\", tree.key);\n            else                // tree是分支节点\n                System.out.printf(\"%2d is %2d's %6s child\\n\", tree.key, key, direction==1?\"right\" : \"left\");\n\n            print(tree.left, tree.key, -1);\n            print(tree.right,tree.key,  1);\n        }\n    }\n\n    public void print() {\n        if (mRoot != null)\n            print(mRoot, mRoot.key, 0);\n    }\n}\n```\n\n伸展树的测试程序(SplayTreeTest.java)\n\n```java\n/**\n * Java 语言: 伸展树\n *\n * @author skywang\n * @date 2014/02/03\n */\npublic class SplayTreeTest {\n\n    private static final int arr[] = {10,50,40,30,20,60};\n\n    public static void main(String[] args) {\n        int i, ilen;\n        SplayTree<Integer> tree=new SplayTree<Integer>();\n\n        System.out.print(\"== 依次添加: \");\n        ilen = arr.length;\n        for(i=0; i<ilen; i++) {\n            System.out.print(arr[i]+\" \");\n            tree.insert(arr[i]);\n        }\n\n        System.out.print(\"\\n== 前序遍历: \");\n        tree.preOrder();\n\n        System.out.print(\"\\n== 中序遍历: \");\n        tree.inOrder();\n\n        System.out.print(\"\\n== 后序遍历: \");\n        tree.postOrder();\n        System.out.println();\n\n        System.out.println(\"== 最小值: \"+ tree.minimum());\n        System.out.println(\"== 最大值: \"+ tree.maximum());\n        System.out.println(\"== 树的详细信息: \");\n        tree.print();\n\n        i = 30;\n        System.out.printf(\"\\n== 旋转节点(%d)为根节点\\n\", i);\n        tree.splay(i);\n        System.out.printf(\"== 树的详细信息: \\n\");\n        tree.print();\n\n        // 销毁二叉树\n        tree.clear();\n    }\n}\n```\n\n在二叉查找树的Java实现中，使用了泛型，也就意味着它支持任意类型；但是该类型必须要实现Comparable接口。\n\n## 伸展树的Java测试程序\n\n伸展树的测试程序运行结果如下：\n\n```\n== 依次添加: 10 50 40 30 20 60 \n== 前序遍历: 60 30 20 10 50 40 \n== 中序遍历: 10 20 30 40 50 60 \n== 后序遍历: 10 20 40 50 30 60 \n== 最小值: 10\n== 最大值: 60\n== 树的详细信息: \n60 is root\n30 is 60's   left child\n20 is 30's   left child\n10 is 20's   left child\n50 is 30's  right child\n40 is 50's   left child\n\n== 旋转节点(30)为根节点\n== 树的详细信息: \n30 is root\n20 is 30's   left child\n10 is 20's   left child\n60 is 30's  right child\n50 is 60's   left child\n40 is 50's   left child\n```\n\n测试程序的主要流程是：新建伸展树，然后向伸展树中依次插入10,50,40,30,20,60。插入完毕这些数据之后，伸展树的节点是60；此时，再旋转节点，使得30成为根节点。\n\n依次插入10,50,40,30,20,60示意图如下：\n\n![](/assets/images/2014/04/01/splay-tree-java-implementation/005.jpg)\n\n将30旋转为根节点的示意图如下：\n\n![](/assets/images/2014/04/01/splay-tree-java-implementation/006.jpg)\n\n---\n\n* Author: [如果天空不死](http://www.cnblogs.com/skywang12345/)\n* Source: [博客园](http://www.cnblogs.com)\n* Link: [伸展树(三)之 Java的实现](http://www.cnblogs.com/skywang12345/p/3604286.html)","tags":["SplayTree"],"categories":["Algorithm"]},{"title":"AVL树(三)之 Java的实现","url":"%2F2014%2F2014-03-30-avl-tree-implementation%2F","content":" \n## 概要\n\n前面分别介绍了AVL树\"C语言版本\"和\"C++版本\"，本章介绍AVL树的Java实现版本，它的算法与C语言和C++版本一样。内容包括：\n\n1. AVL树的介绍\n2. AVL树的Java实现\n3. AVL树的Java测试程序\n\n## AVL树的介绍\n\nAVL树是高度平衡的而二叉树。它的特点是：AVL树中任何节点的两个子树的高度最大差别为1。 \n\n![](/assets/images/2014/03/30/avl-tree-implementation/001.jpg)\n\n上面的两张图片，左边的是AVL树，它的任何节点的两个子树的高度差别都<=1；而右边的不是AVL树，因为7的两颗子树的高度相差为2(以2为根节点的树的高度是3，而以8为根节点的树的高度是1)。\n\n## AVL树的Java实现\n\n### 1. 节点\n\n#### 1.1 节点定义\n\n```java\npublic class AVLTree<T extends Comparable<T>> {\n    private AVLTreeNode<T> mRoot;    // 根结点\n\n    // AVL树的节点(内部类)\n    class AVLTreeNode<T extends Comparable<T>> {\n        T key;                // 关键字(键值)\n        int height;         // 高度\n        AVLTreeNode<T> left;    // 左孩子\n        AVLTreeNode<T> right;    // 右孩子\n\n        public AVLTreeNode(T key, AVLTreeNode<T> left, AVLTreeNode<T> right) {\n            this.key = key;\n            this.left = left;\n            this.right = right;\n            this.height = 0;\n        }\n    }\n    \n    ......\n}\n```\n\nAVLTree是AVL树对应的类，而AVLTreeNode是AVL树节点，它是AVLTree的内部类。AVLTree包含了AVL树的根节点，AVL树的基本操作也定义在AVL树中。AVLTreeNode包括的几个组成对象:\n\n(01) key -- 是关键字，是用来对AVL树的节点进行排序的。\n\n(02) left -- 是左孩子。\n\n(03) right -- 是右孩子。\n\n(04) height -- 是高度。\n\n#### 1.2 树的高度\n\n```java\n/*\n * 获取树的高度\n */\nprivate int height(AVLTreeNode<T> tree) {\n    if (tree != null)\n        return tree.height;\n\n    return 0;\n}\n\npublic int height() {\n    return height(mRoot);\n}\n```\n\n关于高度，有的地方将\"空二叉树的高度是-1\"，而本文采用维基百科上的定义：树的高度为最大层次。即空的二叉树的高度是0，非空树的高度等于它的最大层次(根的层次为1，根的子节点为第2层，依次类推)。\n\n#### 1.3 比较大小\n\n```java\n/*\n * 比较两个值的大小\n */\nprivate int max(int a, int b) {\n    return a>b ? a : b;\n}\n``` \n\n### 2. 旋转\n\n如果在AVL树中进行插入或删除节点后，可能导致AVL树失去平衡。这种失去平衡的可以概括为4种姿态：LL(左左)，LR(左右)，RR(右右)和RL(右左)。下面给出它们的示意图：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/002.jpg)\n\n上图中的4棵树都是\"失去平衡的AVL树\"，从左往右的情况依次是：LL、LR、RL、RR。除了上面的情况之外，还有其它的失去平衡的AVL树，如下图：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/003.jpg)\n\n上面的两张图都是为了便于理解，而列举的关于\"失去平衡的AVL树\"的例子。总的来说，AVL树失去平衡时的情况一定是LL、LR、RL、RR这4种之一，它们都由各自的定义：\n\n(1) LL：LeftLeft，也称为\"左左\"。插入或删除一个节点后，根节点的左子树的左子树还有非空子节点，导致\"根的左子树的高度\"比\"根的右子树的高度\"大2，导致AVL树失去了平衡。\n\n   例如，在上面LL情况中，由于\"根节点(8)的左子树(4)的左子树(2)还有非空子节点\"，而\"根节点(8)的右子树(12)没有子节点\"；导致\"根节点(8)的左子树(4)高度\"比\"根节点(8)的右子树(12)\"高2。\n\n(2) LR：LeftRight，也称为\"左右\"。插入或删除一个节点后，根节点的左子树的右子树还有非空子节点，导致\"根的左子树的高度\"比\"根的右子树的高度\"大2，导致AVL树失去了平衡。\n\n   例如，在上面LR情况中，由于\"根节点(8)的左子树(4)的左子树(6)还有非空子节点\"，而\"根节点(8)的右子树(12)没有子节点\"；导致\"根节点(8)的左子树(4)高度\"比\"根节点(8)的右子树(12)\"高2。\n\n(3) RL：RightLeft，称为\"右左\"。插入或删除一个节点后，根节点的右子树的左子树还有非空子节点，导致\"根的右子树的高度\"比\"根的左子树的高度\"大2，导致AVL树失去了平衡。\n\n   例如，在上面RL情况中，由于\"根节点(8)的右子树(12)的左子树(10)还有非空子节点\"，而\"根节点(8)的左子树(4)没有子节点\"；导致\"根节点(8)的右子树(12)高度\"比\"根节点(8)的左子树(4)\"高2。\n\n(4) RR：RightRight，称为\"右右\"。插入或删除一个节点后，根节点的右子树的右子树还有非空子节点，导致\"根的右子树的高度\"比\"根的左子树的高度\"大2，导致AVL树失去了平衡。\n\n   例如，在上面RR情况中，由于\"根节点(8)的右子树(12)的右子树(14)还有非空子节点\"，而\"根节点(8)的左子树(4)没有子节点\"；导致\"根节点(8)的右子树(12)高度\"比\"根节点(8)的左子树(4)\"高2。\n\n如果在AVL树中进行插入或删除节点后，可能导致AVL树失去平衡。AVL失去平衡之后，可以通过旋转使其恢复平衡，下面分别介绍\"LL(左左)，LR(左右)，RR(右右)和RL(右左)\"这4种情况对应的旋转方法。\n\n#### 2.1 LL的旋转\n\nLL失去平衡的情况，可以通过一次旋转让AVL树恢复平衡。如下图：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/004.jpg)\n\n图中左边是旋转之前的树，右边是旋转之后的树。从中可以发现，旋转之后的树又变成了AVL树，而且该旋转只需要一次即可完成。\n\n对于LL旋转，你可以这样理解为：LL旋转是围绕\"失去平衡的AVL根节点\"进行的，也就是节点k2；而且由于是LL情况，即左左情况，就用手抓着\"左孩子，即k1\"使劲摇。将k1变成根节点，k2变成k1的右子树，\"k1的右子树\"变成\"k2的左子树\"。\n\nLL的旋转代码\n\n```java\n/*\n * LL：左左对应的情况(左单旋转)。\n *\n * 返回值：旋转后的根节点\n */\nprivate AVLTreeNode<T> leftLeftRotation(AVLTreeNode<T> k2) {\n    AVLTreeNode<T> k1;\n\n    k1 = k2.left;\n    k2.left = k1.right;\n    k1.right = k2;\n\n    k2.height = max( height(k2.left), height(k2.right)) + 1;\n    k1.height = max( height(k1.left), k2.height) + 1;\n\n    return k1;\n}\n```\n\n#### 2.2 RR的旋转\n\n理解了LL之后，RR就相当容易理解了。RR是与LL对称的情况！RR恢复平衡的旋转方法如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/005.jpg)\n\n图中左边是旋转之前的树，右边是旋转之后的树。RR旋转也只需要一次即可完成。\n\nRR的旋转代码\n\n```java\n/*\n * RR：右右对应的情况(右单旋转)。\n *\n * 返回值：旋转后的根节点\n */\nprivate AVLTreeNode<T> rightRightRotation(AVLTreeNode<T> k1) {\n    AVLTreeNode<T> k2;\n\n    k2 = k1.right;\n    k1.right = k2.left;\n    k2.left = k1;\n\n    k1.height = max( height(k1.left), height(k1.right)) + 1;\n    k2.height = max( height(k2.right), k1.height) + 1;\n\n    return k2;\n}\n```\n\n#### 2.3 LR的旋转\n\nLR失去平衡的情况，需要经过两次旋转才能让AVL树恢复平衡。如下图：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/006.jpg)\n\n第一次旋转是围绕\"k1\"进行的\"RR旋转\"，第二次是围绕\"k3\"进行的\"LL旋转\"。\n\nLR的旋转代码\n\n```java\n/*\n * LR：左右对应的情况(左双旋转)。\n *\n * 返回值：旋转后的根节点\n */\nprivate AVLTreeNode<T> leftRightRotation(AVLTreeNode<T> k3) {\n    k3.left = rightRightRotation(k3.left);\n\n    return leftLeftRotation(k3);\n}\n```\n\n#### 2.4 RL的旋转\n\nRL是与LR的对称情况！RL恢复平衡的旋转方法如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/007.jpg)\n\n第一次旋转是围绕\"k3\"进行的\"LL旋转\"，第二次是围绕\"k1\"进行的\"RR旋转\"。\n\nRL的旋转代码\n\n```java\n/*\n * RL：右左对应的情况(右双旋转)。\n *\n * 返回值：旋转后的根节点\n */\nprivate AVLTreeNode<T> rightLeftRotation(AVLTreeNode<T> k1) {\n    k1.right = leftLeftRotation(k1.right);\n\n    return rightRightRotation(k1);\n}\n```\n\n### 3. 插入\n\n插入节点的代码\n\n```java\n/* \n * 将结点插入到AVL树中，并返回根节点\n *\n * 参数说明：\n *     tree AVL树的根结点\n *     key 插入的结点的键值\n * 返回值：\n *     根节点\n */\nprivate AVLTreeNode<T> insert(AVLTreeNode<T> tree, T key) {\n    if (tree == null) {\n        // 新建节点\n        tree = new AVLTreeNode<T>(key, null, null);\n        if (tree==null) {\n            System.out.println(\"ERROR: create avltree node failed!\");\n            return null;\n        }\n    } else {\n        int cmp = key.compareTo(tree.key);\n\n           if (cmp < 0) {    // 应该将key插入到\"tree的左子树\"的情况\n            tree.left = insert(tree.left, key);\n            // 插入节点后，若AVL树失去平衡，则进行相应的调节。\n            if (height(tree.left) - height(tree.right) == 2) {\n                if (key.compareTo(tree.left.key) < 0)\n                    tree = leftLeftRotation(tree);\n                else\n                    tree = leftRightRotation(tree);\n            }\n        } else if (cmp > 0) {    // 应该将key插入到\"tree的右子树\"的情况\n            tree.right = insert(tree.right, key);\n            // 插入节点后，若AVL树失去平衡，则进行相应的调节。\n            if (height(tree.right) - height(tree.left) == 2) {\n                if (key.compareTo(tree.right.key) > 0)\n                    tree = rightRightRotation(tree);\n                else\n                    tree = rightLeftRotation(tree);\n            }\n        } else {    // cmp==0\n            System.out.println(\"添加失败：不允许添加相同的节点！\");\n        }\n    }\n\n    tree.height = max( height(tree.left), height(tree.right)) + 1;\n\n    return tree;\n}\n\npublic void insert(T key) {\n    mRoot = insert(mRoot, key);\n}\n```\n \n### 4. 删除\n\n删除节点的代码\n\n```java\n/* \n * 删除结点(z)，返回根节点\n *\n * 参数说明：\n *     tree AVL树的根结点\n *     z 待删除的结点\n * 返回值：\n *     根节点\n */\nprivate AVLTreeNode<T> remove(AVLTreeNode<T> tree, AVLTreeNode<T> z) {\n    // 根为空 或者 没有要删除的节点，直接返回null。\n    if (tree==null || z==null)\n        return null;\n\n    int cmp = z.key.compareTo(tree.key);\n    if (cmp < 0) {        // 待删除的节点在\"tree的左子树\"中\n        tree.left = remove(tree.left, z);\n        // 删除节点后，若AVL树失去平衡，则进行相应的调节。\n        if (height(tree.right) - height(tree.left) == 2) {\n            AVLTreeNode<T> r =  tree.right;\n            if (height(r.left) > height(r.right))\n                tree = rightLeftRotation(tree);\n            else\n                tree = rightRightRotation(tree);\n        }\n    } else if (cmp > 0) {    // 待删除的节点在\"tree的右子树\"中\n        tree.right = remove(tree.right, z);\n        // 删除节点后，若AVL树失去平衡，则进行相应的调节。\n        if (height(tree.left) - height(tree.right) == 2) {\n            AVLTreeNode<T> l =  tree.left;\n            if (height(l.right) > height(l.left))\n                tree = leftRightRotation(tree);\n            else\n                tree = leftLeftRotation(tree);\n        }\n    } else {    // tree是对应要删除的节点。\n        // tree的左右孩子都非空\n        if ((tree.left!=null) && (tree.right!=null)) {\n            if (height(tree.left) > height(tree.right)) {\n                // 如果tree的左子树比右子树高；\n                // 则(01)找出tree的左子树中的最大节点\n                //   (02)将该最大节点的值赋值给tree。\n                //   (03)删除该最大节点。\n                // 这类似于用\"tree的左子树中最大节点\"做\"tree\"的替身；\n                // 采用这种方式的好处是：删除\"tree的左子树中最大节点\"之后，AVL树仍然是平衡的。\n                AVLTreeNode<T> max = maximum(tree.left);\n                tree.key = max.key;\n                tree.left = remove(tree.left, max);\n            } else {\n                // 如果tree的左子树不比右子树高(即它们相等，或右子树比左子树高1)\n                // 则(01)找出tree的右子树中的最小节点\n                //   (02)将该最小节点的值赋值给tree。\n                //   (03)删除该最小节点。\n                // 这类似于用\"tree的右子树中最小节点\"做\"tree\"的替身；\n                // 采用这种方式的好处是：删除\"tree的右子树中最小节点\"之后，AVL树仍然是平衡的。\n                AVLTreeNode<T> min = maximum(tree.right);\n                tree.key = min.key;\n                tree.right = remove(tree.right, min);\n            }\n        } else {\n            AVLTreeNode<T> tmp = tree;\n            tree = (tree.left!=null) ? tree.left : tree.right;\n            tmp = null;\n        }\n    }\n\n    return tree;\n}\n\npublic void remove(T key) {\n    AVLTreeNode<T> z; \n\n    if ((z = search(mRoot, key)) != null)\n        mRoot = remove(mRoot, z);\n}\n```\n \n完整的实现代码\n\nAVL树的实现文件(AVRTree.java)\n\n```java\n/**\n * Java 语言: AVL树\n *\n * @author skywang\n * @date 2013/11/07\n */\n\npublic class AVLTree<T extends Comparable<T>> {\n    private AVLTreeNode<T> mRoot;    // 根结点\n\n    // AVL树的节点(内部类)\n    class AVLTreeNode<T extends Comparable<T>> {\n        T key;                // 关键字(键值)\n        int height;         // 高度\n        AVLTreeNode<T> left;    // 左孩子\n        AVLTreeNode<T> right;    // 右孩子\n\n        public AVLTreeNode(T key, AVLTreeNode<T> left, AVLTreeNode<T> right) {\n            this.key = key;\n            this.left = left;\n            this.right = right;\n            this.height = 0;\n        }\n    }\n\n    // 构造函数\n    public AVLTree() {\n        mRoot = null;\n    }\n\n    /*\n     * 获取树的高度\n     */\n    private int height(AVLTreeNode<T> tree) {\n        if (tree != null)\n            return tree.height;\n\n        return 0;\n    }\n\n    public int height() {\n        return height(mRoot);\n    }\n\n    /*\n     * 比较两个值的大小\n     */\n    private int max(int a, int b) {\n        return a>b ? a : b;\n    }\n\n    /*\n     * 前序遍历\"AVL树\"\n     */\n    private void preOrder(AVLTreeNode<T> tree) {\n        if(tree != null) {\n            System.out.print(tree.key+\" \");\n            preOrder(tree.left);\n            preOrder(tree.right);\n        }\n    }\n\n    public void preOrder() {\n        preOrder(mRoot);\n    }\n\n    /*\n     * 中序遍历\"AVL树\"\n     */\n    private void inOrder(AVLTreeNode<T> tree) {\n        if(tree != null)\n        {\n            inOrder(tree.left);\n            System.out.print(tree.key+\" \");\n            inOrder(tree.right);\n        }\n    }\n\n    public void inOrder() {\n        inOrder(mRoot);\n    }\n\n    /*\n     * 后序遍历\"AVL树\"\n     */\n    private void postOrder(AVLTreeNode<T> tree) {\n        if(tree != null) {\n            postOrder(tree.left);\n            postOrder(tree.right);\n            System.out.print(tree.key+\" \");\n        }\n    }\n\n    public void postOrder() {\n        postOrder(mRoot);\n    }\n\n    /*\n     * (递归实现)查找\"AVL树x\"中键值为key的节点\n     */\n    private AVLTreeNode<T> search(AVLTreeNode<T> x, T key) {\n        if (x==null)\n            return x;\n\n        int cmp = key.compareTo(x.key);\n        if (cmp < 0)\n            return search(x.left, key);\n        else if (cmp > 0)\n            return search(x.right, key);\n        else\n            return x;\n    }\n\n    public AVLTreeNode<T> search(T key) {\n        return search(mRoot, key);\n    }\n\n    /*\n     * (非递归实现)查找\"AVL树x\"中键值为key的节点\n     */\n    private AVLTreeNode<T> iterativeSearch(AVLTreeNode<T> x, T key) {\n        while (x!=null) {\n            int cmp = key.compareTo(x.key);\n\n            if (cmp < 0)\n                x = x.left;\n            else if (cmp > 0)\n                x = x.right;\n            else\n                return x;\n        }\n\n        return x;\n    }\n\n    public AVLTreeNode<T> iterativeSearch(T key) {\n        return iterativeSearch(mRoot, key);\n    }\n\n    /* \n     * 查找最小结点：返回tree为根结点的AVL树的最小结点。\n     */\n    private AVLTreeNode<T> minimum(AVLTreeNode<T> tree) {\n        if (tree == null)\n            return null;\n\n        while(tree.left != null)\n            tree = tree.left;\n        return tree;\n    }\n\n    public T minimum() {\n        AVLTreeNode<T> p = minimum(mRoot);\n        if (p != null)\n            return p.key;\n\n        return null;\n    }\n     \n    /* \n     * 查找最大结点：返回tree为根结点的AVL树的最大结点。\n     */\n    private AVLTreeNode<T> maximum(AVLTreeNode<T> tree) {\n        if (tree == null)\n            return null;\n\n        while(tree.right != null)\n            tree = tree.right;\n        return tree;\n    }\n\n    public T maximum() {\n        AVLTreeNode<T> p = maximum(mRoot);\n        if (p != null)\n            return p.key;\n\n        return null;\n    }\n\n    /*\n     * LL：左左对应的情况(左单旋转)。\n     *\n     * 返回值：旋转后的根节点\n     */\n    private AVLTreeNode<T> leftLeftRotation(AVLTreeNode<T> k2) {\n        AVLTreeNode<T> k1;\n\n        k1 = k2.left;\n        k2.left = k1.right;\n        k1.right = k2;\n\n        k2.height = max( height(k2.left), height(k2.right)) + 1;\n        k1.height = max( height(k1.left), k2.height) + 1;\n\n        return k1;\n    }\n\n    /*\n     * RR：右右对应的情况(右单旋转)。\n     *\n     * 返回值：旋转后的根节点\n     */\n    private AVLTreeNode<T> rightRightRotation(AVLTreeNode<T> k1) {\n        AVLTreeNode<T> k2;\n\n        k2 = k1.right;\n        k1.right = k2.left;\n        k2.left = k1;\n\n        k1.height = max( height(k1.left), height(k1.right)) + 1;\n        k2.height = max( height(k2.right), k1.height) + 1;\n\n        return k2;\n    }\n\n    /*\n     * LR：左右对应的情况(左双旋转)。\n     *\n     * 返回值：旋转后的根节点\n     */\n    private AVLTreeNode<T> leftRightRotation(AVLTreeNode<T> k3) {\n        k3.left = rightRightRotation(k3.left);\n\n        return leftLeftRotation(k3);\n    }\n\n    /*\n     * RL：右左对应的情况(右双旋转)。\n     *\n     * 返回值：旋转后的根节点\n     */\n    private AVLTreeNode<T> rightLeftRotation(AVLTreeNode<T> k1) {\n        k1.right = leftLeftRotation(k1.right);\n\n        return rightRightRotation(k1);\n    }\n\n    /* \n     * 将结点插入到AVL树中，并返回根节点\n     *\n     * 参数说明：\n     *     tree AVL树的根结点\n     *     key 插入的结点的键值\n     * 返回值：\n     *     根节点\n     */\n    private AVLTreeNode<T> insert(AVLTreeNode<T> tree, T key) {\n        if (tree == null) {\n            // 新建节点\n            tree = new AVLTreeNode<T>(key, null, null);\n            if (tree==null) {\n                System.out.println(\"ERROR: create avltree node failed!\");\n                return null;\n            }\n        } else {\n            int cmp = key.compareTo(tree.key);\n\n               if (cmp < 0) {    // 应该将key插入到\"tree的左子树\"的情况\n                tree.left = insert(tree.left, key);\n                // 插入节点后，若AVL树失去平衡，则进行相应的调节。\n                if (height(tree.left) - height(tree.right) == 2) {\n                    if (key.compareTo(tree.left.key) < 0)\n                        tree = leftLeftRotation(tree);\n                    else\n                        tree = leftRightRotation(tree);\n                }\n            } else if (cmp > 0) {    // 应该将key插入到\"tree的右子树\"的情况\n                tree.right = insert(tree.right, key);\n                // 插入节点后，若AVL树失去平衡，则进行相应的调节。\n                if (height(tree.right) - height(tree.left) == 2) {\n                    if (key.compareTo(tree.right.key) > 0)\n                        tree = rightRightRotation(tree);\n                    else\n                        tree = rightLeftRotation(tree);\n                }\n            } else {    // cmp==0\n                System.out.println(\"添加失败：不允许添加相同的节点！\");\n            }\n        }\n\n        tree.height = max( height(tree.left), height(tree.right)) + 1;\n\n        return tree;\n    }\n\n    public void insert(T key) {\n        mRoot = insert(mRoot, key);\n    }\n\n    /* \n     * 删除结点(z)，返回根节点\n     *\n     * 参数说明：\n     *     tree AVL树的根结点\n     *     z 待删除的结点\n     * 返回值：\n     *     根节点\n     */\n    private AVLTreeNode<T> remove(AVLTreeNode<T> tree, AVLTreeNode<T> z) {\n        // 根为空 或者 没有要删除的节点，直接返回null。\n        if (tree==null || z==null)\n            return null;\n\n        int cmp = z.key.compareTo(tree.key);\n        if (cmp < 0) {        // 待删除的节点在\"tree的左子树\"中\n            tree.left = remove(tree.left, z);\n            // 删除节点后，若AVL树失去平衡，则进行相应的调节。\n            if (height(tree.right) - height(tree.left) == 2) {\n                AVLTreeNode<T> r =  tree.right;\n                if (height(r.left) > height(r.right))\n                    tree = rightLeftRotation(tree);\n                else\n                    tree = rightRightRotation(tree);\n            }\n        } else if (cmp > 0) {    // 待删除的节点在\"tree的右子树\"中\n            tree.right = remove(tree.right, z);\n            // 删除节点后，若AVL树失去平衡，则进行相应的调节。\n            if (height(tree.left) - height(tree.right) == 2) {\n                AVLTreeNode<T> l =  tree.left;\n                if (height(l.right) > height(l.left))\n                    tree = leftRightRotation(tree);\n                else\n                    tree = leftLeftRotation(tree);\n            }\n        } else {    // tree是对应要删除的节点。\n            // tree的左右孩子都非空\n            if ((tree.left!=null) && (tree.right!=null)) {\n                if (height(tree.left) > height(tree.right)) {\n                    // 如果tree的左子树比右子树高；\n                    // 则(01)找出tree的左子树中的最大节点\n                    //   (02)将该最大节点的值赋值给tree。\n                    //   (03)删除该最大节点。\n                    // 这类似于用\"tree的左子树中最大节点\"做\"tree\"的替身；\n                    // 采用这种方式的好处是：删除\"tree的左子树中最大节点\"之后，AVL树仍然是平衡的。\n                    AVLTreeNode<T> max = maximum(tree.left);\n                    tree.key = max.key;\n                    tree.left = remove(tree.left, max);\n                } else {\n                    // 如果tree的左子树不比右子树高(即它们相等，或右子树比左子树高1)\n                    // 则(01)找出tree的右子树中的最小节点\n                    //   (02)将该最小节点的值赋值给tree。\n                    //   (03)删除该最小节点。\n                    // 这类似于用\"tree的右子树中最小节点\"做\"tree\"的替身；\n                    // 采用这种方式的好处是：删除\"tree的右子树中最小节点\"之后，AVL树仍然是平衡的。\n                    AVLTreeNode<T> min = maximum(tree.right);\n                    tree.key = min.key;\n                    tree.right = remove(tree.right, min);\n                }\n            } else {\n                AVLTreeNode<T> tmp = tree;\n                tree = (tree.left!=null) ? tree.left : tree.right;\n                tmp = null;\n            }\n        }\n\n        return tree;\n    }\n\n    public void remove(T key) {\n        AVLTreeNode<T> z; \n\n        if ((z = search(mRoot, key)) != null)\n            mRoot = remove(mRoot, z);\n    }\n\n    /* \n     * 销毁AVL树\n     */\n    private void destroy(AVLTreeNode<T> tree) {\n        if (tree==null)\n            return ;\n\n        if (tree.left != null)\n            destroy(tree.left);\n        if (tree.right != null)\n            destroy(tree.right);\n\n        tree = null;\n    }\n\n    public void destroy() {\n        destroy(mRoot);\n    }\n\n    /*\n     * 打印\"二叉查找树\"\n     *\n     * key        -- 节点的键值 \n     * direction  --  0，表示该节点是根节点;\n     *               -1，表示该节点是它的父结点的左孩子;\n     *                1，表示该节点是它的父结点的右孩子。\n     */\n    private void print(AVLTreeNode<T> tree, T key, int direction) {\n        if(tree != null) {\n            if(direction==0)    // tree是根节点\n                System.out.printf(\"%2d is root\\n\", tree.key, key);\n            else                // tree是分支节点\n                System.out.printf(\"%2d is %2d's %6s child\\n\", tree.key, key, direction==1?\"right\" : \"left\");\n\n            print(tree.left, tree.key, -1);\n            print(tree.right,tree.key,  1);\n        }\n    }\n\n    public void print() {\n        if (mRoot != null)\n            print(mRoot, mRoot.key, 0);\n    }\n}\n```\n\nAVL树的测试程序(AVLTreeTest.java)\n\n```java\n/**\n * Java 语言: AVL树\n *\n * @author skywang\n * @date 2013/11/07\n */\n\npublic class AVLTreeTest {\n    private static int arr[]= {3,2,1,4,5,6,7,16,15,14,13,12,11,10,8,9};\n\n    public static void main(String[] args) {\n        int i;\n        AVLTree<Integer> tree = new AVLTree<Integer>();\n\n        System.out.printf(\"== 依次添加: \");\n        for(i=0; i<arr.length; i++) {\n            System.out.printf(\"%d \", arr[i]);\n            tree.insert(arr[i]);\n        }\n\n        System.out.printf(\"\\n== 前序遍历: \");\n        tree.preOrder();\n\n        System.out.printf(\"\\n== 中序遍历: \");\n        tree.inOrder();\n\n        System.out.printf(\"\\n== 后序遍历: \");\n        tree.postOrder();\n        System.out.printf(\"\\n\");\n\n        System.out.printf(\"== 高度: %d\\n\", tree.height());\n        System.out.printf(\"== 最小值: %d\\n\", tree.minimum());\n        System.out.printf(\"== 最大值: %d\\n\", tree.maximum());\n        System.out.printf(\"== 树的详细信息: \\n\");\n        tree.print();\n\n        i = 8;\n        System.out.printf(\"\\n== 删除根节点: %d\", i);\n        tree.remove(i);\n\n        System.out.printf(\"\\n== 高度: %d\", tree.height());\n        System.out.printf(\"\\n== 中序遍历: \");\n        tree.inOrder();\n        System.out.printf(\"\\n== 树的详细信息: \\n\");\n        tree.print();\n\n        // 销毁二叉树\n        tree.destroy();\n    }\n}\n```\n\n## AVL树的Java测试程序\n\nAVL树的测试程序运行结果如下：\n\n```\n== 依次添加: 3 2 1 4 5 6 7 16 15 14 13 12 11 10 8 9 \n== 前序遍历: 7 4 2 1 3 6 5 13 11 9 8 10 12 15 14 16 \n== 中序遍历: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \n== 后序遍历: 1 3 2 5 6 4 8 10 9 12 11 14 16 15 13 7 \n== 高度: 5\n== 最小值: 1\n== 最大值: 16\n== 树的详细信息: \n 7 is root\n 4 is  7's   left child\n 2 is  4's   left child\n 1 is  2's   left child\n 3 is  2's  right child\n 6 is  4's  right child\n 5 is  6's   left child\n13 is  7's  right child\n11 is 13's   left child\n 9 is 11's   left child\n 8 is  9's   left child\n10 is  9's  right child\n12 is 11's  right child\n15 is 13's  right child\n14 is 15's   left child\n16 is 15's  right child\n\n== 删除根节点: 8\n== 高度: 5\n== 中序遍历: 1 2 3 4 5 6 7 9 10 11 12 13 14 15 16 \n== 树的详细信息: \n 7 is root\n 4 is  7's   left child\n 2 is  4's   left child\n 1 is  2's   left child\n 3 is  2's  right child\n 6 is  4's  right child\n 5 is  6's   left child\n13 is  7's  right child\n11 is 13's   left child\n 9 is 11's   left child\n10 is  9's  right child\n12 is 11's  right child\n15 is 13's  right child\n14 is 15's   left child\n16 is 15's  right child\n```\n\n下面，我们对测试程序的流程进行分析！\n\n### 1. 新建AVL树\n\n### 2. 依次添加\"3,2,1,4,5,6,7,16,15,14,13,12,11,10,8,9\" 到AVL树中。\n\n#### 2.01 添加3,2\n\n添加3,2都不会破坏AVL树的平衡性。\n\n![](/assets/images/2014/03/30/avl-tree-implementation/008.jpg)\n\n#### 2.02 添加1\n\n添加1之后，AVL树失去平衡(LL)，此时需要对AVL树进行旋转(LL旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/009.jpg)\n\n#### 2.03 添加4\n\n添加4不会破坏AVL树的平衡性。\n\n![](/assets/images/2014/03/30/avl-tree-implementation/010.jpg)\n\n#### 2.04 添加5\n\n添加5之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/011.jpg)\n\n#### 2.05 添加6\n\n添加6之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/012.jpg)\n\n#### 2.06 添加7\n\n添加7之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/013.jpg)\n\n#### 2.07 添加16\n\n添加16不会破坏AVL树的平衡性。\n\n![](/assets/images/2014/03/30/avl-tree-implementation/014.jpg)\n\n#### 2.08 添加15\n\n添加15之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/015.jpg)\n\n#### 2.09 添加14\n\n添加14之后，AVL树失去平衡(RL)，此时需要对AVL树进行旋转(RL旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/016.jpg)\n\n#### 2.10 添加13\n\n添加13之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/017.jpg)\n\n#### 2.11 添加12\n\n添加12之后，AVL树失去平衡(LL)，此时需要对AVL树进行旋转(LL旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/018.jpg)\n\n#### 2.12 添加11\n\n添加11之后，AVL树失去平衡(LL)，此时需要对AVL树进行旋转(LL旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/019.jpg)\n\n#### 2.13 添加10\n\n添加10之后，AVL树失去平衡(LL)，此时需要对AVL树进行旋转(LL旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/020.jpg)\n\n#### 2.14 添加8\n\n添加8不会破坏AVL树的平衡性。\n\n![](/assets/images/2014/03/30/avl-tree-implementation/021.jpg)\n\n#### 2.15 添加9\n\n但是添加9之后，AVL树失去平衡(LR)，此时需要对AVL树进行旋转(LR旋转)。旋转过程如下：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/022.jpg)\n\n### 3. 打印树的信息\n\n输出下面树的信息：\n\n![](/assets/images/2014/03/30/avl-tree-implementation/023.jpg)\n\n```\n前序遍历: 7 4 2 1 3 6 5 13 11 9 8 10 12 15 14 16 \n中序遍历: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \n后序遍历: 1 3 2 5 6 4 8 10 9 12 11 14 16 15 13 7 \n高度: 5\n最小值: 1\n最大值: 16\n```\n\n### 4. 删除节点8\n\n删除操作并不会造成AVL树的不平衡。\n\n![](/assets/images/2014/03/30/avl-tree-implementation/024.jpg)\n\n删除节点8之后，再打印该AVL树的信息。\n\n```\n高度: 5\n中序遍历: 1 2 3 4 5 6 7 9 10 11 12 13 14 15 16\n```\n\n---\n\n* 原文链接：[AVL树(三)之 Java的实现](http://www.cnblogs.com/skywang12345/p/3577479.html)\n","tags":["AVLTree"],"categories":["Algorithm"]},{"title":"二叉查找树(三)之 Java的实现","url":"%2F2014%2F2014-03-28-binary-search-tree-and-implementation%2F","content":"\n## 概要\n\n在前面分别介绍了\"二叉查找树的相关理论知识，然后给出了二叉查找树的C和C++实现版本\"。这一章写一写二叉查找树的Java实现版本。\n\n### 目录\n\n1. 二叉树查找树\n2. 二叉查找树的Java实现\n3. 二叉查找树的Java测试程序\n\n## 二叉查找树简介\n\n二叉查找树(Binary Search Tree)，又被称为二叉搜索树。\n\n它是特殊的二叉树：对于二叉树，假设x为二叉树中的任意一个结点，x节点包含关键字key，节点x的key值记为key[x]。如果y是x的左子树中的一个结点，则key[y] <= key[x]；如果y是x的右子树的一个结点，则key[y] >= key[x]。那么，这棵树就是二叉查找树。如下图所示：\n\n![](/assets/images/2014/03/28/binary-search-tree-and-implementation/001.jpg)\n\n在二叉查找树中：\n\n(01) 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；\n\n(02) 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；\n\n(03) 任意节点的左、右子树也分别为二叉查找树。\n\n(04) 没有键值相等的节点（no duplicate nodes）。\n\n## 二叉查找树的Java实现\n\n### 1. 二叉查找树节点的定义\n\n```java\npublic class BSTree<T extends Comparable<T>> {\n\n    private BSTNode<T> mRoot;    // 根结点\n\n    public class BSTNode<T extends Comparable<T>> {\n        T key;                // 关键字(键值)\n        BSTNode<T> left;      // 左孩子\n        BSTNode<T> right;     // 右孩子\n        BSTNode<T> parent;    // 父结点\n\n        public BSTNode(T key, BSTNode<T> parent, BSTNode<T> left, BSTNode<T> right) {\n            this.key = key;\n            this.parent = parent;\n            this.left = left;\n            this.right = right;\n        }\n    }\n\n        ......\n}\n```\n\nBSTree是二叉树，它保护了二叉树的根节点mRoot；mRoot是BSTNode类型，而BSTNode是二叉查找树的节点，它是BSTree的内部类。BSTNode包含二叉查找树的几个基本信息：\n\n(01) key -- 它是关键字，是用来对二叉查找树的节点进行排序的。\n\n(02) left -- 它指向当前节点的左孩子。\n\n(03) right -- 它指向当前节点的右孩子。\n\n(04) parent -- 它指向当前节点的父结点。\n\n### 2. 遍历\n\n这里讲解前序遍历、中序遍历、后序遍历3种方式。\n\n#### 2.1 前序遍历\n\n若二叉树非空，则执行以下操作：\n\n(01) 访问根结点；\n\n(02) 先序遍历左子树；\n\n(03) 先序遍历右子树。\n\n**前序遍历代码**\n\n```java\nprivate void preOrder(BSTNode<T> tree) {\n    if(tree != null) {\n        System.out.print(tree.key+\" \");\n        preOrder(tree.left);\n        preOrder(tree.right);\n    }\n}\n\npublic void preOrder() {\n    preOrder(mRoot);\n}\n```\n\n#### 2.2 中序遍历\n\n若二叉树非空，则执行以下操作：\n\n(01) 中序遍历左子树；\n\n(02) 访问根结点；\n\n(03) 中序遍历右子树。\n\n**中序遍历代码**\n\n```java\nprivate void inOrder(BSTNode<T> tree) {\n    if(tree != null) {\n        inOrder(tree.left);\n        System.out.print(tree.key+\" \");\n        inOrder(tree.right);\n    }\n}\n\npublic void inOrder() {\n    inOrder(mRoot);\n}\n```\n\n#### 2.3 后序遍历\n\n若二叉树非空，则执行以下操作：\n\n(01) 后序遍历左子树；\n\n(02) 后序遍历右子树；\n\n(03) 访问根结点。\n\n**后序遍历代码**\n\n```java\nprivate void postOrder(BSTNode<T> tree) {\n    if(tree != null)\n    {\n        postOrder(tree.left);\n        postOrder(tree.right);\n        System.out.print(tree.key+\" \");\n    }\n}\n\npublic void postOrder() {\n    postOrder(mRoot);\n}\n```\n\n看看下面这颗树的各种遍历方式：\n\n![](/assets/images/2014/03/28/binary-search-tree-and-implementation/002.jpg)\n\n对于上面的二叉树而言，\n\n(01) 前序遍历结果： 3 1 2 5 4 6\n\n(02) 中序遍历结果： 1 2 3 4 5 6 \n\n(03) 后序遍历结果： 2 1 4 6 5 3\n\n### 3. 查找\n\n递归版本的代码\n\n```java\n/*\n * (递归实现)查找\"二叉树x\"中键值为key的节点\n */\nprivate BSTNode<T> search(BSTNode<T> x, T key) {\n    if (x==null)\n        return x;\n\n    int cmp = key.compareTo(x.key);\n    if (cmp < 0)\n        return search(x.left, key);\n    else if (cmp > 0)\n        return search(x.right, key);\n    else\n        return x;\n}\n\npublic BSTNode<T> search(T key) {\n    return search(mRoot, key);\n}\n```\n\n非递归版本的代码\n\n```java\n/*\n * (非递归实现)查找\"二叉树x\"中键值为key的节点\n */\nprivate BSTNode<T> iterativeSearch(BSTNode<T> x, T key) {\n    while (x!=null) {\n        int cmp = key.compareTo(x.key);\n\n        if (cmp < 0) \n            x = x.left;\n        else if (cmp > 0) \n            x = x.right;\n        else\n            return x;\n    }\n\n    return x;\n}\n\npublic BSTNode<T> iterativeSearch(T key) {\n    return iterativeSearch(mRoot, key);\n}\n```\n\n### 4. 最大值和最小值\n\n查找最大值的代码\n\n```java\n/* \n * 查找最大结点：返回tree为根结点的二叉树的最大结点。\n */\nprivate BSTNode<T> maximum(BSTNode<T> tree) {\n    if (tree == null)\n        return null;\n\n    while(tree.right != null)\n        tree = tree.right;\n    return tree;\n}\n\npublic T maximum() {\n    BSTNode<T> p = maximum(mRoot);\n    if (p != null)\n        return p.key;\n\n    return null;\n}\n```\n\n查找最小值的代码\n\n```java\n/* \n * 查找最小结点：返回tree为根结点的二叉树的最小结点。\n */\nprivate BSTNode<T> minimum(BSTNode<T> tree) {\n    if (tree == null)\n        return null;\n\n    while(tree.left != null)\n        tree = tree.left;\n    return tree;\n}\n\npublic T minimum() {\n    BSTNode<T> p = minimum(mRoot);\n    if (p != null)\n        return p.key;\n\n    return null;\n}\n```\n\n### 5. 前驱和后继\n\n节点的前驱：是该节点的左子树中的最大节点。\n\n节点的后继：是该节点的右子树中的最小节点。\n\n查找前驱节点的代码\n\n```java\n/* \n * 找结点(x)的前驱结点。即，查找\"二叉树中数据值小于该结点\"的\"最大结点\"。\n */\npublic BSTNode<T> predecessor(BSTNode<T> x) {\n    // 如果x存在左孩子，则\"x的前驱结点\"为 \"以其左孩子为根的子树的最大结点\"。\n    if (x.left != null)\n        return maximum(x.left);\n\n    // 如果x没有左孩子。则x有以下两种可能：\n    // (01) x是\"一个右孩子\"，则\"x的前驱结点\"为 \"它的父结点\"。\n    // (01) x是\"一个左孩子\"，则查找\"x的最低的父结点，并且该父结点要具有右孩子\"，找到的这个\"最低的父结点\"就是\"x的前驱结点\"。\n    BSTNode<T> y = x.parent;\n    while ((y!=null) && (x==y.left)) {\n        x = y;\n        y = y.parent;\n    }\n\n    return y;\n}\n```\n\n查找后继节点的代码\n\n```java\n/* \n * 找结点(x)的后继结点。即，查找\"二叉树中数据值大于该结点\"的\"最小结点\"。\n */\npublic BSTNode<T> successor(BSTNode<T> x) {\n    // 如果x存在右孩子，则\"x的后继结点\"为 \"以其右孩子为根的子树的最小结点\"。\n    if (x.right != null)\n        return minimum(x.right);\n\n    // 如果x没有右孩子。则x有以下两种可能：\n    // (01) x是\"一个左孩子\"，则\"x的后继结点\"为 \"它的父结点\"。\n    // (02) x是\"一个右孩子\"，则查找\"x的最低的父结点，并且该父结点要具有左孩子\"，找到的这个\"最低的父结点\"就是\"x的后继结点\"。\n    BSTNode<T> y = x.parent;\n    while ((y!=null) && (x==y.right)) {\n        x = y;\n        y = y.parent;\n    }\n\n    return y;\n}\n```\n\n### 6. 插入\n\n插入节点的代码\n\n```java\n/* \n * 将结点插入到二叉树中\n *\n * 参数说明：\n *     tree 二叉树的\n *     z 插入的结点\n */\nprivate void insert(BSTree<T> bst, BSTNode<T> z) {\n    int cmp;\n    BSTNode<T> y = null;\n    BSTNode<T> x = bst.mRoot;\n\n    // 查找z的插入位置\n    while (x != null) {\n        y = x;\n        cmp = z.key.compareTo(x.key);\n        if (cmp < 0)\n            x = x.left;\n        else\n            x = x.right;\n    }\n\n    z.parent = y;\n    if (y==null)\n        bst.mRoot = z;\n    else {\n        cmp = z.key.compareTo(y.key);\n        if (cmp < 0)\n            y.left = z;\n        else\n            y.right = z;\n    }\n}\n\n/* \n * 新建结点(key)，并将其插入到二叉树中\n *\n * 参数说明：\n *     tree 二叉树的根结点\n *     key 插入结点的键值\n */\npublic void insert(T key) {\n    BSTNode<T> z=new BSTNode<T>(key,null,null,null);\n\n    // 如果新建结点失败，则返回。\n    if (z != null)\n        insert(this, z);\n}\n```\n\n注：本文实现的二叉查找树是允许插入相同键值的节点的。若想禁止二叉查找树中插入相同键值的节点，可以参考\"二叉查找树(一)之 图文解析 和 C语言的实现\"中的插入函数进行修改。\n\n### 7. 删除\n\n删除节点的代码\n\n```java\n/* \n * 删除结点(z)，并返回被删除的结点\n *\n * 参数说明：\n *     bst 二叉树\n *     z 删除的结点\n */\nprivate BSTNode<T> remove(BSTree<T> bst, BSTNode<T> z) {\n    BSTNode<T> x=null;\n    BSTNode<T> y=null;\n\n    if ((z.left == null) || (z.right == null) )\n        y = z;\n    else\n        y = successor(z);\n\n    if (y.left != null)\n        x = y.left;\n    else\n        x = y.right;\n\n    if (x != null)\n        x.parent = y.parent;\n\n    if (y.parent == null)\n        bst.mRoot = x;\n    else if (y == y.parent.left)\n        y.parent.left = x;\n    else\n        y.parent.right = x;\n\n    if (y != z) \n        z.key = y.key;\n\n    return y;\n}\n\n/* \n * 删除结点(z)，并返回被删除的结点\n *\n * 参数说明：\n *     tree 二叉树的根结点\n *     z 删除的结点\n */\npublic void remove(T key) {\n    BSTNode<T> z, node; \n\n    if ((z = search(mRoot, key)) != null)\n        if ( (node = remove(this, z)) != null)\n            node = null;\n}\n```\n\n### 8. 打印\n\n打印二叉查找树的代码\n\n```java\n/*\n * 打印\"二叉查找树\"\n *\n * key        -- 节点的键值 \n * direction  --  0，表示该节点是根节点;\n *               -1，表示该节点是它的父结点的左孩子;\n *                1，表示该节点是它的父结点的右孩子。\n */\nprivate void print(BSTNode<T> tree, T key, int direction) {\n\n    if(tree != null) {\n\n        if(direction==0)    // tree是根节点\n            System.out.printf(\"%2d is root\\n\", tree.key);\n        else                // tree是分支节点\n            System.out.printf(\"%2d is %2d's %6s child\\n\", tree.key, key, direction==1?\"right\" : \"left\");\n\n        print(tree.left, tree.key, -1);\n        print(tree.right,tree.key,  1);\n    }\n}\n\npublic void print() {\n    if (mRoot != null)\n        print(mRoot, mRoot.key, 0);\n}\n```java\n \n\n### 9. 销毁\n\n销毁二叉查找树的代码\n\n```java\n/*\n * 销毁二叉树\n */\nprivate void destroy(BSTNode<T> tree) {\n    if (tree==null)\n        return ;\n\n    if (tree.left != null)\n        destroy(tree.left);\n    if (tree.right != null)\n        destroy(tree.right);\n\n    tree=null;\n}\n\npublic void clear() {\n    destroy(mRoot);\n    mRoot = null;\n}\n```\n\n完整的实现代码\n二叉查找树的Java实现文件(BSTree.java)\n\n```java\n/**\n * Java 语言: 二叉查找树\n *\n * @author skywang\n * @date 2013/11/07\n */\n\npublic class BSTree<T extends Comparable<T>> {\n\n    private BSTNode<T> mRoot;    // 根结点\n\n    public class BSTNode<T extends Comparable<T>> {\n        T key;                // 关键字(键值)\n        BSTNode<T> left;    // 左孩子\n        BSTNode<T> right;    // 右孩子\n        BSTNode<T> parent;    // 父结点\n\n        public BSTNode(T key, BSTNode<T> parent, BSTNode<T> left, BSTNode<T> right) {\n            this.key = key;\n            this.parent = parent;\n            this.left = left;\n            this.right = right;\n        }\n\n        public T getKey() {\n            return key;\n        }\n\n        public String toString() {\n            return \"key:\"+key;\n        }\n    }\n\n    public BSTree() {\n        mRoot=null;\n    }\n\n    /*\n     * 前序遍历\"二叉树\"\n     */\n    private void preOrder(BSTNode<T> tree) {\n        if(tree != null) {\n            System.out.print(tree.key+\" \");\n            preOrder(tree.left);\n            preOrder(tree.right);\n        }\n    }\n\n    public void preOrder() {\n        preOrder(mRoot);\n    }\n\n    /*\n     * 中序遍历\"二叉树\"\n     */\n    private void inOrder(BSTNode<T> tree) {\n        if(tree != null) {\n            inOrder(tree.left);\n            System.out.print(tree.key+\" \");\n            inOrder(tree.right);\n        }\n    }\n\n    public void inOrder() {\n        inOrder(mRoot);\n    }\n\n\n    /*\n     * 后序遍历\"二叉树\"\n     */\n    private void postOrder(BSTNode<T> tree) {\n        if(tree != null)\n        {\n            postOrder(tree.left);\n            postOrder(tree.right);\n            System.out.print(tree.key+\" \");\n        }\n    }\n\n    public void postOrder() {\n        postOrder(mRoot);\n    }\n\n\n    /*\n     * (递归实现)查找\"二叉树x\"中键值为key的节点\n     */\n    private BSTNode<T> search(BSTNode<T> x, T key) {\n        if (x==null)\n            return x;\n\n        int cmp = key.compareTo(x.key);\n        if (cmp < 0)\n            return search(x.left, key);\n        else if (cmp > 0)\n            return search(x.right, key);\n        else\n            return x;\n    }\n\n    public BSTNode<T> search(T key) {\n        return search(mRoot, key);\n    }\n\n    /*\n     * (非递归实现)查找\"二叉树x\"中键值为key的节点\n     */\n    private BSTNode<T> iterativeSearch(BSTNode<T> x, T key) {\n        while (x!=null) {\n            int cmp = key.compareTo(x.key);\n\n            if (cmp < 0) \n                x = x.left;\n            else if (cmp > 0) \n                x = x.right;\n            else\n                return x;\n        }\n\n        return x;\n    }\n\n    public BSTNode<T> iterativeSearch(T key) {\n        return iterativeSearch(mRoot, key);\n    }\n\n    /* \n     * 查找最小结点：返回tree为根结点的二叉树的最小结点。\n     */\n    private BSTNode<T> minimum(BSTNode<T> tree) {\n        if (tree == null)\n            return null;\n\n        while(tree.left != null)\n            tree = tree.left;\n        return tree;\n    }\n\n    public T minimum() {\n        BSTNode<T> p = minimum(mRoot);\n        if (p != null)\n            return p.key;\n\n        return null;\n    }\n     \n    /* \n     * 查找最大结点：返回tree为根结点的二叉树的最大结点。\n     */\n    private BSTNode<T> maximum(BSTNode<T> tree) {\n        if (tree == null)\n            return null;\n\n        while(tree.right != null)\n            tree = tree.right;\n        return tree;\n    }\n\n    public T maximum() {\n        BSTNode<T> p = maximum(mRoot);\n        if (p != null)\n            return p.key;\n\n        return null;\n    }\n\n    /* \n     * 找结点(x)的后继结点。即，查找\"二叉树中数据值大于该结点\"的\"最小结点\"。\n     */\n    public BSTNode<T> successor(BSTNode<T> x) {\n        // 如果x存在右孩子，则\"x的后继结点\"为 \"以其右孩子为根的子树的最小结点\"。\n        if (x.right != null)\n            return minimum(x.right);\n\n        // 如果x没有右孩子。则x有以下两种可能：\n        // (01) x是\"一个左孩子\"，则\"x的后继结点\"为 \"它的父结点\"。\n        // (02) x是\"一个右孩子\"，则查找\"x的最低的父结点，并且该父结点要具有左孩子\"，找到的这个\"最低的父结点\"就是\"x的后继结点\"。\n        BSTNode<T> y = x.parent;\n        while ((y!=null) && (x==y.right)) {\n            x = y;\n            y = y.parent;\n        }\n\n        return y;\n    }\n     \n    /* \n     * 找结点(x)的前驱结点。即，查找\"二叉树中数据值小于该结点\"的\"最大结点\"。\n     */\n    public BSTNode<T> predecessor(BSTNode<T> x) {\n        // 如果x存在左孩子，则\"x的前驱结点\"为 \"以其左孩子为根的子树的最大结点\"。\n        if (x.left != null)\n            return maximum(x.left);\n\n        // 如果x没有左孩子。则x有以下两种可能：\n        // (01) x是\"一个右孩子\"，则\"x的前驱结点\"为 \"它的父结点\"。\n        // (01) x是\"一个左孩子\"，则查找\"x的最低的父结点，并且该父结点要具有右孩子\"，找到的这个\"最低的父结点\"就是\"x的前驱结点\"。\n        BSTNode<T> y = x.parent;\n        while ((y!=null) && (x==y.left)) {\n            x = y;\n            y = y.parent;\n        }\n\n        return y;\n    }\n\n    /* \n     * 将结点插入到二叉树中\n     *\n     * 参数说明：\n     *     tree 二叉树的\n     *     z 插入的结点\n     */\n    private void insert(BSTree<T> bst, BSTNode<T> z) {\n        int cmp;\n        BSTNode<T> y = null;\n        BSTNode<T> x = bst.mRoot;\n\n        // 查找z的插入位置\n        while (x != null) {\n            y = x;\n            cmp = z.key.compareTo(x.key);\n            if (cmp < 0)\n                x = x.left;\n            else\n                x = x.right;\n        }\n\n        z.parent = y;\n        if (y==null)\n            bst.mRoot = z;\n        else {\n            cmp = z.key.compareTo(y.key);\n            if (cmp < 0)\n                y.left = z;\n            else\n                y.right = z;\n        }\n    }\n\n    /* \n     * 新建结点(key)，并将其插入到二叉树中\n     *\n     * 参数说明：\n     *     tree 二叉树的根结点\n     *     key 插入结点的键值\n     */\n    public void insert(T key) {\n        BSTNode<T> z=new BSTNode<T>(key,null,null,null);\n\n        // 如果新建结点失败，则返回。\n        if (z != null)\n            insert(this, z);\n    }\n\n    /* \n     * 删除结点(z)，并返回被删除的结点\n     *\n     * 参数说明：\n     *     bst 二叉树\n     *     z 删除的结点\n     */\n    private BSTNode<T> remove(BSTree<T> bst, BSTNode<T> z) {\n        BSTNode<T> x=null;\n        BSTNode<T> y=null;\n\n        if ((z.left == null) || (z.right == null) )\n            y = z;\n        else\n            y = successor(z);\n\n        if (y.left != null)\n            x = y.left;\n        else\n            x = y.right;\n\n        if (x != null)\n            x.parent = y.parent;\n\n        if (y.parent == null)\n            bst.mRoot = x;\n        else if (y == y.parent.left)\n            y.parent.left = x;\n        else\n            y.parent.right = x;\n\n        if (y != z) \n            z.key = y.key;\n\n        return y;\n    }\n\n    /* \n     * 删除结点(z)，并返回被删除的结点\n     *\n     * 参数说明：\n     *     tree 二叉树的根结点\n     *     z 删除的结点\n     */\n    public void remove(T key) {\n        BSTNode<T> z, node; \n\n        if ((z = search(mRoot, key)) != null)\n            if ( (node = remove(this, z)) != null)\n                node = null;\n    }\n\n    /*\n     * 销毁二叉树\n     */\n    private void destroy(BSTNode<T> tree) {\n        if (tree==null)\n            return ;\n\n        if (tree.left != null)\n            destroy(tree.left);\n        if (tree.right != null)\n            destroy(tree.right);\n\n        tree=null;\n    }\n\n    public void clear() {\n        destroy(mRoot);\n        mRoot = null;\n    }\n\n    /*\n     * 打印\"二叉查找树\"\n     *\n     * key        -- 节点的键值 \n     * direction  --  0，表示该节点是根节点;\n     *               -1，表示该节点是它的父结点的左孩子;\n     *                1，表示该节点是它的父结点的右孩子。\n     */\n    private void print(BSTNode<T> tree, T key, int direction) {\n\n        if(tree != null) {\n\n            if(direction==0)    // tree是根节点\n                System.out.printf(\"%2d is root\\n\", tree.key);\n            else                // tree是分支节点\n                System.out.printf(\"%2d is %2d's %6s child\\n\", tree.key, key, direction==1?\"right\" : \"left\");\n\n            print(tree.left, tree.key, -1);\n            print(tree.right,tree.key,  1);\n        }\n    }\n\n    public void print() {\n        if (mRoot != null)\n            print(mRoot, mRoot.key, 0);\n    }\n}\n```\n\n二叉查找树的C++测试程序(BSTreeTest.java)\n\n```java\n/**\n * Java 语言: 二叉查找树\n *\n * @author skywang\n * @date 2013/11/07\n */\npublic class BSTreeTest {\n\n    private static final int arr[] = {1,5,4,3,2,6};\n\n    public static void main(String[] args) {\n        int i, ilen;\n        BSTree<Integer> tree=new BSTree<Integer>();\n\n        System.out.print(\"== 依次添加: \");\n        ilen = arr.length;\n        for(i=0; i<ilen; i++) {\n            System.out.print(arr[i]+\" \");\n            tree.insert(arr[i]);\n        }\n\n        System.out.print(\"\\n== 前序遍历: \");\n        tree.preOrder();\n\n        System.out.print(\"\\n== 中序遍历: \");\n        tree.inOrder();\n\n        System.out.print(\"\\n== 后序遍历: \");\n        tree.postOrder();\n        System.out.println();\n\n        System.out.println(\"== 最小值: \"+ tree.minimum());\n        System.out.println(\"== 最大值: \"+ tree.maximum());\n        System.out.println(\"== 树的详细信息: \");\n        tree.print();\n\n        System.out.print(\"\\n== 删除根节点: \"+ arr[3]);\n        tree.remove(arr[3]);\n\n        System.out.print(\"\\n== 中序遍历: \");\n        tree.inOrder();\n        System.out.println();\n\n        // 销毁二叉树\n        tree.clear();\n    }\n}\n```\n\n在二叉查找树的Java实现中，使用了泛型，也就意味着支持任意类型； 但是该类型必须要实现Comparable接口。\n\n### 二叉查找树的Java测试程序\n\n上面的BSTreeTest.java是二叉查找树树的测试程序，运行结果如下：\n\n```\n== 依次添加: 1 5 4 3 2 6 \n== 前序遍历: 1 5 4 3 2 6 \n== 中序遍历: 1 2 3 4 5 6 \n== 后序遍历: 2 3 4 6 5 1 \n== 最小值: 1\n== 最大值: 6\n== 树的详细信息: \n 1 is root\n 5 is  1's  right child\n 4 is  5's   left child\n 3 is  4's   left child\n 2 is  3's   left child\n 6 is  5's  right child\n\n== 删除根节点: 3\n== 中序遍历: 1 2 4 5 6 \n```\n\n下面对测试程序的流程进行分析！\n\n(01) 新建\"二叉查找树\"root。\n\n(02) 向二叉查找树中依次插入1,5,4,3,2,6 。如下图所示：\n\n![](/assets/images/2014/03/28/binary-search-tree-and-implementation/003.jpg)\n\n(03) 遍历和查找\n\n插入1,5,4,3,2,6之后，得到的二叉查找树如下：\n\n![](/assets/images/2014/03/28/binary-search-tree-and-implementation/004.jpg)\n\n前序遍历结果: 1 5 4 3 2 6 \n\n中序遍历结果: 1 2 3 4 5 6 \n\n后序遍历结果: 2 3 4 6 5 1 \n\n最小值是1，而最大值是6。\n\n(04) 删除节点4。如下图所示：\n\n![](/assets/images/2014/03/28/binary-search-tree-and-implementation/005.jpg)\n\n(05) 重新遍历该二叉查找树。\n\n中序遍历结果: 1 2 4 5 6\n\n---\n\n* 原文链接：[二叉查找树(三)之 Java的实现](http://www.cnblogs.com/skywang12345/p/3576452.html)\n","tags":["BinarySearchTree"],"categories":["Algorithm"]},{"title":"队列的图文解析 和 对应3种语言的实现(C/C++/Java)","url":"%2F2014%2F2014-03-26-queue-and-implementation%2F","content":"\n## 概要\n\n本章和介绍\"栈\"时的流程一样，先对队列进行介绍，然后分别给出队列的C、C++和Java三种语言的实现。内容包括：\n\n1. 队列的介绍\n2. 队列的C实现\n3. 队列的C++实现\n4. 队列的Java实现\n\n## 队列的介绍\n\n队列（Queue），是一种线性存储结构。它有以下几个特点：\n\n(01) 队列中数据是按照\"先进先出（FIFO, First-In-First-Out）\"方式进出队列的。\n\n(02) 队列只允许在\"队首\"进行删除操作，而在\"队尾\"进行插入操作。\n\n队列通常包括的两种操作：入队列 和 出队列。\n\n### 1. 队列的示意图\n\n![](/assets/images/2014/03/26/queue-and-implementation/001.jpg)\n\n队列中有10，20，30共3个数据。\n\n### 2. 出队列\n\n![](/assets/images/2014/03/26/queue-and-implementation/002.jpg)\n\n出队列前：队首是10，队尾是30。\n\n出队列后：出队列(队首)之后。队首是20，队尾是30。\n\n### 3. 入队列\n\n![](/assets/images/2014/03/26/queue-and-implementation/003.jpg)\n\n入队列前：队首是20，队尾是30。\n\n入队列后：40入队列(队尾)之后。队首是20，队尾是40。\n\n## 实现\n\n下面介绍队列的实现，分别介绍C/C++/Java三种实现\n\n### 队列的C实现\n\n共介绍4种C语言实现。\n\n1. C语言实现一：数组实现的队列，并且只能存储int数据。\n2. C语言实现二：单向链表实现的队列，并且只能存储int数据。\n3. C语言实现三：双向链表实现的队列，并且只能存储int数据。\n4. C语言实现四：双向链表实现的队列，能存储任意类型的数据。\n\n#### 1. C语言实现一：数组实现的队列，并且只能存储int数据\n\n实现代码(array_queue.c)\n\n```c\n```\n\n运行结果：\n\n```\ntmp=10\ntmp=20\nis_empty()=0\nsize()=3\n20\n30\n40\n```\n\n结果说明：该示例中的队列，是通过\"数组\"来实现的！\n\n由于代码中已经给出了详细了注释，这里就不再对函数进行说明了。仅对主函数main的逻辑进行简单介绍。\n\n(01) 在主函数main中，先将 \"10, 20, 30\"依次入队列。此时，队列的数据是： 10 --> 20 --> 30 \n\n(02) 接着通过pop()返回队首元素；pop()操作并不会改变队列中的数据。此时，队列的数据依然是： 10 --> 20 --> 30 \n\n(03) 接着通过front()返回并删除队首元素。front()操作之后，队列的数据是： 10 --> 30 \n\n(04) 接着通过add(40)将40入队列。add(40)操作之后，队列中的数据是： 10 --> 20 --> 40\n\n#### 2. C语言实现二：单向链表实现的队列，并且只能存储int数据\n\n实现代码(slink_queue.c)\n\n```c\n```\n\n代码说明：\"运行结果\" 以及 \"主函数main的逻辑\"都和\"C语言实现一\"的一样。不同的是，该示例中的队列是通过单向链表实现的。\n\n#### 3. C语言实现三：双向链表实现的队列，并且只能存储int数据\n\n实现代码\n\n双向链表的头文件(double_link.h)\n\n```c\n```\n\n双向链表的实现文件(double_link.c)\n\n```c\n```\n\n双向链表的测试程序(dlink_queue.c)\n\n```c\n```\n\n代码说明：\"运行结果\" 以及 \"主函数main的逻辑\"都和前两个示例的一样。不同的是，该示例中的队列是通过双向链表实现的。\n\n#### 4. C语言实现四：双向链表实现的队列，能存储任意类型的数据\n\n实现代码\n\n双向链表的头文件(double_link.h)\n\n```c\n```\n\n双向链表的实现文件(double_link.c)\n\n```c\n```\n\n双向链表的测试程序(dlink_queue.c)\n\n```c\n```\n\n运行结果：\n\n```\nid=10, name=sky\nid=20, name=jody\nis_empty()=0\nsize()=3\nid=20, name=jody\nid=30, name=vic\nid=40, name=dan\n```\n\n结果说明：该示例中的队列是通过双向链表实现的，并且能存储任意类型的数据。\n\n### 队列的C++实现\n\nC++的STL中本身就包含了list类，基本上该list类就能满足我们的需求，所以很少需要我们自己来实现。本部分介绍2种C++实现。\n\n1. C++实现一：数组实现的队列，能存储任意类型的数据。\n2. C++实现二：C++的 STL 中自带的\"队列\"(list)的示例。\n\n#### 1. C++实现一：数组实现的队列，能存储任意类型的数据\n\n实现代码\n\n队列的实现文件(ArrayQueue.h)\n\n```cpp\n```\n\n队列的测试程序(Main.cpp)\n\n```cpp\n```\n\n运行结果：\n\n```\ntmp=10\ntmp=20\nis_empty()=0\nsize()=3\n20\n30\n40\n```\n\n结果说明：关于\"队列的声明和实现都在头文件中\"的原因，是因为队列的实现利用了C++模板，而\"C++编译器不能支持对模板的分离式编译\"。\n\n#### 2. C++实现二：C++的 STL 中自带的\"队列\"(list)的示例\n\n实现代码(StlQueue.cpp)\n\n```cpp\n```\n\n运行结果：\n\n```\ntmp=20\nempty()=0\nsize()=3\n20\n30\n40\n```\n\n### 队列的Java实现\n\n和C++一样，JDK包Queue中的也提供了\"队列\"的实现。JDK中的Queue接口就是\"队列\"，它的实现类也都是队列，用的最多的是LinkedList。本部分介绍给出2种Java实现\n\n1. Java实现一：数组实现的队列，能存储任意类型的数据。\n2. Java实现二：Java的 Collection集合 中自带的\"队列\"(LinkedList)的示例。\n\n#### 1. Java实现一：数组实现的队列，能存储任意类型的数据\n\n实现代码(ArrayQueue.java)\n\n```java\n```\n\n运行结果：\n\n```\ntmp=10\ntmp=20\nisEmpty()=false\nsize()=3\nsize()=20\nsize()=30\nsize()=40\n```\n\n结果说明：ArrayQueue是通过数组实现的队列，而且ArrayQueue中使用到了泛型，因此它支持任意类型的数据。\n\n#### 2. Java实现二：Java的 Collection集合 中自带的\"队列\"(LinkedList)的示例\n\n实现代码(QueueTest.java)\n\n```java\n```\n\n运行结果：\n\n```\ntmp=10\ntmp=20\nisEmpty()=false\nsize()=3\ntmp=20\ntmp=30\ntmp=40\n```\n\n---\n\n* 原文链接：[队列的图文解析 和 对应3种语言的实现(C/C++/Java)](http://www.cnblogs.com/skywang12345/p/3562279.html)\n","tags":["Queue"],"categories":["Algorithm"]},{"title":"栈的图文解析 和 对应3种语言的实现(C/C++/Java)","url":"%2F2014%2F2014-03-25-stack-and-implementation%2F","content":" \n## 概要\n\n本章会先对栈的原理进行介绍，然后分别通过C/C++/Java三种语言来演示栈的实现示例。注意：本文所说的栈是数据结构中的栈，而不是内存模型中栈。内容包括：\n\n1. 栈的介绍\n2. 栈的C实现\n3. 栈的C++实现\n4. 栈的Java实现\n\n## 栈的介绍\n栈（stack），是一种线性存储结构，它有以下几个特点：\n\n(01) 栈中数据是按照\"后进先出（LIFO, Last In First Out）\"方式进出栈的。\n\n(02) 向栈中添加/删除数据时，只能从栈顶进行操作。\n\n栈通常包括的三种操作：push、peek、pop。\n\n```\npush -- 向栈中添加元素。\npeek -- 返回栈顶元素。\npop  -- 返回并删除栈顶元素的操作。\n```\n\n1. 栈的示意图\n\n![](/assets/images/2014/03/25/stack-and-implementation/001.jpg)\n\n栈中的数据依次是 30 --> 20 --> 10\n\n2. 出栈\n\n![](/assets/images/2014/03/25/stack-and-implementation/002.jpg)\n\n出栈前：栈顶元素是30。此时，栈中的元素依次是 30 --> 20 --> 10 \n\n出栈后：30出栈之后，栈顶元素变成20。此时，栈中的元素依次是 20 --> 10\n\n3. 入栈\n\n![](/assets/images/2014/03/25/stack-and-implementation/003.jpg)\n\n入栈前：栈顶元素是20。此时，栈中的元素依次是 20 --> 10 \n\n入栈后：40入栈之后，栈顶元素变成40。此时，栈中的元素依次是 40 --> 20 --> 10\n\n## 实现\n\n下面介绍栈的实现，分别介绍C/C++/Java三种实现。\n\n### 栈的C实现\n\n共介绍4种C语言实现。\n\n1. C语言实现一：数组实现的栈，并且只能存储int数据。\n2. C语言实现二：单向链表实现的栈，并且只能存储int数据。\n3. C语言实现三：双向链表实现的栈，并且只能存储int数据。\n4. C语言实现四：双向链表实现的栈，能存储任意类型的数据。\n\n#### 1. C语言实现一：数组实现的栈，并且只能存储int数据\n\n实现代码(array_stack.c)\n\n```c\n#include <stdio.h>\n#include <malloc.h>\n\n/**\n * C 语言: 数组实现的栈，只能存储int数据。\n *\n * @author skywang\n * @date 2013/11/07\n */\n\n// 保存数据的数组\nstatic int *arr=NULL;\n// 栈的实际大小\nstatic int count;\n\n// 创建“栈”，默认大小是12\nint create_array_stack(int sz) \n{\n    arr = (int *)malloc(sz*sizeof(int));\n    if (!arr) \n    {\n        printf(\"arr malloc error!\");\n        return -1;\n    }\n\n    return 0;\n}\n\n// 销毁“栈”\nint destroy_array_stack() \n{\n    if (arr) \n    {\n        free(arr);\n        arr = NULL;\n    }\n\n    return 0;\n}\n\n// 将val添加到栈中\nvoid push(int val) \n{\n    arr[count++] = val;\n}\n\n// 返回“栈顶元素值”\nint peek() \n{\n    return arr[count-1];\n}\n\n// 返回“栈顶元素值”，并删除“栈顶元素”\nint pop() \n{\n    int ret = arr[count-1];\n    count--;\n    return ret;\n}\n\n// 返回“栈”的大小\nint size() \n{\n    return count;\n}\n\n// 返回“栈”是否为空\nint is_empty()\n{\n    return size()==0;\n}\n\n// 打印“栈”\nvoid print_array_stack()\n{\n    if (is_empty()) \n    {\n        printf(\"stack is Empty\\n\");\n        return ;\n    }\n\n    printf(\"stack size()=%d\\n\", size());\n\n    int i=size()-1;\n    while (i>=0)\n    {\n        printf(\"%d\\n\", arr[i]);\n        i--;\n    }\n}\n\n\nvoid main() \n{\n    int tmp=0;\n\n    // 创建“栈”\n    create_array_stack(12);\n\n    // 将10, 20, 30 依次推入栈中\n    push(10);\n    push(20);\n    push(30);\n\n    //print_array_stack();    // 打印栈\n\n    // 将“栈顶元素”赋值给tmp，并删除“栈顶元素”\n    tmp = pop();\n    printf(\"tmp=%d\\n\", tmp);\n    //print_array_stack();    // 打印栈\n\n    // 只将“栈顶”赋值给tmp，不删除该元素.\n    tmp = peek();\n    printf(\"tmp=%d\\n\", tmp);\n    //print_array_stack();    // 打印栈\n\n    push(40);\n    print_array_stack();    // 打印栈\n\n    // 销毁栈\n    destroy_array_stack();\n}\n```\n\n运行结果：\n\n```\ntmp=30\ntmp=20\nstack size()=3\n40\n20\n10\n```\n\n结果说明：该示例中的栈，是通过\"数组\"来实现的！\n\n由于代码中已经给出了详细了注释，这里就不再对函数进行说明了。仅对主函数main的逻辑进行简单介绍。\n\n(01) 在主函数main中，先将 \"10, 20, 30\"依次压入栈。此时，栈的数据是： 30 --> 20 --> 10 \n\n(02) 接着通过pop()返回栈顶元素；pop()操作并不会改变栈中的数据。此时，栈的数据依然是： 30 --> 20 --> 10 \n\n(03) 接着通过peek()返回并删除栈顶元素。peek操作之后，栈的数据是： 20 --> 10 \n\n(04) 接着通过push(40)将40压入栈中。push(40)操作之后，栈的数据是： 40 --> 20 --> 10\n\n#### 2. C语言实现二：单向链表实现的栈，并且只能存储int数据\n\n实现代码(slink_stack.c)\n\n```c\n#include <stdio.h>\n#include <malloc.h>\n\n/**\n * C 语言: 单向链表实现的栈，只能存储int数据。\n *\n * @author skywang\n * @date 2013/11/07\n */\n\n// 单向链表的“节点”\nstruct node {\n    int val;\n    struct node* next;\n};\n\n// 单向链表的“表头”\nstatic struct node *phead=NULL;\n\n// 创建节点，val为节点值\nstatic struct node* create_node(int val) \n{\n    struct node *pnode=NULL;\n    pnode = (struct node*)malloc(sizeof(struct node));\n    if (!pnode)\n        return NULL;\n    pnode->val = val;\n    pnode->next = NULL;\n    \n    return pnode;\n}\n\n// 销毁单向链表\nstatic int destroy_single_link() \n{\n    struct node *pnode=NULL;\n\n    while (phead != NULL) {\n        pnode = phead;\n        phead = phead->next;\n        free(pnode);\n    }\n    return 0;\n}\n\n// 将val插入到链表的表头位置\nstatic struct node* push(int val) \n{\n    struct node *pnode = NULL;\n    \n    pnode = create_node(val);\n    pnode->next = phead;\n    phead = pnode;\n    \n    return phead;\n}\n\n// 删除链表的表头\nstatic int pop() \n{\n    if (!phead)\n    {\n        printf(\"remove failed! link is empty!\");\n        return -1;\n    }\n    \n    int ret;\n    struct node *pnode;\n    ret = phead->val;\n    pnode = phead;\n    phead = phead->next;\n    free(pnode);\n\n    return ret;\n}\n\n// 返回链表的表头节点的值\nstatic int peek() \n{\n    if (!phead)\n    {\n        printf(\"peek failed! link is empty!\");\n        return -1;\n    }\n\n    return phead->val;\n}\n\n// 返回链表中节点的个数\nstatic int size() \n{\n    int count=0;\n    struct node *pnode=phead;\n\n    while (pnode != NULL) {\n        pnode = pnode->next;\n        count++;\n    }\n    return count;\n}\n\n// 链表是否为空\nstatic int is_empty() \n{\n    return phead==NULL;\n}\n\n// 打印“栈”\nstatic void print_single_link()\n{\n    if (is_empty()) \n    {\n        printf(\"stack is Empty\\n\");\n        return 0;\n    }\n\n    printf(\"stack size()=%d\\n\", size());\n\n    struct node *pnode=NULL;\n\n    while (phead != NULL) {\n        printf(\"%d\\n\", phead->val);\n        pnode = phead;\n        phead = phead->next;\n        free(pnode);\n    }\n}\n\nvoid main() \n{\n    int tmp=0;\n\n    // 将10, 20, 30 依次推入栈中\n    push(10);\n    push(20);\n    push(30);\n\n    //print_single_link();    // 打印栈\n\n    // 将“栈顶元素”赋值给tmp，并删除“栈顶元素”\n    tmp = pop();\n    printf(\"tmp=%d\\n\", tmp);\n    //print_single_link();    // 打印栈\n\n    // 只将“栈顶”赋值给tmp，不删除该元素.\n    tmp = peek();\n    printf(\"tmp=%d\\n\", tmp);\n    //print_single_link();    // 打印栈\n\n    push(40);\n    print_single_link();    // 打印栈\n\n    // 销毁栈\n    destroy_single_link();\n}\n```\n\n代码说明：\"运行结果\" 以及 \"主函数main的逻辑\"都和\"C语言实现一\"的一样。不同的是，该示例中的栈是通过单向链表实现的。\n\n#### 3. C语言实现三：双向链表实现的栈，并且只能存储int数据\n\n实现代码\n\n双向链表的头文件(double_link.h)\n\n```c\n#ifndef _DOUBLE_LINK_H\n#define _DOUBLE_LINK_H\n\n// 新建“双向链表”。成功，返回表头；否则，返回NULL\nextern int create_dlink();\n// 撤销“双向链表”。成功，返回0；否则，返回-1\nextern int destroy_dlink();\n\n// “双向链表是否为空”。为空的话返回1；否则，返回0。\nextern int dlink_is_empty();\n// 返回“双向链表的大小”\nextern int dlink_size();\n\n// 获取“双向链表中第index位置的元素的值”。成功，返回节点值；否则，返回-1。\nextern int dlink_get(int index);\n// 获取“双向链表中第1个元素的值”。成功，返回节点值；否则，返回-1。\nextern int dlink_get_first();\n// 获取“双向链表中最后1个元素的值”。成功，返回节点值；否则，返回-1。\nextern int dlink_get_last();\n\n// 将“value”插入到index位置。成功，返回0；否则，返回-1。\nextern int dlink_insert(int index, int value);\n// 将“value”插入到表头位置。成功，返回0；否则，返回-1。\nextern int dlink_insert_first(int value);\n// 将“value”插入到末尾位置。成功，返回0；否则，返回-1。\nextern int dlink_append_last(int value);\n\n// 删除“双向链表中index位置的节点”。成功，返回0；否则，返回-1\nextern int dlink_delete(int index);\n// 删除第一个节点。成功，返回0；否则，返回-1\nextern int dlink_delete_first();\n// 删除组后一个节点。成功，返回0；否则，返回-1\nextern int dlink_delete_last();\n\n// 打印“双向链表”\nextern void print_dlink();\n\n#endif\n```\n\n双向链表的实现文件double_link.c)\n\n```c\n#include <stdio.h>\n#include <malloc.h>\n\n/**\n * c语言实现的双向链表\n *\n * @author skywang\n * @date   2013/11/07\n */\n// 双向链表节点\ntypedef struct tag_node \n{\n    struct tag_node *prev;\n    struct tag_node *next;\n    int value;\n}node;\n\n// 表头。注意，表头不存放元素值！！！\nstatic node *phead=NULL;\n// 节点个数。\nstatic int  count=0;\n\n// 新建“节点”。成功，返回节点指针；否则，返回NULL。\nstatic node* create_node(int value)\n{\n    node *pnode=NULL;\n    pnode = (node *)malloc(sizeof(node));\n    if (!pnode)\n    {\n        printf(\"create node error!\\n\");\n        return NULL;\n    }\n    // 默认的，pnode的前一节点和后一节点都指向它自身\n    pnode->prev = pnode->next = pnode;\n    // 节点的值为value\n    pnode->value = value;\n\n    return pnode;\n}\n\n// 新建“双向链表”。成功，返回0；否则，返回-1。\nint create_dlink()\n{\n    // 创建表头\n    phead = create_node(-1);\n    if (!phead)\n        return -1;\n\n    // 设置“节点个数”为0\n    count = 0;\n\n    return 0;\n}\n\n// “双向链表是否为空”\nint dlink_is_empty()\n{\n    return count == 0;\n}\n\n// 返回“双向链表的大小”\nint dlink_size() {\n    return count;\n}\n\n// 获取“双向链表中第index位置的节点”\nstatic node* get_node(int index) \n{\n    if (index<0 || index>=count)\n    {\n        printf(\"%s failed! the index in out of bound!\\n\", __func__);\n        return NULL;\n    }\n\n    // 正向查找\n    if (index <= (count/2))\n    {\n        int i=0;\n        node *pnode=phead->next;\n        while ((i++) < index) \n            pnode = pnode->next;\n\n//        printf(\"%s %d i=%d, pnode->value=%d\\n\", \n//                __func__, __LINE__, i, pnode->value);\n        return pnode;\n    }\n\n    // 反向查找\n    int j=0;\n    int rindex = count - index - 1;\n    node *rnode=phead->prev;\n    while ((j++) < rindex) \n        rnode = rnode->prev;\n\n//    printf(\"%s %d j=%d, rnode->value=%d\\n\", \n//            __func__, __LINE__, j, rnode->value);\n    return rnode;\n}\n\n// 获取“第一个节点”\nstatic node* get_first_node() \n{\n    return get_node(0);\n}\n\n// 获取“最后一个节点”\nstatic node* get_last_node() \n{\n    return get_node(count-1);\n}\n\n// 获取“双向链表中第index位置的元素的值”。成功，返回节点值；否则，返回-1。\nint dlink_get(int index)\n{\n    node *pindex=get_node(index);\n    if (!pindex) \n    {\n        printf(\"%s failed!\\n\", __func__);\n        return -1;\n    }\n\n    return pindex->value;\n\n}\n\n// 获取“双向链表中第1个元素的值”\nint dlink_get_first()\n{\n    return dlink_get(0);\n}\n\n// 获取“双向链表中最后1个元素的值”\nint dlink_get_last()\n{\n    return dlink_get(count-1);\n}\n\n// 将“value”插入到index位置。成功，返回0；否则，返回-1。\nint dlink_insert(int index, int value) \n{\n    // 插入表头\n    if (index==0)\n        return dlink_insert_first(value);\n\n    // 获取要插入的位置对应的节点\n    node *pindex=get_node(index);\n    if (!pindex) \n        return -1;\n\n    // 创建“节点”\n    node *pnode=create_node(value);\n    if (!pnode)\n        return -1;\n\n    pnode->prev = pindex->prev;\n    pnode->next = pindex;\n    pindex->prev->next = pnode;\n    pindex->prev = pnode;\n    // 节点个数+1\n    count++;\n\n    return 0;\n}\n\n// 将“value”插入到表头位置\nint dlink_insert_first(int value) \n{\n    node *pnode=create_node(value);\n    if (!pnode)\n        return -1;\n\n    pnode->prev = phead;\n    pnode->next = phead->next;\n    phead->next->prev = pnode;\n    phead->next = pnode;\n    count++;\n    return 0;\n}\n\n// 将“value”插入到末尾位置\nint dlink_append_last(int value) \n{\n    node *pnode=create_node(value);\n    if (!pnode)\n        return -1;\n    \n    pnode->next = phead;\n    pnode->prev = phead->prev;\n    phead->prev->next = pnode;\n    phead->prev = pnode;\n    count++;\n    return 0;\n}\n\n// 删除“双向链表中index位置的节点”。成功，返回0；否则，返回-1。\nint dlink_delete(int index)\n{\n    node *pindex=get_node(index);\n    if (!pindex) \n    {\n        printf(\"%s failed! the index in out of bound!\\n\", __func__);\n        return -1;\n    }\n\n    pindex->next->prev = pindex->prev;\n    pindex->prev->next = pindex->next;\n    free(pindex);\n    count--;\n\n    return 0;\n}    \n\n// 删除第一个节点\nint dlink_delete_first() \n{\n    return dlink_delete(0);\n}\n\n// 删除组后一个节点\nint dlink_delete_last() \n{\n    return dlink_delete(count-1);\n}\n\n// 撤销“双向链表”。成功，返回0；否则，返回-1。\nint destroy_dlink()\n{\n    if (!phead)\n    {\n        printf(\"%s failed! dlink is null!\\n\", __func__);\n        return -1;\n    }\n\n    node *pnode=phead->next;\n    node *ptmp=NULL;\n    while(pnode != phead)\n    {\n        ptmp = pnode;\n        pnode = pnode->next;\n        free(ptmp);\n    }\n\n    free(phead);\n    phead = NULL;\n    count = 0;\n\n    return 0;\n}\n\n// 打印“双向链表”\nvoid print_dlink()\n{\n    if (count==0 || (!phead))\n    {\n        printf(\"stack is Empty\\n\");\n        return ;\n    }\n\n    printf(\"stack size()=%d\\n\", count);\n    node *pnode=phead->next;\n    while(pnode != phead)\n    {\n        printf(\"%d\\n\", pnode->value);\n        pnode = pnode->next;\n    }\n}\n```\n\n双向链表的测试程序(dlink_stack.c)\n\n```c\n#include <stdio.h>\n#include \"double_link.h\"\n\n/**\n * C 语言: 双向链表实现栈，只能存储int数据。\n *\n * @author skywang\n * @date 2013/11/07\n */\n// 创建栈\nint create_dlink_stack() \n{\n    return create_dlink();\n}\n\n// 销毁栈\nint destroy_dlink_stack() \n{\n    return destroy_dlink();\n}\n\n// 将val添加到栈中\nint push(int val) \n{\n    return dlink_insert_first(val);\n}\n\n// 返回“栈顶元素值”\nint peek() \n{\n    return dlink_get_first();\n}\n\n// 返回“栈顶元素值”，并删除“栈顶元素”\nint pop() \n{\n    int ret = peek();\n    dlink_delete_first();\n    return ret;\n}\n\n// 返回“栈”的大小\nint size() \n{\n    return dlink_size();\n}\n\n// 返回“栈”是否为空\nint is_empty()\n{\n    return dlink_is_empty();\n}\n\n// 打印“栈”\nvoid print_dlink_stack()\n{\n    return print_dlink();\n}\n\nvoid main()\n{\n    int tmp=0;\n\n    // 创建“栈”\n    create_dlink_stack();\n\n    // 将10, 20, 30 依次推入栈中\n    push(10);\n    push(20);\n    push(30);\n\n    //print_dlink_stack();    // 打印栈\n\n    // 将“栈顶元素”赋值给tmp，并删除“栈顶元素”\n    tmp = pop();\n    printf(\"tmp=%d\\n\", tmp);\n    //print_dlink_stack();    // 打印栈\n\n    // 只将“栈顶”赋值给tmp，不删除该元素.\n    tmp = peek();\n    printf(\"tmp=%d\\n\", tmp);\n    //print_dlink_stack();    // 打印栈\n\n    push(40);\n    print_dlink_stack();    // 打印栈\n\n    // 销毁栈\n    destroy_dlink_stack();\n}\n```\n\n代码说明：\"运行结果\" 以及 \"主函数main的逻辑\"都和前两个示例的一样。不同的是，该示例中的栈是通过双向链表实现的。\n\n#### 4. C语言实现四：双向链表实现的栈，能存储任意类型的数据\n\n实现代码\n\n双向链表的头文件(double_link.h)\n\n```c\n#ifndef _DOUBLE_LINK_H\n#define _DOUBLE_LINK_H\n\n// 新建“双向链表”。成功，返回表头；否则，返回NULL\nextern int create_dlink();\n// 撤销“双向链表”。成功，返回0；否则，返回-1\nextern int destroy_dlink();\n\n// “双向链表是否为空”。为空的话返回1；否则，返回0。\nextern int dlink_is_empty();\n// 返回“双向链表的大小”\nextern int dlink_size();\n\n// 获取“双向链表中第index位置的元素”。成功，返回节点指针；否则，返回NULL。\nextern void* dlink_get(int index);\n// 获取“双向链表中第1个元素”。成功，返回节点指针；否则，返回NULL。\nextern void* dlink_get_first();\n// 获取“双向链表中最后1个元素”。成功，返回节点指针；否则，返回NULL。\nextern void* dlink_get_last();\n\n// 将“value”插入到index位置。成功，返回0；否则，返回-1。\nextern int dlink_insert(int index, void *pval);\n// 将“value”插入到表头位置。成功，返回0；否则，返回-1。\nextern int dlink_insert_first(void *pval);\n// 将“value”插入到末尾位置。成功，返回0；否则，返回-1。\nextern int dlink_append_last(void *pval);\n\n// 删除“双向链表中index位置的节点”。成功，返回0；否则，返回-1\nextern int dlink_delete(int index);\n// 删除第一个节点。成功，返回0；否则，返回-1\nextern int dlink_delete_first();\n// 删除组后一个节点。成功，返回0；否则，返回-1\nextern int dlink_delete_last();\n\n#endif\n```\n\n双向链表的实现文件(double_link.c)\n\n```c\n#include <stdio.h>\n#include <malloc.h>\n\n\n/**\n * C 语言实现的双向链表，能存储任意数据。\n *\n * @author skywang\n * @date 2013/11/07\n */\n// 双向链表节点\ntypedef struct tag_node \n{\n    struct tag_node *prev;\n    struct tag_node *next;\n    void* p;\n}node;\n\n// 表头。注意，表头不存放元素值！！！\nstatic node *phead=NULL;\n// 节点个数。\nstatic int  count=0;\n\n// 新建“节点”。成功，返回节点指针；否则，返回NULL。\nstatic node* create_node(void *pval)\n{\n    node *pnode=NULL;\n    pnode = (node *)malloc(sizeof(node));\n    if (!pnode)\n    {\n        printf(\"create node error!\\n\");\n        return NULL;\n    }\n    // 默认的，pnode的前一节点和后一节点都指向它自身\n    pnode->prev = pnode->next = pnode;\n    // 节点的值为pval\n    pnode->p = pval;\n\n    return pnode;\n}\n\n// 新建“双向链表”。成功，返回0；否则，返回-1。\nint create_dlink()\n{\n    // 创建表头\n    phead = create_node(NULL);\n    if (!phead)\n        return -1;\n\n    // 设置“节点个数”为0\n    count = 0;\n\n    return 0;\n}\n\n// “双向链表是否为空”\nint dlink_is_empty()\n{\n    return count == 0;\n}\n\n// 返回“双向链表的大小”\nint dlink_size() {\n    return count;\n}\n\n// 获取“双向链表中第index位置的节点”\nstatic node* get_node(int index) \n{\n    if (index<0 || index>=count)\n    {\n        printf(\"%s failed! index out of bound!\\n\", __func__);\n        return NULL;\n    }\n\n    // 正向查找\n    if (index <= (count/2))\n    {\n        int i=0;\n        node *pnode=phead->next;\n        while ((i++) < index) \n            pnode = pnode->next;\n\n        return pnode;\n    }\n\n    // 反向查找\n    int j=0;\n    int rindex = count - index - 1;\n    node *rnode=phead->prev;\n    while ((j++) < rindex) \n        rnode = rnode->prev;\n\n    return rnode;\n}\n\n// 获取“第一个节点”\nstatic node* get_first_node() \n{\n    return get_node(0);\n}\n\n// 获取“最后一个节点”\nstatic node* get_last_node() \n{\n    return get_node(count-1);\n}\n\n// 获取“双向链表中第index位置的元素”。成功，返回节点值；否则，返回-1。\nvoid* dlink_get(int index)\n{\n    node *pindex=get_node(index);\n    if (!pindex) \n    {\n        printf(\"%s failed!\\n\", __func__);\n        return NULL;\n    }\n\n    return pindex->p;\n\n}\n\n// 获取“双向链表中第1个元素的值”\nvoid* dlink_get_first()\n{\n    return dlink_get(0);\n}\n\n// 获取“双向链表中最后1个元素的值”\nvoid* dlink_get_last()\n{\n    return dlink_get(count-1);\n}\n\n// 将“pval”插入到index位置。成功，返回0；否则，返回-1。\nint dlink_insert(int index, void* pval) \n{\n    // 插入表头\n    if (index==0)\n        return dlink_insert_first(pval);\n\n    // 获取要插入的位置对应的节点\n    node *pindex=get_node(index);\n    if (!pindex) \n        return -1;\n\n    // 创建“节点”\n    node *pnode=create_node(pval);\n    if (!pnode)\n        return -1;\n\n    pnode->prev = pindex->prev;\n    pnode->next = pindex;\n    pindex->prev->next = pnode;\n    pindex->prev = pnode;\n    // 节点个数+1\n    count++;\n\n    return 0;\n}\n\n// 将“pval”插入到表头位置\nint dlink_insert_first(void *pval) \n{\n    node *pnode=create_node(pval);\n    if (!pnode)\n        return -1;\n\n    pnode->prev = phead;\n    pnode->next = phead->next;\n    phead->next->prev = pnode;\n    phead->next = pnode;\n    count++;\n    return 0;\n}\n\n// 将“pval”插入到末尾位置\nint dlink_append_last(void *pval) \n{\n    node *pnode=create_node(pval);\n    if (!pnode)\n        return -1;\n    \n    pnode->next = phead;\n    pnode->prev = phead->prev;\n    phead->prev->next = pnode;\n    phead->prev = pnode;\n    count++;\n    return 0;\n}\n\n// 删除“双向链表中index位置的节点”。成功，返回0；否则，返回-1。\nint dlink_delete(int index)\n{\n    node *pindex=get_node(index);\n    if (!pindex) \n    {\n        printf(\"%s failed! the index in out of bound!\\n\", __func__);\n        return -1;\n    }\n\n    pindex->next->prev = pindex->prev;\n    pindex->prev->next = pindex->next;\n    free(pindex);\n    count--;\n\n    return 0;\n}    \n\n// 删除第一个节点\nint dlink_delete_first() \n{\n    return dlink_delete(0);\n}\n\n// 删除组后一个节点\nint dlink_delete_last() \n{\n    return dlink_delete(count-1);\n}\n\n// 撤销“双向链表”。成功，返回0；否则，返回-1。\nint destroy_dlink()\n{\n    if (!phead)\n    {\n        printf(\"%s failed! dlink is null!\\n\", __func__);\n        return -1;\n    }\n\n    node *pnode=phead->next;\n    node *ptmp=NULL;\n    while(pnode != phead)\n    {\n        ptmp = pnode;\n        pnode = pnode->next;\n        free(ptmp);\n    }\n\n    free(phead);\n    phead = NULL;\n    count = 0;\n\n    return 0;\n}\n```\n\n双向链表的测试程序(dlink_stack.c)\n\n```c\n#include <stdio.h>\n#include \"double_link.h\"\n\n/**\n * C 语言: 双向链表实现栈，能存储任意数据。\n *\n * @author skywang\n * @date 2013/11/07\n */\n// 创建栈\nint create_dlink_stack() \n{\n    return create_dlink();\n}\n\n// 销毁栈\nint destroy_dlink_stack() \n{\n    return destroy_dlink();\n}\n\n// 将val添加到栈中\nint push(void *p) \n{\n    return dlink_insert_first(p);\n}\n\n// 返回“栈顶元素值”\nvoid* peek() \n{\n    return dlink_get_first();\n}\n\n// 返回“栈顶元素值”，并删除“栈顶元素”\nvoid* pop() \n{\n    void *p = peek();\n    dlink_delete_first();\n    return p;\n}\n\n// 返回“栈”的大小\nint size() \n{\n    return dlink_size();\n}\n\n// 返回“栈”是否为空\nint is_empty()\n{\n    return dlink_is_empty();\n}\n\n\ntypedef struct tag_stu\n{\n    int id;\n    char name[20];\n}stu;\n\nstatic stu arr_stu[] = \n{\n    {10, \"sky\"},\n    {20, \"jody\"},\n    {30, \"vic\"},\n    {40, \"dan\"},\n};\n#define ARR_STU_SIZE ( (sizeof(arr_stu)) / (sizeof(arr_stu[0])) )\n\nstatic void print_stu(stu *p) \n{\n    if (!p)\n        return ;\n\n    printf(\"id=%d, name=%s\\n\", p->id, p->name);\n}\n\nvoid main()\n{\n    stu *pval=NULL;\n\n    // 创建“栈”\n    create_dlink_stack();\n\n    // 将10, 20, 30 依次推入栈中\n    int i=0;\n    for (i=0; i<ARR_STU_SIZE-1; i++)\n    {\n        push(&arr_stu[i]);\n    }\n\n    // 将“栈顶元素”赋值给pval，并删除“栈顶元素”\n    pval = (stu*)pop();\n    //print_stu(pval) ;\n\n    // 只将“栈顶”赋值给pval，不删除该元素.\n    pval = peek();\n    //print_stu(pval) ;\n\n    push(&arr_stu[ARR_STU_SIZE-1]);\n\n\n    // 打印栈中的所有元素\n    while (!is_empty())\n    {\n        pval = pop();\n        print_stu(pval) ;\n    }\n\n    // 销毁栈\n    destroy_dlink_stack();\n}\n```\n\n运行结果：\n\n```\nid=40, name=dan\nid=20, name=jody\nid=10, name=sky\n```\n\n结果说明：该示例中的栈是通过双向链表实现的，并且能存储任意类型的数据。示例中是以结构体类型的数据进行演示的，由于代码中已经给出了详细的注释，这里就不再介绍了。\n\n### 栈的C++实现\n\nC++的STL中本身就包含了stack类，基本上该stack类就能满足我们的需求，所以很少需要我们自己来实现。本部分介绍2种C++实现。\n\n1. C++实现一：数组实现的栈，能存储任意类型的数据。\n\n2. C++实现二：C++的 STL 中自带的\"栈\"(stack)的示例。\n\n#### 1. C++实现一：数组实现的栈，能存储任意类型的数据\n\n实现代码\n\n栈的实现文件(ArrayStack.h)\n\n```cpp\n#ifndef ARRAY_STACK_HXX\n#define ARRAY_STACK_HXX\n\n#include <iostream>\n#include \"ArrayStack.h\"\nusing namespace std;\n\ntemplate<class T> class ArrayStack{\n    public:\n        ArrayStack();\n        ~ArrayStack();\n\n        void push(T t);\n        T peek();\n        T pop();\n        int size();\n        int isEmpty();\n    private:\n        T *arr;\n        int count;\n};\n\n// 创建“栈”，默认大小是12\ntemplate<class T>\nArrayStack<T>::ArrayStack() \n{\n    arr = new T[12];\n    if (!arr) \n    {\n        cout<<\"arr malloc error!\"<<endl;\n    }\n}\n\n// 销毁“栈”\ntemplate<class T>\nArrayStack<T>::~ArrayStack() \n{\n    if (arr) \n    {\n        delete[] arr;\n        arr = NULL;\n    }\n}\n\n// 将val添加到栈中\ntemplate<class T>\nvoid ArrayStack<T>::push(T t) \n{\n    //arr[count++] = val;\n    arr[count++] = t;\n}\n\n// 返回“栈顶元素值”\ntemplate<class T>\nT ArrayStack<T>::peek() \n{\n    return arr[count-1];\n}\n\n// 返回“栈顶元素值”，并删除“栈顶元素”\ntemplate<class T>\nT ArrayStack<T>::pop() \n{\n    int ret = arr[count-1];\n    count--;\n    return ret;\n}\n\n// 返回“栈”的大小\ntemplate<class T>\nint ArrayStack<T>::size() \n{\n    return count;\n}\n\n// 返回“栈”是否为空\ntemplate<class T>\nint ArrayStack<T>::isEmpty()\n{\n    return size()==0;\n}\n\n#endif\n```\n\n栈的测试程序(Main.cpp)\n\n```cpp\n#include <iostream>\n#include \"ArrayStack.h\"\nusing namespace std;\n\nint main() \n{\n    int tmp=0;\n    ArrayStack<int> *astack = new ArrayStack<int>();\n\n    cout<<\"main\"<<endl;\n\n    // 将10, 20, 30 依次推入栈中\n    astack->push(10);\n    astack->push(20);\n    astack->push(30);\n\n    // 将“栈顶元素”赋值给tmp，并删除“栈顶元素”\n    tmp = astack->pop();\n    cout<<\"tmp=\"<<tmp<<endl;\n\n    // 只将“栈顶”赋值给tmp，不删除该元素.\n    tmp = astack->peek();\n\n    astack->push(40);\n\n    while (!astack->isEmpty())\n    {\n        tmp = astack->pop();\n        cout<<tmp<<endl;\n    }\n\n    return 0;\n}\n```\n\n运行结果：\n\n```\nmain\ntmp=30\n40\n20\n10\n```\n\n结果说明：关于\"栈的声明和实现都在头文件中\"的原因，是因为栈的实现利用了C++模板，而\"C++编译器不能支持对模板的分离式编译\"。这在\"数据结构和算法01之 线性表\"中已经介绍过了。  程序的实现和逻辑都非常简单。需要说明的是，采用C++模板实现的；但是，默认数组的大小只有12，而且该实现不支持动态扩展。\n\n#### 2. C++实现二：C++的 STL 中自带的\"栈\"(stack)的示例\n\n实现代码(StlStack.cpp)\n\n```cpp\n#include <iostream>\n#include <stack>\nusing namespace std;\n\n/**\n * C++ 语言: STL 自带的“栈”(stack)的示例。\n *\n * @author skywang\n * @date 2013/11/07\n */\nint main ()\n{\n    int tmp=0;\n    stack<int> istack;\n\n    // 将10, 20, 30 依次推入栈中\n    istack.push(10);\n    istack.push(20);\n    istack.push(30);\n\n    // 将“栈顶元素”赋值给tmp，并删除“栈顶元素”\n    istack.pop();\n\n    // 只将“栈顶”赋值给tmp，不删除该元素.\n    tmp = istack.top();\n\n    istack.push(40);\n\n    while (!istack.empty())\n    {\n        tmp = istack.top();\n        istack.pop();\n        cout<<tmp<<endl;\n    }\n\n    return 0;\n}\n```\n\n运行结果：\n\n```\n40\n20\n10\n```\n\n### 栈的Java实现\n\n和C++一样，JDK包中也提供了\"栈\"的实现，它就是集合框架中的Stack类。关于Stack类的原理，在\"Java 集合系列07之 Stack详细介绍(源码解析)和使用示例\"中，已经详细介绍过了。本部分给出2种Java实现\n\nJava实现一：数组实现的栈，能存储任意类型的数据。\n\nJava实现二：Java的 Collection集合 中自带的\"栈\"(stack)的示例。\n\n#### 1. Java实现一：数组实现的栈，能存储任意类型的数据\n\n实现代码(GeneralArrayStack.java)\n\n```java\n/**\n * Java : 数组实现的栈，能存储任意类型的数据\n *\n * @author skywang\n * @date 2013/11/07\n */\nimport java.lang.reflect.Array;\n\npublic class GeneralArrayStack<T> {\n\n    private static final int DEFAULT_SIZE = 12;\n    private T[] mArray;\n    private int count;\n\n    public GeneralArrayStack(Class<T> type) {\n        this(type, DEFAULT_SIZE);\n    }\n\n    public GeneralArrayStack(Class<T> type, int size) {\n        // 不能直接使用mArray = new T[DEFAULT_SIZE];\n        mArray = (T[]) Array.newInstance(type, size);\n        count = 0;\n    }\n\n    // 将val添加到栈中\n    public void push(T val) {\n        mArray[count++] = val;\n    }\n\n    // 返回“栈顶元素值”\n    public T peek() {\n        return mArray[count-1];\n    }\n\n    // 返回“栈顶元素值”，并删除“栈顶元素”\n    public T pop() {\n        T ret = mArray[count-1];\n        count--;\n        return ret;\n    }\n\n    // 返回“栈”的大小\n    public int size() {\n        return count;\n    }\n\n    // 返回“栈”是否为空\n    public boolean isEmpty() {\n        return size()==0;\n    }\n\n    // 打印“栈”\n    public void PrintArrayStack() {\n        if (isEmpty()) {\n            System.out.printf(\"stack is Empty\\n\");\n        }\n\n        System.out.printf(\"stack size()=%d\\n\", size());\n\n        int i=size()-1;\n        while (i>=0) {\n            System.out.println(mArray[i]);\n            i--;\n        }\n    }\n\n    public static void main(String[] args) {\n        String tmp;\n        GeneralArrayStack<String> astack = new GeneralArrayStack<String>(String.class);\n\n        // 将10, 20, 30 依次推入栈中\n        astack.push(\"10\");\n        astack.push(\"20\");\n        astack.push(\"30\");\n\n        // 将“栈顶元素”赋值给tmp，并删除“栈顶元素”\n        tmp = astack.pop();\n        System.out.println(\"tmp=\"+tmp);\n\n        // 只将“栈顶”赋值给tmp，不删除该元素.\n        tmp = astack.peek();\n        System.out.println(\"tmp=\"+tmp);\n\n        astack.push(\"40\");\n        astack.PrintArrayStack();    // 打印栈\n    }\n}\n```\n\n运行结果：\n\n```\ntmp=30\ntmp=20\nstack size()=3\n40\n20\n10\n```\n\n结果说明：GeneralArrayStack是通过数组实现的栈，而且GeneralArrayStack中使用到了泛型。\n\n#### 2. Java实现二：Java的 Collection集合 中自带的\"栈\"(stack)的示例\n\n实现代码(StackTest.java)\n\n```java\nimport java.util.Stack;\n\n/**\n * Java : java集合包中的Stack的演示程序\n *\n * @author skywang\n * @date 2013/11/07\n */\npublic class StackTest {\n\n    public static void main(String[] args) {\n        int tmp=0;\n        Stack<Integer> astack = new Stack<Integer>();\n\n        // 将10, 20, 30 依次推入栈中\n        astack.push(10);\n        astack.push(20);\n        astack.push(30);\n\n        // 将“栈顶元素”赋值给tmp，并删除“栈顶元素”\n        tmp = astack.pop();\n        //System.out.printf(\"tmp=%d\\n\", tmp);\n\n        // 只将“栈顶”赋值给tmp，不删除该元素.\n        tmp = (int)astack.peek();\n        //System.out.printf(\"tmp=%d\\n\", tmp);\n\n        astack.push(40);\n        while(!astack.empty()) {\n            tmp = (int)astack.pop();\n            System.out.printf(\"tmp=%d\\n\", tmp);\n        }\n    }\n}\n```\n\n运行结果：\n\n```\ntmp=40\ntmp=20\ntmp=10\n```\n\n---\n\n* 原文链接：[栈的图文解析 和 对应3种语言的实现(C/C++/Java)](http://www.cnblogs.com/skywang12345/p/3562239.html)\n","tags":["Stack"],"categories":["Algorithm"]},{"title":"Hadoop安全实践","url":"%2F2014%2F2014-03-24-hadoop-security-practice%2F","content":"\n### 前言\n\n在2014年初，我们将线上使用的 Hadoop 1.0 集群切换到 [Hadoop 2.2.0 稳定版](http://hadoop.apache.org/releases.html#15+October%2C+2013%3A+Release+2.2.0+available)， 与此同时部署了 Hadoop 的安全认证。本文主要介绍在 Hadoop 2.2.0 上部署安全认证的方案调研实施以及相应的解决方法。\n\n### 背景\n\n#### 集群安全措施相对薄弱\n\n最早部署Hadoop集群时并没有考虑安全问题，随着集群的不断扩大， 各部门对集群的使用需求增加，集群安全问题就显得颇为重要。说到安全问题，一般包括如下方面:\n\n* 用户认证(Authentication)\n\n   即是对用户身份进行核对， 确认用户即是其声明的身份， 这里包括用户和服务的认证。\n\n* 用户授权(Authorization)\n\n   即是权限控制，对特定资源， 特定访问用户进行授权或拒绝访问。用户授权是建立再用户认证的基础上， 没有可靠的用户认证谈不上用户授权。\n\n未开启安全认证时，Hadoop 是以客户端提供的用户名作为用户凭证， 一般即是发起任务的Unix 用户。一般线上机器部署服务会采用统一账号，当以统一账号部署集群时，所有执行 Hadoop 任务的用户都是集群的超级管理员，容易发生误操作。即便是以管理员账号部署集群，恶意用户在客户端仍然可以冒充管理员账号执行。\n\n#### 集群整体升级到 hadoop 2.0\n\n2013年10月份 Hadoop 2.2.0 发布，作为 Apache Hadoop 2.X 的 GA 版本。我们考虑将集群整体升级 Hadoop 2.2.0，进入 yarn 时代。与此同时，我们计划在升级过程中一并把集群安全工作做到位，主要基于以下考虑:\n\n* 与升级工作一样，安全同样是基础工作，把安全搞好会方便我们后续的工作，否则会成为下一个阻碍。\n\n* 所谓基础工作，就是越往后改动越难的工作，目前不做，将来依赖更多，开展代价更大。\n\n综上，我们的需求是在低版本hadoop升级到Yarn的过程中部署Hadoop安全认证，做好认证之后我们可以在此之上开启适当的权限控制(hdfs， 队列)。\n\n### 方案调研\n\n在方案调研之前先明确以下安全实践的原则，如下:\n\n* 做为一个后端服务平台，部署安全的主要目的是防止用户误操作导致的事故(比如误删数据，误操作等)\n\n* 做安全是为了开放，开放的前提是保证基本的安全，数据安全与平台安全\n\n* 在保证安全的前提下，尽量简化运维\n\n分析我们遇到的问题，这里我们需要调研:\n\n* 账号拆分与相应管理方案\n\n* 开启 Hadoop 安全认证\n\n* 客户端针对安全认证的相应调整\n\n#### 账号拆分与相应管理方案\n\n##### 集群账号管理\n\n原先我们使用单一账号作为集群管理员，且这一账号为线上统一登录账号， 这存在极大的安全隐患。我们需要使用特殊账号来管理集群。这里涉及的问题是，我们需要几个运维账号呢?\n\n一种简单的做法是使用一个特殊运维账号(比如 hadoop)， [CDH](https://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/latest/CDH4-Security-Guide/cdh4sg_topic_3_2.html) 和 [Apache官方](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html) 都推荐按服务划分分账号来启动集群:\n\n| User:Group | Daemons |\n| ---------- | ------- |\n| hdfs:hadoop | NameNode， Secondary NameNode， Checkpoint Node， Backup Node， DataNode |\n| yarn:hadoop | ResourceManager， NodeManager |\n| mapred:hadoop | MapReduce JobHistory Server |\n\n考虑到精细化控制可以有效避免误操作，这里我们遵循官方的建议使用多账号。\n\n在从单一运维账号迁移到多个账号部署时，需要考虑相关文件权限问题，包括本地以及hdfs两部分，这可以在安全部署上线时完成相应改动。\n\n##### 用户账号管理\n\n美团很多小组都有使用 Hadoop 来进行大数据处理需求， 故需要一定程度的 [多租户环境](http://en.wikipedia.org/wiki/Multitenancy)， 这里主要考虑其中的数据和操作的权限问题。hdfs 本身仅提供类 Unix 的权限系统， 默认的组概念也相对鸡肋。鉴于此，在多用户的管理上可以有简单粗暴的方案:\n\n> 不同组有各自的根目录，使用不同的账号，对组内文件有全部权限。不同组之间相互不能访问数据(除非手动修改)。\n\n在一个集中的数据仓库环境下，又要生产各个部门的统计数据的话，上述策略不够灵活。目前Cloudera 有一个精细化权限控制的解决方案 [Sentry](http://www.ibm.com/developerworks/security/library/se-hadoop/index.html)， 支持 Role based 的权限管理。由于其定制化较高，不方便使用， 故暂未考虑。\n\n#### 开启 Hadoop 安全认证\n\nHadoop 的安全认证是基于 [Kerberos](http://web.mit.edu/kerberos/) 实现的。 Kerberos 是一个网络身份验证协议，用户只需输入身份验证信息，验证通过获取票据即可访问多个接入 Kerberos 的服务， 机器的单点登录也可以基于此协议完成的。 Hadoop 本身并不创建用户账号，而是使用 Kerberos 协议来进行用户身份验证，从Kerberos凭证中的用户信息获取用户账号， 这样一来跟实际用户运行的账号也无关。\n\n这里我们从 YARN 上的 MR 任务提交过程简单说明一下:\n\n![](/assets/images/2014/03/24/hadoop-security-practice/yarn-mr.png)\n\n* 用户执行任务前，先通过KDC认证自己，获取TGT(Ticket Granting Ticket)。KDC是 Kerberos 认证的中心服务，存储用户和服务的认证信息。\n\n* 用户通过 TGT 向 KDC 请求访问服务的Ticket， KDC 生成 session key 后一并发给客户端。\n\n* 客户端通过 service ticket 向服务认证自己，完成身份认证。\n\n* 完成身份认证后客户端向服务请求若干token供后续任务执行认证使用(比如 HDFS NameNode Delegation Token, YARN ResourceManager Delegation Token)\n\n* 客户端连同获取到的 token 一并提交任务，后续任务执行使用 token 进行来自服务的认证\n\n从上可以看出，出于性能的考虑，Hadoop 安全认证体系中仅在用户跟服务通信以及各个服务之间通信适用 Kerberos 认证，在用户认证后任务执行，访问服务，读取/写入数据等均采用 [特定服务(NameNode， Resource Manager)发起访问token，让需求方凭借 token 访问相应服务和数据](http://hortonworks.com/blog/the-role-of-delegation-tokens-in-apache-hadoop-security/)。这里 token 的传递，认证以及更新不做深入讨论。\n\n关于开启 Hadoop 安全认证， [Cloudera](https://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/latest/CDH4-Security-Guide/cdh4sg_topic_3.html) 有详细的文档介绍。由于自身环境以及部署运维的考虑，最终的部署方案有些许出入， 一一说明。\n\n##### Kerberos 部署\n\nHadoop 安全认证需要一个 Kerberos 集群， [部署 Kerberos](http://techpubs.spinlocksolutions.com/dklar/kerberos.html) 需要部署KDC。 由于我们的环境中使用 [freeIPA](http://www.freeipa.org/page/About) 进行主机认证相关的权限控制，已经集成 Kerberos 服务， 故不需要另外部署。\n\nKerberos 相关的运维操作， 比如添加用户，服务，导出keytab，均可以通过 ipa 相关接口来进行。\n\n##### Container 的选择\n\n从上图可以看出用户发起的任务是在特定的容器(Container)内执行的， 一开始我们考虑使用DefaultContainer 而不是官方推荐的 LinuxContainer， 缺点是对任务之间的物理隔离以及防范恶意任务方面会有缺陷， 不过方便部署，使用LinuxContainer需要在集群各台机器上部署用户账号。\n\n实际测试发现由于[MAPREDUCE-5208](https://issues.apache.org/jira/browse/MAPREDUCE-5208)的引入，在 hadoop 2.2.0 上开启安全认证后[无法使用 DefaultContainer](https://issues.apache.org/jira/browse/YARN-1432)。\n\n这里不希望对代码有过多定制化的修改，我们考虑还是使用 LinuxContainer， 需要解决一下问题:\n\n* 用户账号创建\n\n   我们需要在集群内添加所有可能的任务发起用户账号。借助 freeipa 的统一的用户管理 ， 我们只需要在 freeipa 上添加相应用户即可。\n\n* container-executor 和 container-executor.cfg 的部署\n\n   [container-executor](https://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/latest/CDH4-Security-Guide/cdh4sg_topic_18.html?scroll=topic_18_unique_2) 作为Yarn 的 container 执行程序，有一系列的权限要求:\n\n   > Be owned by root\n   > Be owned by a group that contains only the user running the YARN daemons\n   > Be setuid\n   > Be group readable and executable\n\n配置 container-executor.cfg 不仅需要是owned by root，且其所在目录同样需要 owned by root。这两者都给自动化部署带来不便，鉴于此部分比较独立且基本不会改变，我们可以将其加入集群机器的 puppet 管理当中。\n\n##### DataNode 启动方式\n\nCDH 推荐的datanode 的启动方式需要使用低端口并且使用jsvc发布， 在运维方面也不太方便。这里我们通过配置ignore.secure.ports.for.testing=true来启动datanode， 规避这些约束。\n\n#### 客户端针对安全认证的相应调整\n\n集群开启安全认证之后， 依赖集群的客户端(脚本， 服务)都需要做相应修改，不过改动基本无异。大部分服务都已包括对 Kerberos 认证的相应处理， 基本不需要修改。\n\n这里首先得说明一下开启安全认证后的认证方式:\n\n* 使用密码认证\n\n   使用用户密码通过kinit认证， 获取到的TGT存在本地凭证缓存当中， 供后续访问服务认证使用。一般在交互式访问中使用。\n\n* 使用 [keytab](http://kb.iu.edu/data/aumh.html**) 认证\n\n   用户通过导出的keytab 可以免密码进行用户认证， 后续步骤一致。一般在应用程序中配置使用。\n\nKerberos 凭证(ticket) 有两个属性， ticket_lifetime 和 renew_lifetime。其中 ticket_lifetime 表明凭证生效的时限，一般为24小时。在凭证失效前部分凭证可以延期失效时间(即Renewable)， renew_lifetime 表明凭证最长可以被延期的时限，一般为一个礼拜。当凭证过期之后，对安全认证的服务的后续访问则会失败。这里第一个问题就是如何处理凭证过期。\n\n##### 凭证过期处理策略\n\n在最早的 [Security features for Hadoop](https://issues.apache.org/jira/browse/HADOOP-4487) 设计中提出这样的假设:\n\n> A Hadoop job will run no longer than 7 days (configurable) on a MapReduce cluster or accessing HDFS from the job will fail.\n\n对于一般的任务， 24小时甚至延迟到一周的凭证时限是足够充分的。所以大部分时间我们只需要在执行操作之前使用 kinit 认证一遍，再起后台任务进行周期性凭证更新即可。\n\n```\nwhile true ; do kinit -R; sleep $((3600 * 6)) ; done &\n```\n\n不过对于需要常驻的访问Hadoop集群的服务来说，上述假设就不成立了。这时候我们可以\n\n* 扩大 ticket_lifetime 和 renew_lifetime 时限\n\n   扩大凭证存活时限可以解决此问题，但由于Kerberos跟我们线上用户登陆认证绑定，会带来安全隐患，故不方便修改。\n\n* 定期重新进行kinit 认证更新凭证。\n\n   不仅仅是定期延长认证时间，可以直接定期重新认证以延长凭证有限期限。一般我们需要导出 keytab 来进行定期认证的操作。\n\nHadoop 将 Kerberos 认证部分进行了一定的封装，实际上并不需要那么复杂， 这里重点可以看看 UserGroupInformation 这个类。\n\n##### UserGroupInformation\n\nUserGroupInformation 这个类在 [JAAS](http://docs.oracle.com/javase/6/docs/technotes/guides/security/jaas/JAASRefGuide.html#Core) 框架上封装了 Hadoop 的用户信息， 更确切地说是对 Subject 做了一层封装。\n\n```java\n  UserGroupInformation(Subject subject) {\n    this.subject = subject;\n    this.user = subject.getPrincipals(User.class).iterator().next();\n    this.isKeytab = !subject.getPrivateCredentials(KerberosKey.class).isEmpty();\n    this.isKrbTkt = !subject.getPrivateCredentials(KerberosTicket.class).isEmpty();\n  }\n```\n\nJAAS 是 Java 认证和授权服务（Java Authentication and Authorization Service）的缩写， 主要包含以下几个实体:\n\n* Subject\n\n   Subject 是一个不可继承的实体类，它标志一个请求的来源， 包含相关的凭证标识(Principal) 和 公开和私有的凭据(Credential)。\n\n* Principal\n\n   凭证标识，认证成功后，一个 Subject 可以被关联多个Principal。\n\n* Credential\n\n   凭据，有公有凭据以及私有凭据。\n\nJAAS的认证过程如下:\n\n> An application instantiates a LoginContext.\n> The LoginContext consults a Configuration to load all of the LoginModules configured for that application.\n> The application invokes the LoginContext's login method.\n> The login method invokes all of the loaded LoginModules. Each LoginModule attempts to authenticate the subject. Upon success， LoginModules associate relevant Principals and credentials with a Subject object that represents the subject being authenticated.\n> The LoginContext returns the authentication status to the application.\n> If authentication succeeded， the application retrieves the Subject from the LoginContext.\n\n需要认证的代码片段可以包装在 [doPrivileged](http://docs.oracle.com/javase/6/docs/technotes/guides/security/doprivileged.html) 当中， 可以直接使用 Subject.doAs 方法，支持嵌套。\n\n在安全模式下，UGI 支持不同LoginContext 配置， 均是通过 HadoopConfiguration 类动态产生:\n\n* hadoop-user-kerberos\n\n   使用kerberos缓存凭证登陆的配置， useTicketCache 置为 true.\n\n* hadoop-keytab-kerberos\n\n   使用keytab登陆的配置， useKeyTab 置为 true.\n\nUGI 当中有多处认证， getLoginUser 方法使用 hadoop-user-kerberos 配置认证:\n\n* 通过配置生成 LoginContext\n\n* 调用 LoginContext.login 方法完成登陆， 通过 ticket cache 中凭证完成登陆\n\n* [判断是否需要其他用户身份(proxy user)执行](https://issues.apache.org/jira/browse/HADOOP-8561)\n\n* 将 HADOOP_TOKEN_FILE_LOCATION 中的 token 加入 Credentials 集合当中\n\n* 另起一个线程做周期性的凭证更新 spawnAutoRenewalThreadForUserCreds\n\n步骤5可以看出当我们存在凭证后并不需要主动做周期性地凭证更新。\n\n而 loginUserFromKeytab 方法使用 hadoop-kerberos 配置认证:\n\n* 通过配置生成 LoginContext\n\n* 调用 LoginContext.login 方法完成登陆， 使用keytab完成登陆\n\nloginUserFromKeytab 没有对凭证做周期的更新， 那怎么保证凭证不会过期呢?\n\n* 在访问集群执行相关操作前， 可以调用 checkTGTAndReloginFromKeytab 来尝试更新凭证(实际上是重新登陆了)\n\n* 在凭证过期时，创建 IPC 失败会触发调用 reloginFromKeytab 来重新登陆\n\nClient.java\n\n```java\n    private synchronized void handleSaslConnectionFailure(\n        final int currRetries， final int maxRetries， final Exception ex，\n        final Random rand， final UserGroupInformation ugi) throws IOException，\n        InterruptedException {\n      ugi.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws IOException， InterruptedException {\n          final short MAX_BACKOFF = 5000;\n          closeConnection();\n          disposeSasl();\n          if (shouldAuthenticateOverKrb()) {\n            if (currRetries < maxRetries) {\n              if(LOG.isDebugEnabled()) {\n                LOG.debug(\"Exception encountered while connecting to \"\n                    + \"the server : \" + ex);\n              }\n              // try re-login\n              if (UserGroupInformation.isLoginKeytabBased()) {\n                UserGroupInformation.getLoginUser().reloginFromKeytab();\n              } else {\n                UserGroupInformation.getLoginUser().reloginFromTicketCache();\n              }\n```\n\n可见如果是使用 keytab 认证的话，认证是长期有效的。\n\n从上述代码中可以看到，不论是否是keytab认证，创建IPC失败均会尝试重新登陆。\n\n##### 基于keytab 的Kerberos认证方式\n\n为了让用户免于记忆密码，我们可以考虑导出并交付keytab给相关用户(前提是用户数量可控， 比如是以虚拟用户为单位)。\n\n这样，用户的Hadoop任务认证方式可以有:\n\n* 直接使用 keytab kinit 之后访问\n\n* 或者调用 loginUserFromKeytab 完成登录，然后将代码片段包裹在 UGI 的 doAs 方法当中执行\n\n### 上线部署\n\n确定了部署方案之后， 我们在升级 hadoop 版本的同时完成了安全认证的部署。在部署和使用中我们遇到若干问题，这里一一说明。\n\n#### JCE 部署\n\n开启安全认证时发现 Kerberos 认证不通过:\n\n> Client failed to SASL authenticate: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Checksum failed)]\n\n由于我们部署的Kerberos默认使用 AES-256 加密， 需要在Hadoop环境(集群以及客户端)上安装 [Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy File](http://www.oracle.com/technetwork/java/javase/downloads/index.html)， 否则Kerberos认证不通过。可以通过此 [gist](https://gist.github.com/jehrhardt/5167854) 验证改动是否生效。此步骤可以添加到puppet当中。\n\n#### SNN getimage 返回 NPE\n\n开启安全认证发现 SNN 持续由于 getimage 报错NPE 退出， 相关错误如下。\n\n```bash\n2013-12-29 23:56:19，572 DEBUG org.apache.hadoop.security.authentication.server.AuthenticationFilter: Request [http://XXX.com:50070/getimage?getimage=1&txid=8627&storageInfo=-47:200271\n8265:0:CID-3dce02cb-a1c2-4ab8-8b12-f23bbefd7bcc] triggering authentication\n2013-12-29 23:56:19，580 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Authentication exception: GSSException: Failure unspecified at GSS-API level (Mechanism level: Specified\n version of key is not available (44))\norg.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: Failure unspecified at GSS-API level (Mechanism level: Specified version of key is not available (44))\n        at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.authenticate(KerberosAuthenticationHandler.java:360)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:349)\n```\n\n根据报错信息 Specified version of key is not available 发现是由于同一个 HTTP 凭证被导出多遍导致之前的keytab中的凭证失效了，重新生成部署所需的 keytab 即可。\n\n这里的提醒就是不要重复导出相同的凭证， 以防止已经分发使用的keytab中的凭证失效。\n\n#### Balancer 执行过长导致认证过期\n\n在部署安全认证之后， 我们对hdfs数据进行 balance 就需要预先认证一下再执行， 这样就会遇到我们之前说的认证期限的问题。\n\n这里有两种方式可以解决此问题:\n\n* 添加外部定时任务重新认证， 刷新凭证缓存， 延迟凭证有效期限。\n\n* 可以写一个小代码对 balance 的入口 org.apache.hadoop.hdfs.server.balancer.Balancer 进行一点封装，将其封装在一个 doAs 当中， 类似 [hue 中的 SudoFsShell 一样的思路](http://grepcode.com/file/repository.cloudera.com/content/repositories/releases/com.cloudera.hue/sudo-shell/1.2.0-cdh3u0/com/cloudera/hue/SudoFsShell.java?av=f)\n\n#### sssd 服务认证异常\n\n[sssd](https://issues.apache.org/jira/browse/HADOOP-10041) 是指我们用于线上登陆认证的一个底层服务，在过去一段时间内经常出现问题退出，导致用户登录动作hang住，进而导致相关任务执行失败。部署Hadoop安全认证之后相关 kerberos 认证也走这个服务，增大了服务异常退出的概率。目前看起来sssd服务问题是由于系统版本过低sssd服务代码有bug导致，解决方案最方便的是升级系统或切换服务到新的机器。\n\n\n#### \"KDC can't fulfill requested option while renewing credentials\"\n\n应用执行日志偶尔会报如下错误:\n\n```bash\n2014-03-12 21:30:03，593 WARN  security.UserGroupInformation (UserGroupInformation.java:run(794)) - Exception encountered while running the renewal command. Aborting renew thread. org.apache.hadoop.util.Shell$ExitCodeException: kinit(v5): KDC can't fulfill requested option while renewing credentials\n```\n\n表示 UGI的凭证更新线程失败退出了。目前[HADOOP-10041](https://issues.apache.org/jira/browse/HADOOP-10041) 记录了此问题，主要原因是由于凭证无法更新导致， 一般不需要特殊处理。\n\n### 参考资料\n\n* Hadoop， Hbase， Zookeeper安全实践\n\n* YARN & HDFS2 安装和配置Kerberos\n\n* CDH4 Security Guide\n\n* Kerberos ， the network authentication protocol\n\n* Kerberos Overview\n\n* Hadoop Kerberos安全机制介绍\n\n* Security Hadoop is here\n\n* Hadoop Security Analysis\n\n* The Role of Delegation Tokens in Apache Hadoop Security\n\n---\n\n* 原文链接：[Hadoop安全实践](http://tech.meituan.com/hadoop-security-practice.html)\n","tags":["Security"],"categories":["Hadoop"]},{"title":"数组、单链表和双链表介绍 以及 双向链表的C/C++/Java实现","url":"%2F2014%2F2014-03-24-array-linked-list-and-implementation%2F","content":" \n## 概要\n\n线性表是一种线性结构，它是具有相同类型的n(n≥0)个数据元素组成的有限序列。本章先介绍线性表的几个基本组成部分：数组、单向链表、双向链表；随后给出双向链表的C、C++和Java三种语言的实现。内容包括：\n\n* 数组\n* 单向链表\n* 双向链表\n  1. C实现双链表\n  2. C++实现双链表\n  3. Java实现双链表\n\n## 数组\n\n数组有上界和下界，数组的元素在上下界内是连续的。\n\n存储10,20,30,40,50的数组的示意图如下：\n\n![](/assets/images/2014/03/24/array-linked-list-and-implementation/001.jpg)\n\n数组的特点是：数据是连续的；随机访问速度快。\n\n数组中稍微复杂一点的是多维数组和动态数组。对于C语言而言，多维数组本质上也是通过一维数组实现的。至于动态数组，是指数组的容量能动态增长的数组；对于C语言而言，若要提供动态数组，需要手动实现；而对于C++而言，STL提供了Vector；对于Java而言，Collection集合中提供了ArrayList和Vector。\n\n## 单向链表\n\n单向链表(单链表)是链表的一种，它由节点组成，每个节点都包含下一个节点的指针。\n\n单链表的示意图如下：\n\n![](/assets/images/2014/03/24/array-linked-list-and-implementation/002.jpg)\n\n表头为空，表头的后继节点是\"节点10\"(数据为10的节点)，\"节点10\"的后继节点是\"节点20\"(数据为10的节点)，...\n\n### 单链表删除节点\n\n![](/assets/images/2014/03/24/array-linked-list-and-implementation/003.jpg)\n\n删除\"节点30\"\n\n删除之前：\"节点20\" 的后继节点为\"节点30\"，而\"节点30\" 的后继节点为\"节点40\"。\n\n删除之后：\"节点20\" 的后继节点为\"节点40\"。\n\n### 单链表添加节点\n\n![](/assets/images/2014/03/24/array-linked-list-and-implementation/004.jpg)\n\n在\"节点10\"与\"节点20\"之间添加\"节点15\"\n\n添加之前：\"节点10\" 的后继节点为\"节点20\"。\n\n添加之后：\"节点10\" 的后继节点为\"节点15\"，而\"节点15\" 的后继节点为\"节点20\"。\n\n单链表的特点是：节点的链接方向是单向的；相对于数组来说，单链表的的随机访问速度较慢，但是单链表删除/添加数据的效率很高。\n\n## 双向链表\n\n双向链表(双链表)是链表的一种。和单链表一样，双链表也是由节点组成，它的每个数据结点中都有两个指针，分别指向直接后继和直接前驱。所以，从双向链表中的任意一个结点开始，都可以很方便地访问它的前驱结点和后继结点。一般我们都构造双向循环链表。\n\n双链表的示意图如下：\n\n![](/assets/images/2014/03/24/array-linked-list-and-implementation/005.jpg)\n\n表头为空，表头的后继节点为\"节点10\"(数据为10的节点)；\"节点10\"的后继节点是\"节点20\"(数据为10的节点)，\"节点20\"的前继节点是\"节点10\"；\"节点20\"的后继节点是\"节点30\"，\"节点30\"的前继节点是\"节点20\"；...；末尾节点的后继节点是表头。\n\n### 双链表删除节点\n\n![](/assets/images/2014/03/24/array-linked-list-and-implementation/006.jpg)\n\n删除\"节点30\"\n\n删除之前：\"节点20\"的后继节点为\"节点30\"，\"节点30\" 的前继节点为\"节点20\"。\"节点30\"的后继节点为\"节点40\"，\"节点40\" 的前继节点为\"节点30\"。\n\n删除之后：\"节点20\"的后继节点为\"节点40\"，\"节点40\" 的前继节点为\"节点20\"。\n\n### 双链表添加节点\n\n![](/assets/images/2014/03/24/array-linked-list-and-implementation/007.jpg)\n\n在\"节点10\"与\"节点20\"之间添加\"节点15\"\n\n添加之前：\"节点10\"的后继节点为\"节点20\"，\"节点20\" 的前继节点为\"节点10\"。\n\n添加之后：\"节点10\"的后继节点为\"节点15\"，\"节点15\" 的前继节点为\"节点10\"。\"节点15\"的后继节点为\"节点20\"，\"节点20\" 的前继节点为\"节点15\"。\n\n## 实现\n\n下面介绍双链表的实现，分别介绍C/C++/Java三种实现。\n\n### 1. C实现双链表\n\n实现代码\n\n双向链表头文件(double_link.h)\n\n```c\n#ifndef _DOUBLE_LINK_H\n#define _DOUBLE_LINK_H\n\n// 新建“双向链表”。成功，返回表头；否则，返回NULL\nextern int create_dlink();\n// 撤销“双向链表”。成功，返回0；否则，返回-1\nextern int destroy_dlink();\n\n// “双向链表是否为空”。为空的话返回1；否则，返回0。\nextern int dlink_is_empty();\n// 返回“双向链表的大小”\nextern int dlink_size();\n\n// 获取“双向链表中第index位置的元素”。成功，返回节点指针；否则，返回NULL。\nextern void* dlink_get(int index);\n// 获取“双向链表中第1个元素”。成功，返回节点指针；否则，返回NULL。\nextern void* dlink_get_first();\n// 获取“双向链表中最后1个元素”。成功，返回节点指针；否则，返回NULL。\nextern void* dlink_get_last();\n\n// 将“value”插入到index位置。成功，返回0；否则，返回-1。\nextern int dlink_insert(int index, void *pval);\n// 将“value”插入到表头位置。成功，返回0；否则，返回-1。\nextern int dlink_insert_first(void *pval);\n// 将“value”插入到末尾位置。成功，返回0；否则，返回-1。\nextern int dlink_append_last(void *pval);\n\n// 删除“双向链表中index位置的节点”。成功，返回0；否则，返回-1\nextern int dlink_delete(int index);\n// 删除第一个节点。成功，返回0；否则，返回-1\nextern int dlink_delete_first();\n// 删除组后一个节点。成功，返回0；否则，返回-1\nextern int dlink_delete_last();\n\n#endif\n```\n\n双向链表实现文件(double_link.c)\n\n```c\n#include <stdio.h>\n#include <malloc.h>\n\n/**\n * C 语言实现的双向链表，能存储任意数据。\n *\n * @author skywang\n * @date 2013/11/07\n */\n// 双向链表节点\ntypedef struct tag_node \n{\n    struct tag_node *prev;\n    struct tag_node *next;\n    void* p;\n}node;\n\n// 表头。注意，表头不存放元素值！！！\nstatic node *phead=NULL;\n// 节点个数。\nstatic int  count=0;\n\n// 新建“节点”。成功，返回节点指针；否则，返回NULL。\nstatic node* create_node(void *pval)\n{\n    node *pnode=NULL;\n    pnode = (node *)malloc(sizeof(node));\n    if (!pnode)\n    {\n        printf(\"create node error!\\n\");\n        return NULL;\n    }\n    // 默认的，pnode的前一节点和后一节点都指向它自身\n    pnode->prev = pnode->next = pnode;\n    // 节点的值为pval\n    pnode->p = pval;\n\n    return pnode;\n}\n\n// 新建“双向链表”。成功，返回0；否则，返回-1。\nint create_dlink()\n{\n    // 创建表头\n    phead = create_node(NULL);\n    if (!phead)\n        return -1;\n\n    // 设置“节点个数”为0\n    count = 0;\n\n    return 0;\n}\n\n// “双向链表是否为空”\nint dlink_is_empty()\n{\n    return count == 0;\n}\n\n// 返回“双向链表的大小”\nint dlink_size() {\n    return count;\n}\n\n// 获取“双向链表中第index位置的节点”\nstatic node* get_node(int index) \n{\n    if (index<0 || index>=count)\n    {\n        printf(\"%s failed! index out of bound!\\n\", __func__);\n        return NULL;\n    }\n\n    // 正向查找\n    if (index <= (count/2))\n    {\n        int i=0;\n        node *pnode=phead->next;\n        while ((i++) < index) \n            pnode = pnode->next;\n\n        return pnode;\n    }\n\n    // 反向查找\n    int j=0;\n    int rindex = count - index - 1;\n    node *rnode=phead->prev;\n    while ((j++) < rindex) \n        rnode = rnode->prev;\n\n    return rnode;\n}\n\n// 获取“第一个节点”\nstatic node* get_first_node() \n{\n    return get_node(0);\n}\n\n// 获取“最后一个节点”\nstatic node* get_last_node() \n{\n    return get_node(count-1);\n}\n\n// 获取“双向链表中第index位置的元素”。成功，返回节点值；否则，返回-1。\nvoid* dlink_get(int index)\n{\n    node *pindex=get_node(index);\n    if (!pindex) \n    {\n        printf(\"%s failed!\\n\", __func__);\n        return NULL;\n    }\n\n    return pindex->p;\n\n}\n\n// 获取“双向链表中第1个元素的值”\nvoid* dlink_get_first()\n{\n    return dlink_get(0);\n}\n\n// 获取“双向链表中最后1个元素的值”\nvoid* dlink_get_last()\n{\n    return dlink_get(count-1);\n}\n\n// 将“pval”插入到index位置。成功，返回0；否则，返回-1。\nint dlink_insert(int index, void* pval) \n{\n    // 插入表头\n    if (index==0)\n        return dlink_insert_first(pval);\n\n    // 获取要插入的位置对应的节点\n    node *pindex=get_node(index);\n    if (!pindex) \n        return -1;\n\n    // 创建“节点”\n    node *pnode=create_node(pval);\n    if (!pnode)\n        return -1;\n\n    pnode->prev = pindex->prev;\n    pnode->next = pindex;\n    pindex->prev->next = pnode;\n    pindex->prev = pnode;\n    // 节点个数+1\n    count++;\n\n    return 0;\n}\n\n// 将“pval”插入到表头位置\nint dlink_insert_first(void *pval) \n{\n    node *pnode=create_node(pval);\n    if (!pnode)\n        return -1;\n\n    pnode->prev = phead;\n    pnode->next = phead->next;\n    phead->next->prev = pnode;\n    phead->next = pnode;\n    count++;\n    return 0;\n}\n\n// 将“pval”插入到末尾位置\nint dlink_append_last(void *pval) \n{\n    node *pnode=create_node(pval);\n    if (!pnode)\n        return -1;\n    \n    pnode->next = phead;\n    pnode->prev = phead->prev;\n    phead->prev->next = pnode;\n    phead->prev = pnode;\n    count++;\n    return 0;\n}\n\n// 删除“双向链表中index位置的节点”。成功，返回0；否则，返回-1。\nint dlink_delete(int index)\n{\n    node *pindex=get_node(index);\n    if (!pindex) \n    {\n        printf(\"%s failed! the index in out of bound!\\n\", __func__);\n        return -1;\n    }\n\n    pindex->next->prev = pindex->prev;\n    pindex->prev->next = pindex->next;\n    free(pindex);\n    count--;\n\n    return 0;\n}    \n\n// 删除第一个节点\nint dlink_delete_first() \n{\n    return dlink_delete(0);\n}\n\n// 删除组后一个节点\nint dlink_delete_last() \n{\n    return dlink_delete(count-1);\n}\n\n// 撤销“双向链表”。成功，返回0；否则，返回-1。\nint destroy_dlink()\n{\n    if (!phead)\n    {\n        printf(\"%s failed! dlink is null!\\n\", __func__);\n        return -1;\n    }\n\n    node *pnode=phead->next;\n    node *ptmp=NULL;\n    while(pnode != phead)\n    {\n        ptmp = pnode;\n        pnode = pnode->next;\n        free(ptmp);\n    }\n\n    free(phead);\n    phead = NULL;\n    count = 0;\n\n    return 0;\n}\n```\n\n双向链表测试程序(dlink_test.c)\n\n```c\n#include <stdio.h>\n#include \"double_link.h\"\n\n/**\n * C 语言实现的双向链表的测试程序。\n *\n * (01) int_test()\n *      演示向双向链表操作“int数据”。\n * (02) string_test()\n *      演示向双向链表操作“字符串数据”。\n * (03) object_test()\n *      演示向双向链表操作“对象”。\n *\n * @author skywang\n * @date 2013/11/07\n */\n\n// 双向链表操作int数据\nvoid int_test()\n{\n    int iarr[4] = {10, 20, 30, 40};\n\n    printf(\"\\n----%s----\\n\", __func__);\n    create_dlink();        // 创建双向链表\n\n    dlink_insert(0, &iarr[0]);    // 向双向链表的表头插入数据\n    dlink_insert(0, &iarr[1]);    // 向双向链表的表头插入数据\n    dlink_insert(0, &iarr[2]);    // 向双向链表的表头插入数据\n\n    printf(\"dlink_is_empty()=%d\\n\", dlink_is_empty());    // 双向链表是否为空\n    printf(\"dlink_size()=%d\\n\", dlink_size());            // 双向链表的大小\n\n    // 打印双向链表中的全部数据\n    int i;\n    int *p;\n    int sz = dlink_size();\n    for (i=0; i<sz; i++)\n    {\n        p = (int *)dlink_get(i);\n        printf(\"dlink_get(%d)=%d\\n\", i, *p);\n    }\n\n    destroy_dlink();\n}\n\nvoid string_test()\n{\n    char* sarr[4] = {\"ten\", \"twenty\", \"thirty\", \"forty\"};\n\n    printf(\"\\n----%s----\\n\", __func__);\n    create_dlink();        // 创建双向链表\n\n    dlink_insert(0, sarr[0]);    // 向双向链表的表头插入数据\n    dlink_insert(0, sarr[1]);    // 向双向链表的表头插入数据\n    dlink_insert(0, sarr[2]);    // 向双向链表的表头插入数据\n\n    printf(\"dlink_is_empty()=%d\\n\", dlink_is_empty());    // 双向链表是否为空\n    printf(\"dlink_size()=%d\\n\", dlink_size());            // 双向链表的大小\n\n    // 打印双向链表中的全部数据\n    int i;\n    char *p;\n    int sz = dlink_size();\n    for (i=0; i<sz; i++)\n    {\n        p = (char *)dlink_get(i);\n        printf(\"dlink_get(%d)=%s\\n\", i, p);\n    }\n\n    destroy_dlink();\n}\n\ntypedef struct tag_stu\n{\n    int id;\n    char name[20];\n}stu;\n\nstatic stu arr_stu[] = \n{\n    {10, \"sky\"},\n    {20, \"jody\"},\n    {30, \"vic\"},\n    {40, \"dan\"},\n};\n#define ARR_STU_SIZE ( (sizeof(arr_stu)) / (sizeof(arr_stu[0])) )\n\nvoid object_test()\n{\n    printf(\"\\n----%s----\\n\", __func__);\n    create_dlink();    // 创建双向链表\n\n    dlink_insert(0, &arr_stu[0]);    // 向双向链表的表头插入数据\n    dlink_insert(0, &arr_stu[1]);    // 向双向链表的表头插入数据\n    dlink_insert(0, &arr_stu[2]);    // 向双向链表的表头插入数据\n\n    printf(\"dlink_is_empty()=%d\\n\", dlink_is_empty());    // 双向链表是否为空\n    printf(\"dlink_size()=%d\\n\", dlink_size());            // 双向链表的大小\n\n    // 打印双向链表中的全部数据\n    int i;\n    int sz = dlink_size();\n    stu *p;\n    for (i=0; i<sz; i++)\n    {\n        p = (stu *)dlink_get(i);\n        printf(\"dlink_get(%d)=[%d, %s]\\n\", i, p->id, p->name);\n    }\n\n    destroy_dlink();\n}\n\nint main()\n{\n    int_test();        // 演示向双向链表操作“int数据”。\n    string_test();    // 演示向双向链表操作“字符串数据”。\n    object_test();    // 演示向双向链表操作“对象”。\n\n    return 0;\n}\n```\n \n\n运行结果\n\n```\n----int_test----\ndlink_is_empty()=0\ndlink_size()=3\ndlink_get(0)=30\ndlink_get(1)=20\ndlink_get(2)=10\n\n----string_test----\ndlink_is_empty()=0\ndlink_size()=3\ndlink_get(0)=thirty\ndlink_get(1)=twenty\ndlink_get(2)=ten\n\n----object_test----\ndlink_is_empty()=0\ndlink_size()=3\ndlink_get(0)=[30, vic]\ndlink_get(1)=[20, jody]\ndlink_get(2)=[10, sky]\n```\n\n### 2. C++实现双链表\n\n实现代码\n\n双向链表文件(DoubleLink.h)\n\n```cpp\n#ifndef DOUBLE_LINK_HXX\n#define DOUBLE_LINK_HXX\n\n#include <iostream>\nusing namespace std;\n\ntemplate<class T> \nstruct DNode \n{\n    public:\n        T value;\n        DNode *prev;\n        DNode *next;\n    public:\n        DNode() { }\n        DNode(T t, DNode *prev, DNode *next) {\n            this->value = t;\n            this->prev  = prev;\n            this->next  = next;\n           }\n};\n\ntemplate<class T> \nclass DoubleLink \n{\n    public:\n        DoubleLink();\n        ~DoubleLink();\n\n        int size();\n        int is_empty();\n\n        T get(int index);\n        T get_first();\n        T get_last();\n\n        int insert(int index, T t);\n        int insert_first(T t);\n        int append_last(T t);\n\n        int del(int index);\n        int delete_first();\n        int delete_last();\n\n    private:\n        int count;\n        DNode<T> *phead;\n    private:\n        DNode<T> *get_node(int index);\n};\n\ntemplate<class T>\nDoubleLink<T>::DoubleLink() : count(0)\n{\n    // 创建“表头”。注意：表头没有存储数据！\n    phead = new DNode<T>();\n    phead->prev = phead->next = phead;\n    // 设置链表计数为0\n    //count = 0;\n}\n\n// 析构函数\ntemplate<class T>\nDoubleLink<T>::~DoubleLink() \n{\n    // 删除所有的节点\n    DNode<T>* ptmp;\n    DNode<T>* pnode = phead->next;\n    while (pnode != phead)\n    {\n        ptmp = pnode;\n        pnode=pnode->next;\n        delete ptmp;\n    }\n\n    // 删除\"表头\"\n    delete phead;\n    phead = NULL;\n}\n\n// 返回节点数目\ntemplate<class T>\nint DoubleLink<T>::size() \n{\n    return count;\n}\n\n// 返回链表是否为空\ntemplate<class T>\nint DoubleLink<T>::is_empty() \n{\n    return count==0;\n}\n\n// 获取第index位置的节点\ntemplate<class T>\nDNode<T>* DoubleLink<T>::get_node(int index) \n{\n    // 判断参数有效性\n    if (index<0 || index>=count)\n    {\n        cout << \"get node failed! the index in out of bound!\" << endl;\n        return NULL;\n    }\n\n    // 正向查找\n    if (index <= count/2)\n    {\n        int i=0;\n        DNode<T>* pindex = phead->next;\n        while (i++ < index) {\n            pindex = pindex->next;\n        }\n\n        return pindex;\n    }\n\n    // 反向查找\n    int j=0;\n    int rindex = count - index -1;\n    DNode<T>* prindex = phead->prev;\n    while (j++ < rindex) {\n        prindex = prindex->prev;\n    }\n\n    return prindex;\n}\n\n// 获取第index位置的节点的值\ntemplate<class T>\nT DoubleLink<T>::get(int index) \n{\n    return get_node(index)->value;\n}\n\n// 获取第1个节点的值\ntemplate<class T>\nT DoubleLink<T>::get_first() \n{\n    return get_node(0)->value;\n}\n\n// 获取最后一个节点的值\ntemplate<class T>\nT DoubleLink<T>::get_last() \n{\n    return get_node(count-1)->value;\n}\n\n// 将节点插入到第index位置之前\ntemplate<class T>\nint DoubleLink<T>::insert(int index, T t) \n{\n    if (index == 0)\n        return insert_first(t);\n\n    DNode<T>* pindex = get_node(index);\n    DNode<T>* pnode  = new DNode<T>(t, pindex->prev, pindex);\n    pindex->prev->next = pnode;\n    pindex->prev = pnode;\n    count++;\n\n    return 0;\n}\n\n// 将节点插入第一个节点处。\ntemplate<class T>\nint DoubleLink<T>::insert_first(T t) \n{\n    DNode<T>* pnode  = new DNode<T>(t, phead, phead->next);\n    phead->next->prev = pnode;\n    phead->next = pnode;\n    count++;\n\n    return 0;\n}\n\n// 将节点追加到链表的末尾\ntemplate<class T>\nint DoubleLink<T>::append_last(T t) \n{\n    DNode<T>* pnode = new DNode<T>(t, phead->prev, phead);\n    phead->prev->next = pnode;\n    phead->prev = pnode;\n    count++;\n\n    return 0;\n}\n\n// 删除index位置的节点\ntemplate<class T>\nint DoubleLink<T>::del(int index) \n{\n    DNode<T>* pindex = get_node(index);\n    pindex->next->prev = pindex->prev;\n    pindex->prev->next = pindex->next;\n    delete pindex;\n    count--;\n\n    return 0;\n}\n\n// 删除第一个节点\ntemplate<class T>\nint DoubleLink<T>::delete_first() \n{\n    return del(0);\n}\n\n// 删除最后一个节点\ntemplate<class T>\nint DoubleLink<T>::delete_last() \n{\n    return del(count-1);\n}\n\n#endif\n```\n\n双向链表测试文件(DlinkTest.cpp)\n\n```cpp\n#include <iostream>\n#include \"DoubleLink.h\"\nusing namespace std;\n\n// 双向链表操作int数据\nvoid int_test()\n{\n    int iarr[4] = {10, 20, 30, 40};\n\n    cout << \"\\n----int_test----\" << endl;\n    // 创建双向链表\n    DoubleLink<int>* pdlink = new DoubleLink<int>();\n\n    pdlink->insert(0, 20);        // 将 20 插入到第一个位置\n    pdlink->append_last(10);    // 将 10 追加到链表末尾\n    pdlink->insert_first(30);    // 将 30 插入到第一个位置\n\n    // 双向链表是否为空\n    cout << \"is_empty()=\" << pdlink->is_empty() <<endl;\n    // 双向链表的大小\n    cout << \"size()=\" << pdlink->size() <<endl;\n\n    // 打印双向链表中的全部数据\n    int sz = pdlink->size();\n    for (int i=0; i<sz; i++)\n        cout << \"pdlink(\"<<i<<\")=\" << pdlink->get(i) <<endl;\n}\n\nvoid string_test()\n{\n    string sarr[4] = {\"ten\", \"twenty\", \"thirty\", \"forty\"};\n\n    cout << \"\\n----string_test----\" << endl;\n    // 创建双向链表\n    DoubleLink<string>* pdlink = new DoubleLink<string>();\n\n    pdlink->insert(0, sarr[1]);        // 将 sarr中第2个元素 插入到第一个位置\n    pdlink->append_last(sarr[0]);    // 将 sarr中第1个元素  追加到链表末尾\n    pdlink->insert_first(sarr[2]);    // 将 sarr中第3个元素  插入到第一个位置\n\n    // 双向链表是否为空\n    cout << \"is_empty()=\" << pdlink->is_empty() <<endl;\n    // 双向链表的大小\n    cout << \"size()=\" << pdlink->size() <<endl;\n\n    // 打印双向链表中的全部数据\n    int sz = pdlink->size();\n    for (int i=0; i<sz; i++)\n        cout << \"pdlink(\"<<i<<\")=\" << pdlink->get(i) <<endl;\n}\n\nstruct stu\n{\n    int id;\n    char name[20];\n};\n\nstatic stu arr_stu[] = \n{\n    {10, \"sky\"},\n    {20, \"jody\"},\n    {30, \"vic\"},\n    {40, \"dan\"},\n};\n#define ARR_STU_SIZE ( (sizeof(arr_stu)) / (sizeof(arr_stu[0])) )\n\nvoid object_test()\n{\n    cout << \"\\n----object_test----\" << endl;\n    // 创建双向链表\n    DoubleLink<stu>* pdlink = new DoubleLink<stu>();\n\n    pdlink->insert(0, arr_stu[1]);        // 将 arr_stu中第2个元素 插入到第一个位置\n    pdlink->append_last(arr_stu[0]);    // 将 arr_stu中第1个元素  追加到链表末尾\n    pdlink->insert_first(arr_stu[2]);    // 将 arr_stu中第3个元素  插入到第一个位置\n\n    // 双向链表是否为空\n    cout << \"is_empty()=\" << pdlink->is_empty() <<endl;\n    // 双向链表的大小\n    cout << \"size()=\" << pdlink->size() <<endl;\n\n    // 打印双向链表中的全部数据\n    int sz = pdlink->size();\n    struct stu p;\n    for (int i=0; i<sz; i++) \n    {\n        p = pdlink->get(i);\n        cout << \"pdlink(\"<<i<<\")=[\" << p.id << \", \" << p.name <<\"]\" <<endl;\n    }\n}\n\n\nint main()\n{\n    int_test();        // 演示向双向链表操作“int数据”。\n    string_test();    // 演示向双向链表操作“字符串数据”。\n    object_test();    // 演示向双向链表操作“对象”。\n\n    return 0;\n}\n```\n\n示例说明\n\n在上面的示例中，我将双向链表的\"声明\"和\"实现\"都放在头文件中。而编程规范告诫我们：将类的声明和实现分离，在头文件(.h文件或.hpp)中尽量只包含声明，而在实现文件(.cpp文件)中负责实现！\n\n那么为什么要这么做呢？这是因为，在双向链表的实现中，采用了模板；而C++编译器不支持对模板的分离式编译！简单点说，如果在DoubleLink.h中声明，而在DoubleLink.cpp中进行实现的话；当我们在其他类中创建DoubleLink的对象时，会编译出错。具体原因，可以参考\"为什么C++编译器不能支持对模板的分离式编译\"。\n\n运行结果\n\n```\n----int_test----\nis_empty()=0\nsize()=3\npdlink(0)=30\npdlink(1)=20\npdlink(2)=10\n\n----string_test----\nis_empty()=0\nsize()=3\npdlink(0)=thirty\npdlink(1)=twenty\npdlink(2)=ten\n\n----object_test----\nis_empty()=0\nsize()=3\npdlink(0)=[30, vic]\npdlink(1)=[20, jody]\npdlink(2)=[10, sky]\n```\n\n### 3. Java实现双链表\n\n实现代码\n\n双链表类(DoubleLink.java)\n\n```java\n/**\n * Java 实现的双向链表。 \n * 注：java自带的集合包中有实现双向链表，路径是:java.util.LinkedList\n *\n * @author skywang\n * @date 2013/11/07\n */\npublic class DoubleLink<T> {\n\n    // 表头\n    private DNode<T> mHead;\n    // 节点个数\n    private int mCount;\n\n    // 双向链表“节点”对应的结构体\n    private class DNode<T> {\n        public DNode prev;\n        public DNode next;\n        public T value;\n\n        public DNode(T value, DNode prev, DNode next) {\n            this.value = value;\n            this.prev = prev;\n            this.next = next;\n        }\n    }\n\n    // 构造函数\n    public DoubleLink() {\n        // 创建“表头”。注意：表头没有存储数据！\n        mHead = new DNode<T>(null, null, null);\n        mHead.prev = mHead.next = mHead;\n        // 初始化“节点个数”为0\n        mCount = 0;\n    }\n\n    // 返回节点数目\n    public int size() {\n        return mCount;\n    }\n\n    // 返回链表是否为空\n    public boolean isEmpty() {\n        return mCount==0;\n    }\n\n    // 获取第index位置的节点\n    private DNode<T> getNode(int index) {\n        if (index<0 || index>=mCount)\n            throw new IndexOutOfBoundsException();\n\n        // 正向查找\n        if (index <= mCount/2) {\n            DNode<T> node = mHead.next;\n            for (int i=0; i<index; i++)\n                node = node.next;\n\n            return node;\n        }\n\n        // 反向查找\n        DNode<T> rnode = mHead.prev;\n        int rindex = mCount - index -1;\n        for (int j=0; j<rindex; j++)\n            rnode = rnode.prev;\n\n        return rnode;\n    }\n\n    // 获取第index位置的节点的值\n    public T get(int index) {\n        return getNode(index).value;\n    }\n\n    // 获取第1个节点的值\n    public T getFirst() {\n        return getNode(0).value;\n    }\n\n    // 获取最后一个节点的值\n    public T getLast() {\n        return getNode(mCount-1).value;\n    }\n\n    // 将节点插入到第index位置之前\n    public void insert(int index, T t) {\n        if (index==0) {\n            DNode<T> node = new DNode<T>(t, mHead, mHead.next);\n            mHead.next.prev = node;\n            mHead.next = node;\n            mCount++;\n            return ;\n        }\n\n        DNode<T> inode = getNode(index);\n        DNode<T> tnode = new DNode<T>(t, inode.prev, inode);\n        inode.prev.next = tnode;\n        inode.next = tnode;\n        mCount++;\n        return ;\n    }\n\n    // 将节点插入第一个节点处。\n    public void insertFirst(T t) {\n        insert(0, t);\n    }\n\n    // 将节点追加到链表的末尾\n    public void appendLast(T t) {\n        DNode<T> node = new DNode<T>(t, mHead.prev, mHead);\n        mHead.prev.next = node;\n        mHead.prev = node;\n        mCount++;\n    }\n\n    // 删除index位置的节点\n    public void del(int index) {\n        DNode<T> inode = getNode(index);\n        inode.prev.next = inode.next;\n        inode.next.prev = inode.prev;\n        inode = null;\n        mCount--;\n    }\n\n    // 删除第一个节点\n    public void deleteFirst() {\n        del(0);\n    }\n\n    // 删除最后一个节点\n    public void deleteLast() {\n        del(mCount-1);\n    }\n}\n```\n\n测试程序(DlinkTest.java)\n\n```java\n/**\n * Java 实现的双向链表。 \n * 注：java自带的集合包中有实现双向链表，路径是:java.util.LinkedList\n *\n * @author skywang\n * @date 2013/11/07\n */\n\npublic class DlinkTest {\n\n    // 双向链表操作int数据\n    private static void int_test() {\n        int[] iarr = {10, 20, 30, 40};\n\n        System.out.println(\"\\n----int_test----\");\n        // 创建双向链表\n        DoubleLink<Integer> dlink = new DoubleLink<Integer>();\n\n        dlink.insert(0, 20);    // 将 20 插入到第一个位置\n        dlink.appendLast(10);    // 将 10 追加到链表末尾\n        dlink.insertFirst(30);    // 将 30 插入到第一个位置\n\n        // 双向链表是否为空\n        System.out.printf(\"isEmpty()=%b\\n\", dlink.isEmpty());\n        // 双向链表的大小\n        System.out.printf(\"size()=%d\\n\", dlink.size());\n\n        // 打印出全部的节点\n        for (int i=0; i<dlink.size(); i++)\n            System.out.println(\"dlink(\"+i+\")=\"+ dlink.get(i));\n    }\n\n\n    private static void string_test() {\n        String[] sarr = {\"ten\", \"twenty\", \"thirty\", \"forty\"};\n\n        System.out.println(\"\\n----string_test----\");\n        // 创建双向链表\n        DoubleLink<String> dlink = new DoubleLink<String>();\n\n        dlink.insert(0, sarr[1]);    // 将 sarr中第2个元素 插入到第一个位置\n        dlink.appendLast(sarr[0]);    // 将 sarr中第1个元素 追加到链表末尾\n        dlink.insertFirst(sarr[2]);    // 将 sarr中第3个元素 插入到第一个位置\n\n        // 双向链表是否为空\n        System.out.printf(\"isEmpty()=%b\\n\", dlink.isEmpty());\n        // 双向链表的大小\n        System.out.printf(\"size()=%d\\n\", dlink.size());\n\n        // 打印出全部的节点\n        for (int i=0; i<dlink.size(); i++)\n            System.out.println(\"dlink(\"+i+\")=\"+ dlink.get(i));\n    }\n\n\n    // 内部类\n    private static class Student {\n        private int id;\n        private String name;\n\n        public Student(int id, String name) {\n            this.id = id;\n            this.name = name;\n        }\n\n        @Override\n        public String toString() {\n            return \"[\"+id+\", \"+name+\"]\";\n        }\n    }\n\n    private static Student[] students = new Student[]{\n        new Student(10, \"sky\"),\n        new Student(20, \"jody\"),\n        new Student(30, \"vic\"),\n        new Student(40, \"dan\"),\n    };\n\n    private static void object_test() {\n        System.out.println(\"\\n----object_test----\");\n        // 创建双向链表\n        DoubleLink<Student> dlink = new DoubleLink<Student>();\n\n        dlink.insert(0, students[1]);    // 将 students中第2个元素 插入到第一个位置\n        dlink.appendLast(students[0]);    // 将 students中第1个元素 追加到链表末尾\n        dlink.insertFirst(students[2]);    // 将 students中第3个元素 插入到第一个位置\n\n        // 双向链表是否为空\n        System.out.printf(\"isEmpty()=%b\\n\", dlink.isEmpty());\n        // 双向链表的大小\n        System.out.printf(\"size()=%d\\n\", dlink.size());\n\n        // 打印出全部的节点\n        for (int i=0; i<dlink.size(); i++) {\n            System.out.println(\"dlink(\"+i+\")=\"+ dlink.get(i));\n        }\n    }\n\n \n    public static void main(String[] args) {\n        int_test();        // 演示向双向链表操作“int数据”。\n        string_test();    // 演示向双向链表操作“字符串数据”。\n        object_test();    // 演示向双向链表操作“对象”。\n    }\n}\n```\n\n运行结果\n\n```\n----int_test----\nisEmpty()=false\nsize()=3\ndlink(0)=30\ndlink(1)=20\ndlink(2)=10\n\n----string_test----\nisEmpty()=false\nsize()=3\ndlink(0)=thirty\ndlink(1)=twenty\ndlink(2)=ten\n\n----object_test----\nisEmpty()=false\nsize()=3\ndlink(0)=[30, vic]\ndlink(1)=[20, jody]\ndlink(2)=[10, sky]\n```\n\n---\n\n* 原文链接：[数组、单链表和双链表介绍 以及 双向链表的C/C++/Java实现](http://www.cnblogs.com/skywang12345/p/3561803.html)\n","tags":["LinkedList"],"categories":["Algorithm"]},{"title":"Hive SQL 的编译过程","url":"%2F2014%2F2014-02-14-hive-sql-to-mapreduce%2F","content":"\nHive是基于Hadoop的一个数据仓库系统，在各大公司都有广泛的应用。美团数据仓库也是基于Hive搭建，每天执行近万次的Hive ETL计算流程，负责每天数百GB的数据存储和分析。Hive的稳定性和性能对我们的数据分析非常关键。\n\n在几次升级Hive的过程中，我们遇到了一些大大小小的问题。通过向社区的咨询和自己的努力，在解决这些问题的同时我们对Hive将SQL编译为MapReduce的过程有了比较深入的理解。对这一过程的理解不仅帮助我们解决了一些Hive的bug，也有利于我们优化Hive SQL，提升我们对Hive的掌控力，同时有能力去定制一些需要的功能。\n\n### MapReduce实现基本SQL操作的原理\n\n详细讲解SQL编译为MapReduce之前，我们先来看看MapReduce框架实现SQL基本操作的原理\n\n#### Join的实现原理\n\n```sql\nselect u.name, o.orderid from order o join user u on o.uid = u.uid;\n```\n\n在map的输出value中为不同表的数据打上tag标记，在reduce阶段根据tag判断数据来源。MapReduce的过程如下（这里只是说明最基本的Join的实现，还有其他的实现方式）\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/join.png)\n\n#### Group By的实现原理\n\n```sql\nselect rank, isonline, count(*) from city group by rank, isonline;\n```\n\n将GroupBy的字段组合为map的输出key值，利用MapReduce的排序，在reduce阶段保存LastKey区分不同的key。MapReduce的过程如下（当然这里只是说明Reduce端的非Hash聚合过程）\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/groupby.png)\n\n#### Distinct的实现原理\n\n```sql\nselect dealid, count(distinct uid) num from order group by dealid;\n```\n\n当只有一个distinct字段时，如果不考虑Map阶段的Hash GroupBy，只需要将GroupBy字段和Distinct字段组合为map输出key，利用mapreduce的排序，同时将GroupBy字段作为reduce的key，在reduce阶段保存LastKey即可完成去重\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/1distinct.png)\n\n如果有多个distinct字段呢，如下面的SQL\n\n```sql\nselect dealid, count(distinct uid), count(distinct date) from order group by dealid;\n```\n\n实现方式有两种：\n\n（1）如果仍然按照上面一个distinct字段的方法，即下图这种实现方式，无法跟据uid和date分别排序，也就无法通过LastKey去重，仍然需要在reduce阶段在内存中通过Hash去重\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/2distinct-a.png)\n\n（2）第二种实现方式，可以对所有的distinct字段编号，每行数据生成n行数据，那么相同字段就会分别排序，这时只需要在reduce阶段记录LastKey即可去重。\n\n这种实现方式很好的利用了MapReduce的排序，节省了reduce阶段去重的内存消耗，但是缺点是增加了shuffle的数据量。\n\n需要注意的是，在生成reduce value时，除第一个distinct字段所在行需要保留value值，其余distinct数据行value字段均可为空。\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/2distinct-b.png)\n\n### SQL转化为MapReduce的过程\n\n了解了MapReduce实现SQL基本操作之后，我们来看看Hive是如何将SQL转化为MapReduce任务的，整个编译过程分为六个阶段：\n\n* Antlr定义SQL的语法规则，完成SQL词法，语法解析，将SQL转化为抽象语法树AST Tree\n\n* 遍历AST Tree，抽象出查询的基本组成单元QueryBlock\n\n* 遍历QueryBlock，翻译为执行操作树OperatorTree\n\n* 逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量\n\n* 遍历OperatorTree，翻译为MapReduce任务\n\n* 物理层优化器进行MapReduce任务的变换，生成最终的执行计划\n\n下面分别对这六个阶段进行介绍\n\n#### Phase1 SQL词法，语法解析\n\n##### Antlr\n\nHive使用Antlr实现SQL的词法和语法解析。Antlr是一种语言识别的工具，可以用来构造领域语言。\n\n这里不详细介绍Antlr，只需要了解使用Antlr构造特定的语言只需要编写一个语法文件，定义词法和语法替换规则即可，Antlr完成了词法分析、语法分析、语义分析、中间代码生成的过程。\n\nHive中语法规则的定义文件在0.10版本以前是Hive.g一个文件，随着语法规则越来越复杂，由语法规则生成的Java解析类可能超过Java类文件的最大上限，0.11版本将Hive.g拆成了5个文件，词法规则HiveLexer.g和语法规则的4个文件SelectClauseParser.g，FromClauseParser.g，IdentifiersParser.g，HiveParser.g。\n\n##### 抽象语法树AST Tree\n\n经过词法和语法解析后，如果需要对表达式做进一步的处理，使用 Antlr 的抽象语法树语法Abstract Syntax Tree，在语法分析的同时将输入语句转换成抽象语法树，后续在遍历语法树时完成进一步的处理。\n\n下面的一段语法是Hive SQL中SelectStatement的语法规则，从中可以看出，SelectStatement包含select, from, where, groupby, having, orderby等子句。（在下面的语法规则中，箭头表示对于原语句的改写，改写后会加入一些特殊词标示特定语法，比如TOK_QUERY标示一个查询块）\n\n```sql\nselectStatement\n   :\n   selectClause\n   fromClause\n   whereClause?\n   groupByClause?\n   havingClause?\n   orderByClause?\n   clusterByClause?\n   distributeByClause?\n   sortByClause?\n   limitClause? -> ^(TOK_QUERY fromClause ^(TOK_INSERT ^(TOK_DESTINATION ^(TOK_DIR TOK_TMP_FILE))\n                     selectClause whereClause? groupByClause? havingClause? orderByClause? clusterByClause?\n                     distributeByClause? sortByClause? limitClause?))\n   ;\n```\n\n##### 样例SQL\n\n为了详细说明SQL翻译为MapReduce的过程，这里以一条简单的SQL为例，SQL中包含一个子查询，最终将数据写入到一张表中\n\n```sql\nFROM\n( \n  SELECT\n    p.datekey datekey,\n    p.userid userid,\n    c.clienttype\n  FROM\n    detail.usersequence_client c\n    JOIN fact.orderpayment p ON p.orderid = c.orderid\n    JOIN default.user du ON du.userid = p.userid\n  WHERE p.datekey = 20131118 \n) base\nINSERT OVERWRITE TABLE `test`.`customer_kpi`\nSELECT\n  base.datekey,\n  base.clienttype,\n  count(distinct base.userid) buyer_count\nGROUP BY base.datekey, base.clienttype\n```\n\n##### SQL生成AST Tree\n\nAntlr对Hive SQL解析的代码如下，HiveLexerX，HiveParser分别是Antlr对语法文件Hive.g编译后自动生成的词法解析和语法解析类，在这两个类中进行复杂的解析。\n\n```sql\nHiveLexerX lexer = new HiveLexerX(new ANTLRNoCaseStringStream(command));    //词法解析，忽略关键词的大小写\nTokenRewriteStream tokens = new TokenRewriteStream(lexer);\nif (ctx != null) {\n  ctx.setTokenRewriteStream(tokens);\n}\nHiveParser parser = new HiveParser(tokens);                                 //语法解析\nparser.setTreeAdaptor(adaptor);\nHiveParser.statement_return r = null;\ntry {\n  r = parser.statement();                                                   //转化为AST Tree\n} catch (RecognitionException e) {\n  e.printStackTrace();\n  throw new ParseException(parser.errors);\n}\n```\n\n最终生成的AST Tree如下图右侧（使用Antlr Works生成，Antlr Works是Antlr提供的编写语法文件的编辑器），图中只是展开了骨架的几个节点，没有完全展开。\n\n子查询1/2，分别对应右侧第1/2两个部分。\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/sql-ast.png)\n\n这里注意一下内层子查询也会生成一个TOK_DESTINATION节点。请看上面SelectStatement的语法规则，这个节点是在语法改写中特意增加了的一个节点。原因是Hive中所有查询的数据均会保存在HDFS临时的文件中，无论是中间的子查询还是查询最终的结果，Insert语句最终会将数据写入表所在的HDFS目录下。\n\n详细来看，将内存子查询的from子句展开后，得到如下AST Tree，每个表生成一个TOK_TABREF节点，Join条件生成一个“=”节点。其他SQL部分类似，不一一详述。\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/ast-tree.png)\n\n#### Phase2 SQL基本组成单元QueryBlock\n\nAST Tree仍然非常复杂，不够结构化，不方便直接翻译为MapReduce程序，AST Tree转化为QueryBlock就是将SQL进一部抽象和结构化。\n\n##### QueryBlock\n\nQueryBlock是一条SQL最基本的组成单元，包括三个部分：输入源，计算过程，输出。简单来讲一个QueryBlock就是一个子查询。\n\n下图为Hive中QueryBlock相关对象的类图，解释图中几个重要的属性\n\n* QB#aliasToSubq（表示QB类的aliasToSubq属性）保存子查询的QB对象，aliasToSubq key值是子查询的别名\n\n* QB#qbp即QBParseInfo保存一个基本SQL单元中的给个操作部分的AST Tree结构，QBParseInfo#nameToDest这个HashMap保存查询单元的输出，key的形式是inclause-i（由于Hive支持Multi Insert语句，所以可能有多个输出），value是对应的ASTNode节点，即TOK_DESTINATION节点。类QBParseInfo其余HashMap属性分别保存输出和各个操作的ASTNode节点的对应关系。\n\n* QBParseInfo#JoinExpr保存TOK_JOIN节点。QB#QBJoinTree是对Join语法树的结构化。\n\n* QB#qbm保存每个输入表的元信息，比如表在HDFS上的路径，保存表数据的文件格式等。\n\n* QBExpr这个对象是为了表示Union操作。\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/queryblock.png)\n\n##### AST Tree生成QueryBlock\n\nAST Tree生成QueryBlock的过程是一个递归的过程，先序遍历AST Tree，遇到不同的Token节点，保存到相应的属性中，主要包含以下几个过程\n\n* TOK_QUERY => 创建QB对象，循环递归子节点\n\n* TOK_FROM => 将表名语法部分保存到QB对象的aliasToTabs等属性中\n\n* TOK_INSERT => 循环递归子节点\n\n* TOK_DESTINATION => 将输出目标的语法部分保存在QBParseInfo对象的nameToDest属性中\n\n* TOK_SELECT => 分别将查询表达式的语法部分保存在destToSelExpr、destToAggregationExprs、destToDistinctFuncExprs三个属性中\n\n* TOK_WHERE => 将Where部分的语法保存在QBParseInfo对象的destToWhereExpr属性中\n\n最终样例SQL生成两个QB对象，QB对象的关系如下，QB1是外层查询，QB2是子查询\n\n```\nQB1\n  \\\n   QB2\n```\n\n#### Phase3 逻辑操作符Operator\n\n##### Operator\n\nHive最终生成的MapReduce任务，Map阶段和Reduce阶段均由OperatorTree组成。逻辑操作符，就是在Map阶段或者Reduce阶段完成单一特定的操作。\n\n基本的操作符包括TableScanOperator，SelectOperator，FilterOperator，JoinOperator，GroupByOperator，ReduceSinkOperator\n\n从名字就能猜出各个操作符完成的功能，TableScanOperator从MapReduce框架的Map接口原始输入表的数据，控制扫描表的数据行数，标记是从原表中取数据。JoinOperator完成Join操作。FilterOperator完成过滤操作\n\nReduceSinkOperator将Map端的字段组合序列化为Reduce Key/value, Partition Key，只可能出现在Map阶段，同时也标志着Hive生成的MapReduce程序中Map阶段的结束。\n\nOperator在Map Reduce阶段之间的数据传递都是一个流式的过程。每一个Operator对一行数据完成操作后之后将数据传递给childOperator计算。\n\nOperator类的主要属性和方法如下\n\n* RowSchema表示Operator的输出字段\n\n* InputObjInspector outputObjInspector解析输入和输出字段\n\n* processOp接收父Operator传递的数据，forward将处理好的数据传递给子Operator处理\n\n* Hive每一行数据经过一个Operator处理之后，会对字段重新编号，colExprMap记录每个表达式经过当前Operator处理前后的名称对应关系，在下一个阶段逻辑优化阶段用来回溯字段名\n\n* 由于Hive的MapReduce程序是一个动态的程序，即不确定一个MapReduce Job会进行什么运算，可能是Join，也可能是GroupBy，所以Operator将所有运行时需要的参数保存在OperatorDesc中，OperatorDesc在提交任务前序列化到HDFS上，在MapReduce任务执行前从HDFS读取并反序列化。Map阶段OperatorTree在HDFS上的位置在Job.getConf(“hive.exec.plan”) + “/map.xml”\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator.png)\n\n##### QueryBlock生成Operator Tree\n\nQueryBlock生成Operator Tree就是遍历上一个过程中生成的QB和QBParseInfo对象的保存语法的属性，包含如下几个步骤：\n\n* QB#aliasToSubq => 有子查询，递归调用\n\n* QB#aliasToTabs => TableScanOperator\n\n* QBParseInfo#joinExpr => QBJoinTree => ReduceSinkOperator + JoinOperator\n\n* QBParseInfo#destToWhereExpr => FilterOperator\n\n* QBParseInfo#destToGroupby => ReduceSinkOperator + GroupByOperator\n\n* QBParseInfo#destToOrderby => ReduceSinkOperator + ExtractOperator\n\n由于Join/GroupBy/OrderBy均需要在Reduce阶段完成，所以在生成相应操作的Operator之前都会先生成一个ReduceSinkOperator，将字段组合并序列化为Reduce Key/value, Partition Key\n\n接下来详细分析样例SQL生成OperatorTree的过程\n\n先序遍历上一个阶段生成的QB对象\n\n* 首先根据子QueryBlock QB2#aliasToTabs {du=dim.user, c=detail.usersequence_client, p=fact.orderpayment}生成TableScanOperator\n\n```\nTableScanOperator(“dim.user”) TS[0]\nTableScanOperator(“detail.usersequence_client”) TS[1]        TableScanOperator(“fact.orderpayment”) TS[2]\n```\n\n* 先序遍历QBParseInfo#joinExpr生成QBJoinTree，类QBJoinTree也是一个树状结构，QBJoinTree保存左右表的ASTNode和这个查询的别名，最终生成的查询树如下\n\n```\n    base\n    /  \\\n   p    du\n  /      \\\n c        p\n```\n \n* 前序遍历QBJoinTree，先生成detail.usersequence_client和fact.orderpayment的Join操作树\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/qb-to-operator-1.png)\n\n图中 TS=TableScanOperator RS=ReduceSinkOperator JOIN=JoinOperator\n\n* 生成中间表与dim.user的Join操作树\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/qb-to-operator-2.png)\n\n* 根据QB2 QBParseInfo#destToWhereExpr 生成FilterOperator。此时QB2遍历完成。\n\n下图中SelectOperator在某些场景下会根据一些条件判断是否需要解析字段。\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/qb-to-operator-3.png)\n\n图中 FIL= FilterOperator SEL= SelectOperator\n\n* 根据QB1的QBParseInfo#destToGroupby生成ReduceSinkOperator + GroupByOperator\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/qb-to-operator-4.png)\n\n图中 GBY= GroupByOperator\n\nGBY[12]是HASH聚合，即在内存中通过Hash进行聚合运算\n\n* 最终都解析完后，会生成一个FileSinkOperator，将数据写入HDFS\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/qb-to-operator-5.png)\n\n图中FS=FileSinkOperator\n\n#### Phase4 逻辑层优化器\n\n大部分逻辑层优化器通过变换OperatorTree，合并操作符，达到减少MapReduce Job，减少shuffle数据量的目的。\n\n| 名称 | 作用 |\n| --- | --- |\n| ② SimpleFetchOptimizer | 优化没有GroupBy表达式的聚合查询 |\n| ② MapJoinProcessor | MapJoin，需要SQL中提供hint，0.11版本已不用 |\n| ② BucketMapJoinOptimizer | BucketMapJoin |\n| ② GroupByOptimizer | Map端聚合 |\n| ① ReduceSinkDeDuplication | 合并线性的OperatorTree中partition/sort key相同的reduce |\n| ① PredicatePushDown | 谓词前置 |\n| ① CorrelationOptimizer | 利用查询中的相关性，合并有相关性的Job，HIVE-2206 |\n| ColumnPruner | 字段剪枝 |\n\n表格中①的优化器均是一个Job干尽可能多的事情/合并。②的都是减少shuffle数据量，甚至不做Reduce。\n\nCorrelationOptimizer优化器非常复杂，都能利用查询中的相关性，合并有相关性的Job，参考 Hive Correlation Optimizer\n\n对于样例SQL，有两个优化器对其进行优化。下面分别介绍这两个优化器的作用，并补充一个优化器ReduceSinkDeDuplication的作用\n\n##### PredicatePushDown优化器\n\n断言判断提前优化器将OperatorTree中的FilterOperator提前到TableScanOperator之后\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/PredicatePushDown.png)\n\n##### NonBlockingOpDeDupProc优化器\n\nNonBlockingOpDeDupProc优化器合并SEL-SEL 或者 FIL-FIL 为一个Operator\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/NonBlockingOpDeDupProc.png)\n\n##### ReduceSinkDeDuplication优化器\n\nReduceSinkDeDuplication可以合并线性相连的两个RS。实际上CorrelationOptimizer是ReduceSinkDeDuplication的超集，能合并线性和非线性的操作RS，但是Hive先实现的ReduceSinkDeDuplication\n\n譬如下面这条SQL语句\n\n```sql\nfrom (select key, value from src group by key, value) s select s.key group by s.key;\n```\n\n经过前面几个阶段之后，会生成如下的OperatorTree，两个Tree是相连的，这里没有画到一起\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/ReduceSinkDeDuplication1.png)\n\n这时候遍历OperatorTree后能发现前前后两个RS输出的Key值和PartitionKey如下\n\n|     | Key | PartitionKey |\n| --- | --- | ------------ |\n| childRS | key | key |\n| parentRS | key,value | key,value |\n\nReduceSinkDeDuplication优化器检测到：1. pRS Key完全包含cRS Key，且排序顺序一致；2. pRS PartitionKey完全包含cRS PartitionKey。符合优化条件，会对执行计划进行优化。\n\nReduceSinkDeDuplication将childRS和parentheRS与childRS之间的Operator删掉，保留的RS的Key为key,value字段，PartitionKey为key字段。合并后的OperatorTree如下：\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/ReduceSinkDeDuplication2.png) \n\n#### Phase5 OperatorTree生成MapReduce Job的过程\n\nOperatorTree转化为MapReduce Job的过程分为下面几个阶段\n\n* 对输出表生成MoveTask\n\n* 从OperatorTree的其中一个根节点向下深度优先遍历\n\n* ReduceSinkOperator标示Map/Reduce的界限，多个Job间的界限\n\n* 遍历其他根节点，遇过碰到JoinOperator合并MapReduceTask\n\n* 生成StatTask更新元数据\n\n* 剪断Map与Reduce间的Operator的关系\n\n##### 对输出表生成MoveTask\n\n由上一步OperatorTree只生成了一个FileSinkOperator，直接生成一个MoveTask，完成将最终生成的HDFS临时文件移动到目标表目录下\n\n```\nMoveTask[Stage-0]\nMove Operator\n```\n\n##### 开始遍历\n\n将OperatorTree中的所有根节点保存在一个toWalk的数组中，循环取出数组中的元素（省略QB1，未画出）\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/begin-walk.png) \n\n取出最后一个元素TS[p]放入栈 opStack{TS[p]}中\n\n##### Rule #1 TS% 生成MapReduceTask对象，确定MapWork\n\n发现栈中的元素符合下面规则R1（这里用python代码简单表示）\n\n```\n\"\".join([t + \"%\" for t in opStack]) == \"TS%\"\n```\n\n生成一个MapReduceTask[Stage-1]对象，MapReduceTask[Stage-1]对象的MapWork属性保存Operator根节点的引用。由于OperatorTree之间之间的Parent Child关系，这个时候MapReduceTask[Stage-1]包含了以TS[p]为根的所有Operator\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-1.png)\n\n##### Rule #2 TS%.*RS% 确定ReduceWork\n\n继续遍历TS[p]的子Operator，将子Operator存入栈opStack中\n\n当第一个RS进栈后，即栈opStack = {TS[p], FIL[18], RS[4]}时，就会满足下面的规则R2\n\n```\n\"\".join([t + \"%\" for t in opStack]) == \"TS%.*RS%\"\n```\n\n这时候在MapReduceTask[Stage-1]对象的ReduceWork属性保存JOIN[5]的引用\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-2.png)\n\n##### Rule #3 RS%.*RS% 生成新MapReduceTask对象，切分MapReduceTask\n\n继续遍历JOIN[5]的子Operator，将子Operator存入栈opStack中\n\n当第二个RS放入栈时，即当栈opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6]}时，就会满足下面的规则R3\n\n```\n\"\".join([t + \"%\" for t in opStack]) == “RS%.*RS%” //循环遍历opStack的每一个后缀数组\n```\n\n这时候创建一个新的MapReduceTask[Stage-2]对象，将OperatorTree从JOIN[5]和RS[6]之间剪开，并为JOIN[5]生成一个子Operator FS[19]，RS[6]生成一个TS[20]，MapReduceTask[Stage-2]对象的MapWork属性保存TS[20]的引用。\n\n新生成的FS[19]将中间数据落地，存储在HDFS临时文件中。\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-3.png)\n\n继续遍历RS[6]的子Operator，将子Operator存入栈opStack中\n\n当opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13]}时，又会满足R3规则\n\n同理生成MapReduceTask[Stage-3]对象，并切开 Stage-2 和 Stage-3 的OperatorTree\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-4.png)\n\n##### R4 FS% 连接MapReduceTask与MoveTask\n\n最终将所有子Operator存入栈中之后，opStack = {TS[p], FIL[18], RS[4], JOIN[5], RS[6], JOIN[8], SEL[10], GBY[12], RS[13], GBY[14], SEL[15], FS[17]} 满足规则R4\n\n```\n\"\".join([t + \"%\" for t in opStack]) == “FS%”\n```\n\n这时候将MoveTask与MapReduceTask[Stage-3]连接起来，并生成一个StatsTask，修改表的元信息\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-5.png)\n\n##### 合并Stage\n\n此时并没有结束，还有两个根节点没有遍历。\n\n将opStack栈清空，将toWalk的第二个元素加入栈。会发现opStack = {TS[du]}继续满足R1 TS%，生成MapReduceTask[Stage-5]\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-6.png)\n\n继续从TS[du]向下遍历，当opStack={TS[du], RS[7]}时，满足规则R2 TS%.*RS%\n\n此时将JOIN[8]保存为MapReduceTask[Stage-5]的ReduceWork时，发现在一个Map对象保存的Operator与MapReduceWork对象关系的Map<Operator, MapReduceWork>对象中发现，JOIN[8]已经存在。此时将MapReduceTask[Stage-2]和MapReduceTask[Stage-5]合并为一个MapReduceTask\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-7.png)\n\n同理从最后一个根节点TS[c]开始遍历，也会对MapReduceTask进行合并\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-8.png)\n\n##### 切分Map Reduce阶段\n\n最后一个阶段，将MapWork和ReduceWork中的OperatorTree以RS为界限剪开\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-9.png)\n\n##### OperatorTree生成MapReduceTask全貌\n\n最终共生成3个MapReduceTask，如下图\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/operator-to-mapreduce-10.png)\n\n#### Phase6 物理层优化器\n\n这里不详细介绍每个优化器的原理，单独介绍一下MapJoin的优化器\n\n| 名称 | 作用 |\n| --- | --- |\n| Vectorizer | HIVE-4160，将在0.13中发布 |\n| SortMergeJoinResolver | 与bucket配合，类似于归并排序 |\n| SamplingOptimizer | 并行order by优化器，在0.12中发布 |\n| CommonJoinResolver + MapJoinResolver | MapJoin优化器 |\n\n##### MapJoin原理\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/mapjoin.png)\n\nMapJoin简单说就是在Map阶段将小表读入内存，顺序扫描大表完成Join。\n\n上图是Hive MapJoin的原理图，出自Facebook工程师Liyin Tang的一篇介绍Join优化的slice，从图中可以看出MapJoin分为两个阶段：\n\n* 通过MapReduce Local Task，将小表读入内存，生成HashTableFiles上传至Distributed Cache中，这里会对HashTableFiles进行压缩。\n\n* MapReduce Job在Map阶段，每个Mapper从Distributed Cache读取HashTableFiles到内存中，顺序扫描大表，在Map阶段直接进行Join，将数据传递给下一个MapReduce任务。\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/conditionaltask.png)\n\n如果Join的两张表一张表是临时表，就会生成一个ConditionalTask，在运行期间判断是否使用MapJoin\n\n##### CommonJoinResolver优化器\n\nCommonJoinResolver优化器就是将CommonJoin转化为MapJoin，转化过程如下\n\n* 深度优先遍历Task Tree\n\n* 找到JoinOperator，判断左右表数据量大小\n\n* 对与小表 + 大表 => MapJoinTask，对于小/大表 + 中间表 => ConditionalTask\n\n遍历上一个阶段生成的MapReduce任务，发现MapReduceTask[Stage-2] JOIN[8]中有一张表为临时表，先对Stage-2进行深度拷贝（由于需要保留原始执行计划为Backup Plan，所以这里将执行计划拷贝了一份），生成一个MapJoinOperator替代JoinOperator，然后生成一个MapReduceLocalWork读取小表生成HashTableFiles上传至DistributedCache中。\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/mapjoin-1.png) \n\nMapReduceTask经过变换后的执行计划如下图所示\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/mapjoin-2.png) \n\n##### MapJoinResolver优化器\n\nMapJoinResolver优化器遍历Task Tree，将所有有local work的MapReduceTask拆成两个Task\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/MapJoinResolver-1.png)\n\n最终MapJoinResolver处理完之后，执行计划如下图所示\n\n![](/assets/images/2014/02/14/hive-sql-to-mapreduce/MapJoinResolver-2.png)\n\n#### Hive SQL编译过程的设计\n\n从上述整个SQL编译的过程，可以看出编译过程的设计有几个优点值得学习和借鉴\n\n* 使用Antlr开源软件定义语法规则，大大简化了词法和语法的编译解析过程，仅仅需要维护一份语法文件即可。\n\n* 整体思路很清晰，分阶段的设计使整个编译过程代码容易维护，使得后续各种优化器方便的以可插拔的方式开关，譬如Hive 0.13最新的特性Vectorization和对Tez引擎的支持都是可插拔的。\n\n* 每个Operator只完成单一的功能，简化了整个MapReduce程序。\n\n#### 社区发展方向\n\nHive依然在迅速的发展中，为了提升Hive的性能，hortonworks公司主导的Stinger计划提出了一系列对Hive的改进，比较重要的改进有：\n\n* Vectorization - 使Hive从单行单行处理数据改为批量处理方式，大大提升了指令流水线和缓存的利用率\n\n* Hive on Tez - 将Hive底层的MapReduce计算框架替换为Tez计算框架。Tez不仅可以支持多Reduce阶段的任务MRR，还可以一次性提交执行计划，因而能更好的分配资源。\nC\n* ost Based Optimizer - 使Hive能够自动选择最优的Join顺序，提高查询速度\n\n* Implement insert, update, and delete in Hive with full ACID support - 支持表按主键的增量更新\n\n我们也将跟进社区的发展，结合自身的业务需要，提升Hive型ETL流程的性能\n\n#### 参考\n\nAntlr: http://www.antlr.org/\n\nWiki Antlr介绍: http://en.wikipedia.org/wiki/ANTLR\n\n\nHive Wiki: https://cwiki.apache.org/confluence/display/Hive/Home\n\nHiveSQL编译过程: http://www.slideshare.net/recruitcojp/internal-hive\n\nJoin Optimization in Hive: Join Strategies in Hive from the 2011 Hadoop Summit (Liyin Tang, Namit Jain)\n\nHive Design Docs: https://cwiki.apache.org/confluence/display/Hive/DesignDocs\n\n---\n\n* 原文链接：[Hive SQL 的编译过程](http://tech.meituan.com/hive-sql-to-mapreduce.html)\n","tags":["SQL"],"categories":["Hive"]},{"title":"一例 Hive join 优化实战","url":"%2F2014%2F2014-02-12-hive-join-optimize%2F","content":"\n由于 hive 与传统关系型数据库面对的业务场景及底层技术架构都有着很大差异，因此，传统数据库领域的一些技能放到 Hive 中可能已不再适用。关于 hive 的优化与原理、应用的文章，前面也陆陆续续的介绍了一些，但大多都偏向理论层面，本文就介绍一个实例，从实例中一步步加深对 hive 调优的认识与意识。\n\n## 1、需求\n\n需求我做了简化，很简单，两张表做个 join，求指定城市，每天的 pv，用传统的 RDBMS SQL 写出来就这样的：\n\n```sql\nSELECT t.statdate,\n       c.cname,\n       count(t.cookieid)\nFROM tmpdb.city c\nJOIN ecdata.ext_trackflow t ON (t.area1= c.cname\n                                OR t.area2 =c.cname\n                                OR t.area3 = c.cname)\nWHERE t.statdate>='20140818' and t.statdate<='20140824'\n  AND platform='pc'\nGROUP BY t.statdate,\n         c.cname;\n```\n\n怎么样？根据 SQL 看懂需求没问题吧？\n\n## 2、非等值 join 问题\n\n然后把这条 SQL 贴到 hive 中去执行，然后你会发现报错了：\n\n```log\nFAILED: SemanticException [Error 10019]: Line 5:32 OR not supported in JOIN currently 'cname'\n```\n\n这是因为 hive 受限于 MapReduce 算法模型，只支持 equi-joins（等值 join），要实现上述的非等值 join，你可以采用笛卡儿积（ full Cartesian product ）来实现：\n\n```sql\nSELECT t.statdate,\n       c.cname,\n       count(t.cookieid)\nFROM tmpdb.city c\nJOIN ecdata.ext_trackflow t\nWHERE t.statdate>='20140818'\n  AND t.statdate<='20140824'\n  AND platform='pc'\n  AND (t.area1= c.cname\n       OR t.area2 =c.cname\n       OR t.area3 = c.cname)\nGROUP BY t.statdate,\n         c.cname;\n```\n\n然后再拿着这条语句执行下。\n\n## 3、优化：reduce side join VS Cartesian product\n\n如果你真的把这条语句放到 Hive 上执行，然后恰好你有张表还非常大，那么恭喜你。。。集群管理员估计会找你的麻烦了。。。\n\n友情提示：笛卡儿积这种语句在 Hive 下慎用，大数据场景下的 m * n 映射结果你懂的。。。对此，Hive 特意提供了一个环境变量：hive.mapred.mode=strict; 防止笛卡儿积的执行：\n\n```log\nFAILED: SemanticException [Error 10052]: In strict mode, cartesian product is not allowed. If you really want to perform the operation, set hive.mapred.mode=nonstrict\n```\n\n从 2 中的观察得知我们在 on 后面跟 join 条件，走的是 reduce side join，如果你在 where 后跟则是走 Cartesian product，但是这里单条 sql 又没法实现 reduce side join，还有没有其它办法呢？\n\n## 4、改写非等值 join：union all\n\n既然不允许非等值 join，那我们换一下思路，多个子查询 union all，然后汇总：\n\n```sql\nSELECT dt,\n       name,\n       count(cid)\nFROM\n  (SELECT t.statdate dt,\n          c.cname name,\n          t.cookieid cid\n   FROM tmpdb.city c\n   JOIN ecdata.ext_trackflow t ON t.area1 =c.cname\n   WHERE t.statdate>='20140818'\n     AND t.statdate<='20140824'\n     AND platform='pc'\n   UNION ALL SELECT t.statdate dt,\n                    c.cname name,\n                    t.cookieid cid\n   FROM tmpdb.city c\n   JOIN ecdata.ext_trackflow t ON t.area2 =c.cname\n   WHERE t.statdate>='20140818'\n     AND t.statdate<='20140824'\n     AND platform='pc'\n   UNION ALL SELECT t.statdate dt,\n                    c.cname name,\n                    t.cookieid cid\n   FROM tmpdb.city c\n   JOIN ecdata.ext_trackflow t ON t.area3 =c.cname\n   WHERE t.statdate>='20140818'\n     AND t.statdate<='20140824'\n     AND platform='pc') tmp_trackflow\nGROUP BY dt,\n         name;\n```\n\n## 5、优化：map side join\n\n上述语句走的是 reduce side join，从我们的需求及业务得知，tmpdb.city 是一张字典表，数据量很小，因此我们可以试试把上述的语句改写成 mapjoin：\n\n```sql\nSELECT dt,\n       name,\n       count(cid)\nFROM\n  (SELECT /*+ MAPJOIN(c) */ t.statdate dt,\n                            c.cname name,\n                            t.cookieid cid\n   FROM tmpdb.city c\n   JOIN ecdata.ext_trackflow t ON t.area1 =c.cname\n   WHERE t.statdate>='20140818'\n     AND t.statdate<='20140824'\n     AND platform='pc'\n   UNION ALL SELECT /*+ MAPJOIN(c) */ t.statdate dt,\n                                      c.cname name,\n                                      t.cookieid cid\n   FROM tmpdb.city c\n   JOIN ecdata.ext_trackflow t ON t.area2 =c.cname\n   WHERE t.statdate>='20140818'\n     AND t.statdate<='20140824'\n     AND platform='pc'\n   UNION ALL SELECT /*+ MAPJOIN(c) */ t.statdate dt,\n                                      c.cname name,\n                                      t.cookieid cid\n   FROM tmpdb.city c\n   JOIN ecdata.ext_trackflow t ON t.area3 =c.cname\n   WHERE t.statdate>='20140818'\n     AND t.statdate<='20140824'\n     AND platform='pc') tmp_trackflow\nGROUP BY dt,\n         name;\n```\n\n## 6、优化无极限：开启 parallel 和 控制 reduce 个数\n\n上述语句执行时，你可以看到执行计划和状态信息，以及结合你的 union all 语句可知，三个 union 语句之间没有依赖关系，其实是可以并行执行的：\n\n```log\nexplain SQL...\n...\nSTAGE DEPENDENCIES:\n  Stage-11 is a root stage\n  Stage-1 depends on stages: Stage-11\n  Stage-2 depends on stages: Stage-1\n  Stage-3 depends on stages: Stage-2, Stage-6, Stage-9\n  Stage-12 is a root stage\n  Stage-5 depends on stages: Stage-12\n  Stage-6 depends on stages: Stage-5\n  Stage-13 is a root stage\n  Stage-8 depends on stages: Stage-13\n  Stage-9 depends on stages: Stage-8\n  Stage-0 is a root stage\n...\n```\n\n我们在 SQL 前加上如下环境变量选项：\n\n```sql\nset mapred.reduce.tasks=60;\nset hive.exec.parallel=true;\n```\n\n让执行计划中的 Stage-11、Stage-12、Stage-13 并行执行，并控制好 reduce task 个数。\n\n完整的语句如下：\n\n```sql\nhive -e \"\nSET mapred.reduce.tasks=60;\n\n\nSET hive.exec.parallel=TRUE;\n\n\nSELECT dt,\n       name,\n       count(cid)\nFROM\n  (SELECT /*+ MAPJOIN(c) */ t.statdate dt,\n                            c.cname name,\n                            t.cookieid cid\n   FROM tmpdb.city c\n   JOIN ecdata.ext_trackflow t ON t.area1 =c.cname\n   WHERE t.statdate>='20140818'\n     AND t.statdate<='20140824'\n     AND platform='pc'\n   UNION ALL SELECT /*+ MAPJOIN(c) */ t.statdate dt,\n                                      c.cname name,\n                                      t.cookieid cid\n   FROM tmpdb.city c\n   JOIN ecdata.ext_trackflow t ON t.area2 =c.cname\n   WHERE t.statdate>='20140818'\n     AND t.statdate<='20140824'\n     AND platform='pc'\n   UNION ALL SELECT /*+ MAPJOIN(c) */ t.statdate dt,\n                                      c.cname name,\n                                      t.cookieid cid\n   FROM tmpdb.city c\n   JOIN ecdata.ext_trackflow t ON t.area3 =c.cname\n   WHERE t.statdate>='20140818'\n     AND t.statdate<='20140824'\n     AND platform='pc') tmp_trackflow\nGROUP BY dt,\n         name;\n\n\" > a1.txt\n```\n\n最后的优化效果是：2 中的语句三个小时没出结果。。。5 比 4 快 8 倍左右，6 比 5 快 2 倍左右，最终 10min 出结果。\n\n## 7、最后的问题：\n\n在 6 的语句执行的时候你会发现，其扫描了 三遍 源文件。而 hive 本身是对 union all 的 join 做了优化的，当多个 union all 子查询同一张表时，只扫描一次源文件，但这里为什么会三个子查询各扫描一次呢？\n\n可能是这里的 union all 子查询使用了 join 的缘故，导致 hive 的 union all 执行计划优化失效了。\n\n关于这块怎么能优化成只扫描一次源文件，或者你有更好的优化方案，欢迎留言交流。\n\n## 8、关于 hive 中的 笛卡尔集（ full Cartesian product ）\n\n在JION接连查询中没有ON连接key，而通过WHERE条件语句会产生笛卡尔集。\n\nHive本身是不支持笛卡尔集的，不能用select T1.*, T2.* from table1, table2这种语法。但有时候确实需要用到笛卡尔集的时候，可以用下面的语法来实现同样的效果：\n\n```sql\nselect T1.*, T2.* from table1 T1 join table2 T2 where 1=1;\n```\n\n注意在Hive的Strict模式下不能用这种语法，因为这样会产生笛卡尔集，而这种模式禁止产生笛卡尔集。需要先用set hive.mapred.mode=nonstrict;设为非strict模式就可以用了，或者将where改为on连接。\n\n```sql\nselect T1.*, T2.* from table1 T1 join table2 T2 on  T1.id=T2.id;\n```\n\n## 9、关于Strict Mode\n\nHive中的严格模式可以防止用户发出（可以有问题）的查询无意中造成不良的影响。 将hive.mapred.mode设置成strict可以禁止三种类型的查询：\n\n1）、在一个分区表上，如果没有在WHERE条件中指明具体的分区，那么这是不允许的，换句话说，不允许在分区表上全表扫描。这种限制的原因是分区表通常会持非常大的数据集并且可能数据增长迅速，对这样的一个大表做全表扫描会消耗大量资源，必须要再WHERE过滤条件中具体指明分区才可以执行成功的查询。\n\n2）、第二种是禁止执行有ORDER BY的排序要求但没有LIMIT语句的HiveQL查询。因为ORDER BY全局查询会导致有一个单一的reducer对所有的查询结果排序，如果对大数据集做排序，这将导致不可预期的执行时间，必须要加上limit条件才可以执行成功的查询。\n\n3）、第三种是禁止产生笛卡尔集。在JION接连查询中没有ON连接key而通过WHERE条件语句会产生笛卡尔集，需要改为JOIN...ON语句。\n\n## 10、Refer：\n\n[1] Hive Query- Joining two tables on three joining conditions with OR operator\n\n[http://stackoverflow.com/questions/16272804/hive-query-joining-two-tables-on-three-joining-conditions-with-or-operator](http://stackoverflow.com/questions/16272804/hive-query-joining-two-tables-on-three-joining-conditions-with-or-operator)\n\n[2] LanguageManual JoinOptimization\n\n[https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization)\n\n[3] hive 执行计划\n\n[http://yychao.iteye.com/blog/1749562](http://yychao.iteye.com/blog/1749562)\n\n[4] Hive SQL解析/执行计划生成流程分析\n\n[http://yanbohappy.sinaapp.com/?p=265](http://yanbohappy.sinaapp.com/?p=265)\n\n[5] 数据仓库中的SQL性能优化（Hive篇）\n\n[http://www.zihou.me/html/2014/02/12/9207.html](http://www.zihou.me/html/2014/02/12/9207.html)\n\n[6] Hive优化以及执行原理\n\n[http://www.smartcitychina.cn/upload/2014-01/14012015376829.pdf](http://www.smartcitychina.cn/upload/2014-01/14012015376829.pdf)\n\n[7] Hive作业优化总结\n\n[http://my.oschina.net/yangzhiyuan/blog/262910](http://my.oschina.net/yangzhiyuan/blog/262910)\n\n[8] Hive连接产生笛卡尔集\n\n[http://blog.javachen.com/2013/10/17/cartesian-product-in-hive-inner-join/#](http://blog.javachen.com/2013/10/17/cartesian-product-in-hive-inner-join/#)\n\n---\n\n* Author: [xrzs](https://my.oschina.net/leejun2005/blog)\n* Source: [开源中国](https://oschina.net)\n* Link: [一例 Hive join 优化实战](https://my.oschina.net/leejun2005/blog/307812)","tags":["Join"],"categories":["Hive"]},{"title":"数据开放平台的配置管理","url":"%2F2014%2F2014-01-23-mt-confhub%2F","content":" \n美团是数据驱动的技术公司， 非常重视使用数据的效率。为了达到这个目标，我们将数据以开放平台的形式开放给需求方。例如，帮助需求方开发报表的报表开放平台，帮助需求方获取数据的自助查询平台，让需求方参与数据建设的ETL开放平台和调度管理服务。在这些开放平台上，需求方填写必要的配置，平台负责根据这些配置产生需要的报表，导出数据，或者产生ETL流程并通过调度有序执行。通过这种方式，简化用户使用数据的流程，提高用户使用数据的效率。\n\n开放平台的使用导致产生了大量的，不同类型的配置。起初，每个服务独立保存和管理自己的配置。随着开放平台的发展，与开放力度的增加，开放平台对配置的管理遇到了各种各样的问题。主要体现在\n\n1.  可能由于用户误修改或者误删除了配置，导致了运行问题。希望能够追溯配置的变更历史，更好的找到，提醒，并修复类似的问题。\n2.  在开放平台上，用户可以自行测试不同的配置。但是用户如果需要将自己的配置上线成为在线报表，或者添加到调度参与数据仓库数据清洗，就需要确保用户的配置的质量。必须经过数据组的审核，以保证系统的健壮性与逻辑的准确性。\n3.  每个开放服务的业务都与开放配置有关。这些配置的管理需求十分相似。每个服务都自行维护配置会增加开发成本和维护成本。\n\n# 需求分析\n\n针对遇到的问题，我们首先详细的分析了需求:\n\n1.  统一管理和存储配置。支持不同服务器上的不同语言编写的服务将配置统一存储和管理，并可以按照需求调用。从而避免不同服务重复开发，增加开发成本和维护成本。\n2.  配置隔离。不同的开放平台的配置互相之间是独立的，统一管理和存储，但是互相之间需要互不干扰。\n3.  版本控制。记录配置的历史变更。通过对比不同版本，可以追查修改人，修改原因，修改时间等。在用户出现误操作时，也可以有效的回滚，尽量的降低修复成本，从而降低出错的成本，提高对用户错误修改的容忍度。\n4.  审核功能。通过审核，对可能影响到系统正常运行的主要配置进行变更管理。每次变更，都必须经过审核。审核通过的变更才会被提交到系统中，参与系统的正常运行。\n5.  可视化页面。为了方便测试，管理和运维，需要有方便的页面支持浏览配置列表，查看和修改系统中已经存在的配置等。\n\n以上需求为必须满足的需求。为了能够更方便的使用，还希望该解决方案能够在配置审核通过时，通知使用该配置的服务，使其知晓该变更。\n\n# 解决方案\n\n为了满足上述需求，我们决定开发定制的统一集中管理配置的配置管理服务，命名为ConfHub，意为“配置的中心枢纽”。\n\n## 配置规划\n\n集中管理配置时，不同应用之间的隔离就显得非常重要。同时，应用对配置也有分类需求。所以，需要对配置进行规划。\n\n规划的基本思路是，首先，把配置按照应用进行分类。每个配置属于一个应用，每个应用下，可以有很多配置。在应用下设置命名空间，用来满足应用内的配置分类需求。规划方案如下图：\n\n![](/assets/images/2014/01/23/mt-confhub/confhub_config_classify.jpg)\n\n这种配置规划的方式避免了配置冲突。\n\n## 版本管理\n\n版本管理可以带来很多好处，比如\n\n1.  错误修改时，进行回滚。\n2.  在有用户恶意修改时，可以迅速修复。\n3.  执行异常时，根据最近版本修改的内容，定位系统错误的原因。\n\n最基本的版本管理如下图\n\n![](/assets/images/2014/01/23/mt-confhub/confhub_normal_version_control.jpg)\n\n这种基本的版本管理方案可以存储配置的历史变更。但实际使用中，并不能满足需求。\n\n在实际的配置使用时，配置需要最终进入生产环境，如报表开发平台的配置产生报表供分析人员使用，ETL开放平台的配置加入调度定时处理数据等。这些生产环境的配置的改动需要经过数据组审核。但在开发过程中，配置需要不停的变更。所以希望版本管理能支持在既不影响线上实际使用的配置的前提下，能够随意修改测试使用的配置。为了解决这种需求，我们对版本管理的逻辑进行了修改。如下图所示\n\n![](/assets/images/2014/01/23/mt-confhub/confhub_version_control.jpg)\n\n在用户需要修改配置时，在测试环境版本中增加新的版本。测试时，使用最新的测试环境版本的配置进行测试。当用户需要更新生产环境中使用的配置时，向数据组提交上线申请，系统会自动的将最新的测试环境版本和最新的生产环境版本的配置进行对比，并将对比结果发给相应负责人审核。审核通过的配置会被添加到生产环境版本中。\n\n通过这种版本管理方法，既保证了生产环境版本是严格受控的，又能保证用户可以自由的测试。\n\n## 审核\n\n为了保证生产环境运行的配置的质量，生产环境的配置的变更都必须进行审核。在这一点上，我们使用“人工审核，系统辅助”的方案。人工审核，确保配置质量，系统辅助，尽量减少审核人的工作量。\n\n审核过程流程图如下：\n\n![](/assets/images/2014/01/23/mt-confhub/confhub_review.jpg)\n\n为了提高审核的效率，减少人工审核工作量，用户在开放平台，即配置的使用方，提交配置变更申请。配置使用方会首先对配置进行基本校验，校验通过的配置变更才会提交到配置管理系统。\n\n# 未来发展\n\n目前，ConfHub满足了现有开放平台的配置管理需求，有效的支持各个开放平台的发展。\n\n后续，ConfHub主要发展方向是\n\n1.  部分开放平台对配置管理有特殊的需求。在提供大体相同的配置管理方式后，ConfHub也需要提供一些更精细，更定制的配置管理方式。\n2.  开放的方式不止有开放平台一种，而各种不同的开放方式，都有需要管理的配置。管理其他开放方式的配置，也是ConfHub的目标。\n \n---\n\n* 原文链接：[数据开放平台的配置管理](http://tech.meituan.com/mt-confhub.html)\n","tags":["ConfHub"],"categories":["Configuration"]},{"title":"基于Flume的美团日志收集系统(二)改进和优化","url":"%2F2013%2F2013-12-09-flume-log-system-optimization.%2F","content":"\n在《基于Flume的美团日志收集系统(一)架构和设计》中，我们详述了基于Flume的美团日志收集系统的架构设计，以及为什么做这样的设计。在本节中，我们将会讲述在实际部署和使用过程中遇到的问题，对Flume的功能改进和对系统做的优化。\n\n## 1 Flume的问题总结\n\n在Flume的使用过程中，遇到的主要问题如下：\n\na. Channel“水土不服”：使用固定大小的MemoryChannel在日志高峰时常报队列大小不够的异常；使用FileChannel又导致IO繁忙的问题；\n\nb. HdfsSink的性能问题：使用HdfsSink向Hdfs写日志，在高峰时间速度较慢；\n\nc. 系统的管理问题：配置升级，模块重启等；\n\n## 2 Flume的功能改进和优化点\n\n从上面的问题中可以看到，有一些需求是原生Flume无法满足的，因此，基于开源的Flume我们增加了许多功能，修改了一些Bug，并且进行一些调优。下面将对一些主要的方面做一些说明。\n\n### 2.1 增加Zabbix monitor服务\n\n一方面，Flume本身提供了http, ganglia的监控服务，而我们目前主要使用zabbix做监控。因此，我们为Flume添加了zabbix监控模块，和sa的监控服务无缝融合。\n\n另一方面，净化Flume的metrics。只将我们需要的metrics发送给zabbix，避免 zabbix server造成压力。目前我们最为关心的是Flume能否及时把应用端发送过来的日志写到Hdfs上， 对应关注的metrics为：\n\n*   Source : 接收的event数和处理的event数\n*   Channel : Channel中拥堵的event数\n*   Sink : 已经处理的event数\n\n### 2.2 为HdfsSink增加自动创建index功能\n\n首先，我们的HdfsSink写到hadoop的文件采用lzo压缩存储。 HdfsSink可以读取hadoop配置文件中提供的编码类列表，然后通过配置的方式获取使用何种压缩编码，我们目前使用lzo压缩数据。采用lzo压缩而非bz2压缩，是基于以下测试数据：\n\nevent大小(Byte)\tsink.batch-size\thdfs.batchSize\t压缩格式\t总数据大小(G)\t耗时(s)\t平均events/s\t压缩后大小(G)\n544\t300\t10000\tbz2\t9.1\t2448\t6833\t1.36\n544\t300\t10000\tlzo\t9.1\t612\t27333\t3.49\n\n其次，我们的HdfsSink增加了创建lzo文件后自动创建index功能。Hadoop提供了对lzo创建索引，使得压缩文件是可切分的，这样Hadoop Job可以并行处理数据文件。HdfsSink本身lzo压缩，但写完lzo文件并不会建索引，我们在close文件之后添加了建索引功能。\n\n```java\n  /**\n   * Rename bucketPath file from .tmp to permanent location.\n   */\n  private void renameBucket() throws IOException, InterruptedException {\n      if(bucketPath.equals(targetPath)) {\n              return;\n        }\n\n        final Path srcPath = new Path(bucketPath);\n        final Path dstPath = new Path(targetPath);\n\n        callWithTimeout(new CallRunner<Object>() {\n              @Override\n              public Object call() throws Exception {\n                if(fileSystem.exists(srcPath)) { // could block\n                      LOG.info(\"Renaming \" + srcPath + \" to \" + dstPath);\n                     fileSystem.rename(srcPath, dstPath); // could block\n\n                      //index the dstPath lzo file\n                      if (codeC != null && \".lzo\".equals(codeC.getDefaultExtension()) ) {\n                              LzoIndexer lzoIndexer = new LzoIndexer(new Configuration());\n                              lzoIndexer.index(dstPath);\n                      }\n                }\n                return null;\n              }\n    });\n}\n```\n\n### 2.3 增加HdfsSink的开关\n\n我们在HdfsSink和DualChannel中增加开关，当开关打开的情况下，HdfsSink不再往Hdfs上写数据，并且数据只写向DualChannel中的FileChannel。以此策略来防止Hdfs的正常停机维护。\n\n### 2.4 增加DualChannel\n\nFlume本身提供了MemoryChannel和FileChannel。MemoryChannel处理速度快，但缓存大小有限，且没有持久化；FileChannel则刚好相反。我们希望利用两者的优势，在Sink处理速度够快，Channel没有缓存过多日志的时候，就使用MemoryChannel，当Sink处理速度跟不上，又需要Channel能够缓存下应用端发送过来的日志时，就使用FileChannel，由此我们开发了DualChannel，能够智能的在两个Channel之间切换。\n\n其具体的逻辑如下：\n\n```java\n/***\n * putToMemChannel indicate put event to memChannel or fileChannel\n * takeFromMemChannel indicate take event from memChannel or fileChannel\n * */\nprivate AtomicBoolean putToMemChannel = new AtomicBoolean(true);\nprivate AtomicBoolean takeFromMemChannel = new AtomicBoolean(true);\n\nvoid doPut(Event event) {\n        if (switchon && putToMemChannel.get()) {\n              //往memChannel中写数据\n              memTransaction.put(event);\n\n              if ( memChannel.isFull() || fileChannel.getQueueSize() > 100) {\n                putToMemChannel.set(false);\n              }\n        } else {\n              //往fileChannel中写数据\n              fileTransaction.put(event);\n        }\n  }\n\nEvent doTake() {\n    Event event = null;\n    if ( takeFromMemChannel.get() ) {\n        //从memChannel中取数据\n        event = memTransaction.take();\n        if (event == null) {\n            takeFromMemChannel.set(false);\n        } \n    } else {\n        //从fileChannel中取数据\n        event = fileTransaction.take();\n        if (event == null) {\n            takeFromMemChannel.set(true);\n\n            putToMemChannel.set(true);\n        } \n    }\n    return event;\n}\n```\n\n### 2.5 增加NullChannel\n\nFlume提供了NullSink，可以把不需要的日志通过NullSink直接丢弃，不进行存储。然而，Source需要先将events存放到Channel中，NullSink再将events取出扔掉。为了提升性能，我们把这一步移到了Channel里面做，所以开发了NullChannel。\n\n### 2.6 增加KafkaSink\n\n为支持向Storm提供实时数据流，我们增加了KafkaSink用来向Kafka写实时数据流。其基本的逻辑如下：\n\n```java\npublic class KafkaSink extends AbstractSink implements Configurable {\n        private String zkConnect;\n        private Integer zkTimeout;\n        private Integer batchSize;\n        private Integer queueSize;\n        private String serializerClass;\n        private String producerType;\n        private String topicPrefix;\n\n        private Producer<String, String> producer;\n\n        public void configure(Context context) {\n            //读取配置，并检查配置\n        }\n\n        @Override\n        public synchronized void start() {\n            //初始化producer\n        }\n\n        @Override\n        public synchronized void stop() {\n            //关闭producer\n        }\n\n        @Override\n        public Status process() throws EventDeliveryException {\n\n            Status status = Status.READY;\n\n            Channel channel = getChannel();\n            Transaction tx = channel.getTransaction();\n            try {\n                    tx.begin();\n\n                    //将日志按category分队列存放\n                    Map<String, List<String>> topic2EventList = new HashMap<String, List<String>>();\n\n                    //从channel中取batchSize大小的日志，从header中获取category，生成topic，并存放于上述的Map中；\n\n                    //将Map中的数据通过producer发送给kafka \n\n                   tx.commit();\n            } catch (Exception e) {\n                    tx.rollback();\n                    throw new EventDeliveryException(e);\n            } finally {\n                tx.close();\n            }\n            return status;\n        }\n}\n```\n\n### 2.7 修复和scribe的兼容问题\n\nScribed在通过ScribeSource发送数据包给Flume时，大于4096字节的包，会先发送一个Dummy包检查服务器的反应，而Flume的ScribeSource对于logentry.size()=0的包返回TRY_LATER，此时Scribed就认为出错，断开连接。这样循环反复尝试，无法真正发送数据。现在在ScribeSource的Thrift接口中，对size为0的情况返回OK，保证后续正常发送数据。\n\n## 3.  Flume系统调优经验总结\n\n### 3.1 基础参数调优经验\n\n*   HdfsSink中默认的serializer会每写一行在行尾添加一个换行符，我们日志本身带有换行符，这样会导致每条日志后面多一个空行，修改配置不要自动添加换行符；\n\n```java\nlc.sinks.sink_hdfs.serializer.appendNewline = false\n```\n\n*   调大MemoryChannel的capacity，尽量利用MemoryChannel快速的处理能力；\n*   调大HdfsSink的batchSize，增加吞吐量，减少hdfs的flush次数；\n*   适当调大HdfsSink的callTimeout，避免不必要的超时错误；\n\n### 3.2 HdfsSink获取Filename的优化\n\nHdfsSink的path参数指明了日志被写到Hdfs的位置，该参数中可以引用格式化的参数，将日志写到一个动态的目录中。这方便了日志的管理。例如我们可以将日志写到category分类的目录，并且按天和按小时存放：\n\n```java\nlc.sinks.sink_hdfs.hdfs.path = /user/hive/work/orglog.db/%{category}/dt=%Y%m%d/hour=%H\n```\n\nHdfsS ink中处理每条event时，都要根据配置获取此event应该写入的Hdfs path和filename，默认的获取方法是通过正则表达式替换配置中的变量，获取真实的path和filename。因为此过程是每条event都要做的操作，耗时很长。通过我们的测试，20万条日志，这个操作要耗时6-8s左右。\n\n由于我们目前的path和filename有固定的模式，可以通过字符串拼接获得。而后者比正则匹配快几十倍。拼接定符串的方式，20万条日志的操作只需要几百毫秒。\n\n### 3.3 HdfsSink的b/m/s优化\n\n在我们初始的设计中，所有的日志都通过一个Channel和一个HdfsSink写到Hdfs上。我们来看一看这样做有什么问题。\n\n首先，我们来看一下HdfsSink在发送数据的逻辑：\n\n```java\n//从Channel中取batchSize大小的events\nfor (txnEventCount = 0; txnEventCount < batchSize; txnEventCount++) {\n    //对每条日志根据category append到相应的bucketWriter上；\n    bucketWriter.append(event);\n｝\n\nfor (BucketWriter bucketWriter : writers) {\n    //然后对每一个bucketWriter调用相应的flush方法将数据flush到Hdfs上\n    bucketWriter.flush();\n｝\n```\n\n假设我们的系统中有100个category，batchSize大小设置为20万。则每20万条数据，就需要对100个文件进行append或者flush操作。\n\n其次，对于我们的日志来说，基本符合80/20原则。即20%的category产生了系统80%的日志量。这样对大部分日志来说，每20万条可能只包含几条日志，也需要往Hdfs上flush一次。\n\n上述的情况会导致HdfsSink写Hdfs的效率极差。下图是单Channel的情况下每小时的发送量和写hdfs的时间趋势图。\n\n![](2013/12/09/flume-log-system-optimization/single_hdfssink.png)\n\n鉴于这种实际应用场景，我们把日志进行了大小归类，分为big, middle和small三类，这样可以有效的避免小日志跟着大日志一起频繁的flush，提升效果明显。下图是分队列后big队列的每小时的发送量和写hdfs的时间趋势图。\n\n![](2013/12/09/flume-log-system-optimization/multi_hdfssink.png)\n\n## 4 未来发展\n\n目前，Flume日志收集系统提供了一个高可用，高可靠，可扩展的分布式服务，已经有效地支持了美团的日志数据收集工作。\n\n后续，我们将在如下方面继续研究：\n\n*   日志管理系统：图形化的展示和控制日志收集系统；\n\n*   跟进社区发展：跟进Flume 1.5的进展，同时回馈社区；\n\n---\n\n* 原文链接：[基于Flume的美团日志收集系统(二)改进和优化](http://tech.meituan.com/mt-log-system-optimization.html)\n","tags":["Optimization"],"categories":["Log"]},{"title":"基于Flume的美团日志收集系统(一)架构和设计","url":"%2F2013%2F2013-12-09-flume-log-system-arch%2F","content":" \n美团的日志收集系统负责美团的所有业务日志的收集，并分别给Hadoop平台提供离线数据和Storm平台提供实时数据流。美团的日志收集系统基于Flume设计和搭建而成。\n\n《基于Flume的美团日志收集系统》将分两部分给读者呈现美团日志收集系统的架构设计和实战经验。\n\n第一部分架构和设计，将主要着眼于日志收集系统整体的架构设计，以及为什么要做这样的设计。\n\n第二部分改进和优化，将主要着眼于实际部署和使用过程中遇到的问题，对Flume做的功能修改和优化等。\n\n## 1 日志收集系统简介\n\n日志收集是大数据的基石。\n\n许多公司的业务平台每天都会产生大量的日志数据。收集业务日志数据，供离线和在线的分析系统使用，正是日志收集系统的要做的事情。高可用性，高可靠性和可扩展性是日志收集系统所具有的基本特征。\n\n目前常用的开源日志收集系统有Flume, Scribe等。Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，目前已经是Apache的一个子项目。Scribe是Facebook开源的日志收集系统，它为日志的分布式收集，统一处理提供一个可扩展的，高容错的简单方案。\n\n## 2 常用的开源日志收集系统对比\n\n下面将对常见的开源日志收集系统Flume和Scribe的各方面进行对比。对比中Flume将主要采用Apache下的Flume-NG为参考对象。同时，我们将常用的日志收集系统分为三层（Agent层，Collector层和Store层）来进行对比。\n\n| 对比项\t| Flume-NG\t| Scribe |\n| ----- | --------- | ------ |\n| 使用语言\t| Java\t| c/c++ |\n| 容错性\t| Agent和Collector间，Collector和Store间都有容错性，且提供三种级别的可靠性保证；\t| Agent和Collector间, Collector和Store之间有容错性； |\n| 负载均衡\t| Agent和Collector间，Collector和Store间有LoadBalance和Failover两种模式\t| 无\n| 可扩展性\t| 好\t| 好 |\n| Agent丰富程度\t| 提供丰富的Agent，包括avro/thrift socket, text, tail等\t| 主要是thrift端口 |\n| Store丰富程度\t| 可以直接写hdfs, text, console, tcp；写hdfs时支持对text和sequence的压缩；\t| 提供buffer, network, file(hdfs, text)等 |\n| 代码结构\t| 系统框架好，模块分明，易于开发\t| 代码简单 |\n\n## 3 美团日志收集系统架构\n\n美团的日志收集系统负责美团的所有业务日志的收集，并分别给Hadoop平台提供离线数据和Storm平台提供实时数据流。美团的日志收集系统基于Flume设计和搭建而成。目前每天收集和处理约T级别的日志数据。\n\n下图是美团的日志收集系统的整体框架图。\n\n![](/assets/images/2013/12/09/flume-log-system-arch/flume_base_arch.png)\n\na. 整个系统分为三层：Agent层，Collector层和Store层。其中Agent层每个机器部署一个进程，负责对单机的日志收集工作；Collector层部署在中心服务器上，负责接收Agent层发送的日志，并且将日志根据路由规则写到相应的Store层中；Store层负责提供永久或者临时的日志存储服务，或者将日志流导向其它服务器。\n\nb. Agent到Collector使用LoadBalance策略，将所有的日志均衡地发到所有的Collector上，达到负载均衡的目标，同时并处理单个Collector失效的问题。\n\nc. Collector层的目标主要有三个：SinkHdfs, SinkKafka和SinkBypass。分别提供离线的数据到Hdfs，和提供实时的日志流到Kafka和Bypass。其中SinkHdfs又根据日志量的大小分为SinkHdfs_b，SinkHdfs_m和SinkHdfs_s三个Sink，以提高写入到Hdfs的性能，具体见后面介绍。\n\nd. 对于Store来说，Hdfs负责永久地存储所有日志；Kafka存储最新的7天日志，并给Storm系统提供实时日志流；Bypass负责给其它服务器和应用提供实时日志流。\n\n下图是美团的日志收集系统的模块分解图，详解Agent, Collector和Bypass中的Source, Channel和Sink的关系。\n\n![](/assets/images/2013/12/09/flume-log-system-arch/flume_arch.png)\n\na. 模块命名规则：所有的Source以src开头，所有的Channel以ch开头，所有的Sink以sink开头；\n\nb. Channel统一使用美团开发的DualChannel，具体原因后面详述；对于过滤掉的日志使用NullChannel，具体原因后面详述；\n\nc. 模块之间内部通信统一使用Avro接口；\n\n## 4 架构设计考虑\n\n下面将从可用性，可靠性，可扩展性和兼容性等方面，对上述的架构做细致的解析。\n\n### 4.1 可用性(availablity)\n\n对日志收集系统来说，可用性(availablity)指固定周期内系统无故障运行总时间。要想提高系统的可用性，就需要消除系统的单点，提高系统的冗余度。下面来看看美团的日志收集系统在可用性方面的考虑。\n\n#### 4.1.1 Agent死掉\n\nAgent死掉分为两种情况：机器死机或者Agent进程死掉。\n\n对于机器死机的情况来说，由于产生日志的进程也同样会死掉，所以不会再产生新的日志，不存在不提供服务的情况。\n\n对于Agent进程死掉的情况来说，确实会降低系统的可用性。对此，我们有下面三种方式来提高系统的可用性。首先，所有的Agent在supervise的方式下启动，如果进程死掉会被系统立即重启，以提供服务。其次，对所有的Agent进行存活监控，发现Agent死掉立即报警。最后，对于非常重要的日志，建议应用直接将日志写磁盘，Agent使用spooldir的方式获得最新的日志。\n\n#### 4.1.2 Collector死掉\n\n由于中心服务器提供的是对等的且无差别的服务，且Agent访问Collector做了LoadBalance和重试机制。所以当某个Collector无法提供服务时，Agent的重试策略会将数据发送到其它可用的Collector上面。所以整个服务不受影响。\n\n#### 4.1.3 Hdfs正常停机\n\n我们在Collector的HdfsSink中提供了开关选项，可以控制Collector停止写Hdfs，并且将所有的events缓存到FileChannel的功能。\n\n#### 4.1.4 Hdfs异常停机或不可访问\n\n假如Hdfs异常停机或不可访问，此时Collector无法写Hdfs。由于我们使用DualChannel，Collector可以将所收到的events缓存到FileChannel，保存在磁盘上，继续提供服务。当Hdfs恢复服务以后，再将FileChannel中缓存的events再发送到Hdfs上。这种机制类似于Scribe，可以提供较好的容错性。\n\n#### 4.1.5 Collector变慢或者Agent/Collector网络变慢\n\n如果Collector处理速度变慢（比如机器load过高）或者Agent/Collector之间的网络变慢，可能导致Agent发送到Collector的速度变慢。同样的，对于此种情况，我们在Agent端使用DualChannel，Agent可以将收到的events缓存到FileChannel，保存在磁盘上，继续提供服务。当Collector恢复服务以后，再将FileChannel中缓存的events再发送给Collector。\n\n#### 4.1.6 Hdfs变慢\n\n当Hadoop上的任务较多且有大量的读写操作时，Hdfs的读写数据往往变的很慢。由于每天，每周都有高峰使用期，所以这种情况非常普遍。\n\n对于Hdfs变慢的问题，我们同样使用DualChannel来解决。当Hdfs写入较快时，所有的events只经过MemChannel传递数据，减少磁盘IO，获得较高性能。当Hdfs写入较慢时，所有的events只经过FileChannel传递数据，有一个较大的数据缓存空间。\n\n### 4.2 可靠性(reliability)\n\n对日志收集系统来说，可靠性(reliability)是指Flume在数据流的传输过程中，保证events的可靠传递。\n\n对Flume来说，所有的events都被保存在Agent的Channel中，然后被发送到数据流中的下一个Agent或者最终的存储服务中。那么一个Agent的Channel中的events什么时候被删除呢？当且仅当它们被保存到下一个Agent的Channel中或者被保存到最终的存储服务中。这就是Flume提供数据流中点到点的可靠性保证的最基本的单跳消息传递语义。\n\n那么Flume是如何做到上述最基本的消息传递语义呢？\n\n首先，Agent间的事务交换。Flume使用事务的办法来保证event的可靠传递。Source和Sink分别被封装在事务中，这些事务由保存event的存储提供或者由Channel提供。这就保证了event在数据流的点对点传输中是可靠的。在多级数据流中，如下图，上一级的Sink和下一级的Source都被包含在事务中，保证数据可靠地从一个Channel到另一个Channel转移。\n\n![](/assets/images/2013/12/09/flume-log-system-arch/flume_trans.png)\n\n其次，数据流中 Channel的持久性。Flume中MemoryChannel是可能丢失数据的（当Agent死掉时），而FileChannel是持久性的，提供类似mysql的日志机制，保证数据不丢失。\n\n### 4.3 可扩展性(scalability)\n\n对日志收集系统来说，可扩展性(scalability)是指系统能够线性扩展。当日志量增大时，系统能够以简单的增加机器来达到线性扩容的目的。\n\n对于基于Flume的日志收集系统来说，需要在设计的每一层，都可以做到线性扩展地提供服务。下面将对每一层的可扩展性做相应的说明。\n\n#### 4.3.1 Agent层\n\n对于Agent这一层来说，每个机器部署一个Agent，可以水平扩展，不受限制。一个方面，Agent收集日志的能力受限于机器的性能，正常情况下一个Agent可以为单机提供足够服务。另一方面，如果机器比较多，可能受限于后端Collector提供的服务，但Agent到Collector是有Load Balance机制，使得Collector可以线性扩展提高能力。\n\n#### 4.3.2 Collector层\n\n对于Collector这一层，Agent到Collector是有Load Balance机制，并且Collector提供无差别服务，所以可以线性扩展。其性能主要受限于Store层提供的能力。\n\n#### 4.3.3 Store层\n\n对于Store这一层来说，Hdfs和Kafka都是分布式系统，可以做到线性扩展。Bypass属于临时的应用，只对应于某一类日志，性能不是瓶颈。\n\n### 4.4 Channel的选择\n\nFlume1.4.0中，其官方提供常用的MemoryChannel和FileChannel供大家选择。其优劣如下：\n\n*   MemoryChannel: 所有的events被保存在内存中。优点是高吞吐。缺点是容量有限并且Agent死掉时会丢失内存中的数据。\n\n*   FileChannel: 所有的events被保存在文件中。优点是容量较大且死掉时数据可恢复。缺点是速度较慢。\n\n上述两种Channel，优缺点相反，分别有自己适合的场景。然而，对于大部分应用来说，我们希望Channel可以同提供高吞吐和大缓存。基于此，我们开发了DualChannel。\n\n*   DualChannel：基于 MemoryChannel和 FileChannel开发。当堆积在Channel中的events数小于阈值时，所有的events被保存在MemoryChannel中，Sink从MemoryChannel中读取数据； 当堆积在Channel中的events数大于阈值时， 所有的events被自动存放在FileChannel中，Sink从FileChannel中读取数据。这样当系统正常运行时，我们可以使用MemoryChannel的高吞吐特性；当系统有异常时，我们可以利用FileChannel的大缓存的特性。\n\n### 4.5 和scribe兼容\n\n在设计之初，我们就要求每类日志都有一个category相对应，并且Flume的Agent提供AvroSource和ScribeSource两种服务。这将保持和之前的Scribe相对应，减少业务的更改成本。\n\n### 4.6 权限控制\n\n在目前的日志收集系统中，我们只使用最简单的权限控制。只有设定的category才可以进入到存储系统。所以目前的权限控制就是category过滤。\n\n如果权限控制放在Agent端，优势是可以较好地控制垃圾数据在系统中流转。但劣势是配置修改麻烦，每增加一个日志就需要重启或者重载Agent的配置。\n\n如果权限控制放在Collector端，优势是方便进行配置的修改和加载。劣势是部分没有注册的数据可能在Agent/Collector之间传输。\n\n考虑到Agent/Collector之间的日志传输并非系统瓶颈，且目前日志收集属内部系统，安全问题属于次要问题，所以选择采用Collector端控制。\n\n### 4.7 提供实时流\n\n美团的部分业务，如实时推荐，反爬虫服务等服务，需要处理实时的数据流。因此我们希望Flume能够导出一份实时流给Kafka/Storm系统。\n\n一个非常重要的要求是实时数据流不应该受到其它Sink的速度影响，保证实时数据流的速度。这一点，我们是通过Collector中设置不同的Channel进行隔离，并且DualChannel的大容量保证了日志的处理不受Sink的影响。\n\n## 5 系统监控\n\n对于一个大型复杂系统来说，监控是必不可少的部分。设计合理的监控，可以对异常情况及时发现，只要有一部手机，就可以知道系统是否正常运作。对于美团的日志收集系统，我们建立了多维度的监控，防止未知的异常发生。\n\n### 5.1 发送速度，拥堵情况，写Hdfs速度\n\n通过发送给zabbix的数据，我们可以绘制出发送数量、拥堵情况和写Hdfs速度的图表，对于超预期的拥堵，我们会报警出来查找原因。\n\n下面是Flume Collector HdfsSink写数据到Hdfs的速度截图：\n\n![](/assets/images/2013/12/09/flume-log-system-arch/flume_monitor_1.png)\n\n下面是Flume Collector的FileChannel中拥堵的events数据量截图：\n\n![](/assets/images/2013/12/09/flume-log-system-arch/flume_monitor_2.png)\n\n### 5.2 flume写hfds状态的监控\n\nFlume写入Hdfs会先生成tmp文件，对于特别重要的日志，我们会每15分钟左右检查一下各个Collector是否都产生了tmp文件，对于没有正常产生tmp文件的Collector和日志我们需要检查是否有异常。这样可以及时发现Flume和日志的异常.\n\n### 5.3 日志大小异常监控\n\n对于重要的日志，我们会每个小时都监控日志大小周同比是否有较大波动，并给予提醒，这个报警有效的发现了异常的日志，且多次发现了应用方日志发送的异常，及时给予了对方反馈，帮助他们及早修复自身系统的异常。\n\n通过上述的讲解，我们可以看到，基于Flume的美团日志收集系统已经是具备高可用性，高可靠性，可扩展等特性的分布式服务。\n\n---\n\n* 原文链接：[基于Flume的美团日志收集系统(一)架构和设计](http://tech.meituan.com/mt-log-system-arch.html)\n","tags":["Architecture"],"categories":["Log"]},{"title":"美团数据仓库的演进","url":"%2F2013%2F2013-12-05-meituan-datawarehouse-evolution%2F","content":"\n美团数据仓库，在过去的两年中，与我们的业务一起高速发展。在这一演进过程中，有很多值得总结和沉淀的内容。这篇文档回顾下美团数据仓库这两年发展过程中遇到的各种问题，为什么选择了现在的技术方案，每一个功能和模块是在什么情况下产生的，解决的是什么问题，中间有过哪些弯路。既可以作为大家熟悉美团数据仓库构建过程的一篇文档，也可以作为初次建立数据仓库的参考。\n\n### 史前时代\n\n在正式建设美团数据仓库之前，数据组也为各部门提供数据支持，不过那个时候的数据需求还比较少，而且也相对简单。\n\n通常的做法是：\n\n* 工程师写一段PHP或者Shell脚本，从命令行输入参数。\n\n* 自己连接数据库，通常是一个业务数据库的从库，将需要的原始数据提取出来。\n\n* 在内存中计算数据。\n\n* 然后将结果写入一个专门存放统计结果的DB。\n\n* 再写一个PHP页面作为报表提供给需求方。\n\n这是简单明了的流程，但是随着需求的增加和精细化，有一些问题变得很棘手，并严重影响的开发效率：\n\n* 有很多重复劳动和代码，比如连接数据库的代码，每个人都要写，各种写法不同，分布在很多地方，如果哪个DB的连接方法变更了，需要更改很多地方。\n\n* 中间数据缺失，中间计算结果不能共享。比如每个Deal每天的销量，不同的人写报表，每人都可能要重算一次。\n\n* 很难管理和维护，程序语言五花八门，同一指标可以写多种统计方法，各种语言各种执行方式，缺少文档，其他人很难接手维护。\n\n* 数据的清洗和转换没有统一方法，比如，哪天是每月第一天或每周第几天这种需求，靠手工调用各种时间函数来计算，非常容易出错。\n\n* 不同数据源的数据很难综合使用， 比如一个数 据需要使用主站的数据和合同系统的数据， 要把这些数据组织在一起就很麻烦\n\n* 为了解决这些问题，在2011年Q2初，数据组开始搭建美团的数据仓库。\n\n### 引入ETL\n\n数据仓库的学术定义有很多版本和特点，其中有几个词能概括这一段工作的特点，规范和集成。\n\n首先需要建立一个DB用于保存从各个数据源提取出来的数据。\n\n* 第一，解决不同数据源的数据联合使用的问题。\n\n* 第二，因为是独立的DB，可以进行复杂的计算而不用考虑会影响线上个系统的DB。\n\n* 第三，可以保留大量需要重复使用的中间数据。\n\n* 第四，数据在首次进入数据仓库时，就可以进行清洗整理，去掉无效数据和脏数据，添加常用字段比如 datekey。\n\n这一时间的一个重要工作是，引入了一个工具——ETL。ETL是Extract（抽取），Transform（转换），Load（载入）的首字母组合。顾名思义，ETL工具的功能就是抽取数据，经过加工后，再载入到新的位置。\n\nETL的优点是：\n\n* 封装了到各个数据库的连接，使得工程师只需要关注数据的抽取和转换逻辑，而不必处理各种数据库的连接细节。\n\n* 将数据抽取和转换统一使用SQL来表示，形式化的统一使得理解处理过程变的简单，便于不同的人协作开发，同时，用SQL表示逻辑将各种复杂的统计交给关系数据库来处理，也降低了出错的可能性。数据抽取的过程中同时完成各种清洗和转换，替换空值，规范时间表示等。\n\n这一时间也同时确定了很多规范:\n\n用数据表示逻辑，典型例子是，不再使用各种时间函数来计算时间，而是建立一个日期表，把某一天的各种信息属性全部算出来存在一张表里，需要的时候只要连表就可以得到。大大降低了时间逻辑出错的可能性并简化了开发。\n\n将数据分为维度数据，事实数据，衍生数据，聚合数据等类型， 以及第一版的命名规范。 为后续数据的组织和管理奠定了基础。\n\n数据仓库的基础数据建设，一直是数据组的一个主要工作，直到2011年Q4，随着各种数据需求的增加，在如何使用数据上，有了一些新想法。\n\n### 尝试OLAP\n\n要做数据仓库，而不是数据坟墓，数据如果不被使用，就毫无用处。怎么能供各部门更好的使用这些数据呢？我们要做平台，可供人去探索数据的平台。\n\n2011年下半年，随着美团业务的高速发展，用数据支撑运营变得越来越重要，各种数据需求出现了一个井喷期，开发人手比较少，一时间有些捉襟见肘。\n\n有没有方法能让需求方自助的获取数据，而不依赖RD呢，想到了一个非常流行的概念是OLAP——联机分析处理（相对于OLTP——联机事务处理），目标是做成一个自助探索工具的平台。\n\n从2011年Q4开始到2012Q1，数据组开始调研试用开源的OLAP工具套件。耗时较长，从调研和最后试用的情况看，现有的OLAP系统不适合我们。\n\n有几个主要的问题：\n\n* 开发和使用太复杂，成本太高。\n\n* 产品成熟度较低，很多数据需求没法支持。\n\n* 笨重，不太适应互联网公司快速灵活的节奏。\n\n因为上述原因，到2012Q1， 放弃了OLAP的尝试。\n\n同时在这个时间点上，公司对数据需求的增长，暴露出了数据仓库的很多问题，可以说是需求走在了技术的前面，迫使我们集中力量做很多大规模的升级。\n\n### 数据仓库是一套完整的环境\n\n2012Q1时，数据仓库出现了很多新的棘手的问题。\n\n* 首先，有哪些流程在线我们不清楚，什么时间执行的，有没有按时执行不清楚。报表出了问题要查流程历史记录都很难查。\n\n* 其次，我们已经有了几百个ETL流程，流程之间有执行顺序的依赖关系，但是没有好的工具来管理，靠crontab里设定执行时间间隔。经常出现上游还没有算完，下游就启动了，会出现脏数据。另一方面，并行开发太多，一个人的修改，不知道会不会影响别人，经常出现冲突。\n\n* 第三，每次都用PHP手写报表，重复工作太多，开发上线都非常复杂。\n\n* 第四，数据表和指标很多，命名不规范，经常会遇到两个相近概念的比较问题，解释起来非常麻烦，需要遍历整个计算过程才能梳理清楚。\n\n针对这些问题，分别开发了相应的工具。\n\n* 第一个是流程的注册，管理，查看的工具，每个流程都有了户口本和行为记录。\n\n* 第二，写工具分析流程之间的依赖关系，画出关系图。\n\n* 第三，开发调度系统，根据关系图调度ETL流程执行。\n\n* 第四，抽象报表工具，屏蔽复杂的报表页面开发，将报表抽象为SQL和配置。\n\n* 第五，建立数据字典，解释每个指标和名词的意思和计算过程。\n\n通过这几项主要工作，美团数据仓库发展到了一个比较成熟的阶段。也正是经历了这样一个过程，我们深刻体会到，数据仓库不仅仅是一个“数据存储的工具”， 数据仓库应该是一套完整的软件环境，它应该包括：数据抽取，计算，存储，查询，展示，以及管理这些过程的工具。\n\n### 协作开放\n\n美团的数据需求发展非常快，这体现在数据规模的增长，数据分析人员的增长，数据分析复杂程度的增长。2012年下半年，快速发展的数据需求让原有的数据仓库架构达到了瓶颈。无论是DB的计算和存储能力，还是开发人员的精力，都达到了很高的负荷。而且由于开发流程和提取数据的重复劳动很多，团队士气也比较低落。这一时间的迫切工作是，如何能让需求方自助获取数据并分析，如何能让数据的计算和存储方便的扩展。\n\n从2012年中开始，重点推进了几项工作以解决上述问题：\n\n* 第一，建设主题表，将各种数据按照常用的维度展开成宽达几十列上百列的表，使得查数据非常的容易。比如，将一个城市一天的几百个指标放在一行，以城市id和日期作为主键，不用任何连表，使用简单的语法就能获取关于城市的各个角度的数据。类似的主题表还有用户，订单，Deal等角度。丰富的主题表不但简化了报表开发， 也为非技术人员能够自助查询数据提供了方便。\n\n* 第二，开发自助查询工具，培训使用，让各个部门的人都能在数据仓库上查自己需求的数据，培训大家使用SQL，自助完成需求。\n\n* 第三，建立数据集市，按业务拆分，将部分数据导入到各个不同的DB，供业务部门更灵活的数据需求。\n\n* 第四，将数据的存储和计算，向Hadoop/Hive 分布式平台迁移，已达到线性扩展计算和存储能力的需求。\n\n* 第五，开放数据的存储和计算环境，让ETL流程的编写和部署Web化，让其它组有能力的RD，可以自己在数据仓库上部署计算流程，计算自己需要的数据。\n\n这几个工作的周期都比较长，现在也在进行中，效果也十分明显，终于有和需求并肩走在一起，没有落后的压迫感了。但还没有走在需求前面。\n\n### 还有很多挑战\n\n美团的成长速度非常快，数据的规模和复杂度还将十倍百倍的增长；业务多样且变化迅速。如何能够在海量数据基础上进行数据的管理、加工、分析以支持快速成长的业务，后续还面临很多挑战。\n\n我们期待对数据敏感、对管理海量复杂数据、对建设大型互联网电商数据仓库有兴趣的朋友们，加入美团数据仓库团队！欢迎投递简历到 diaoshihan(#)meituan.com\n\n---\n\n* 原文链接：[美团数据仓库的演进](http://tech.meituan.com/meituan-datawarehouse-evolution.html)\n","tags":["Data-Warehouse"],"categories":["Data-Warehouse"]},{"title":"Java Annotation认知(包括框架图、详细介绍、示例说明)","url":"%2F2013%2F2013-09-28-java-annotation%2F","content":" \n## 摘要\n\nJava Annotation是JDK5.0引入的一种注释机制。\n\n网上很多关于Java Annotation的文章，看得人眼花缭乱。Java Annotation本来很简单的，结果说的人没说清楚；弄的看的人更加迷糊。\n\n我按照自己的思路，对Annotation进行了整理。理解 Annotation 的关键，是理解Annotation的语法和用法，对这些内容，我都进行了详细说明；理解Annotation的语法和用法之后，再看Annotation的框架图，可能有更深刻体会。废话就说这么多，下面开始对Annotation进行说明。若您发现文章中存在错误或不足的地方，希望您能指出！\n\n## 第1部分 Annotation架构\n\n先看看Annotation的架构图：\n\n![](/assets/images/2013/09/28/java-annotation/001.jpg)\n\n从中，我们可以看出：\n\n(01) 1个Annotation 和 1个RetentionPolicy关联。\n\n   可以理解为：每1个Annotation对象，都会有唯一的RetentionPolicy属性。\n\n(02) 1个Annotation 和 1~n个ElementType关联。\n\n   可以理解为：对于每1个Annotation对象，可以有若干个ElementType属性。\n\n(03) Annotation 有许多实现类，包括：Deprecated, Documented, Inherited, Override等等。\n\n   Annotation 的每一个实现类，都“和1个RetentionPolicy关联”并且“和1~n个ElementType关联”。\n\n下面，我先介绍框架图的左半边(如下图)，即Annotation, RetentionPolicy, ElementType；然后在就Annotation的实现类进行举例说明。\n\n![](/assets/images/2013/09/28/java-annotation/002.jpg)\n\n## 第2部分 Annotation组成部分\n\n### 1 annotation组成成分\n\njava annotation 的组成中，有3个非常重要的主干类。它们分别是：\n\n(01) Annotation.java\n\n```java\npackage java.lang.annotation;\npublic interface Annotation {\n    boolean equals(Object obj);\n    int hashCode();\n    String toString();\n    Class<? extends Annotation> annotationType();\n}\n```\n\n(02) ElementType.java\n\n```java\npackage java.lang.annotation;\n\npublic enum ElementType {\n    TYPE,               /* 类、接口（包括注释类型）或枚举声明  */\n    FIELD,              /* 字段声明（包括枚举常量）  */\n    METHOD,             /* 方法声明  */\n    PARAMETER,          /* 参数声明  */\n    CONSTRUCTOR,        /* 构造方法声明  */\n    LOCAL_VARIABLE,     /* 局部变量声明  */\n    ANNOTATION_TYPE,    /* 注释类型声明  */\n    PACKAGE             /* 包声明  */\n}\n```\n\n(03) RetentionPolicy.java\n\n```java\npackage java.lang.annotation;\npublic enum RetentionPolicy {\n    SOURCE,            /* Annotation信息仅存在于编译器处理期间，编译器处理完之后就没有该Annotation信息了  */\n    CLASS,             /* 编译器将Annotation存储于类对应的.class文件中。默认行为  */\n    RUNTIME            /* 编译器将Annotation存储于class文件中，并且可由JVM读入 */\n}\n```\n\n说明：\n\n(01) Annotation 就是个接口。\n\n   “每1个Annotation” 都与 “1个RetentionPolicy”关联，并且与 “1～n个ElementType”关联。可以通俗的理解为：每1个Annotation对象，都会有唯一的RetentionPolicy属性；至于ElementType属性，则有1~n个。\n\n(02) ElementType 是Enum枚举类型，它用来指定Annotation的类型。\n\n   “每1个Annotation” 都与 “1～n个ElementType”关联。当Annotation与某个ElementType关联时，就意味着：Annotation有了某种用途。\n   例如，若一个Annotation对象是METHOD类型，则该Annotation只能用来修饰方法。\n\n(03) RetentionPolicy 是Enum枚举类型，它用来指定Annotation的策略。通俗点说，就是不同RetentionPolicy类型的Annotation的作用域不同。\n\n   “每1个Annotation” 都与 “1个RetentionPolicy”关联。\n   a) 若Annotation的类型为 SOURCE，则意味着：Annotation仅存在于编译器处理期间，编译器处理完之后，该Annotation就没用了。\n   例如，“ @Override ”标志就是一个Annotation。当它修饰一个方法的时候，就意味着该方法覆盖父类的方法；并且在编译期间会进行语法检查！编译器处理完后，“@Override”就没有任何作用了。\n   b) 若Annotation的类型为 CLASS，则意味着：编译器将Annotation存储于类对应的.class文件中，它是Annotation的默认行为。\n   c) 若Annotation的类型为 RUNTIME，则意味着：编译器将Annotation存储于class文件中，并且可由JVM读入。\n\n这时，只需要记住“每1个Annotation” 都与 “1个RetentionPolicy”关联，并且与 “1～n个ElementType”关联。学完后面的内容之后，再回头看这些内容，会更容易理解。\n\n## 第3部分 java自带的Annotation\n\n理解了上面的3个类的作用之后，我们接下来可以讲解Annotation实现类的语法定义了。\n\n### 1 Annotation通用定义\n\n```java\n@Documented\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface MyAnnotation1 {\n}\n```\n\n说明：\n\n上面的作用是定义一个Annotation，它的名字是MyAnnotation1。定义了MyAnnotation1之后，我们可以在代码中通过“@MyAnnotation1”来使用它。\n\n其它的，@Documented, @Target, @Retention, @interface都是来修饰MyAnnotation1的。下面分别说说它们的含义：\n\n(01) @interface\n\n   使用@interface定义注解时，意味着它实现了java.lang.annotation.Annotation接口，即该注解就是一个Annotation。\n\n   定义Annotation时，@interface是必须的。\n\n   注意：它和我们通常的implemented实现接口的方法不同。Annotation接口的实现细节都由编译器完成。通过@interface定义注解后，该注解不能继承其他的注解或接口。\n\n(02) @Documented \n\n   类和方法的Annotation在缺省情况下是不出现在javadoc中的。如果使用@Documented修饰该Annotation，则表示它可以出现在javadoc中。\n\n   定义Annotation时，@Documented可有可无；若没有定义，则Annotation不会出现在javadoc中。\n\n(03) @Target(ElementType.TYPE)\n\n   前面我们说过，ElementType 是Annotation的类型属性。而@Target的作用，就是来指定Annotation的类型属性。\n\n   @Target(ElementType.TYPE) 的意思就是指定该Annotation的类型是ElementType.TYPE。这就意味着，MyAnnotation1是来修饰“类、接口（包括注释类型）或枚举声明”的注解。\n\n   定义Annotation时，@Target可有可无。若有@Target，则该Annotation只能用于它所指定的地方；若没有@Target，则该Annotation可以用于任何地方。\n\n(04) @Retention(RetentionPolicy.RUNTIME)\n\n   前面我们说过，RetentionPolicy 是Annotation的策略属性，而@Retention的作用，就是指定Annotation的策略属性。\n\n   @Retention(RetentionPolicy.RUNTIME) 的意思就是指定该Annotation的策略是RetentionPolicy.RUNTIME。这就意味着，编译器会将该Annotation信息保留在.class文件中，并且能被虚拟机读取。\n\n   定义Annotation时，@Retention可有可无。若没有@Retention，则默认是RetentionPolicy.CLASS。\n\n### 2 java自带的Annotation\n\n通过上面的示例，我们能理解：@interface用来声明Annotation，@Documented用来表示该Annotation是否会出现在javadoc中， @Target用来指定Annotation的类型，@Retention用来指定Annotation的策略。\n\n理解这一点之后，我们就很容易理解java中自带的Annotation的实现类，即Annotation架构图的右半边。如下图：\n\n![](/assets/images/2013/09/28/java-annotation/003.jpg)\n\njava 常用的Annotation：\n\n```\n   @Deprecated  -- @Deprecated 所标注内容，不再被建议使用。\n   @Override    -- @Override 只能标注方法，表示该方法覆盖父类中的方法。\n   @Documented  -- @Documented 所标注内容，可以出现在javadoc中。\n   @Inherited   -- @Inherited只能被用来标注“Annotation类型”，它所标注的Annotation具有继承性。\n   @Retention   -- @Retention只能被用来标注“Annotation类型”，而且它被用来指定Annotation的RetentionPolicy属性。\n   @Target      -- @Target只能被用来标注“Annotation类型”，而且它被用来指定Annotation的ElementType属性。\n   @SuppressWarnings -- @SuppressWarnings 所标注内容产生的警告，编译器会对这些警告保持静默。\n```\n\n由于“@Deprecated和@Override”类似，“@Documented, @Inherited, @Retention, @Target”类似；下面，我们只对@Deprecated, @Inherited, @SuppressWarnings 这3个Annotation进行说明。\n\n#### 2.1 @Deprecated\n\n@Deprecated 的定义如下：\n\n```java\n@Documented\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface Deprecated {\n}\n```\n\n说明：\n\n(01) @interface -- 它的用来修饰Deprecated，意味着Deprecated实现了java.lang.annotation.Annotation接口；即Deprecated就是一个注解。\n\n(02) @Documented -- 它的作用是说明该注解能出现在javadoc中。\n\n(03) @Retention(RetentionPolicy.RUNTIME) -- 它的作用是指定Deprecated的策略是RetentionPolicy.RUNTIME。这就意味着，编译器会将Deprecated的信息保留在.class文件中，并且能被虚拟机读取。\n\n(04) @Deprecated 所标注内容，不再被建议使用。\n\n   例如，若某个方法被 @Deprecated 标注，则该方法不再被建议使用。如果有开发人员试图使用或重写被@Deprecated标示的方法，编译器会给相应的提示信息。示例如下:\n\n![](/assets/images/2013/09/28/java-annotation/004.jpg)\n\n源码如下(DeprecatedTest.java)：\n\n```java\npackage com.skywang.annotation;\n\nimport java.util.Date;\nimport java.util.Calendar;\n\npublic class DeprecatedTest {\n    // @Deprecated 修饰 getString1(),表示 它是建议不被使用的函数\n    @Deprecated\n    private static void getString1(){\n        System.out.println(\"Deprecated Method\");\n    }\n    \n    private static void getString2(){\n        System.out.println(\"Normal Method\");\n    }\n    \n    // Date是日期/时间类。java已经不建议使用该类了\n    private static void testDate() {\n        Date date = new Date(113, 8, 25);\n        System.out.println(date.getYear());\n    }\n    // Calendar是日期/时间类。java建议使用Calendar取代Date表示“日期/时间”\n    private static void testCalendar() {\n        Calendar cal = Calendar.getInstance();\n        System.out.println(cal.get(Calendar.YEAR));\n    }\n    \n    public static void main(String[] args) {\n        getString1(); \n        getString2();\n        testDate(); \n        testCalendar();\n    }\n}\n```\n\n说明：\n\n上面是eclipse中的截图，比较类中 “getString1() 和 getString2()” 以及 “testDate() 和 testCalendar()” 。\n\n(01) getString1() 被@Deprecated标注，意味着建议不再使用getString1()；所以getString1()的定义和调用时，都会一横线。这一横线是eclipse()对@Deprecated方法的处理。\n\n   getString2() 没有被@Deprecated标注，它的显示正常。\n\n(02) testDate() 调用了Date的相关方法，而java已经建议不再使用Date操作日期/时间。因此，在调用Date的API时，会产生警告信息，途中的warnings。\n\n   testCalendar() 调用了Calendar的API来操作日期/时间，java建议用Calendar取代Date。因此，操作Calendar不回产生warning。\n\n#### 2.2 @Inherited\n\n@Inherited 的定义如下：\n\n```java\n@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.ANNOTATION_TYPE)\npublic @interface Inherited {\n}\n```\n\n说明：\n\n(01) @interface -- 它的用来修饰Inherited，意味着Inherited实现了java.lang.annotation.Annotation接口；即Inherited就是一个注解。\n\n(02) @Documented -- 它的作用是说明该注解能出现在javadoc中。\n\n(03) @Retention(RetentionPolicy.RUNTIME) -- 它的作用是指定Inherited的策略是RetentionPolicy.RUNTIME。这就意味着，编译器会将Inherited的信息保留在.class文件中，并且能被虚拟机读取。\n\n(04) @Target(ElementType.ANNOTATION_TYPE) -- 它的作用是指定Inherited的类型是ANNOTATION_TYPE。这就意味着，@Inherited只能被用来标注“Annotation类型”。\n\n(05) @Inherited 的含义是，它所标注的Annotation将具有继承性。\n\n   假设，我们定义了某个Annotaion，它的名称是MyAnnotation，并且MyAnnotation被标注为@Inherited。现在，某个类Base使用了MyAnnotation，则Base具有了“具有了注解MyAnnotation”；现在，Sub继承了Base，由于MyAnnotation是@Inherited的(具有继承性)，所以，Sub也“具有了注解MyAnnotation”。\n\n@Inherited的使用示例\n\n源码如下(InheritableSon.java)：\n\n```java\n /**\n  * @Inherited 演示示例\n  * \n  * @author skywang\n  * @email kuiwu-wang@163.com\n  */\n package com.skywang.annotation;\n \n import java.lang.annotation.Target;\n import java.lang.annotation.ElementType;\n import java.lang.annotation.Retention;\n import java.lang.annotation.RetentionPolicy;\n import java.lang.annotation.Inherited;\n \n /**\n  * 自定义的Annotation。\n  */\n @Target(ElementType.TYPE)\n @Retention(RetentionPolicy.RUNTIME)\n @Inherited\n @interface Inheritable\n {\n }\n \n @Inheritable\n class InheritableFather\n {\n     public InheritableFather() {\n         // InheritableBase是否具有 Inheritable Annotation\n         System.out.println(\"InheritableFather:\"+InheritableFather.class.isAnnotationPresent(Inheritable.class));\n     }\n }\n \n /**\n  * InheritableSon 类只是继承于 InheritableFather，\n  */\n public class InheritableSon extends InheritableFather\n {\n     public InheritableSon() {\n         super();    // 调用父类的构造函数\n         // InheritableSon类是否具有 Inheritable Annotation\n         System.out.println(\"InheritableSon:\"+InheritableSon.class.isAnnotationPresent(Inheritable.class));\n     }\n     \n     public static void main(String[] args)\n     {\n         InheritableSon is = new InheritableSon();\n     }\n }\n```\n\n运行结果：\n\n```\nInheritableFather:true\nInheritableSon:true\n```\n\n现在，我们对InheritableSon.java进行修改：注释掉“Inheritable的@Inherited注解”。\n\n源码如下(InheritableSon.java)：\n\n```java\n/**\n * @Inherited 演示示例\n * \n * @author skywang\n * @email kuiwu-wang@163.com\n */\npackage com.skywang.annotation;\n\nimport java.lang.annotation.Target;\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Inherited;\n\n/**\n * 自定义的Annotation。\n */\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n//@Inherited\n@interface Inheritable\n{\n}\n\n@Inheritable\nclass InheritableFather\n{\n    public InheritableFather() {\n        // InheritableBase是否具有 Inheritable Annotation\n        System.out.println(\"InheritableFather:\"+InheritableFather.class.isAnnotationPresent(Inheritable.class));\n    }\n}\n\n/**\n * InheritableSon 类只是继承于 InheritableFather，\n */\npublic class InheritableSon extends InheritableFather\n{\n    public InheritableSon() {\n        super();    // 调用父类的构造函数\n        // InheritableSon类是否具有 Inheritable Annotation\n        System.out.println(\"InheritableSon:\"+InheritableSon.class.isAnnotationPresent(Inheritable.class));\n    }\n    \n    public static void main(String[] args)\n    {\n        InheritableSon is = new InheritableSon();\n    }\n}\n```\n\n运行结果：\n\n```\nInheritableFather:true\nInheritableSon:false\n```\n\n对比上面的两个结果，我们发现：当注解Inheritable被@Inherited标注时，它具有继承性。否则，没有继承性。\n\n#### 2.3 @SuppressWarnings\n\n@SuppressWarnings 的定义如下：\n\n```java\n@Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE})\n@Retention(RetentionPolicy.SOURCE)\npublic @interface SuppressWarnings {\n    String[] value();\n}\n```\n\n说明：\n\n(01) @interface -- 它的用来修饰SuppressWarnings，意味着SuppressWarnings实现了java.lang.annotation.Annotation接口；即SuppressWarnings就是一个注解。\n\n(02) @Retention(RetentionPolicy.SOURCE) -- 它的作用是指定SuppressWarnings的策略是RetentionPolicy.SOURCE。这就意味着，SuppressWarnings信息仅存在于编译器处理期间，编译器处理完之后SuppressWarnings就没有作用了。\n\n(03) @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE}) -- 它的作用是指定SuppressWarnings的类型同时包括TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE。\n\n   TYPE意味着，它能标注“类、接口（包括注释类型）或枚举声明”。\n   FIELD意味着，它能标注“字段声明”。\n   METHOD意味着，它能标注“方法”。\n   PARAMETER意味着，它能标注“参数”。\n   CONSTRUCTOR意味着，它能标注“构造方法”。\n   LOCAL_VARIABLE意味着，它能标注“局部变量”。\n\n(04) String[] value(); 意味着，SuppressWarnings能指定参数\n\n(05) SuppressWarnings 的作用是，让编译器对“它所标注的内容”的某些警告保持静默。例如，\"@SuppressWarnings(value={\"deprecation\", \"unchecked\"})\" 表示对“它所标注的内容”中的 “SuppressWarnings不再建议使用警告”和“未检查的转换时的警告”保持沉默。示例如下：\n\n![](/assets/images/2013/09/28/java-annotation/005.jpg)\n\n源码如下(SuppressWarningTest.java)：\n\n```java\npackage com.skywang.annotation;\n\nimport java.util.Date;\n\npublic class SuppressWarningTest {\n\n    //@SuppressWarnings(value={\"deprecation\"})\n    public static void doSomething(){\n        Date date = new Date(113, 8, 26);\n        System.out.println(date);\n    }\n\n    public static void main(String[] args) {\n        doSomething();\n    }\n}\n```\n\n说明：\n\n(01) 左边的图中，没有使用 @SuppressWarnings(value={\"deprecation\"}) , 而Date属于java不再建议使用的类。因此，调用Date的API时，会产生警告。\n\n   而右边的途中，使用了 @SuppressWarnings(value={\"deprecation\"})。因此，编译器对“调用Date的API产生的警告”保持沉默。\n\n补充：SuppressWarnings 常用的关键字的表格\n\n```\ndeprecation  -- 使用了不赞成使用的类或方法时的警告\nunchecked    -- 执行了未检查的转换时的警告，例如当使用集合时没有用泛型 (Generics) 来指定集合保存的类型。\nfallthrough  -- 当 Switch 程序块直接通往下一种情况而没有 Break 时的警告。\npath         -- 在类路径、源文件路径等中有不存在的路径时的警告。\nserial       -- 当在可序列化的类上缺少 serialVersionUID 定义时的警告。\nfinally      -- 任何 finally 子句不能正常完成时的警告。\nall          -- 关于以上所有情况的警告。\n```\n \n## 第4部分 Annotation 的作用\n\nAnnotation 是一个辅助类，它在Junit、Struts、Spring等工具框架中被广泛使用。\n\n我们在编程中经常会使用到的Annotation作用有：\n\n### 1 编译检查\n\nAnnotation具有“让编译器进行编译检查的作用”。\n\n例如，@SuppressWarnings, @Deprecated和@Override都具有编译检查作用。\n\n(01) 关于@SuppressWarnings和@Deprecated，已经在“第3部分”中详细介绍过了。这里就不再举例说明了。\n\n(02) 若某个方法被 @Override的 标注，则意味着该方法会覆盖父类中的同名方法。如果有方法被@Override标示，但父类中却没有“被@Override标注”的同名方法，则编译器会报错。示例如下：\n\n![](/assets/images/2013/09/28/java-annotation/006.jpg)\n\n源码(OverrideTest.java):\n\n```java\npackage com.skywang.annotation;\n\n/**\n * @Override测试程序\n * \n * @author skywang\n * @email kuiwu-wang@163.com\n */\npublic class OverrideTest {\n\n    /**\n     * toString() 在java.lang.Object中定义；\n     * 因此，这里用 @Override 标注是对的。\n     */\n    @Override\n    public String toString(){\n        return \"Override toString\";\n    }\n\n    /**\n     * getString() 没有在OverrideTest的任何父类中定义；\n     * 但是，这里却用 @Override 标注，因此会产生编译错误！\n     */\n    @Override\n    public String getString(){\n        return \"get toString\";\n    }\n    \n    public static void main(String[] args) {\n    }\n}\n```\n\n上面是该程序在eclipse中的截图。从中，我们可以发现“getString()”函数会报错。这是因为“getString() 被@Override所标注，但在OverrideTest的任何父类中都没有定义getString1()函数”。“将getString() 上面的@Override注释掉”，即可解决该错误。\n\n### 2 在反射中使用Annotation\n\n在反射的Class, Method, Field等函数中，有许多于Annotation相关的接口。\n\n这也意味着，我们可以在反射中解析并使用Annotation。\n\n源码如下(AnnotationTest.java)：\n\n```java\npackage com.skywang.annotation;\n\nimport java.lang.annotation.Annotation;\nimport java.lang.annotation.Target;\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Inherited;\nimport java.lang.reflect.Method;\n\n/**\n * Annotation在反射函数中的使用示例\n * \n * @author skywang\n * @email kuiwu-wang@163.com\n */\n@Retention(RetentionPolicy.RUNTIME)\n@interface MyAnnotation {\n    String[] value() default \"unknown\";\n}\n\n/**\n * Person类。它会使用MyAnnotation注解。\n */\nclass Person {\n    \n    /**\n     * empty()方法同时被 \"@Deprecated\" 和 “@MyAnnotation(value={\"a\",\"b\"})”所标注 \n     * (01) @Deprecated，意味着empty()方法，不再被建议使用\n     * (02) @MyAnnotation, 意味着empty() 方法对应的MyAnnotation的value值是默认值\"unknown\"\n     */\n    @MyAnnotation\n    @Deprecated\n    public void empty(){\n        System.out.println(\"\\nempty\");\n    }\n    \n    /**\n     * sombody() 被 @MyAnnotation(value={\"girl\",\"boy\"}) 所标注，\n     * @MyAnnotation(value={\"girl\",\"boy\"}), 意味着MyAnnotation的value值是{\"girl\",\"boy\"}\n     */\n    @MyAnnotation(value={\"girl\",\"boy\"})\n    public void somebody(String name, int age){\n        System.out.println(\"\\nsomebody: \"+name+\", \"+age);\n    }\n}\n\npublic class AnnotationTest {\n\n    public static void main(String[] args) throws Exception {\n        \n        // 新建Person\n        Person person = new Person();\n        // 获取Person的Class实例\n        Class<Person> c = Person.class;\n        // 获取 somebody() 方法的Method实例\n        Method mSomebody = c.getMethod(\"somebody\", new Class[]{String.class, int.class});\n        // 执行该方法\n        mSomebody.invoke(person, new Object[]{\"lily\", 18});\n        iteratorAnnotations(mSomebody);\n        \n\n        // 获取 somebody() 方法的Method实例\n        Method mEmpty = c.getMethod(\"empty\", new Class[]{});\n        // 执行该方法\n        mEmpty.invoke(person, new Object[]{});        \n        iteratorAnnotations(mEmpty);\n    }\n    \n    public static void iteratorAnnotations(Method method) {\n\n        // 判断 somebody() 方法是否包含MyAnnotation注解\n        if(method.isAnnotationPresent(MyAnnotation.class)){\n            // 获取该方法的MyAnnotation注解实例\n            MyAnnotation myAnnotation = method.getAnnotation(MyAnnotation.class);\n            // 获取 myAnnotation的值，并打印出来\n            String[] values = myAnnotation.value();\n            for (String str:values)\n                System.out.printf(str+\", \");\n            System.out.println();\n        }\n        \n        // 获取方法上的所有注解，并打印出来\n        Annotation[] annotations = method.getAnnotations();\n        for(Annotation annotation : annotations){\n            System.out.println(annotation);\n        }\n    }\n}\n```\n\n运行结果：\n\n```\nsomebody: lily, 18\ngirl, boy, \n@com.skywang.annotation.MyAnnotation(value=[girl, boy])\n\nempty\nunknown, \n@com.skywang.annotation.MyAnnotation(value=[unknown])\n@java.lang.Deprecated()\n```\n\n### 3 根据Annotation生成帮助文档\n\n通过给Annotation注解加上@Documented标签，能使该Annotation标签出现在javadoc中。\n\n### 4 能够帮忙查看查看代码\n\n通过@Override, @Deprecated等，我们能很方便的了解程序的大致结构。\n另外，我们也可以通过自定义Annotation来实现一些功能。\n\n---\n\n* 原文链接：[Java Annotation认知(包括框架图、详细介绍、示例说明)](http://www.cnblogs.com/skywang12345/p/3344137.html)\n","tags":["Annotation"],"categories":["Java"]},{"title":"红黑树(一)之 原理和算法详细介绍","url":"%2F2013%2F2013-08-13-red-black-tree-principle-algorithm%2F","content":"\n## 概要\n\n1. 红黑树的介绍\n2. 红黑树的应用\n3. 红黑树的时间复杂度和相关证明\n4. 红黑树的基本操作(一) 左旋和右旋\n5. 红黑树的基本操作(二) 添加\n6. 红黑树的基本操作(三) 删除                       \n\n概述：R-B Tree，又称为“红黑树”。本文参考了《算法导论》中红黑树相关知识，加之自己的理解，然后以图文的形式对红黑树进行说明。本文的主要内容包括：红黑树的特性，红黑树的时间复杂度和它的证明，红黑树的左旋、右旋、插入、删除等操作。\n\n## R-B Tree简介\n\nR-B Tree，全称是Red-Black Tree，又称为“红黑树”，它一种特殊的二叉查找树。红黑树的每个节点上都有存储位表示节点的颜色，可以是红(Red)或黑(Black)。\n\n红黑树的特性:\n\n   （1）每个节点或者是黑色，或者是红色。\n   （2）根节点是黑色。\n   （3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]\n   （4）如果一个节点是红色的，则它的子节点必须是黑色的。\n   （5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。\n\n注意：\n\n   (01) 特性(3)中的叶子节点，是只为空(NIL或null)的节点。\n   (02) 特性(5)，确保没有一条路径会比其他路径长出俩倍。因而，红黑树是相对是接近平衡的二叉树。\n\n红黑树示意图如下：\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/001.jpg)\n\n## 红黑树的应用\n\n红黑树的应用比较广泛，主要是用它来存储有序的数据，它的时间复杂度是O(lgn)，效率非常之高。\n\n例如，Java集合中的TreeSet和TreeMap，C++ STL中的set、map，以及Linux虚拟内存的管理，都是通过红黑树去实现的。\n\n## 红黑树的时间复杂度和相关证明\n\n红黑树的时间复杂度为: O(lgn)\n\n下面通过“数学归纳法”对红黑树的时间复杂度进行证明。\n\n定理：一棵含有n个节点的红黑树的高度至多为2log(n+1).\n\n证明：\n    \"一棵含有n个节点的红黑树的高度至多为2log(n+1)\" 的逆否命题是 \"高度为h的红黑树，它的包含的内节点个数至少为 2h/2-1个\"。\n    我们只需要证明逆否命题，即可证明原命题为真；即只需证明 \"高度为h的红黑树，它的包含的内节点个数至少为 2h/2-1个\"。\n\n    从某个节点x出发（不包括该节点）到达一个叶节点的任意一条路径上，黑色节点的个数称为该节点的黑高度(x's black height)，记为bh(x)。关于bh(x)有两点需要说明： \n    第1点：根据红黑树的\"特性(5) ，即从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点\"可知，从节点x出发到达的所有的叶节点具有相同数目的黑节点。这也就意味着，bh(x)的值是唯一的！\n    第2点：根据红黑色的\"特性(4)，即如果一个节点是红色的，则它的子节点必须是黑色的\"可知，从节点x出发达到叶节点\"所经历的黑节点数目\">= \"所经历的红节点的数目\"。假设x是根节点，则可以得出结论\"bh(x) >= h/2\"。进而，我们只需证明 \"高度为h的红黑树，它的包含的黑节点个数至少为 2bh(x)-1个\"即可。\n\n    到这里，我们将需要证明的定理已经由\n    \"一棵含有n个节点的红黑树的高度至多为2log(n+1)\" \n    转变成只需要证明\n    \"高度为h的红黑树，它的包含的内节点个数至少为 2bh(x)-1个\"。\n\n下面通过\"数学归纳法\"开始论证高度为h的红黑树，它的包含的内节点个数至少为 2bh(x)-1个\"。\n\n    (01) 当树的高度h=0时，\n    内节点个数是0，bh(x) 为0，2bh(x)-1 也为 0。显然，原命题成立。\n\n    (02) 当h>0，且树的高度为 h-1 时，它包含的节点个数至少为 2bh(x)-1-1。这个是根据(01)推断出来的！\n\n    下面，由树的高度为 h-1 的已知条件推出“树的高度为 h 时，它所包含的节点树为 2bh(x)-1”。\n\n    当树的高度为 h 时，\n    对于节点x(x为根节点)，其黑高度为bh(x)。\n    对于节点x的左右子树，它们黑高度为 bh(x) 或者 bh(x)-1。\n    根据(02)的已知条件，我们已知 \"x的左右子树，即高度为 h-1 的节点，它包含的节点至少为 2bh(x)-1-1 个\"；\n\n    所以，节点x所包含的节点至少为 ( 2bh(x)-1-1 ) + ( 2bh(x)-1-1 ) + 1 = 2^bh(x)-1。即节点x所包含的节点至少为 2bh(x)-1。\n    因此，原命题成立。\n\n    由(01)、(02)得出，\"高度为h的红黑树，它的包含的内节点个数至少为 2^bh(x)-1个\"。\n    因此，“一棵含有n个节点的红黑树的高度至多为2log(n+1)”。\n\n## 红黑树的基本操作(一) 左旋和右旋\n\n红黑树的基本操作是添加、删除。在对红黑树进行添加或删除之后，都会用到旋转方法。为什么呢？道理很简单，添加或删除红黑树中的节点之后，红黑树就发生了变化，可能不满足红黑树的5条性质，也就不再是一颗红黑树了，而是一颗普通的树。而通过旋转，可以使这颗树重新成为红黑树。简单点说，旋转的目的是让树保持红黑树的特性。\n\n旋转包括两种：左旋 和 右旋。下面分别对它们进行介绍。\n\n### 1. 左旋\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/002.jpg)\n\n对x进行左旋，意味着\"将x变成一个左节点\"。\n\n左旋的伪代码《算法导论》：参考上面的示意图和下面的伪代码，理解“红黑树T的节点x进行左旋”是如何进行的。\n\n```\nLEFT-ROTATE(T, x)  \n y ← right[x]            // 前提：这里假设x的右孩子为y。下面开始正式操作\n right[x] ← left[y]      // 将 “y的左孩子” 设为 “x的右孩子”，即 将β设为x的右孩子\n p[left[y]] ← x          // 将 “x” 设为 “y的左孩子的父亲”，即 将β的父亲设为x\n p[y] ← p[x]             // 将 “x的父亲” 设为 “y的父亲”\n if p[x] = nil[T]       \n then root[T] ← y                 // 情况1：如果 “x的父亲” 是空节点，则将y设为根节点\n else if x = left[p[x]]  \n           then left[p[x]] ← y    // 情况2：如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子”\n           else right[p[x]] ← y   // 情况3：(x是它父节点的右孩子) 将y设为“x的父节点的右孩子”\n left[y] ← x             // 将 “x” 设为 “y的左孩子”\n p[x] ← y                // 将 “x的父节点” 设为 “y”\n```\n\n理解左旋之后，看看下面一个更鲜明的例子。你可以先不看右边的结果，自己尝试一下。\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/003.jpg)\n\n### 2. 右旋\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/004.jpg)\n\n对x进行左旋，意味着\"将x变成一个左节点\"。\n\n右旋的伪代码《算法导论》：参考上面的示意图和下面的伪代码，理解“红黑树T的节点y进行右旋”是如何进行的。 \n\n```\nRIGHT-ROTATE(T, y)  \n x ← left[y]             // 前提：这里假设y的左孩子为x。下面开始正式操作\n left[y] ← right[x]      // 将 “x的右孩子” 设为 “y的左孩子”，即 将β设为y的左孩子\n p[right[x]] ← y         // 将 “y” 设为 “x的右孩子的父亲”，即 将β的父亲设为y\n p[x] ← p[y]             // 将 “y的父亲” 设为 “x的父亲”\n if p[y] = nil[T]       \n then root[T] ← x                 // 情况1：如果 “y的父亲” 是空节点，则将x设为根节点\n else if y = right[p[y]]  \n           then right[p[y]] ← x   // 情况2：如果 y是它父节点的右孩子，则将x设为“y的父节点的左孩子”\n           else left[p[y]] ← x    // 情况3：(y是它父节点的左孩子) 将x设为“y的父节点的左孩子”\n right[x] ← y            // 将 “y” 设为 “x的右孩子”\n p[y] ← x                // 将 “y的父节点” 设为 “x”\n```\n\n理解右旋之后，看看下面一个更鲜明的例子。你可以先不看右边的结果，自己尝试一下。\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/005.jpg)\n\n旋转总结：\n\n    (01) 左旋 和 右旋 是相对的两个概念，原理类似。理解一个也就理解了另一个。\n\n    (02) 下面谈谈如何区分 左旋 和 右旋。\n\n在实际应用中，若没有彻底理解 左旋 和 右旋，可能会将它们混淆。下面谈谈我对如何区分 左旋 和 右旋 的理解。\n\n### 3. 区分 左旋 和 右旋\n\n仔细观察上面\"左旋\"和\"右旋\"的示意图。我们能清晰的发现，它们是对称的。无论是左旋还是右旋，被旋转的树，在旋转前是二叉查找树，并且旋转之后仍然是一颗二叉查找树。\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/006.jpg)\n\n左旋示例图(以x为节点进行左旋)：\n\n```\n                               z\n   x                          /                  \n  / \\      --(左旋)-->       x\n y   z                      /\n                           y\n```\n\n对x进行左旋，意味着，将“x的右孩子”设为“x的父亲节点”；即，将 x变成了一个左节点(x成了为z的左孩子)！。 因此，左旋中的“左”，意味着“被旋转的节点将变成一个左节点”。\n\n右旋示例图(以x为节点进行右旋)：\n\n```\n                               y\n   x                            \\                 \n  / \\      --(右旋)-->           x\n y   z                            \\\n                                   z\n```\n\n对x进行右旋，意味着，将“x的左孩子”设为“x的父亲节点”；即，将 x变成了一个右节点(x成了为y的右孩子)！ 因此，右旋中的“右”，意味着“被旋转的节点将变成一个右节点”。\n\n## 红黑树的基本操作(二) 添加\n\n将一个节点插入到红黑树中，需要执行哪些步骤呢？首先，将红黑树当作一颗二叉查找树，将节点插入；然后，将节点着色为红色；最后，通过旋转和重新着色等方法来修正该树，使之重新成为一颗红黑树。详细描述如下：\n\n第一步: 将红黑树当作一颗二叉查找树，将节点插入。\n\n    红黑树本身就是一颗二叉查找树，将节点插入后，该树仍然是一颗二叉查找树。也就意味着，树的键值仍然是有序的。此外，无论是左旋还是右旋，若旋转之前这棵树是二叉查找树，旋转之后它一定还是二叉查找树。这也就意味着，任何的旋转和重新着色操作，都不会改变它仍然是一颗二叉查找树的事实。\n    好吧？那接下来，我们就来想方设法的旋转以及重新着色，使这颗树重新成为红黑树！\n\n第二步：将插入的节点着色为\"红色\"。\n\n    为什么着色成红色，而不是黑色呢？为什么呢？在回答之前，我们需要重新温习一下红黑树的特性：\n    (1) 每个节点或者是黑色，或者是红色。\n    (2) 根节点是黑色。\n    (3) 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！]\n    (4) 如果一个节点是红色的，则它的子节点必须是黑色的。\n    (5) 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。\n    将插入的节点着色为红色，不会违背\"特性(5)\"！少违背一条特性，就意味着我们需要处理的情况越少。接下来，就要努力的让这棵树满足其它性质即可；满足了的话，它就又是一颗红黑树了。o(∩∩)o...哈哈\n\n第三步: 通过一系列的旋转或着色等操作，使之重新成为一颗红黑树。\n\n    第二步中，将插入节点着色为\"红色\"之后，不会违背\"特性(5)\"。那它到底会违背哪些特性呢？\n    对于\"特性(1)\"，显然不会违背了。因为我们已经将它涂成红色了。\n    对于\"特性(2)\"，显然也不会违背。在第一步中，我们是将红黑树当作二叉查找树，然后执行的插入操作。而根据二叉查找数的特点，插入操作不会改变根节点。所以，根节点仍然是黑色。\n    对于\"特性(3)\"，显然不会违背了。这里的叶子节点是指的空叶子节点，插入非空节点并不会对它们造成影响。\n    对于\"特性(4)\"，是有可能违背的！\n    那接下来，想办法使之\"满足特性(4)\"，就可以将树重新构造成红黑树了。\n\n下面看看代码到底是怎样实现这三步的。\n\n添加操作的伪代码《算法导论》\n\n```\nRB-INSERT(T, z)  \n y ← nil[T]                        // 新建节点“y”，将y设为空节点。\n x ← root[T]                       // 设“红黑树T”的根节点为“x”\n while x ≠ nil[T]                  // 找出要插入的节点“z”在二叉树T中的位置“y”\n     do y ← x                      \n        if key[z] < key[x]  \n           then x ← left[x]  \n           else x ← right[x]  \n p[z] ← y                          // 设置 “z的父亲” 为 “y”\n if y = nil[T]                     \n    then root[T] ← z               // 情况1：若y是空节点，则将z设为根\n    else if key[z] < key[y]        \n            then left[y] ← z       // 情况2：若“z所包含的值” < “y所包含的值”，则将z设为“y的左孩子”\n            else right[y] ← z      // 情况3：(“z所包含的值” >= “y所包含的值”)将z设为“y的右孩子” \n left[z] ← nil[T]                  // z的左孩子设为空\n right[z] ← nil[T]                 // z的右孩子设为空。至此，已经完成将“节点z插入到二叉树”中了。\n color[z] ← RED                    // 将z着色为“红色”\n RB-INSERT-FIXUP(T, z)             // 通过RB-INSERT-FIXUP对红黑树的节点进行颜色修改以及旋转，让树T仍然是一颗红黑树\n ```\n\n结合伪代码以及为代码上面的说明，先理解RB-INSERT。理解了RB-INSERT之后，我们接着对 RB-INSERT-FIXUP的伪代码进行说明。\n\n添加修正操作的伪代码《算法导论》\n\n```\nRB-INSERT-FIXUP(T, z)\nwhile color[p[z]] = RED                                                  // 若“当前节点(z)的父节点是红色”，则进行以下处理。\n    do if p[z] = left[p[p[z]]]                                           // 若“z的父节点”是“z的祖父节点的左孩子”，则进行以下处理。\n          then y ← right[p[p[z]]]                                        // 将y设置为“z的叔叔节点(z的祖父节点的右孩子)”\n               if color[y] = RED                                         // Case 1条件：叔叔是红色\n                  then color[p[z]] ← BLACK                    ▹ Case 1   //  (01) 将“父节点”设为黑色。\n                       color[y] ← BLACK                       ▹ Case 1   //  (02) 将“叔叔节点”设为黑色。\n                       color[p[p[z]]] ← RED                   ▹ Case 1   //  (03) 将“祖父节点”设为“红色”。\n                       z ← p[p[z]]                            ▹ Case 1   //  (04) 将“祖父节点”设为“当前节点”(红色节点)\n                  else if z = right[p[z]]                                // Case 2条件：叔叔是黑色，且当前节点是右孩子\n                          then z ← p[z]                       ▹ Case 2   //  (01) 将“父节点”作为“新的当前节点”。\n                               LEFT-ROTATE(T, z)              ▹ Case 2   //  (02) 以“新的当前节点”为支点进行左旋。\n                          color[p[z]] ← BLACK                 ▹ Case 3   // Case 3条件：叔叔是黑色，且当前节点是左孩子。(01) 将“父节点”设为“黑色”。\n                          color[p[p[z]]] ← RED                ▹ Case 3   //  (02) 将“祖父节点”设为“红色”。\n                          RIGHT-ROTATE(T, p[p[z]])            ▹ Case 3   //  (03) 以“祖父节点”为支点进行右旋。\n       else (same as then clause with \"right\" and \"left\" exchanged)      // 若“z的父节点”是“z的祖父节点的右孩子”，将上面的操作中“right”和“left”交换位置，然后依次执行。\ncolor[root[T]] ← BLACK\n```\n\n根据被插入节点的父节点的情况，可以将\"当节点z被着色为红色节点，并插入二叉树\"划分为三种情况来处理。\n\n    ① 情况说明：被插入的节点是根节点。\n    处理方法：直接把此节点涂为黑色。\n    ② 情况说明：被插入的节点的父节点是黑色。\n    处理方法：什么也不需要做。节点被插入后，仍然是红黑树。\n    ③ 情况说明：被插入的节点的父节点是红色。\n    处理方法：那么，该情况与红黑树的“特性(5)”相冲突。这种情况下，被插入节点是一定存在非空祖父节点的；进一步的讲，被插入节点也一定存在叔叔节点(即使叔叔节点为空，我们也视之为存在，空节点本身就是黑色节点)。理解这点之后，我们依据\"叔叔节点的情况\"，将这种情况进一步划分为3种情况(Case)。\n\n|  | 现象说明 | 处理策略 |\n| - | ------- | -------- |\n| Case 1 | 当前节点的父节点是红色，且当前节点的祖父节点的另一个子节点（叔叔节点）也是红色。 | (01) 将“父节点”设为黑色。(02) 将“叔叔节点”设为黑色。(03) 将“祖父节点”设为“红色”。(04) 将“祖父节点”设为“当前节点”(红色节点)；即，之后继续对“当前节点”进行操作。 |\n| Case 2 | 当前节点的父节点是红色，叔叔节点是黑色，且当前节点是其父节点的右孩子 | (01) 将“父节点”作为“新的当前节点”。(02) 以“新的当前节点”为支点进行左旋。 |\n| Case 3 | 当前节点的父节点是红色，叔叔节点是黑色，且当前节点是其父节点的左孩子 | (01) 将“父节点”设为“黑色”。(02) 将“祖父节点”设为“红色”。(03) 以“祖父节点”为支点进行右旋。 |\n\n上面三种情况(Case)处理问题的核心思路都是：**将红色的节点移到根节点；然后，将根节点设为黑色**。下面对它们详细进行介绍。\n\n### 1. (Case 1)叔叔是红色\n\n1.1 现象说明\n\n当前节点(即，被插入节点)的父节点是红色，且当前节点的祖父节点的另一个子节点（叔叔节点）也是红色。\n\n1.2 处理策略\n\n    (01) 将“父节点”设为黑色。\n    (02) 将“叔叔节点”设为黑色。\n    (03) 将“祖父节点”设为“红色”。\n    (04) 将“祖父节点”设为“当前节点”(红色节点)；即，之后继续对“当前节点”进行操作。\n\n下面谈谈为什么要这样处理。(建议理解的时候，通过下面的图进行对比)\n\n“当前节点”和“父节点”都是红色，违背“特性(4)”。所以，将“父节点”设置“黑色”以解决这个问题。\n\n但是，将“父节点”由“红色”变成“黑色”之后，违背了“特性(5)”：因为，包含“父节点”的分支的黑色节点的总数增加了1。  解决这个问题的办法是：将“祖父节点”由“黑色”变成红色，同时，将“叔叔节点”由“红色”变成“黑色”。关于这里，说明几点：第一，为什么“祖父节点”之前是黑色？这个应该很容易想明白，因为在变换操作之前，该树是红黑树，“父节点”是红色，那么“祖父节点”一定是黑色。 第二，为什么将“祖父节点”由“黑色”变成红色，同时，将“叔叔节点”由“红色”变成“黑色”；能解决“包含‘父节点’的分支的黑色节点的总数增加了1”的问题。这个道理也很简单。“包含‘父节点’的分支的黑色节点的总数增加了1” 同时也意味着 “包含‘祖父节点’的分支的黑色节点的总数增加了1”，既然这样，我们通过将“祖父节点”由“黑色”变成“红色”以解决“包含‘祖父节点’的分支的黑色节点的总数增加了1”的问题； 但是，这样处理之后又会引起另一个问题“包含‘叔叔’节点的分支的黑色节点的总数减少了1”，现在我们已知“叔叔节点”是“红色”，将“叔叔节点”设为“黑色”就能解决这个问题。 所以，将“祖父节点”由“黑色”变成红色，同时，将“叔叔节点”由“红色”变成“黑色”；就解决了该问题。\n\n按照上面的步骤处理之后：当前节点、父节点、叔叔节点之间都不会违背红黑树特性，但祖父节点却不一定。若此时，祖父节点是根节点，直接将祖父节点设为“黑色”，那就完全解决这个问题了；若祖父节点不是根节点，那我们需要将“祖父节点”设为“新的当前节点”，接着对“新的当前节点”进行分析。\n\n1.3 示意图\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/007.jpg)\n\n### 2. (Case 2)叔叔是黑色，且当前节点是右孩子\n\n2.1 现象说明\n\n当前节点(即，被插入节点)的父节点是红色，叔叔节点是黑色，且当前节点是其父节点的右孩子\n\n2.2 处理策略\n\n    (01) 将“父节点”作为“新的当前节点”。\n    (02) 以“新的当前节点”为支点进行左旋。\n\n\n下面谈谈为什么要这样处理。(建议理解的时候，通过下面的图进行对比)\n\n首先，将“父节点”作为“新的当前节点”；接着，以“新的当前节点”为支点进行左旋。 为了便于理解，我们先说明第(02)步，再说明第(01)步；为了便于说明，我们设置“父节点”的代号为F(Father)，“当前节点”的代号为S(Son)。\n\n为什么要“以F为支点进行左旋”呢？根据已知条件可知：S是F的右孩子。而之前我们说过，我们处理红黑树的核心思想：将红色的节点移到根节点；然后，将根节点设为黑色。既然是“将红色的节点移到根节点”，那就是说要不断的将破坏红黑树特性的红色节点上移(即向根方向移动)。 而S又是一个右孩子，因此，我们可以通过“左旋”来将S上移！ \n\n按照上面的步骤(以F为支点进行左旋)处理之后：若S变成了根节点，那么直接将其设为“黑色”，就完全解决问题了；若S不是根节点，那我们需要执行步骤(01)，即“将F设为‘新的当前节点’”。那为什么不继续以S为新的当前节点继续处理，而需要以F为新的当前节点来进行处理呢？这是因为“左旋”之后，F变成了S的“子节点”，即S变成了F的父节点；而我们处理问题的时候，需要从下至上(由叶到根)方向进行处理；也就是说，必须先解决“孩子”的问题，再解决“父亲”的问题；所以，我们执行步骤(01)：将“父节点”作为“新的当前节点”。\n\n2.2 示意图\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/008.jpg)\n\n### 3. (Case 3)叔叔是黑色，且当前节点是左孩子\n\n3.1 现象说明\n\n当前节点(即，被插入节点)的父节点是红色，叔叔节点是黑色，且当前节点是其父节点的左孩子\n\n3.2 处理策略\n\n    (01) 将“父节点”设为“黑色”。\n    (02) 将“祖父节点”设为“红色”。\n    (03) 以“祖父节点”为支点进行右旋。\n\n下面谈谈为什么要这样处理。(建议理解的时候，通过下面的图进行对比)\n\n为了便于说明，我们设置“当前节点”为S(Original Son)，“兄弟节点”为B(Brother)，“叔叔节点”为U(Uncle)，“父节点”为F(Father)，祖父节点为G(Grand-Father)。\n\nS和F都是红色，违背了红黑树的“特性(4)”，我们可以将F由“红色”变为“黑色”，就解决了“违背‘特性(4)’”的问题；但却引起了其它问题：违背特性(5)，因为将F由红色改为黑色之后，所有经过F的分支的黑色节点的个数增加了1。那我们如何解决“所有经过F的分支的黑色节点的个数增加了1”的问题呢？ 我们可以通过“将G由黑色变成红色”，同时“以G为支点进行右旋”来解决。\n\n2.3 示意图\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/009.jpg)\n\n提示：上面的进行Case 3处理之后，再将节点\"120\"当作当前节点，就变成了Case 2的情况。\n\n## 红黑树的基本操作(三) 删除\n\n将红黑树内的某一个节点删除。需要执行的操作依次是：首先，将红黑树当作一颗二叉查找树，将该节点从二叉查找树中删除；然后，通过\"旋转和重新着色\"等一系列来修正该树，使之重新成为一棵红黑树。详细描述如下：\n\n第一步：将红黑树当作一颗二叉查找树，将节点删除。\n\n    这和\"删除常规二叉查找树中删除节点的方法是一样的\"。分3种情况：\n    ① 被删除节点没有儿子，即为叶节点。那么，直接将该节点删除就OK了。\n    ② 被删除节点只有一个儿子。那么，直接删除该节点，并用该节点的唯一子节点顶替它的位置。\n    ③ 被删除节点有两个儿子。那么，先找出它的后继节点；然后把“它的后继节点的内容”复制给“该节点的内容”；之后，删除“它的后继节点”。在这里，后继节点相当于替身，在将后继节点的内容复制给\"被删除节点\"之后，再将后继节点删除。这样就巧妙的将问题转换为\"删除后继节点\"的情况了，下面就考虑后继节点。 在\"被删除节点\"有两个非空子节点的情况下，它的后继节点不可能是双子非空。既然\"的后继节点\"不可能双子都非空，就意味着\"该节点的后继节点\"要么没有儿子，要么只有一个儿子。若没有儿子，则按\"情况① \"进行处理；若只有一个儿子，则按\"情况② \"进行处理。\n\n第二步：通过\"旋转和重新着色\"等一系列来修正该树，使之重新成为一棵红黑树。\n       \n    因为\"第一步\"中删除节点之后，可能会违背红黑树的特性。所以需要通过\"旋转和重新着色\"来修正该树，使之重新成为一棵红黑树。\n\n删除操作的伪代码《算法导论》\n\n```\nRB-DELETE(T, z)\nif left[z] = nil[T] or right[z] = nil[T]         \n   then y ← z                                  // 若“z的左孩子” 或 “z的右孩子”为空，则将“z”赋值给 “y”；\n   else y ← TREE-SUCCESSOR(z)                  // 否则，将“z的后继节点”赋值给 “y”。\nif left[y] ≠ nil[T]\n   then x ← left[y]                            // 若“y的左孩子” 不为空，则将“y的左孩子” 赋值给 “x”；\n   else x ← right[y]                           // 否则，“y的右孩子” 赋值给 “x”。\np[x] ← p[y]                                    // 将“y的父节点” 设置为 “x的父节点”\nif p[y] = nil[T]                               \n   then root[T] ← x                            // 情况1：若“y的父节点” 为空，则设置“x” 为 “根节点”。\n   else if y = left[p[y]]                    \n           then left[p[y]] ← x                 // 情况2：若“y是它父节点的左孩子”，则设置“x” 为 “y的父节点的左孩子”\n           else right[p[y]] ← x                // 情况3：若“y是它父节点的右孩子”，则设置“x” 为 “y的父节点的右孩子”\nif y ≠ z                                    \n   then key[z] ← key[y]                        // 若“y的值” 赋值给 “z”。注意：这里只拷贝z的值给y，而没有拷贝z的颜色！！！\n        copy y's satellite data into z         \nif color[y] = BLACK                            \n   then RB-DELETE-FIXUP(T, x)                  // 若“y为黑节点”，则调用\nreturn y\n```\n\n结合伪代码以及为代码上面的说明，先理解RB-DELETE。理解了RB-DELETE之后，接着对 RB-DELETE-FIXUP的伪代码进行说明\n\n```\nRB-DELETE-FIXUP(T, x)\nwhile x ≠ root[T] and color[x] = BLACK  \n    do if x = left[p[x]]      \n          then w ← right[p[x]]                                             // 若 “x”是“它父节点的左孩子”，则设置 “w”为“x的叔叔”(即x为它父节点的右孩子)                                          \n               if color[w] = RED                                           // Case 1: x是“黑+黑”节点，x的兄弟节点是红色。(此时x的父节点和x的兄弟节点的子节点都是黑节点)。\n                  then color[w] ← BLACK                        ▹  Case 1   //   (01) 将x的兄弟节点设为“黑色”。\n                       color[p[x]] ← RED                       ▹  Case 1   //   (02) 将x的父节点设为“红色”。\n                       LEFT-ROTATE(T, p[x])                    ▹  Case 1   //   (03) 对x的父节点进行左旋。\n                       w ← right[p[x]]                         ▹  Case 1   //   (04) 左旋后，重新设置x的兄弟节点。\n               if color[left[w]] = BLACK and color[right[w]] = BLACK       // Case 2: x是“黑+黑”节点，x的兄弟节点是黑色，x的兄弟节点的两个孩子都是黑色。\n                  then color[w] ← RED                          ▹  Case 2   //   (01) 将x的兄弟节点设为“红色”。\n                       x ←  p[x]                               ▹  Case 2   //   (02) 设置“x的父节点”为“新的x节点”。\n                  else if color[right[w]] = BLACK                          // Case 3: x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的左孩子是红色，右孩子是黑色的。\n                          then color[left[w]] ← BLACK          ▹  Case 3   //   (01) 将x兄弟节点的左孩子设为“黑色”。\n                               color[w] ← RED                  ▹  Case 3   //   (02) 将x兄弟节点设为“红色”。\n                               RIGHT-ROTATE(T, w)              ▹  Case 3   //   (03) 对x的兄弟节点进行右旋。\n                               w ← right[p[x]]                 ▹  Case 3   //   (04) 右旋后，重新设置x的兄弟节点。\n                        color[w] ← color[p[x]]                 ▹  Case 4   // Case 4: x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的右孩子是红色的。(01) 将x父节点颜色 赋值给 x的兄弟节点。\n                        color[p[x]] ← BLACK                    ▹  Case 4   //   (02) 将x父节点设为“黑色”。\n                        color[right[w]] ← BLACK                ▹  Case 4   //   (03) 将x兄弟节点的右子节设为“黑色”。\n                        LEFT-ROTATE(T, p[x])                   ▹  Case 4   //   (04) 对x的父节点进行左旋。\n                        x ← root[T]                            ▹  Case 4   //   (05) 设置“x”为“根节点”。\n       else (same as then clause with \"right\" and \"left\" exchanged)        // 若 “x”是“它父节点的右孩子”，将上面的操作中“right”和“left”交换位置，然后依次执行。\ncolor[x] ← BLACK\n```\n\n下面对删除函数进行分析。在分析之前，我们再次温习一下红黑树的几个特性：\n\n    (1) 每个节点或者是黑色，或者是红色。\n    (2) 根节点是黑色。\n    (3) 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！]\n    (4) 如果一个节点是红色的，则它的子节点必须是黑色的。\n    (5) 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。\n\n前面我们将\"删除红黑树中的节点\"大致分为两步，在第一步中\"将红黑树当作一颗二叉查找树，将节点删除\"后，可能违反\"特性(2)、(4)、(5)\"三个特性。第二步需要解决上面的三个问题，进而保持红黑树的全部特性。\n\n为了便于分析，我们假设\"x包含一个额外的黑色\"(x原本的颜色还存在)，这样就不会违反\"特性(5)\"。为什么呢？\n\n通过RB-DELETE算法，我们知道：删除节点y之后，x占据了原来节点y的位置。 既然删除y(y是黑色)，意味着减少一个黑色节点；那么，再在该位置上增加一个黑色即可。这样，当我们假设\"x包含一个额外的黑色\"，就正好弥补了\"删除y所丢失的黑色节点\"，也就不会违反\"特性(5)\"。 因此，假设\"x包含一个额外的黑色\"(x原本的颜色还存在)，这样就不会违反\"特性(5)\"。\n\n现在，x不仅包含它原本的颜色属性，x还包含一个额外的黑色。即x的颜色属性是\"红+黑\"或\"黑+黑\"，它违反了\"特性(1)\"。\n\n现在，我们面临的问题，由解决\"违反了特性(2)、(4)、(5)三个特性\"转换成了\"解决违反特性(1)、(2)、(4)三个特性\"。RB-DELETE-FIXUP需要做的就是通过算法恢复红黑树的特性(1)、(2)、(4)。RB-DELETE-FIXUP的思想是：将x所包含的额外的黑色不断沿树上移(向根方向移动)，直到出现下面的姿态：\n\n    a) x指向一个\"红+黑\"节点。此时，将x设为一个\"黑\"节点即可。\n    b) x指向根。此时，将x设为一个\"黑\"节点即可。\n    c) 非前面两种姿态。\n\n将上面的姿态，可以概括为3种情况。\n\n① 情况说明：x是“红+黑”节点。\n\n    处理方法：直接把x设为黑色，结束。此时红黑树性质全部恢复。\n\n② 情况说明：x是“黑+黑”节点，且x是根。\n\n    处理方法：什么都不做，结束。此时红黑树性质全部恢复。\n\n③ 情况说明：x是“黑+黑”节点，且x不是根。\n\n    处理方法：这种情况又可以划分为4种子情况。这4种子情况如下表所示：\n\n|  | 现象说明 | 处理策略 |\n| - | ------- | -------- |\n| Case 1 | x是\"黑+黑\"节点，x的兄弟节点是红色。(此时x的父节点和x的兄弟节点的子节点都是黑节点)。 | (01) 将x的兄弟节点设为“黑色”。(02) 将x的父节点设为“红色”。(03) 对x的父节点进行左旋。(04) 左旋后，重新设置x的兄弟节点。 |\n| Case 2 | x是“黑+黑”节点，x的兄弟节点是黑色，x的兄弟节点的两个孩子都是黑色。 | (01) 将x的兄弟节点设为“红色”。(02) 设置“x的父节点”为“新的x节点”。 |\n| Case 3 | x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的左孩子是红色，右孩子是黑色的。 | (01) 将x兄弟节点的左孩子设为“黑色”。(02) 将x兄弟节点设为“红色”。(03) 对x的兄弟节点进行右旋。(04) 右旋后，重新设置x的兄弟节点。 |\n| Case 4 | x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的右孩子是红色的，x的兄弟节点的左孩子任意颜色。 | (01) 将x父节点颜色 赋值给 x的兄弟节点。(02) 将x父节点设为“黑色”。(03) 将x兄弟节点的右子节设为“黑色”。(04) 对x的父节点进行左旋。(05) 设置“x”为“根节点”。 |\n\n### 1. (Case 1)x是\"黑+黑\"节点，x的兄弟节点是红色\n\n1.1 现象说明\n\nx是\"黑+黑\"节点，x的兄弟节点是红色。(此时x的父节点和x的兄弟节点的子节点都是黑节点)。\n\n1.2 处理策略\n\n    (01) 将x的兄弟节点设为“黑色”。\n    (02) 将x的父节点设为“红色”。\n    (03) 对x的父节点进行左旋。\n    (04) 左旋后，重新设置x的兄弟节点。\n\n下面谈谈为什么要这样处理。(建议理解的时候，通过下面的图进行对比)\n\n这样做的目的是将“Case 1”转换为“Case 2”、“Case 3”或“Case 4”，从而进行进一步的处理。对x的父节点进行左旋；左旋后，为了保持红黑树特性，就需要在左旋前“将x的兄弟节点设为黑色”，同时“将x的父节点设为红色”；左旋后，由于x的兄弟节点发生了变化，需要更新x的兄弟节点，从而进行后续处理。\n\n1.3 示意图\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/010.jpg)\n\n### 2. (Case 2) x是\"黑+黑\"节点，x的兄弟节点是黑色，x的兄弟节点的两个孩子都是黑色\n\n2.1 现象说明\n\nx是“黑+黑”节点，x的兄弟节点是黑色，x的兄弟节点的两个孩子都是黑色。\n\n2.2 处理策略\n\n    (01) 将x的兄弟节点设为“红色”。\n    (02) 设置“x的父节点”为“新的x节点”。\n\n下面谈谈为什么要这样处理。(建议理解的时候，通过下面的图进行对比)\n\n这个情况的处理思想：是将“x中多余的一个黑色属性上移(往根方向移动)”。 x是“黑+黑”节点，我们将x由“黑+黑”节点 变成 “黑”节点，多余的一个“黑”属性移到x的父节点中，即x的父节点多出了一个黑属性(若x的父节点原先是“黑”，则此时变成了“黑+黑”；若x的父节点原先时“红”，则此时变成了“红+黑”)。 此时，需要注意的是：所有经过x的分支中黑节点个数没变化；但是，所有经过x的兄弟节点的分支中黑色节点的个数增加了1(因为x的父节点多了一个黑色属性)！为了解决这个问题，我们需要将“所有经过x的兄弟节点的分支中黑色节点的个数减1”即可，那么就可以通过“将x的兄弟节点由黑色变成红色”来实现。\n\n经过上面的步骤(将x的兄弟节点设为红色)，多余的一个颜色属性(黑色)已经跑到x的父节点中。我们需要将x的父节点设为“新的x节点”进行处理。若“新的x节点”是“黑+红”，直接将“新的x节点”设为黑色，即可完全解决该问题；若“新的x节点”是“黑+黑”，则需要对“新的x节点”进行进一步处理。\n\n2.3 示意图\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/011.jpg)\n\n### 3. (Case 3)x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的左孩子是红色，右孩子是黑色的\n\n3.1 现象说明\n\nx是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的左孩子是红色，右孩子是黑色的。\n\n3.2 处理策略\n\n    (01) 将x兄弟节点的左孩子设为“黑色”。\n    (02) 将x兄弟节点设为“红色”。\n    (03) 对x的兄弟节点进行右旋。\n    (04) 右旋后，重新设置x的兄弟节点。\n\n下面谈谈为什么要这样处理。(建议理解的时候，通过下面的图进行对比)\n\n我们处理“Case 3”的目的是为了将“Case 3”进行转换，转换成“Case 4”,从而进行进一步的处理。转换的方式是对x的兄弟节点进行右旋；为了保证右旋后，它仍然是红黑树，就需要在右旋前“将x的兄弟节点的左孩子设为黑色”，同时“将x的兄弟节点设为红色”；右旋后，由于x的兄弟节点发生了变化，需要更新x的兄弟节点，从而进行后续处理。\n\n3.3 示意图\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/012.jpg)\n\n### 4. (Case 4)x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的右孩子是红色的，x的兄弟节点的左孩子任意颜色\n\n4.1 现象说明\n\nx是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的右孩子是红色的，x的兄弟节点的左孩子任意颜色。\n\n4.2 处理策略\n\n    (01) 将x父节点颜色 赋值给 x的兄弟节点。\n    (02) 将x父节点设为“黑色”。\n    (03) 将x兄弟节点的右子节设为“黑色”。\n    (04) 对x的父节点进行左旋。\n    (05) 设置“x”为“根节点”。\n\n下面谈谈为什么要这样处理。(建议理解的时候，通过下面的图进行对比)\n\n我们处理“Case 4”的目的是：去掉x中额外的黑色，将x变成单独的黑色。处理的方式是“：进行颜色修改，然后对x的父节点进行左旋。下面，我们来分析是如何实现的。\n\n为了便于说明，我们设置“当前节点”为S(Original Son)，“兄弟节点”为B(Brother)，“兄弟节点的左孩子”为BLS(Brother's Left Son)，“兄弟节点的右孩子”为BRS(Brother's Right Son)，“父节点”为F(Father)。\n\n我们要对F进行左旋。但在左旋前，我们需要调换F和B的颜色，并设置BRS为黑色。为什么需要这里处理呢？因为左旋后，F和BLS是父子关系，而我们已知BL是红色，如果F是红色，则违背了“特性(4)”；为了解决这一问题，我们将“F设置为黑色”。 但是，F设置为黑色之后，为了保证满足“特性(5)”，即为了保证左旋之后：\n\n第一，“同时经过根节点和S的分支的黑色节点个数不变”。\n\n    若满足“第一”，只需要S丢弃它多余的颜色即可。因为S的颜色是“黑+黑”，而左旋后“同时经过根节点和S的分支的黑色节点个数”增加了1；现在，只需将S由“黑+黑”变成单独的“黑”节点，即可满足“第一”。\n\n第二，“同时经过根节点和BLS的分支的黑色节点数不变”。\n\n    若满足“第二”，只需要将“F的原始颜色”赋值给B即可。之前，我们已经将“F设置为黑色”(即，将B的颜色\"黑色\"，赋值给了F)。至此，我们算是调换了F和B的颜色。\n\n第三，“同时经过根节点和BRS的分支的黑色节点数不变”。\n\n    在“第二”已经满足的情况下，若要满足“第三”，只需要将BRS设置为“黑色”即可。\n\n经过，上面的处理之后。红黑树的特性全部得到的满足！接着，我们将x设为根节点，就可以跳出while循环(参考伪代码)；即完成了全部处理。\n\n至此，我们就完成了Case 4的处理。理解Case 4的核心，是了解如何“去掉当前节点额外的黑色”。\n\n4.3 示意图\n\n![](/assets/images/2013/08/13/red-black-tree-principle-algorithm/013.jpg)\n\nOK！至此，红黑树的理论知识差不多讲完了。后续再更新红黑树的实现代码！\n\n## 参考文献\n\n1. 《算法导论》\n2.  [教你透彻了解红黑树](http://blog.csdn.net/v_JULY_v/article/details/6105630)\n\n---\n\n* Author: [如果天空不死](http://www.cnblogs.com/skywang12345/)\n* Source: [博客园](http://www.cnblogs.com)\n* Link: [红黑树(一)之 原理和算法详细介绍](http://www.cnblogs.com/skywang12345/p/3245399.html)","tags":["RedBlackTree"],"categories":["Algorithm"]},{"title":"Kimball’s Data Warehouse Toolkit Classics","url":"%2F2013%2F2013-07-07-kimball-data-warehouse-toolkit-classics%2F","content":"\nThis boxed set combines the three Kimball Toolkits that set the standard for data warehousing and business intelligence methods and techniques.\n\n![](http://blog.hyperj.net/assets/images/2013/07/07/kimball-data-warehouse-toolkit-classics/kg-dw-toolkit-classics.png)\n\nThe set includes:\n\n* **The Data Warehouse Toolkit, 3rd Edition**: The Definitive Guide to Dimensional Modeling (Wiley, 2013)\n* **The Data Warehouse ETL Toolkit**: Practical Techniques for Extracting, Cleaning, Conforming and Delivering Data (Wiley, 2004)\n* **The Data Warehouse Lifecycle Toolkit, 2nd Edition**: Practical Techniques for Building Data Warehouse and Business Intelligence Systems (Wiley, 2008)\n\nThree books by the bestselling authors on Data Warehousing! The most authoritative guides from the inventor of the technique all for a value price.\n\n**The Data Warehouse Toolkit, 3rd Edition** Ralph Kimball invented a data warehousing technique called \"dimensional modeling\" and popularized it in his first Wiley book, The Data Warehouse Toolkit. Since this book was first published in 1996, dimensional modeling has become the most widely accepted technique for data warehouse design. Over the past 10 years, Kimball has improved on his earlier techniques and created many new ones. In this 3rd edition, he will provide a comprehensive collection of all of these techniques, from basic to advanced.\n\n**The Data Warehouse Lifecycle Toolkit, 2nd Edition** Complete coverage of best practices from data warehouse project inception through on-going program management.  Updates industry best practices to be in sync with current recommendations of Kimball Group.  Streamlines the lifecycle methodology to be more efficient and user-friendly\n\n**The Data Warehouse ETL Toolkit** shows data warehouse developers how to effectively manage the ETL (Extract, Transform, Load) phase of the data warehouse development lifecycle.  The authors show developers the best methods for extracting data from scattered sources throughout the enterprise, removing obsolete, redundant, and innaccurate data, transforming the remaining data into correctly formatted data structures, and then physically loading them into the data warehouse.  \n\nThis book provides complete coverage of proven, time-saving ETL techniques. It begins with a quick overview of ETL fundamentals and the role of the ETL development team.  It then quickly moves into an overview of the ETL data structures, both relational and dimensional.  The authors show how to build useful dimensional stuctures, providing practical examples of beginning through advanced techniques.\n\n---\n\n* 原文链接：[Kimball’s Data Warehouse Toolkit Classics](http://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/kimball-toolkit-classics/ \"Kimball’s Data Warehouse Toolkit Classics\")\n","tags":["Book"],"categories":["Data-Warehouse"]},{"title":"TAO: Facebook’s Distributed Data Store for the Social Graph","url":"%2F2013%2F2013-06-26-tao-facebook-distributed-social-graph-data-store%2F","content":"\n### Abstract\n\nWe introduce a simple data model and API tailored for serving the social graph, and TAO, an implementation of this model. TAO is a geographically distributed data store that provides efficient and timely access to the social graph for Facebook’s demanding workload using a fixed set of queries. It is deployed at Facebook, replacing memcache for many data types that fit its model. The system runs on thousands of machines, is widely distributed, and provides access to many petabytes of data. TAO can process a billion reads and millions of writes each second.\n\n论文：[TAO: Facebook’s Distributed Data Store for the Social Graph](http://www.cs.cmu.edu/~pavlo/courses/fall2013/static/papers/11730-atc13-bronson.pdf)\n\n---\n\n原文链接：[TAO: Facebook’s Distributed Data Store for the Social Graph](https://www.usenix.org/conference/atc13/technical-sessions/presentation/bronson)\n","tags":["Social-Graph"],"categories":["Graph-Database"]},{"title":"Java引用总结--StrongReference、SoftReference、WeakReference、PhantomReference","url":"%2F2013%2F2013-06-25-java-reference-strongreference-softreference-weakreference-phantomreference%2F","content":"\n## Java引用介绍\n\nJava从1.2版本开始引入了4种引用，这4种引用的级别由高到低依次为：\n\n强引用  >  软引用  >  弱引用  >  虚引用\n\n1. 强引用（StrongReference）\n\n   强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。\n\n2. 软引用（SoftReference）\n\n   如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。\n\n   软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。\n\n3. 弱引用（WeakReference）\n\n    弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。\n\n   弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。\n\n4. 虚引用（PhantomReference）\n\n   “虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。\n\n   虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之 关联的引用队列中。\n\n由于引用和内存回收关系紧密。下面，先通过实例对内存回收有个认识；然后，进一步通过引用实例加深对引用的了解。\n\n## 内存回收\n\n创建公共类MyDate，它的作用是覆盖finalize()函数：在finalize()中输出打印信息，方便追踪。\n\n说明：finalize()函数是在JVM回收内存时执行的，但JVM并不保证在回收内存时一定会调用finalize()。\n\nMyDate代码如下：\n\n```java\npackage com.skywang.java;\n\nimport java.util.Date;\n\npublic class MyDate extends Date { \n\n    /** Creates a new instance of MyDate */\n    public MyDate() {\n    }\n    // 覆盖finalize()方法\n    protected void finalize() throws Throwable {\n        super.finalize();\n        System.out.println(\"obj [Date: \" + this.getTime() + \"] is gc\");\n    }   \n\n    public String toString() {\n        return \"Date: \" + this.getTime();\n    }\n}\n```\n\n在这个类中，对java.util.Date类进行了扩展，并重写了finalize()和toString()方法。\n\n创建公共类ReferenceTest，它的作用是定义一个方法drainMemory()：消耗大量内存，以此来引发JVM回收内存。\n\nReferenceTest代码如下：\n\n```java\npackage com.skywang.java;\n\npublic class ReferenceTest {   \n    /** Creates a new instance of ReferenceTest */\n    public ReferenceTest() {\n    }   \n    \n    // 消耗大量内存\n    public static void drainMemory() {\n        String[] array = new String[1024 * 10];\n        for(int i = 0; i < 1024 * 10; i++) {\n            for(int j = 'a'; j <= 'z'; j++) {\n                array[i] += (char)j;\n            }           \n        }\n    }\n} \n```\n\n在这个类中定义了一个静态方法drainMemory()，此方法旨在消耗大量的内存，促使JVM运行垃圾回收。\n\n有了上面两个公共类之后，我们即可测试JVM什么时候进行垃圾回收。下面分3种情况进行测试：\n\n**情况1：清除对象**\n\n实现代码：\n\n```java\npackage com.skywang.java;\n\npublic class NoGarbageRetrieve {\n\n    public static void main(String[] args) {\n        MyDate date = new MyDate();\n        date = null;\n    }\n}\n```\n\n运行结果：\n\n```\n<无任何输出>\n```\n\n结果分析：date虽然设为null，但由于JVM没有执行垃圾回收操作，MyDate的finalize()方法没有被运行。\n\n**情况2：显式调用垃圾回收**\n\n实现代码： \n\n```java\npackage com.skywang.java;\n\npublic class ExplicitGarbageRetrieve {\n\n    /**\n     * @param args\n     */\n    public static void main(String[] args) {\n        // TODO Auto-generated method stub\n        MyDate date = new MyDate();\n        date = null;\n        System.gc();\n    }\n\n}\n```\n\n运行结果：\n\n```\nobj [Date: 1372137067328] is gc\n```\n\n结果分析：调用了System.gc()，使JVM运行垃圾回收，MyDate的finalize()方法被运行。\n\n**情况3：隐式调用垃圾回收**\n\n实现代码： \n\n```java\npackage com.skywang.java;\n\npublic class ImplicitGarbageRetrieve {\n\n    /**\n     * @param args\n     */\n    public static void main(String[] args) {\n        // TODO Auto-generated method stub\n        MyDate date = new MyDate();\n        date = null;\n        ReferenceTest.drainMemory();\n    }\n\n} \n```\n\n运行结果：\n\n```\nobj [Date: 1372137171965] is gc\n```\n\n结果分析：虽然没有显式调用垃圾回收方法System.gc()，但是由于运行了耗费大量内存的方法，触发JVM进行垃圾回收。\n\n总结：JVM的垃圾回收机制，在内存充足的情况下，除非你显式调用System.gc()，否则它不会进行垃圾回收；在内存不足的情况下，垃圾回收将自动运行\n\n## Java对引用的分类\n\n### 3.1 强引用\n\n实例代码：\n\n```java\npackage com.skywang.java;\n\npublic class StrongReferenceTest {\n\n    public static void main(String[] args) {\n        MyDate date = new MyDate();\n        System.gc();\n    }\n}\n```\n\n运行结果：\n\n```\n<无任何输出>\n```\n\n结果说明：即使显式调用了垃圾回收，但是用于date是强引用，date没有被回收。\n\n### 3.2 软引用\n\n实例代码：\n\n```java\npackage com.skywang.java;\n\nimport java.lang.ref.SoftReference;\n\npublic class SoftReferenceTest {\n\n    public static void main(String[] args) {\n        SoftReference ref = new SoftReference(new MyDate());\n        ReferenceTest.drainMemory();\n    }\n}\n```\n\n运行结果：\n\n```\n<无任何输出>\n```\n\n结果说明：在内存不足时，软引用被终止。软引用被禁止时，\n\n```\nSoftReference ref = new SoftReference(new MyDate());\nReferenceTest.drainMemory();\n```\n\n等价于\n\n```\nMyDate date = new MyDate();\n\n// 由JVM决定运行\nIf(JVM.内存不足()) {\ndate = null;\nSystem.gc();\n}\n```\n \n### 3.3 弱引用\n\n示例代码： \n\n```java\npackage com.skywang.java;\n\nimport java.lang.ref.WeakReference;\n\npublic class WeakReferenceTest {\n\n    public static void main(String[] args) {\n        WeakReference ref = new WeakReference(new MyDate());\n        System.gc(); \n    }\n}\n```\n\n运行结果：\n\n```\nobj [Date: 1372142034360] is gc\n```\n\n结果说明：在JVM垃圾回收运行时，弱引用被终止.\n\n```\nWeakReference ref = new WeakReference(new MyDate());\nSystem.gc();\n```\n\n等同于：\n\n```\nMyDate date = new MyDate();\n\n// 垃圾回收\nIf(JVM.内存不足()) {\ndate = null;\nSystem.gc();\n}\n```\n\n### 3.4 假象引用\n\n示例代码： \n\n```java\npackage com.skywang.java;\n\nimport java.lang.ref.ReferenceQueue;\nimport java.lang.ref.PhantomReference;\n\npublic class PhantomReferenceTest {\n\n    public static void main(String[] args) {\n        ReferenceQueue queue = new ReferenceQueue();\n        PhantomReference ref = new PhantomReference(new MyDate(), queue);\n        System.gc();\n    }\n}\n```\n\n运行结果：\n\n```\nobj [Date: 1372142282558] is gc\n```\n\n结果说明：假象引用，在实例化后，就被终止了。\n\n```\nReferenceQueue queue = new ReferenceQueue();\nPhantomReference ref = new PhantomReference(new MyDate(), queue);\nSystem.gc();\n```\n\n等同于：\n\n```\nMyDate date = new MyDate();\ndate = null;\n```\n\n可以用以下表格总结上面的内容： \n\n| 级别 | 什么时候被垃圾回收 | 用途 | 生存时间 |\n| --- | --------------- | --- | ------- |\n| 强引用 | 从来不会 | 对象的一般状态 | JVM停止运行时终止 |\n| 软引用 | 在内存不足时 | 对象简单？缓存 | 内存不足时终止 |\n| 弱引用 | 在垃圾回收时 | 对象缓存 | gc运行后终止 |\n| 虚引用 | Unknown | Unknown | Unknown |\n\n点击下载：源代码\n\n原文链接：[Java引用总结--StrongReference、SoftReference、WeakReference、PhantomReference](http://www.cnblogs.com/skywang12345/p/3154474.html)\n\n参考链接：\n\n* [Soft Reference](http://mindprod.com/jgloss/softreferences.html)\n* [Weak Reference](http://mindprod.com/jgloss/weak.html)\n* [Phantom Reference](http://mindprod.com/jgloss/phantom.html)\n\n| Type | Purpose | Use | When GCed | Implementing Class |\n| ---- | ------- | --- | --------- | ------------------ |\n| Strong Reference | An ordinary reference. Keeps objects alive as long as they are referenced. | normal reference. | Any object not pointed to can be reclaimed. | default |\n| Soft Reference | Keeps objects alive provided there’s enough memory. | to keep objects alive even after clients have removed their references (memory-sensitive caches), in case clients start asking for them again by key. | After a first gc pass, the JVM decides it still needs to reclaim more space. | java.lang.ref.SoftReference |\n| Weak Reference | Keeps objects alive only while they’re in use (reachable) by clients. | Containers that automatically delete objects no longer in use. | After gc determines the object is only weakly reachable | java.lang.ref.WeakReference |\njava.util.WeakHashMap\n| Phantom Reference | Lets you clean up after finalization but before the space is reclaimed (replaces or augments the use of finalize()) | Special clean up processing | After finalization. | java.lang.ref.PhantomReference |\n\n---\n\n* [Reference (Java Platform SE 8 )](http://docs.oracle.com/javase/8/docs/api/java/lang/ref/Reference.html)\n","tags":["Reference"],"categories":["Java"]},{"title":"HBase Shell Commands","url":"%2F2013%2F2013-03-02-hbase-shell-commends%2F","content":"\nApache HBase 提供了一种基于 JRuby（JIRB）的、可扩展的 Shell 操作特性，以此来执行一些操作或命令（每个操作或命令对应一个功能点）。\n\n## HBase shell commands are mainly categorized into 6 parts\n\n### 1) General HBase shell commands\n\n**status**\n\nShow cluster status. Can be ‘summary’, ‘simple’, or ‘detailed’. \nThe default is ‘summary’.\n\n```shell\nhbase> status\nhbase> status ‘simple’\nhbase> status ‘summary’\nhbase> status ‘detailed’\n```\n\n**version**\n\nOutput this HBase versionUsage:\n\n```shell\nhbase> version\n```\n\n**whoami**\n\nShow the current hbase user.Usage:\n\n```shell\nhbase> whoami\n```\n\n### 2) Tables Management commands\n\n**alter**\n\nAlter column family schema; pass table name and a dictionary specifying \nnew column family schema. Dictionaries are described on the main help \ncommand output. Dictionary must include name of column family to alter.\nFor example, to change or add the ‘f1’ column family in table ‘t1’ from \ncurrent value to keep a maximum of 5 cell VERSIONS, do:\n\n```shell\nhbase> alter ‘t1’, NAME => ‘f1’, VERSIONS => 5\n```\n\nYou can operate on several column families:\n\n```shell\nhbase> alter ‘t1’, ‘f1’, {NAME => ‘f2’, IN_MEMORY => true}, {NAME => ‘f3’, VERSIONS => 5}\n```\n\nTo delete the ‘f1’ column family in table ‘t1’, use one of:\n\n```shell\nhbase> alter ‘t1’, NAME => ‘f1’, METHOD => ‘delete’\nhbase> alter ‘t1’, ‘delete’ => ‘f1’\n```\n\nYou can also change table-scope attributes like MAX_FILESIZE, READONLY, \nMEMSTORE_FLUSHSIZE, DEFERRED_LOG_FLUSH, etc. These can be put at the end; \nfor example, to change the max size of a region to 128MB, do:\n\n```shell\nhbase> alter ‘t1’, MAX_FILESIZE => ‘134217728’\n```\n\nYou can add a table coprocessor by setting a table coprocessor attribute:\n\n```shell\nhbase> alter ‘t1’, ‘coprocessor’=>’hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2’\n```\n\nSince you can have multiple coprocessors configured for a table, a sequence number will be automatically appended to the attribute name to uniquely identify it.\n\nThe coprocessor attribute must match the pattern below in order for the framework to understand how to load the coprocessor classes: [coprocessor jar file location] / class name / [priority] / [arguments]\n\nYou can also set configuration settings specific to this table or column family:\n\n```shell\nhbase> alter ‘t1’, CONFIGURATION => {‘hbase.hregion.scan.loadColumnFamiliesOnDemand’ => ‘true’}\nhbase> alter ‘t1’, {NAME => ‘f2’, CONFIGURATION => {‘hbase.hstore.blockingStoreFiles’ => ’10’}}\n```\n\nYou can also remove a table-scope attribute:\n\n```shell\nhbase> alter ‘t1’, METHOD => ‘table_att_unset’, NAME => ‘MAX_FILESIZE’\nhbase> alter ‘t1’, METHOD => ‘table_att_unset’, NAME => ‘coprocessor$1’\n```\n\nThere could be more than one alteration in one command:\n\n```shell\nhbase> alter ‘t1’, { NAME => ‘f1’, VERSIONS => 3 }, { MAX_FILESIZE => ‘134217728’ }, { METHOD => ‘delete’, NAME => ‘f2’ }, OWNER => ‘johndoe’, METADATA => { ‘mykey’ => ‘myvalue’ }\n```\n\n**create**\n\nCreate table; pass table name, a dictionary of specifications per column family, and optionally a dictionary of table configuration.\n\n```shell\nhbase> create ‘t1’, {NAME => ‘f1’, VERSIONS => 5}\nhbase> create ‘t1’, {NAME => ‘f1’}, {NAME => ‘f2’}, {NAME => ‘f3’}\nhbase> # The above in shorthand would be the following:\nhbase> create ‘t1’, ‘f1’, ‘f2’, ‘f3’\nhbase> create ‘t1’, {NAME => ‘f1’, VERSIONS => 1, TTL => 2592000, BLOCKCACHE => true}\nhbase> create ‘t1’, {NAME => ‘f1’, CONFIGURATION => {‘hbase.hstore.blockingStoreFiles’ => ’10’}}\n```\n\nTable configuration options can be put at the end.\n\n**describe**\n\nDescribe the named table.\n\n```shell\nhbase> describe ‘t1’\n```\n\n**disable**\n\nStart disable of named table\n\n```shell\nhbase> disable ‘t1’\n```\n\n**disable_all**\n\nDisable all of tables matching the given regex\n\n```shell\nhbase> disable_all ‘t.*’\n```\n\n**is_disabled**\n\nverifies Is named table disabled\n\n```shell\nhbase> is_disabled ‘t1’\n```\n\n**drop**\n\nDrop the named table. Table must first be disabled\n\n```shell\nhbase> drop ‘t1’\n```\n\n**drop_all**\n\nDrop all of the tables matching the given regex\n\n```shell\nhbase> drop_all ‘t.*’\n```\n\n**enable**\n\nStart enable of named table\n\n```shell\nhbase> enable ‘t1’\n```\n\n**enable_all**\n\nEnable all of the tables matching the given regex\n\n```shell\nhbase> enable_all ‘t.*’\n```\n\n**is_enabled**\n\nverifies Is named table enabled\n\n```shell\nhbase> is_enabled ‘t1’\n```\n\n**exists**\n\nDoes the named table exist\n\n```shell\nhbase> exists ‘t1’\n```\n\n**list**\n\nList all tables in hbase. Optional regular expression parameter could \nbe used to filter the output\n\n```shell\nhbase> list\nhbase> list ‘abc.*’\n```\n\n**show_filters**\n\nShow all the filters in hbase.\n\n```shell\nhbase> show_filters\n```\n\n**alter_status**\n\nGet the status of the alter command. Indicates the number of regions of \nthe table that have received the updated schema Pass table name.\n\n```shell\nhbase> alter_status ‘t1’\n```\n\n**alter_async**\n\nAlter column family schema, does not wait for all regions to receive the\nschema changes. Pass table name and a dictionary specifying new column\nfamily schema. Dictionaries are described on the main help command output.\nDictionary must include name of column family to alter.\nTo change or add the ‘f1’ column family in table ‘t1’ from defaults\nto instead keep a maximum of 5 cell VERSIONS, do:\n\n```shell\nhbase> alter_async ‘t1’, NAME => ‘f1’, VERSIONS => 5\n```\n\nTo delete the ‘f1’ column family in table ‘t1’, do:\n\n```shell\nhbase> alter_async ‘t1’, NAME => ‘f1’, METHOD => ‘delete’\n```\n\nor a shorter version:\n\n```shell\nhbase> alter_async ‘t1’, ‘delete’ => ‘f1’\n```\n\nYou can also change table-scope attributes like MAX_FILESIZE, \nMEMSTORE_FLUSHSIZE, READONLY, and DEFERRED_LOG_FLUSH.\n\nFor example, to change the max size of a family to 128MB, do:\n\n```shell\nhbase> alter ‘t1’, METHOD => ‘table_att’, MAX_FILESIZE => ‘134217728’\n```\n\nThere could be more than one alteration in one command:\n\n```shell\nhbase> alter ‘t1’, {NAME => ‘f1’}, {NAME => ‘f2’, METHOD => ‘delete’}\n```\n\nTo check if all the regions have been updated, use alter_status <table_name>\n\n### 3) Data Manipulation commands\n\n**count**\n\nCount the number of rows in a table. Return value is the number of rows.\nThis operation may take a LONG time (Run ‘$HADOOP_HOME/bin/hadoop jar\nhbase.jar rowcount’ to run a counting mapreduce job). Current count is shown\nevery 1000 rows by default. Count interval may be optionally specified. Scan\ncaching is enabled on count scans by default. Default cache size is 10 rows.\nIf your rows are small in size, you may want to increase this\nparameter. Examples:\n\n```shell\nhbase> count ‘t1’\nhbase> count ‘t1’, INTERVAL => 100000\nhbase> count ‘t1’, CACHE => 1000\nhbase> count ‘t1’, INTERVAL => 10, CACHE => 1000\n```\n\nThe same commands also can be run on a table reference. Suppose you had a reference\nt to table ‘t1’, the corresponding commands would be:\n\n```shell\nhbase> t.count\nhbase> t.count INTERVAL => 100000\nhbase> t.count CACHE => 1000\nhbase> t.count INTERVAL => 10, CACHE => 1000\n```\n\n**delete**\n\nPut a delete cell value at specified table/row/column and optionally\ntimestamp coordinates. Deletes must match the deleted cell’s\ncoordinates exactly. When scanning, a delete cell suppresses older\nversions. To delete a cell from ‘t1’ at row ‘r1’ under column ‘c1’\nmarked with the time ‘ts1’, do:\n\n```shell\nhbase> delete ‘t1’, ‘r1’, ‘c1’, ts1\n```\n\nThe same command can also be run on a table reference. Suppose you had a reference\nt to table ‘t1’, the corresponding command would be:\n\n```shell\nhbase> t.delete ‘r1’, ‘c1’, ts1\n```\n\n**deleteall**\n\nDelete all cells in a given row; pass a table name, row, and optionally\na column and timestamp. Examples:\n\n```shell\nhbase> deleteall ‘t1’, ‘r1’\nhbase> deleteall ‘t1’, ‘r1’, ‘c1’\nhbase> deleteall ‘t1’, ‘r1’, ‘c1’, ts1\n```\n\nThe same commands also can be run on a table reference. Suppose you had a reference\nt to table ‘t1’, the corresponding command would be:\n\n```shell\nhbase> t.deleteall ‘r1’\nhbase> t.deleteall ‘r1’, ‘c1’\nhbase> t.deleteall ‘r1’, ‘c1’, ts1\n```\n\n**get**\n\nGet row or cell contents; pass table name, row, and optionally\na dictionary of column(s), timestamp, timerange and versions. Examples:\n\n```shell\nhbase> get ‘t1’, ‘r1’\nhbase> get ‘t1’, ‘r1’, {TIMERANGE => [ts1, ts2]}\nhbase> get ‘t1’, ‘r1’, {COLUMN => ‘c1’}\nhbase> get ‘t1’, ‘r1’, {COLUMN => [‘c1’, ‘c2’, ‘c3’]}\nhbase> get ‘t1’, ‘r1’, {COLUMN => ‘c1’, TIMESTAMP => ts1}\nhbase> get ‘t1’, ‘r1’, {COLUMN => ‘c1’, TIMERANGE => [ts1, ts2], VERSIONS => 4}\nhbase> get ‘t1’, ‘r1’, {COLUMN => ‘c1’, TIMESTAMP => ts1, VERSIONS => 4}\nhbase> get ‘t1’, ‘r1’, {FILTER => “ValueFilter(=, ‘binary:abc’)”}\nhbase> get ‘t1’, ‘r1’, ‘c1’\nhbase> get ‘t1’, ‘r1’, ‘c1’, ‘c2’\nhbase> get ‘t1’, ‘r1’, [‘c1’, ‘c2’]\n```\n\nBesides the default ‘toStringBinary’ format, ‘get’ also supports custom formatting by\ncolumn. A user can define a FORMATTER by adding it to the column name in the get\nspecification. The FORMATTER can be stipulated:1. either as a org.apache.hadoop.hbase.util.Bytes method name (e.g, toInt, toString)\n2.or as a custom class followed by method name: e.g. ‘c(MyFormatterClass).format’.Example formatting cf:qualifier1 and cf:qualifier2 both as Integers:\n\n```shell\nhbase> get ‘t1’, ‘r1’ {COLUMN => [‘cf:qualifier1:toInt’,\n‘cf:qualifier2:c(org.apache.hadoop.hbase.util.Bytes).toInt’] }\n```\n\nNote that you can specify a FORMATTER by column only (cf:qualifer). You cannot specify\na FORMATTER for all columns of a column family.The same commands also can be run on a reference to a table (obtained via get_table or\ncreate_table). Suppose you had a reference t to table ‘t1’, the corresponding commands\nwould be:\n\n```shell\nhbase> t.get ‘r1’\nhbase> t.get ‘r1’, {TIMERANGE => [ts1, ts2]}\nhbase> t.get ‘r1’, {COLUMN => ‘c1’}\nhbase> t.get ‘r1’, {COLUMN => [‘c1’, ‘c2’, ‘c3’]}\nhbase> t.get ‘r1’, {COLUMN => ‘c1’, TIMESTAMP => ts1}\nhbase> t.get ‘r1’, {COLUMN => ‘c1’, TIMERANGE => [ts1, ts2], VERSIONS => 4}\nhbase> t.get ‘r1’, {COLUMN => ‘c1’, TIMESTAMP => ts1, VERSIONS => 4}\nhbase> t.get ‘r1’, {FILTER => “ValueFilter(=, ‘binary:abc’)”}\nhbase> t.get ‘r1’, ‘c1’\nhbase> t.get ‘r1’, ‘c1’, ‘c2’\nhbase> t.get ‘r1’, [‘c1’, ‘c2’]\n```\n\n**get_counter**\n\nReturn a counter cell value at specified table/row/column coordinates.\nA cell cell should be managed with atomic increment function oh HBase\nand the data should be binary encoded. Example:\n\n```shell\nhbase> get_counter ‘t1’, ‘r1’, ‘c1’\n```\n\nThe same commands also can be run on a table reference. Suppose you had a reference\nt to table ‘t1’, the corresponding command would be:\n\n```shell\nhbase> t.get_counter ‘r1’, ‘c1’\n```\n\n**incr**\n\nIncrements a cell ‘value’ at specified table/row/column coordinates.\nTo increment a cell value in table ‘t1’ at row ‘r1’ under column\n‘c1’ by 1 (can be omitted) or 10 do:\n\n```shell\nhbase> incr ‘t1’, ‘r1’, ‘c1’\nhbase> incr ‘t1’, ‘r1’, ‘c1’, 1\nhbase> incr ‘t1’, ‘r1’, ‘c1’, 10\n```\n\nThe same commands also can be run on a table reference. Suppose you had a reference\nt to table ‘t1’, the corresponding command would be:\n\n```shell\nhbase> t.incr ‘r1’, ‘c1’\nhbase> t.incr ‘r1’, ‘c1’, 1\nhbase> t.incr ‘r1’, ‘c1’, 10\n```\n\n**put**\n\nPut a cell ‘value’ at specified table/row/column and optionally\ntimestamp coordinates. To put a cell value into table ‘t1’ at\nrow ‘r1’ under column ‘c1’ marked with the time ‘ts1’, do:\n\n```shell\nhbase> put ‘t1’, ‘r1’, ‘c1’, ‘value’, ts1\n```\n\nThe same commands also can be run on a table reference. Suppose you had a reference\nt to table ‘t1’, the corresponding command would be:\n\n```shell\nhbase> t.put ‘r1’, ‘c1’, ‘value’, ts1\n```\n\n**scan**\n\nScan a table; pass table name and optionally a dictionary of scanner\nspecifications. Scanner specifications may include one or more of:\nTIMERANGE, FILTER, LIMIT, STARTROW, STOPROW, TIMESTAMP, MAXLENGTH,\nor COLUMNS, CACHEIf no columns are specified, all columns will be scanned.\nTo scan all members of a column family, leave the qualifier empty as in\n‘col_family:’.The filter can be specified in two ways:\n1.Using a filterString – more information on this is available in the\nFilter Language document attached to the HBASE-4176 JIRA\n2.Using the entire package name of the filter.Some examples:\n\n```shell\nhbase> scan ‘.META.’\nhbase> scan ‘.META.’, {COLUMNS => ‘info:regioninfo’}\nhbase> scan ‘t1’, {COLUMNS => [‘c1’, ‘c2’], LIMIT => 10, STARTROW => ‘xyz’}\nhbase> scan ‘t1’, {COLUMNS => ‘c1’, TIMERANGE => [1303668804, 1303668904]}\nhbase> scan ‘t1’, {FILTER => “(PrefixFilter (‘row2’) AND (QualifierFilter (>=, ‘binary:xyz’))) AND (TimestampsFilter ( 123, 456))”}\nhbase> scan ‘t1’, {FILTER =>\n```\n\norg.apache.hadoop.hbase.filter.ColumnPaginationFilter.new(1, 0)}\nFor experts, there is an additional option — CACHE_BLOCKS — which\nswitches block caching for the scanner on (true) or off (false). By\ndefault it is enabled. Examples:\n\n```shell\nhbase> scan ‘t1’, {COLUMNS => [‘c1’, ‘c2’], CACHE_BLOCKS => false}\n```\n\nAlso for experts, there is an advanced option — RAW — which instructs the\nscanner to return all cells (including delete markers and uncollected deleted\ncells). This option cannot be combined with requesting specific COLUMNS.\nDisabled by default. Example:\n\n```shell\nhbase> scan ‘t1’, {RAW => true, VERSIONS => 10}\n```\n\nBesides the default ‘toStringBinary’ format, ‘scan’ supports custom formatting\nby column. A user can define a FORMATTER by adding it to the column name in\nthe scan specification. The FORMATTER can be stipulated:\n\n1.either as a org.apache.hadoop.hbase.util.Bytes method name (e.g, toInt, toString)\n2.or as a custom class followed by method name: e.g. ‘c(MyFormatterClass).format’.\n\nExample formatting cf:qualifier1 and cf:qualifier2 both as Integers:\n\n```shell\nhbase> scan ‘t1’, {COLUMNS => [‘cf:qualifier1:toInt’, ‘cf:qualifier2:c(org.apache.hadoop.hbase.util.Bytes).toInt’] }\n```\n\nNote that you can specify a FORMATTER by column only (cf:qualifer). You cannot\nspecify a FORMATTER for all columns of a column family.\n\nScan can also be used directly from a table, by first getting a reference to a\ntable, like such:\n\n```shell\nhbase> t = get_table ‘t’\nhbase> t.scan\n```\n\nNote in the above situation, you can still provide all the filtering, columns,\noptions, etc as described above.\n\n**truncate**\n\nDisables, drops and recreates the specified table.\nExamples:\n\n```shell\nhbase>truncate ‘t1’\n```\n\n### 4) HBase surgery tools\n\n**assign**\n\nAssign a region. Use with caution. If region already assigned,\nthis command will do a force reassign. For experts only.\nExamples:\n\n```shell\nhbase> assign ‘REGION_NAME’\n```\n\n**balancer**\n\nTrigger the cluster balancer. Returns true if balancer ran and was able to\ntell the region servers to unassign all the regions to balance (the re-assignment itself is async).\nOtherwise false (Will not run if regions in transition).\nExamples:\n\n```shell\nhbase> balancer\n```\n\n**balance_switch**\n\nEnable/Disable balancer. Returns previous balancer state.\nExamples:\n\n```shell\nhbase> balance_switch true\nhbase> balance_switch false\n```\n\n**close_region**\n\nClose a single region. Ask the master to close a region out on the cluster\nor if ‘SERVER_NAME’ is supplied, ask the designated hosting regionserver to\nclose the region directly. Closing a region, the master expects ‘REGIONNAME’\nto be a fully qualified region name. When asking the hosting regionserver to\ndirectly close a region, you pass the regions’ encoded name only. A region\nname looks like this:TestTable,0094429456,1289497600452.527db22f95c8a9e0116f0cc13c680396.The trailing period is part of the regionserver name. A region’s encoded name\nis the hash at the end of a region name; e.g. 527db22f95c8a9e0116f0cc13c680396\n(without the period). A ‘SERVER_NAME’ is its host, port plus startcode. For\nexample: host187.example.com,60020,1289493121758 (find servername in master ui\nor when you do detailed status in shell). This command will end up running\nclose on the region hosting regionserver. The close is done without the\nmaster’s involvement (It will not know of the close). Once closed, region will\nstay closed. Use assign to reopen/reassign. Use unassign or move to assign\nthe region elsewhere on cluster. Use with caution. For experts only.\nExamples:\n\n```shell\nhbase> close_region ‘REGIONNAME’\nhbase> close_region ‘REGIONNAME’, ‘SERVER_NAME’\n```\n\n**compact**\n\nCompact all regions in passed table or pass a region row to compact an individual region. You can also compact a single column family within a region.\nExamples:\nCompact all regions in a table:\n\n```shell\nhbase> compact ‘t1’\n```\n\nCompact an entire region:\n\n```shell\nhbase> compact ‘r1’\n```\n\nCompact only a column family within a region:\n\n```shell\nhbase> compact ‘r1’, ‘c1’\n```\n\nCompact a column family within a table:\n\n```shell\nhbase> compact ‘t1’, ‘c1’\n```\n\n**flush**\n\nFlush all regions in passed table or pass a region row to flush an individual region. For example:\n\n```shell\nhbase> flush ‘TABLENAME’\nhbase> flush ‘REGIONNAME’\n```\n\n**major_compact**\n\nRun major compaction on passed table or pass a region row\nto major compact an individual region. To compact a single\ncolumn family within a region specify the region name\nfollowed by the column family name.\nExamples:\nCompact all regions in a table:\n\n```shell\nhbase> major_compact ‘t1’\n```\n\nCompact an entire region:\n\n```shell\nhbase> major_compact ‘r1’\n```\n\nCompact a single column family within a region:\n\n```shell\nhbase> major_compact ‘r1’, ‘c1’\n```\n\nCompact a single column family within a table:\n\n```shell\nhbase> major_compact ‘t1’, ‘c1’\n```\n\n**move**\n\nMove a region. Optionally specify target regionserver else we choose one\nat random. NOTE: You pass the encoded region name, not the region name so\nthis command is a little different to the others. The encoded region name\nis the hash suffix on region names: e.g. if the region name were\nTestTable,0094429456,1289497600452.527db22f95c8a9e0116f0cc13c680396. then\nthe encoded region name portion is 527db22f95c8a9e0116f0cc13c680396\nA server name is its host, port plus startcode. For example:\nhost187.example.com,60020,1289493121758\nExamples:\n\n```shell\nhbase> move ‘ENCODED_REGIONNAME’\nhbase> move ‘ENCODED_REGIONNAME’, ‘SERVER_NAME’\n```\n\n**split**\n\nSplit entire table or pass a region to split individual region. With the second parameter, you can specify an explicit split key for the region.\nExamples:\nsplit ‘tableName’\nsplit ‘regionName’ # format: ‘tableName,startKey,id’\nsplit ‘tableName’, ‘splitKey’\nsplit ‘regionName’, ‘splitKey’\n\n**unassign**\n\nUnassign a region. Unassign will close region in current location and then reopen it again. Pass ‘true’ to force the unassignment (‘force’ will clear all in-memory state in master before the reassign. If results in double assignment use hbck -fix to resolve. To be used by experts).\nUse with caution. For expert use only. Examples:\n\n```shell\nhbase> unassign ‘REGIONNAME’\nhbase> unassign ‘REGIONNAME’, true\n```\n\n**hlog_roll**\n\nRoll the log writer. That is, start writing log messages to a new file. The name of the regionserver should be given as the parameter. A ‘server_name’ is the host, port plus startcode of a regionserver. For example: host187.example.com,60020,1289493121758 (find servername in master ui or when you do detailed status in shell)\n\n```shell\nhbase>hlog_roll\n```\n\n**zk_dump**\n\nDump status of HBase cluster as seen by ZooKeeper. Example:\n\n```shell\nhbase>zk_dump\n```\n\n### 5) Cluster replication tools\n\n**add_peer**\n\nAdd a peer cluster to replicate to, the id must be a short and the cluster key is composed like this:\nhbase.zookeeper.quorum:hbase.zookeeper.property.clientPort:zookeeper.znode.parent\nThis gives a full path for HBase to connect to another cluster.\nExamples:\n\n```shell\nhbase> add_peer ‘1’, “server1.cie.com:2181:/hbase”\nhbase> add_peer ‘2’, “zk1,zk2,zk3:2182:/hbase-prod”\n```\n\n**remove_peer**\n\nStops the specified replication stream and deletes all the meta information kept about it. Examples:\n\n```shell\nhbase> remove_peer ‘1’\n```\n\n**list_peers**\n\nList all replication peer clusters.\n\n```shell\nhbase> list_peers\n```\n\n**enable_peer**\n\nRestarts the replication to the specified peer cluster, continuing from where it was disabled.Examples:\n\n```shell\nhbase> enable_peer ‘1’\n```\n\n**disable_peer**\n\nStops the replication stream to the specified cluster, but still keeps track of new edits to replicate.Examples:\n\n```shell\nhbase> disable_peer ‘1’\n```\n**start_replication**\n\nRestarts all the replication features. The state in which each stream starts in is undetermined.\nWARNING: start/stop replication is only meant to be used in critical load situations.\nExamples:\n\n```shell\nhbase> start_replication\n```\n\n**stop_replication**\n\nStops all the replication features. The state in which each stream stops in is undetermined.\nWARNING: start/stop replication is only meant to be used in critical load situations.\nExamples:\n\n```shell\nhbase> stop_replication\n```\n\n### 6) Security tools\n\n**grant**\n\nGrant users specific rights.\nSyntax : grantpermissions is either zero or more letters from the set “RWXCA”.\nREAD(‘R’), WRITE(‘W’), EXEC(‘X’), CREATE(‘C’), ADMIN(‘A’)For example:\n\n```shell\nhbase> grant ‘bobsmith’, ‘RWXCA’\nhbase> grant ‘bobsmith’, ‘RW’, ‘t1’, ‘f1’, ‘col1’\n```\n\n**revoke**\n\nRevoke a user’s access rights.\nSyntax : revoke\nFor example:\n\n```shell\nhbase> revoke ‘bobsmith’, ‘t1’, ‘f1’, ‘col1’\n```\n\n**user_permission**\n\nShow all permissions for the particular user. \nSyntax : user_permission \nFor example:\n\n```shell\nhbase> user_permission\nhbase> user_permission ‘table1’\n```\n\n---\n\n* 相关链接：[The Apache HBase Shell](http://hbase.apache.org/book.html#shell \"The Apache HBase Shell\")\n* 原文链接：[HBase shell commands](https://learnhbase.wordpress.com/2013/03/02/hbase-shell-commands/ \"HBase shell commands\")\n","tags":["HBase"],"categories":["HBase"]},{"title":"日志结构的合并树（The Log-Structured Merge-Tree）","url":"%2F2013%2F2013-01-12-the-log-structured-merge-tree%2F","content":"\n近年来，随着互联网数据的日益增长，管理分布式数据需求的日益增加，Bigtable[1]等一系列NoSQL数据库开始涌现。Bigtable是一个分布式的结构化数据存储系统，它被设计用来处理海量数据，其在提供Tablet服务时使用内存中的memtable和GFS[2]中的SSTable来相互配合着来存储数据更新，其中存储和更新的方法与日志结构的合并树[3]（Log-Structured Merge-Tree，LSM-tree）类似，并以其为基础。\n\nLog-Structured的思想最早由 Rosenblum和Ousterhout[4]于1992年在研究日志结构的文件系统时提出。他们将整个磁盘就看做是一个日志，在日志中存放永久性数据及其索引，每次都添加到日志的末尾；通过将很多小文件的存取转换为连续的大批量传输，使得对于文件系统的大多数存取都是顺序性的，从而提高磁盘带宽利用率，故障恢复速度快。 O'Neil[3]等人受到这种思想的启发，借鉴了Log不断追加（而不是修改）的特点，结合B-tree的数据结构，提出了一种延迟更新，批量写入硬盘的数据结构LSM-tree及其算法。LSM-tree努力地在读和写两方面寻找一个平衡点以最小化系统的存取性能的开销，特别适用于会产生大量插入操作的应用环境。\n\n**LSM-tree**\n\nLSM-tree是由两个或两个以上存储数据的结构组成的。最简单的LSM-tree由两个部件构成。一个部件常驻内存，称为C0树（或C0），可以为任何方便键值查找的数据结构，另一个部件常驻硬盘之中，称为C1树（或C1），其数据结构与B-tree类似。C1中经常被访问的结点也将会被缓存在内存中。如下图所示：\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/1.png)\n\n图1：两部件的LSM-tree\n\n当插入一条新的数据条目时，首先会向日志文件中写入插入操作的日志，为以后的恢复做准备。然后将根据新条目的索引值将新条目插入到C0中。将新条目插入内存的C0中，不需要任何与硬盘的I/O操作，但内存的存储代价比硬盘的要高上不少，因此当C0的大小达到某一阈值时，内存存储的代价会比硬盘的I/O操作和存储代价还高。故每当C0的大小接近其阈值时，将有一部分的条目从C0滚动合并到硬盘中的C1，以减少C0的大小，降低内存存储数据的代价。\nC1的结构与B-tree相似，但其结点中的条目是满的，结点的大小为一页，树根之下的所有单页结点合并到地址连续的多页块中。\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/2.png)\n\n图2：多页块的结构及其结点的结构\n\n事实上，除了在多页块中不必从左至右填充结点外，C1与SB-tree[5]几乎相同。如图所示。J-1层结点包含连续的指向J层结点（node1，node2，...nodeK）的指针（P1，P2，...，PK）和分割指针的键（S1，S2，...，SK-1）。J层结点连续存放在多页块的K页中，并且不必按照键的大小排列。如果J层的两个结点存放于同一个多页块中，那这两个结点的键值之间的所有结点也存放在多页块中。M是多页块分割的标记，表示直到下一个M标记或空结点之内的所有后续结点都存放在同一个多页块中。M中包含了多页块开始的硬盘页号和多页块中结点的数量。树根始终是以一个单页存储的。可以看出多页块可用于范围检索，而多页块中结点可用于精确的键值匹配的检索。\n假设C0也是一种B-tree，设想在滚动合并时，C0和C1都有一个指向相等键值的游标，游标指向下一个将要合并的叶子结点中的条目。从根结点到达这个位置的路径将C1上所有正在进行滚动合并的多页块分成两部分。一部分是游标还未到达的结点，合并时读入清空块（emptying block），另一部分是游标已经过的结点，即滚动合并的结果，合并时写入填充块（filling block）。这样的过程如下：\n\n* 从C1中读入未合并的叶子结点，存储于内存的清空块中；\n* 从C0中读取叶子结点，并与清空块中的叶子结点进行合并排序；\n* 将合并排序的结果写入填充块中，并从C0中删除用于合并排序的旧叶子结点；\n* 不断地重复步骤2和3，当填充块被合并排序的结果填满时，将填充块追加到硬盘的新位置，并从C1中删除用于合并排序的旧叶子结点，当清空块被全部读取完时，再从C1中读入未合并的叶子结点；\n* 当C0和C1的所有叶子节点都被读入内存进行合并，并产生新的叶子结点之后，C0和C1的一次滚动合并就结束了。\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/3.png)\n\n图3：C0与C1之间的滚动合并\n\nC0并不将所有的条目都拿来滚动合并。由于C0存储在内存之中，所以C0可以保留最近插入或最常访问的那些数据，以提高访问速率并降低I/O操作的次数。C1的旧多页块可用于崩溃恢复，所以为了不覆盖旧多页块，滚动合并产生的新多页块将被写入硬盘的新空间。一般来说，每次合并之后，会剩下一些不满的没有写入硬盘的填充块，没有填入填充块的叶子结点，这些结点会和它们的目录结点一样暂时缓存在内存中，等待下次滚动合并时，再写入相应的填充块或者填满并写入硬盘。另外当设置检查点时，这些缓存的信息会被强制写入硬盘。叶子结点载入内存后，其父结点（目录结点）也会被缓存至内存中以减小滚动合并时所需的I/O操作。当滚动合并产生新的叶子结点产生后，会导致父结点（或者目录结点）发生相应的变化。当C1的父结点所属的多页块不满时，通常会停留在内存中一段时间，但其所指的叶子结点可以先写入硬盘之中。当发生下列情况时，目录结点及其多页块将被强制写入硬盘：\n\n* 一个包含目录结点的多页块已满；只将满的多页块写入硬盘。\n* 根结点分裂，C1树的深度增加；所有的多页块缓存都将被写入硬盘。\n* 设置检查点。所有的多页块都将被写入硬盘。\n\n**两部件LSM-tree的代价估计**\n\n为了对LSM-tree的代价进行简单地估计。首先定义硬盘和内存的代价符号如下：\nCOSTd=1M字节的硬盘存储的代价\nCOSTm=1M字节的内存存储的代价\nCOSTP=随机访问时，每秒读写一页的I/O操作所需硬盘臂移动的代价\nCOSTπ=多页块读写时，每秒读写一页的I/O操作所需硬盘臂移动的代价\n这里需要注意的是，就目前而言，硬盘存储的代价要低于内存存储的代价，即COSTd<COSTm。\n\n**LSM-tree与B-tree的插入代价比较**\n\n执行B-tree的插入操作需要首先找到条目要插入的位置，即要进行一次B-tree查找。假设插入的位置是随机的，那么之前插入所缓存的结点页面可能就无法重复使用了。由此定义：\nDe=使用B-tree进行随机访问时，在内存缓存中未找到的页数\n为了执行一个插入操作，需要进行De次I/O操作以在B-tree叶结点中找到插入的位置，插入数据之后，再进行1次I/O操作将新数据写回。由于相关结点的分裂对开销作用不大，这里我们就不考虑结点的分裂问题了。那么B-tree的插入代价就是\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/4.png)\n\nLSM-tree的插入操作首先是直接作用在常驻内存的C0上的，然后是批量地从C0将条目滚动合并到C1中。滚动合并是以多页块作为单元进行合并的，合并时读取一页所需的I/O代价为COSTπ。为了评价滚动合并的延迟插入的效果，定义\nM=从C0合并到C1的平均条目数\nSe=条目的字节大小\nSp=硬盘页的字节大小\nS0=C0的叶子层的大小（以兆字节为单位）\nS1=C1的叶子层的大小（以兆字节为单位）\n一个硬盘页（通常就是一个结点的大小）中所含的条目的数目约为Sp/Se，那么滚动合并时一页中来自于C0的条目约为S0/(S0 + S1)。那么M就可以估计为：\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/5.png)\n\n当C0相对于C1的大小越大时，参数M也就越大。对于一次插入来说，LSM-tree在插入C0之后，滚动合并时需要读进C1的叶子结点，再写回C1。由于滚动合并是批量插入C0的条目的，所以一次插入的代价是滚动合并代价的1/M。所以LSM-tree的插入代价：\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/6.png)\n\n将B-tree与LSM-tree的插入代价相比，即可得到：\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/7.png)\n\n在实际应用中说，K1接近于一个常数。所以LSM-tree与B-tree之比取决于M和COSTπ/COSTP。由于C1的多页块在硬盘中是连续存储的，COSTπ一般会比COSTP来得小，故公式的大小其实取决于M。当一页中包含的条目数较多，C0的规模与C1差距不大时，LSM-tree在数据插入上是优于B-tree的。\n\n**代价与数据温度**\n\n从另一个角度看，B-tree往往限制在硬盘或内存中，而LSM-tree则是跨越硬盘和内存实现数据存取的优化。假设有一个应用程序使用B-tree有S兆字节数据存储（假设不变），并需要每秒随机访问硬盘中的数据H次。那么应用程序使用硬盘臂的代价就是H∙COSTB-ins，使用硬盘进行存储的代价就是S∙COSTd。在应用程序刚开始运行的时候，主要是加载应用程序的数据等初始化动作，这时随机访问硬盘的次数较少，H相当小，这时应用程序的开销主要是硬盘存储数据的开销，即是S∙COSTd。随着程序的不断运行，应用程序内的业务逻辑会需要访问之前存储的数据，随机访问硬盘的次数就会越来越大，H也就越来越大，随机访问的代价就无法忽略了。具体来说，就是S∙COSTd>H∙COSTB-ins。应用程序的开销代价就变为H∙COSTP。随机访问的不断增加会使得硬盘磁盘臂的功率逐渐达到最大，但在访问硬盘的代价小于使用内存缓存（即H∙COSTB-ins<S∙COSTm）之前，依然可以直接访问硬盘。当H∙COSTB-ins>S∙COSTm时，将应用程序存储数据的B-tree全部缓存到内存中，可以使得应用程序的开销代价减小，这样应用程序的开销代价就是S∙COSTm。\n综上所述，可以看出应用程序在两个地方发生的转折，一个是在随机访问的代价与存储的代价相等时，即\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/8.png)\n\n另一个是在随机访问的代价与缓存的代价相等时，即\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/9.png)\n\n由此，将H/S定义为数据的温度，将两个转折点之间的区域称温数据，两端的区域分别称为冷数据和热数据，同理可得使用LSM-tree存储S兆字节时，代价也会在两个地方发生转折，即\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/10.png)\n\n通常来说，De+1通常大于2，M大于1，并且随着H的增加，De+1和M都会不断变大。所以LSM-tree的两个转折点均要后于B-tree的转折点，而且LSM-tree的第二个转折点要远远在B-tree第二个转折点之后。应用程序的总体代价COSTTOT随H/S变化如下图所示：\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/11.png)\n\n图4：存取1兆字节数据所需的代价随温度的变化\n\n冷数据区域的代价由硬盘的存储代价决定，不大能反映数据结构和算法的好坏。但越迟走出冷数据就越能反映对硬盘的利用率。热数据区域的代价主要集中在内存存储的代价上，同样也不大能反映数据结构和算法的好坏。但越迟进入就越能反映对内存的利用率。综合来看，LSM-tree的代价曲线在B-tree之下，可见LSM-tree对硬盘和内存的利用率都比B-tree要高。这主要是因为两点：\n\n滚动合并时批量写入新插入的数据，平摊单个条目插入的开销；\nC1的各层结点存储在多页块中，合并时顺序读写多页块，减小磁盘臂的移动。\n在热数据区域，无论是B-tree还是LSM-tree都将数据全部读到内存中，LSM-tree主要是增大C0的规模，使之与C1相当。此时的问题内存的开销就越来越大。由于内存的空间毕竟是有限的，一味地增加C0是不可取的。若减少C0的规模，由M的估计公式，M可能会下降。其实当某些比较大的条目需要不只一页来存放的时侯，M也可能会下降。这种情况下，从C0到C1的每次滚动合并需要从C1读入和写出多个页或多页块。特别地，当\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/12.png)\n\n时，多页块的读写优势将荡然无存，B树的插入性能将优于LSM-tree。为了避免M小于1，就又不得不增加C0的规模。\n一个解决方法就是在日益增大的C1和有空间上限的C0之间加入一个C做为C0和C1的缓冲。这时LSM-tree就由三个部分（C1、C和C0）组成。这种LSM-tree称为多部件的LSM-tree。\n\n**多部件的LSM-tree**\n\n在数据不断增加的情况下，即使在C1和C0之间增加上一个C，C的规模也会不断增长。当C像过去C1那么大时，就需要在C和C0之间再增加一个C。以此类推，硬盘中的C树将会越来越多。如下图所示：\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/13.png)\n\n图5：多部件的LSM-tree\n\n通常，一个多部件的LSM-tree由大小依次递增的C0，C1，C2，...，CK-1和CK组成，C0常驻内存之中，可以是键值索引的数据结构。而C1~CK则存储于硬盘之中，但其经常访问的页会被缓存于内存之中，它们的结构都是索引树。在数据不断插入的过程中，当较小的Ci-1的规模超过某一阈值时，相邻的两个部件Ci-1和Ci会进行滚动合并，从较小的Ci-1转移条目至较大的Ci中。各个相邻部件Ci-1和Ci的滚动合并是异步的。也就是说，一个条目会插入到C0中，之后经过不断的异步滚动合并过程，最终合并至CK中。\n由于各个相邻部件Ci-1和Ci的滚动合并是异步的，但当对其中的数据进行访问时，常常发生一些并发性问题。例如当进行精确检索或者加载多页块至内存时，Ci里的一个节点会被读入内存；当进行范围检索或滚动合并时，Ci里的多页块会被读入内存中。这些情况下，查找数据时Ci里的所有未被锁住的结点都可以被访问，并会定位被读入内存的结点。即使结点正在进行滚动合并，结点也可以被访问。显然，这时结点上的数据可能是不完整的。基于这些考虑，访问LSM-tree必须遵循下列规则：\n\n* 当硬盘中的相邻部件进行滚动合并的时候，当前参与合并的结点不能被查找；\n* 当C0和C1进行滚动合并的时候，当前参与合并的C0的结点周边不能被查找和插入；\n* 在Ci-1和Ci与Ci和Ci+1同时进行滚动合并时，Ci-1与Ci滚动合并的游标有时会超过Ci和Ci+1滚动合并的游标。\n\n为了避免对硬盘里的部件进行存取时产生的物理冲突，LSM-tree设置了以结点为单位的锁。在进行滚动合并时，正在合并的结点会在写模式下被锁住，直到有来自较大部件的结点被合并才被释放。在进行查找时，正在被读取的结点会在读模式下被锁住，读取完毕后，锁即被释放。\n\n与C0和C1的滚动合并相比，硬盘内的相邻部件Ci-1和Ci之间的滚动合并多了一个清空块和填充块。这是因为Ci-1和Ci都存储在硬盘之中，合并时需要先将Ci-1和Ci的清空块和填充块存入内存，合并的过程与C0和C1的相同，但Ci-1不会将所有的条目都拿去合并，而是会保留一部分条目（例如新插入的那部分条目）到Ci-1的填充块。如下图所示：\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/14.png)\n\n图6：硬盘中相邻两部件的滚动合并\n\n当前正在进行滚动合并的结点被加锁（红圈圈住的点），写保护。蓝色的点表示游标，绿色的点表示游标未到达的结点，树上折线表示从树根到游标的路径\n\n**查找、删除和修改**\n\n在LSM-tree树进行查找时，为了保证LSM-tree上的所有条目都被检查。首先要搜索C0，再搜索C1，进而搜索C2，...，CK-1和CK。即使硬盘中的部件C1，C2，...，CK-1和CK的结构都是B-tree，这也将耗费一些时间。但在实际的应用中，总可以将搜索限制在前几个的部件的搜索上。\n试想新条目插入时首先插入至C0中，然后通过各相邻部件Ci，和Ci+1之间的滚动合并，逐步转移到更大的部件中。在滚动合并时，如果将最近τ时间内被访问的条目保留下来，而将其它条目用于合并，那么经常被访问的那些数据就会被依次保存在C0，C1，...，CK-1和CK中。也就是说，我们可以简单的认为，C0保存的是最近τ时间内被访问的条目，C1保存的是除了C0保存的数据外，最近2τ时间内被访问的条目，C2保存的是除了C0和C1保存的数据外，最近3τ时间内被访问的条目。依此可推广到CK-1。而最后的部件CK保存的是最近Kτ之前的条目。这样凡是在最近τ时间内被执行的事务都不需要与硬盘进行I/O交换，可以直接在内存中找到数据。\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/15.png)\n\n图7：查找与删除\n\nLSM-tree的优势在于其能推迟写回硬盘的时间，进而达到批量地插入数据的目的。为了更高效地利用LSM-tree的插入优势，删除操作被设计为通过插入操作来执行。当C0所索引的一个条目被删除时，首先在C0上查找该条目所对应的索引是否存在，若不存在，就建立一个索引。然后在该索引键值的位置上设置删除条目（delete node entry）。删除条目的意义仅在于通知所有访问该索引的操作，“此索引键值所索引的条目已经被删除了”。在后续的滚动合并中，凡是在较大的部件中碰到的与该索引键值相同的条目都将被删除。此外，当在LSM-tree中查找删除的条目时，如果碰到这种删除条目，就会直接返回未找到。对于条目的修改，依仗LSM-tree的插入优势，可以先插入一个对应的删除条目，待删除条目经滚动合并离开C0后，再在上插入该条目的新值。\n\n**崩溃恢复**\n\n在新条目插入到C0后，当C0与C1进行滚动合并时，某些条目将从C0转移到更大的部件中。由于滚动合并发生在内存缓存的多页块中，所以只有当条目真正写入硬盘时，滚动合并的成果才会真正生效。然而滚动合并时可能就会发生系统故障，进而使得内存数据丢失。为了能有效地进行系统恢复，在LSM-tree的日常使用中，需要记录一些用以恢复数据的日志。然而与以往数据库中的日志不同的是，日志中只需要要记录数据插入的事务。简单地说，这些日志只包含了被插入数据的行的号码及插入的域和值。\nLSM-tree在记日志时设置检查点（checkpoint）以恢复某一时刻的LSM-tree。当需要在时刻T0设置检查点时：\n\n* 完成所有部件的当前合并，这样结点上的锁就会被释放；\n* 将所有新条目的插入操作以及滚动合并推迟至检查点设置完成之后；\n* 将C0写入硬盘中的一个已知的位置；此后对C0的插入操作可以开始，但是合并操作还要继续等待；\n* 将硬盘中的所有部件（C1~CK）在内存中缓存的结点写入硬盘；\n* 向日志中写入一条特殊的检查点日志。\n\n检查点日志的内容包括：\n\n* T0时刻最后一个插入的已索引的行的日志序列号（Log Sequence Number，LSN0）；\n* 硬盘中的所有部件的根在硬盘中的地址；\n* 各个部件的合并游标；\n* 新多页块动态分配的当前信息。在以后的恢复中，硬盘存储的动态分配算法将使用此信息判别哪些多页块是可用的。\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/16.png)\n\n图8：Checkpoint\n\n一旦检查点的信息设置完毕，就可以开始执行被推迟的新条目的插入操作了。由于后续合并操作中向硬盘写入多页块时，会将信息写入硬盘中的新位置，所以检查点的信息不会被消除。只有当后续检查点使得过期的多页块作废时，检查点的信息才会被废弃。\n\n**恢复**\n\n当系统崩溃后重启进行恢复时，需要进行如下操作：\n\n* 在日志中定位一个检查点；\n* 将之前写入硬盘的C0和其它部件在内存中缓存的多页块加载到内存中；\n* 将日志中在LSN0之后的部分读入内存，执行其中索引条目的插入操作；\n* 读取检查点日志中硬盘部件（C1~CK）的根的位置和合并游标，启动滚动合并，覆盖检查点之后的多页块；\n* 当检查点之后的所有新索引条目都已插入至LSM-tree且被索引后，恢复即完成。\n\n这一恢复措施的唯一的一个缺点就是恢复的时间可能会比较长，但通常这并不严重。因为内存中的数据可以很快地写入硬盘。当两个相邻的部件进行滚动合并时，新产生的结点将会写入到硬盘中的新位置。这样在将合并产生的结点写入硬盘时，上层结点中指向该结点的指针需要更新为结点的新位置。当正在进行滚动合并，却临时需要设置检查点时，加载进内存的多页块和目录结点都会写入到硬盘中新的位置。这样，在高层的目录结点中指向这些结点的指针同样需要立即更新为硬盘中的新地址。在恢复的过程中需要注意的是目录结点的更新。\n\n![](/assets/images/2013/01/12/the-log-structured-merge-tree/17.png)\n\n图9：高层结点引用下层结点的新位置\n\n更进一步，当使用检查点进行恢复时，滚动合并所需的所有的多页块都会从硬盘重新读回内存，由于所有的多页块的新位置较之设置检查点时的旧位置都发生了改变，这样所有目录结点的指针都需要更新。这听起来似乎是一大笔性能开销，但这些多页块其实都已加载到内存里了，所以没有I/O开销。若要使得恢复的时间不超过几分钟，那么可以每隔几分钟的I/O操作就设置一次检查点。\n\n**小结**\n\n日志结构的合并树（LSM-tree）是一种基于硬盘的数据结构，与B-tree相比，能显著地减少硬盘磁盘臂的开销，并能在较长的时间提供对文件的高速插入（删除）。然而LSM-tree在某些情况下，特别是在查询需要快速响应时性能不佳。通常LSM-tree适用于索引插入比检索更频繁的应用系统。Bigtable在提供Tablet服务时，使用GFS来存储日志和SSTable，而GFS的设计初衷就是希望通过添加新数据的方式而不是通过重写旧数据的方式来修改文件。而LSM-tree通过滚动合并和多页块的方法推迟和批量进行索引更新，充分利用内存来存储近期或常用数据以降低查找代价，利用硬盘来存储不常用数据以减少存储代价。\n\n**参考文献**\n\n[1]FAY CHANG,JEFFREY DEAN,SANJAY GHEMAWAT et al.Bigtable: A Distributed Storage System for Structured Data[J].ACM Transactions on Computer Systems,2008,26(2):1-26.\n\n[2]Sanjay Ghemawat,Howard Gobioff,Shun-Tak Leung et al.The Google File System[J].Operating systems review,2003,37(5):29-43.DOI:10.1145/1165389.945450.\n\n[3]O'Neil P;Cheng E;Gawlick D.The log-structured merge-tree[J].Acta Informatica,1996,33(04):351-385.DOI:10.1007/s002360050048.\n\n[4]M.Rosenblum;J.K.Osterhout.The design and implementation of a log-structured file system[J].ACM Trans on Computer Systems vol,1992,10(01):26-52.DOI:10.1145/146941.146943.\n\n[5]O'Neil P; The SB-tree:An index-sequential structure for high-performance sequential access[J].Acta Informatica,1992,29, 241-265\n\n---\n\n* 原文链接：[日志结构的合并树 The Log-Structured Merge-Tree](http://www.cnblogs.com/siegfang/archive/2013/01/12/lsm-tree.html)\n","tags":["Succinct"],"categories":["Succinct"]},{"title":"海量数据处理算法—BitMap","url":"%2F2012%2F2012-08-21-bitmap%2F","content":"\n### Bit Map算法简介\n\n来自于《编程珠玑》。所谓的Bit-map就是用一个bit位来标记某个元素对应的Value，而Key即是该元素。由于采用了Bit为单位来存储数据，因此在存储空间方面，可以大大节省。\n\n### Bit Map的基本思想\n\n我们先来看一个具体的例子，假设我们要对0-7内的5个元素(4,7,2,5,3)排序（这里假设这些元素没有重复）。那么我们就可以采用Bit-map的方法来达到排序的目的。要表示8个数，我们就只需要8个Bit（1Bytes），首先我们开辟1Byte的空间，将这些空间的所有Bit位都置为0，如下图：\n\n![](/assets/images/2012/08/21/bitmap/1.jpg)\n\n然后遍历这5个元素，首先第一个元素是4，那么就把4对应的位置为1（可以这样操作 `p+(i/8)|(0x01<<(i%8))` 当然了这里的操作涉及到Big-ending和Little-ending的情况，这里默认为Big-ending）,因为是从零开始的，所以要把第五位置为一（如下图）：\n\n![](/assets/images/2012/08/21/bitmap/2.jpg)\n\n然后再处理第二个元素7，将第八位置为1,，接着再处理第三个元素，一直到最后处理完所有的元素，将相应的位置为1，这时候的内存的Bit位的状态如下：\n\n![](/assets/images/2012/08/21/bitmap/3.jpg)\n\n然后我们现在遍历一遍Bit区域，将该位是一的位的编号输出（2，3，4，5，7），这样就达到了排序的目的。\n\n优点：\n\n* 运算效率高，不许进行比较和移位；\n* 占用内存少，比如N=10000000；只需占用内存为N/8=1250000Byte=1.25M。\n\n缺点：\n\n* 所有的数据不能重复。即不可对重复的数据进行排序和查找。\n\n算法思想比较简单，但关键是如何确定十进制的数映射到二进制bit位的map图。\n\n### Map映射表\n\n假设需要排序或者查找的总数N=10000000，那么我们需要申请内存空间的大小为int a[1 + N/32]，其中：a[0]在内存中占32为可以对应十进制数0-31，依次类推，bitmap表为：\n\n```\na[0]--------->0-31\na[1]--------->32-63\na[2]--------->64-95\na[3]--------->96-127\n..........\n```\n\n那么十进制数如何转换为对应的bit位，下面介绍用位移将十进制数转换为对应的bit位。\n\n### 位移转换 \n\n申请一个int一维数组，那么可以当作为列为32位的二维数组，\n\n```\n二维数组     |               32位                   |\n\nint a[0]    |0000000000000000000000000000000000000|\n\nint a[1]    |0000000000000000000000000000000000000|\n\n………………\n\nint a[N]    |0000000000000000000000000000000000000|\n```\n\n例如十进制0，对应在a[0]所占的bit为中的第一位：00000000000000000000000000000001\n\n```\n# 0-31：对应在a[0]中 \n\ni=0                   00000000000000000000000000000000 \ntemp=0                00000000000000000000000000000000 \nanswer=1              00000000000000000000000000000001 \n\ni=1                   00000000000000000000000000000001 \ntemp=1                00000000000000000000000000000001 \nanswer=2              00000000000000000000000000000010 \n\ni=2                   00000000000000000000000000000010 \ntemp=2                00000000000000000000000000000010 \nanswer=4              00000000000000000000000000000100 \n\ni=30                  00000000000000000000000000011110 \ntemp=30               00000000000000000000000000011110 \nanswer=1073741824     01000000000000000000000000000000 \n\ni=31                  00000000000000000000000000011111 \ntemp=31               00000000000000000000000000011111 \nanswer=-2147483648    10000000000000000000000000000000 \n\n# 32-63：对应在a[1]中 \n\ni=32                  00000000000000000000000000100000 \ntemp=0                00000000000000000000000000000000 \nanswer=1              00000000000000000000000000000001 \n\ni=33                  00000000000000000000000000100001 \ntemp=1                00000000000000000000000000000001 \nanswer=2              00000000000000000000000000000010 \n\ni=34                  00000000000000000000000000100010 \ntemp=2                00000000000000000000000000000010 \nanswer=4              00000000000000000000000000000100 \n\ni=61                  00000000000000000000000000111101 \ntemp=29               00000000000000000000000000011101 \nanswer=536870912      00100000000000000000000000000000 \n\ni=62                  00000000000000000000000000111110 \ntemp=30               00000000000000000000000000011110 \nanswer=1073741824     01000000000000000000000000000000 \n\ni=63                  00000000000000000000000000111111 \ntemp=31               00000000000000000000000000011111 \nanswer=-2147483648    10000000000000000000000000000000\n```\n\n浅析上面的对应表，分三步：\n \n**1.求十进制0-N对应在数组a中的下标：**\n\n十进制0-31，对应在a[0]中，先由十进制数n转换为与32的余可转化为对应在数组a中的下标。比如n=24,那么 n/32=0，则24对应在数组a中的下标为0。又比如n=60,那么n/32=1，则60对应在数组a中的下标为1，同理可以计算0-N在数组a中的下标。 \n\n**2.求0-N对应0-31中的数：**\n\n十进制0-31就对应0-31，而32-63则对应也是0-31，即给定一个数n可以通过模32求得对应0-31中的数。 \n\n**3.利用移位0-31使得对应32bit位为1.**\n\n找到对应0-31的数为M, 左移M位：即2^M. 然后置1.\n\n由此我们计算10000000个bit占用的空间：\n\n1byte = 8bit\n\n1kb = 1024byte\n\n1mb = 1024kb\n\n占用的空间为：10000000/8/1024/1024mb。\n\n大概为1mb多一些。\n\n### 扩展 \n\nBloom filter可以看做是对bit-map的扩展 \n\n### Bit-Map的应用\n\n1）可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下。\n\n2）去重数据而达到压缩数据\n\n### Bit-Map的具体实现\n\nc语言实现：\n\n```c\n#define BITSPERWORD 32\n#define SHIFT 5\n#define MASK 0x1F\n#define N 10000000\n\nint a[1 + N/BITSPERWORD];//申请内存的大小\n\n//set 设置所在的bit位为1\nvoid set(int i) {\n    a[i>>SHIFT] |=  (1<<(i & MASK)); \n}\n//clr 初始化所有的bit位为0\nvoid clr(int i) {\n    a[i>>SHIFT] &= ~(1<<(i & MASK)); \n}\n//test 测试所在的bit为是否为1\nint  test(int i){ \n    return a[i>>SHIFT] &   (1<<(i & MASK)); \n}\n\nint main()\n{   int i;\n    for (i = 0; i < N; i++)\n        clr(i);\n    while (scanf(\"%d\", &i) != EOF)\n        set(i);\n    for (i = 0; i < N; i++)\n        if (test(i))\n            printf(\"%d\\n\", i);\n    return 0;\n} \n```\n\n注明： 左移n位就是乘以2的n次方，右移n位就是除以2的n次方\n\n解析本例中的 `void set(int i) { a[i>>SHIFT] |=  (1<<(i & MASK)); }`\n\n* i>>SHIFT： \n\n其中SHIFT=5，即i右移5为，2^5=32,相当于i/32，即求出十进制i对应在数组a中的下标。比如i=20，通过i>>SHIFT=20>>5=0 可求得i=20的下标为0；\n\n* i & MASK： \n\n其中MASK=0X1F,十六进制转化为十进制为31，二进制为0001 1111，i&（0001 1111）相当于保留i的后5位。 \n\n比如i=23，二进制为：0001 0111，那么：\n\n```\n       0001 0111 \n  &    0001 1111 = 0001 0111 //十进制为：23 \n```\n\n比如i=83，二进制为：0000 0000 0101 0011，那么：\n\n```\n      0000 0000 0101 0011 \n  &   0000 0000 0001 0000 = 0000 0000 0001 0011 //十进制为：19 \n```\n\ni & MASK相当于i%32。 \n\n3. 1<<(i & MASK) \n\n相当于把1左移 (i & MASK)位。 比如(i & MASK)=20，那么i<<20就相当于： \n\n```\n   0000 0000 0000 0000 0000 0000 0000 0001 << 20 \n  =0000 0000 0001 0000 0000 0000 0000 0000 \n```\n\n注意上面 `“|=”`.\n\n在博文：位运算符及其应用 提到过这样位运算应用：\n\n  将int型变量a的第k位清0，即a=a&~(1<<k)\n  将int型变量a的第k位置1， 即a=a|(1<<k)\n\n这里的将 `a[i/32] |= (1<<M));` 第M位置1 .\n\n4) `void set(int i) { a[i>>SHIFT] |= (1<<(i & MASK)); }` 等价于：\n\n```cpp\nvoid set(int i) \n{ \n   a[i/32] |= (1<<(i%32)); \n}\n```\n\n即实现上面提到的三步：\n\n1.求十进制0-N对应在数组a中的下标： n/32 \n\n2.求0-N对应0-31中的数： N%32=M\n\n3.利用移位0-31使得对应32bit位为1: 1<<M，并置1;\n\nphp实现是一样的：\n\n```php\n<?php\n  error_reporting(E_ERROR);\ndefine(\"MASK\", 0x1f);//31\ndefine(\"BITSPERWORD\",32); \ndefine(\"SHIFT\",5);\ndefine(\"MASK\",0x1F); \ndefine(\"N\",1000); \n\n $a = array(); \n//set 设置所在的bit位为1\nfunction set($i) { \n    global $a; \n    $a[$i>>SHIFT] |=  (1<<($i & MASK)); \n}\n//clr 初始化所有的bit位为0\nfunction clr($i) {\n    $a[$i>>SHIFT] &= ~(1<<($i & MASK)); \n}\n//test 测试所在的bit为是否为1\nfunction test($i){\n    global $a;\n    return $a[$i>>SHIFT] & (1<<($i & MASK)); \n}\n$aa = array(1,2,3,31, 33,56,199,30,50);\nwhile ($v =current($aa))  {\n   set($v); \n   if(!next($aa)) {\n       break;\n   }\n}\nforeach ($a as $key=>$v){\n    echo $key,'=', decbin($v),\"\\r\\n\";\n}\n```\n\n然后我们打印结果：\n\n0=11000000000000000000000000001110\n\n1=1000001000000000000000010\n\n6=10000000\n\n32位表示，实际结果一目了然了，看看1,2,3,30,31,33,50，56,199数据所在的具体位置：\n\n```\n   31 30                                          3  2  1\n    ↑  ↑                                          ↑  ↑  ↑\n0=  1  1  00  0000  0000  0000  0000  0000  0000  1  1  1  0\n\n            56        50                       33\n             ↑         ↑                        ↑\n1=  0000  0001  0000  0100  0000  0000  0000  0010\n\n                                      199\n                                        ↑\n6=  0000  0000  0000  0000  0000  0000  1000  0000\n```\n\n【问题实例】\n\n1. 已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。\n\n8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。 （可以理解为从0-99 999 999的数字，每个数字对应一个Bit位，所以只需要99M个Bit==1.2MBytes，这样，就用了小小的1.2M左右的内存表示了所有的8位数的电话）\n\n2. 5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。 \n\n将bit-map扩展一下，用2bit表示一个数即可，0表示未出现，1表示出现一次，2表示出现2次及以上，在遍历这些数的时候，如果对应位置的值是0，则将其置为1；如果是1，将其置为2；如果是2，则保持不变。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map，都是一样的道理。\n\n实现：\n\n```cpp\n// TestWin32.cpp : Defines the entry point for the console application.\n#include \"stdafx.h\"\n\n#include<memory.h>\n\n//用char数组存储2-Bitmap,不用考虑大小端内存的问题\nunsigned char flags[1000]; //数组大小自定义 \nunsigned get_val(int idx)  { \n//  |    8 bit  |\n//  |00 00 00 00|  //映射3 2 1 0\n//  |00 00 00 00|  //表示7 6 5 4\n//  ……\n//  |00 00 00 00|\n\n    int i = idx/4;  //一个char 表示4个数，\n    int j = idx%4;\n    unsigned ret = (flags[i]&(0x3<<(2*j)))>>(2*j);\n    //0x3是0011 j的范围为0-3，因此0x3<<(2*j)范围为00000011到11000000 如idx=7 i=1 ,j=3 那么flags[1]&11000000, 得到的是|00 00 00 00|\n    //表示7 6 5 4\n   return ret;\n}\n\nunsigned set_val(int idx, unsigned int val)  {\n    int i = idx/4;\n    int j = idx%4;\n    unsigned tmp = (flags[i]&~((0x3<<(2*j))&0xff)) | (((val%4)<<(2*j))&0xff);\n    flags[i] = tmp;\n    return 0;\n}\nunsigned add_one(int idx)\n{\n    if (get_val(idx)>=2) {  //这一位置上已经出现过了？？\n        return 1;\n    }  else  {\n        set_val(idx, get_val(idx)+1);\n        return 0;\n    }\n}\n\n//只测试非负数的情况;\n//假如考虑负数的话,需增加一个2-Bitmap数组.\nint a[]={1, 3, 5, 7, 9, 1, 3, 5, 7, 1, 3, 5,1, 3, 1,10,2,4,6,8,0};\n\nint main()   {\n    int i;\n    memset(flags, 0, sizeof(flags));\n\n    printf(\"原数组为:\");\n    for(i=0;i < sizeof(a)/sizeof(int); ++i)  {\n        printf(\"%d  \", a[i]);\n        add_one(a[i]);\n    }\n    printf(\"\\r\\n\");\n\n    printf(\"只出现过一次的数:\");\n    for(i=0;i < 100; ++i)  {\n        if(get_val(i) == 1)\n            printf(\"%d  \", i);\n        }\n    printf(\"\\r\\n\");\n\n    return 0;\n}\n```\n\n---\n\n* 原文链接：[海量数据处理算法—Bit-Map](http://blog.csdn.net/hguisu/article/details/7880288)\n","tags":["BitMap"],"categories":["BitMap"]},{"title":"Bloom Filter 系列文章","url":"%2F2012%2F2012-07-13-bloom-filter%2F","content":"\nBloom Filter是一种空间效率很高的随机数据结构，它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。Bloom Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。\n\n**理论**\n\n* [布隆过滤器(Bloom Filter)详解](http://www.cnblogs.com/haippy/archive/2012/07/13/2590351.html)\n\n**理论&实践**\n\n* [BloomFilter–大规模数据处理利器(解决空查问题)](http://www.dbafree.net/?p=36)\n* [海量数据处理算法—Bloom Filter](http://blog.csdn.net/hguisu/article/details/7866173)\n\n**系列**\n\n* [Bloom Filter](http://blog.csdn.net/jiaomeng/article/category/275566)","tags":["Bloom-Filter"],"categories":["Bloom-Filter"]},{"title":"拓扑排序的原理及其实现","url":"%2F2012%2F2012-07-04-topological-sorting%2F","content":"\n**本文将从以下几个方面介绍拓扑排序：**\n\n*  拓扑排序的定义和前置条件\n*  和离散数学中偏序/全序概念的联系\n*  典型实现算法\n   *  Kahn算法\n   *  基于DFS的算法\n*  解的唯一性问题\n*  实际例子\n\n**取材自以下材料：**\n\n* http://en.wikipedia.org/wiki/Topological_sorting\n* http://en.wikipedia.org/wiki/Hamiltonian_path\n\n# 定义和前置条件：\n\n定义：将有向图中的顶点以线性方式进行排序。即对于任何连接自顶点u到顶点v的有向边uv，在最后的排序结果中，顶点u总是在顶点v的前面。\n \n如果这个概念还略显抽象的话，那么不妨考虑一个非常非常经典的例子——选课。我想任何看过数据结构相关书籍的同学都知道它吧。假设我非常想学习一门机器学习的课程，但是在修这么课程之前，我们必须要学习一些基础课程，比如计算机科学概论，C语言程序设计，数据结构，算法等等。那么这个制定选修课程顺序的过程，实际上就是一个拓扑排序的过程，每门课程相当于有向图中的一个顶点，而连接顶点之间的有向边就是课程学习的先后关系。只不过这个过程不是那么复杂，从而很自然的在我们的大脑中完成了。将这个过程以算法的形式描述出来的结果，就是拓扑排序。\n \n那么是不是所有的有向图都能够被拓扑排序呢？显然不是。继续考虑上面的例子，如果告诉你在选修计算机科学概论这门课之前需要你先学习机器学习，你是不是会被弄糊涂？在这种情况下，就无法进行拓扑排序，因为它中间存在互相依赖的关系，从而无法确定谁先谁后。在有向图中，这种情况被描述为存在环路。因此，一个有向图能被拓扑排序的充要条件就是它是一个有向无环图(DAG：Directed Acyclic Graph)。\n\n# 偏序/全序关系：\n\n偏序和全序实际上是离散数学中的概念。\n\n这里不打算说太多形式化的定义，形式化的定义教科书上或者上面给的链接中就说的很详细。\n \n还是以上面选课的例子来描述这两个概念。假设我们在学习完了算法这门课后，可以选修机器学习或者计算机图形学。这个或者表示，学习机器学习和计算机图形学这两门课之间没有特定的先后顺序。因此，在我们所有可以选择的课程中，任意两门课程之间的关系要么是确定的(即拥有先后关系)，要么是不确定的(即没有先后关系)，绝对不存在互相矛盾的关系(即环路)。以上就是偏序的意义，抽象而言，有向图中两个顶点之间不存在环路，至于连通与否，是无所谓的。所以，有向无环图必然是满足偏序关系的。\n \n理解了偏序的概念，那么全序就好办了。所谓全序，就是在偏序的基础之上，有向无环图中的任意一对顶点还需要有明确的关系(反映在图中，就是单向连通的关系，注意不能双向连通，那就成环了)。可见，全序就是偏序的一种特殊情况。回到我们的选课例子中，如果机器学习需要在学习了计算机图形学之后才能学习(可能学的是图形学领域相关的机器学习算法……)，那么它们之间也就存在了确定的先后顺序，原本的偏序关系就变成了全序关系。\n \n实际上，很多地方都存在偏序和全序的概念。\n\n比如对若干互不相等的整数进行排序，最后总是能够得到唯一的排序结果(从小到大，下同)。这个结论应该不会有人表示疑问吧:)但是如果我们以偏序/全序的角度来考虑一下这个再自然不过的问题，可能就会有别的体会了。\n \n那么如何用偏序/全序来解释排序结果的唯一性呢？\n\n我们知道不同整数之间的大小关系是确定的，即1总是小于4的，不会有人说1大于或者等于4吧。这就是说，这个序列是满足全序关系的。而对于拥有全序关系的结构(如拥有不同整数的数组)，在其线性化(排序)之后的结果必然是唯一的。对于排序的算法，我们评价指标之一是看该排序算法是否稳定，即值相同的元素的排序结果是否和出现的顺序一致。比如，我们说快速排序是不稳定的，这是因为最后的快排结果中相同元素的出现顺序和排序前不一致了。如果用偏序的概念可以这样解释这一现象：相同值的元素之间的关系是无法确定的。因此它们在最终的结果中的出现顺序可以是任意的。而对于诸如插入排序这种稳定性排序，它们对于值相同的元素，还有一个潜在的比较方式，即比较它们的出现顺序，出现靠前的元素大于出现后出现的元素。因此通过这一潜在的比较，将偏序关系转换为了全序关系，从而保证了结果的唯一性。\n \n拓展到拓扑排序中，结果具有唯一性的条件也是其所有顶点之间都具有全序关系。如果没有这一层全序关系，那么拓扑排序的结果也就不是唯一的了。在后面会谈到，如果拓扑排序的结果唯一，那么该拓扑排序的结果同时也代表了一条哈密顿路径。\n\n# 典型实现算法：\n\n### Kahn算法：\n\n摘一段维基百科上关于Kahn算法的伪码描述：\n```\nL← Empty list that will contain the sorted elements\nS ← Set of all nodes with no incoming edges\nwhile S is non-empty do\n    remove a node n from S\n    insert n into L\n    foreach node m with an edge e from nto m do\n        remove edge e from thegraph\n        ifm has no other incoming edges then\n            insert m into S\nif graph has edges then\n    return error (graph has at least onecycle)\nelse \n    return L (a topologically sortedorder)\n```\n不难看出该算法的实现十分直观，关键在于需要维护一个入度为0的顶点的集合：\n每次从该集合中取出(没有特殊的取出规则，随机取出也行，使用队列/栈也行，下同)一个顶点，将该顶点放入保存结果的List中。\n紧接着循环遍历由该顶点引出的所有边，从图中移除这条边，同时获取该边的另外一个顶点，如果该顶点的入度在减去本条边之后为0，那么也将这个顶点放到入度为0的集合中。然后继续从集合中取出一个顶点…………\n \n当集合为空之后，检查图中是否还存在任何边，如果存在的话，说明图中至少存在一条环路。不存在的话则返回结果List，此List中的顺序就是对图进行拓扑排序的结果。\n\n```java\npublic class KahnTopological\n{\n\tprivate List<Integer> result;   // 用来存储结果集\n\tprivate Queue<Integer> setOfZeroIndegree;  // 用来存储入度为0的顶点\n\tprivate int[] indegrees;  // 记录每个顶点当前的入度\n\tprivate int edges;\n\tprivate Digraph di;\n\t\n\tpublic KahnTopological(Digraph di)\n\t{\n\t\tthis.di = di;\n\t\tthis.edges = di.getE();\n\t\tthis.indegrees = new int[di.getV()];\n\t\tthis.result = new ArrayList<Integer>();\n\t\tthis.setOfZeroIndegree = new LinkedList<Integer>();\n\t\t\n\t\t// 对入度为0的集合进行初始化\n\t\tIterable<Integer>[] adjs = di.getAdj();\n\t\tfor(int i = 0; i < adjs.length; i++)\n\t\t{\n\t\t\t// 对每一条边 v -> w \n\t\t\tfor(int w : adjs[i])\n\t\t\t{\n\t\t\t\tindegrees[w]++;\n\t\t\t}\n\t\t}\n\t\t\n\t\tfor(int i = 0; i < indegrees.length; i++)\n\t\t{\n\t\t\tif(0 == indegrees[i])\n\t\t\t{\n\t\t\t\tsetOfZeroIndegree.enqueue(i);\n\t\t\t}\n\t\t}\n\t\tprocess();\n\t}\n\t\n\tprivate void process()\n\t{\n\t\twhile(!setOfZeroIndegree.isEmpty())\n\t\t{\n\t\t\tint v = setOfZeroIndegree.dequeue();\n\t\t\t\n\t\t\t// 将当前顶点添加到结果集中\n\t\t\tresult.add(v);\n\t\t\t\n\t\t\t// 遍历由v引出的所有边\n\t\t\tfor(int w : di.adj(v))\n\t\t\t{\n\t\t\t\t// 将该边从图中移除，通过减少边的数量来表示\n\t\t\t\tedges--;\n\t\t\t\tif(0 == --indegrees[w])   // 如果入度为0，那么加入入度为0的集合\n\t\t\t\t{\n\t\t\t\t\tsetOfZeroIndegree.enqueue(w);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// 如果此时图中还存在边，那么说明图中含有环路\n\t\tif(0 != edges)\n\t\t{\n\t\t\tthrow new IllegalArgumentException(\"Has Cycle !\");\n\t\t}\n\t}\n\t\n\tpublic Iterable<Integer> getResult()\n\t{\n\t\treturn result;\n\t}\n}\n\n```\n![](/assets/images/2012/07/04/topological_sorting/001.png)\n\n对上图进行拓扑排序的结果：\n\n2->8->0->3->7->1->5->6->9->4->11->10->12\n\n复杂度分析：\n\n初始化入度为0的集合需要遍历整张图，检查每个节点和每条边，因此复杂度为O(E+V);\n\n然后对该集合进行操作，又需要遍历整张图中的，每条边，复杂度也为O(E+V);\n\n因此Kahn算法的复杂度即为O(E+V)。\n\n### 基于DFS的拓扑排序：\n\n除了使用上面直观的Kahn算法之外，还能够借助深度优先遍历来实现拓扑排序。这个时候需要使用到栈结构来记录拓扑排序的结果。\n\n同样摘录一段维基百科上的伪码：\n\n```\nL ← Empty list that will contain the sorted nodes\nS ← Set of all nodes with no outgoing edges\nfor each node n in S do\n    visit(n) \nfunction visit(node n)\n    if n has not been visited yet then\n        mark n as visited\n        for each node m with an edgefrom m to ndo\n            visit(m)\n        add n to L\n```\n\nDFS的实现更加简单直观，使用递归实现。利用DFS实现拓扑排序，实际上只需要添加一行代码，即上面伪码中的最后一行：add n to L。\n\n需要注意的是，将顶点添加到结果List中的时机是在visit方法即将退出之时。\n\n这个算法的实现非常简单，但是要理解的话就相对复杂一点。\n\n关键在于为什么在visit方法的最后将该顶点添加到一个集合中，就能保证这个集合就是拓扑排序的结果呢？\n\n因为添加顶点到集合中的时机是在dfs方法即将退出之时，而dfs方法本身是个递归方法，只要当前顶点还存在边指向其它任何顶点，它就会递归调用dfs方法，而不会退出。因此，退出dfs方法，意味着当前顶点没有指向其它顶点的边了，即当前顶点是一条路径上的最后一个顶点。\n \n下面简单证明一下它的正确性：\n\n考虑任意的边v->w，当调用dfs(v)的时候，有如下三种情况：\n\ndfs(w)还没有被调用，即w还没有被mark，此时会调用dfs(w)，然后当dfs(w)返回之后，dfs(v)才会返回\n\ndfs(w)已经被调用并返回了，即w已经被mark\n\ndfs(w)已经被调用但是在此时调用dfs(v)的时候还未返回\n\n需要注意的是，以上第三种情况在拓扑排序的场景下是不可能发生的，因为如果情况3是合法的话，就表示存在一条由w到v的路径。而现在我们的前提条件是由v到w有一条边，这就导致我们的图中存在环路，从而该图就不是一个有向无环图(DAG)，而我们已经知道，非有向无环图是不能被拓扑排序的。\n \n那么考虑前两种情况，无论是情况1还是情况2，w都会先于v被添加到结果列表中。所以边v->w总是由结果集中后出现的顶点指向先出现的顶点。为了让结果更自然一些，可以使用栈来作为存储最终结果的数据结构，从而能够保证边v->w总是由结果集中先出现的顶点指向后出现的顶点。\n\n```java\npublic class DirectedDepthFirstOrder\n{\n\t// visited数组，DFS实现需要用到\n\tprivate boolean[] visited;\n\t// 使用栈来保存最后的结果\n\tprivate Stack<Integer> reversePost;\n\n\t/**\n\t * Topological Sorting Constructor\n\t */\n\tpublic DirectedDepthFirstOrder(Digraph di, boolean detectCycle)\n\t{\n\t\t// 这里的DirectedDepthFirstCycleDetection是一个用于检测有向图中是否存在环路的类\n\t\tDirectedDepthFirstCycleDetection detect = new DirectedDepthFirstCycleDetection(\n\t\t\t\tdi);\n\t\t\n\t\tif (detectCycle && detect.hasCycle())\n\t\t\tthrow new IllegalArgumentException(\"Has cycle\");\n\t\t\t\n\t\tthis.visited = new boolean[di.getV()];\n\t\tthis.reversePost = new Stack<Integer>();\n\n\t\tfor (int i = 0; i < di.getV(); i++)\n\t\t{\n\t\t\tif (!visited[i])\n\t\t\t{\n\t\t\t\tdfs(di, i);\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate void dfs(Digraph di, int v)\n\t{\n\t\tvisited[v] = true;\n\n\t\tfor (int w : di.adj(v))\n\t\t{\n\t\t\tif (!visited[w])\n\t\t\t{\n\t\t\t\tdfs(di, w);\n\t\t\t}\n\t\t}\n\n\t\t// 在即将退出dfs方法的时候，将当前顶点添加到结果集中\n\t\treversePost.push(v);\n\t}\n\n\tpublic Iterable<Integer> getReversePost()\n\t{\n\t\treturn reversePost;\n\t}\n}\n```\n\n复杂度分析：\n\n复杂度同DFS一致，即O(E+V)。具体而言，首先需要保证图是有向无环图，判断图是DAG可以使用基于DFS的算法，复杂度为O(E+V)，而后面的拓扑排序也是依赖于DFS，复杂度为O(E+V)\n \n还是对上文中的那张有向图进行拓扑排序，只不过这次使用的是基于DFS的算法，结果是：\n\n8->7->2->3->0->6->9->10->11->12->1->5->4\n\n### 两种实现算法的总结：\n\n这两种算法分别使用链表和栈来表示结果集。\n\n对于基于DFS的算法，加入结果集的条件是：顶点的出度为0。这个条件和Kahn算法中入度为0的顶点集合似乎有着异曲同工之妙，这两种算法的思想犹如一枚硬币的两面，看似矛盾，实则不然。一个是从入度的角度来构造结果集，另一个则是从出度的角度来构造。\n \n实现上的一些不同之处：\n\nKahn算法不需要检测图为DAG，如果图为DAG，那么在出度为0的集合为空之后，图中还存在没有被移除的边，这就说明了图中存在环路。而基于DFS的算法需要首先确定图为DAG，当然也能够做出适当调整，让环路的检测和拓扑排序同时进行，毕竟环路检测也能够在DFS的基础上进行。\n\n二者的复杂度均为O(V+E)。\n \n环路检测和拓扑排序同时进行的实现：\n\n```java\npublic class DirectedDepthFirstTopoWithCircleDetection\n{\n\tprivate boolean[] visited;\n\t// 用于记录dfs方法的调用栈，用于环路检测\n\tprivate boolean[] onStack;\n\t// 用于当环路存在时构造之\n\tprivate int[] edgeTo;\n\tprivate Stack<Integer> reversePost;\n\tprivate Stack<Integer> cycle;\n\n\t/**\n\t * Topological Sorting Constructor\n\t */\n\tpublic DirectedDepthFirstTopoWithCircleDetection(Digraph di)\n\t{\n\t\tthis.visited = new boolean[di.getV()];\n\t\tthis.onStack = new boolean[di.getV()];\n\t\tthis.edgeTo = new int[di.getV()];\n\t\tthis.reversePost = new Stack<Integer>();\n\n\t\tfor (int i = 0; i < di.getV(); i++)\n\t\t{\n\t\t\tif (!visited[i])\n\t\t\t{\n\t\t\t\tdfs(di, i);\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate void dfs(Digraph di, int v)\n\t{\n\t\tvisited[v] = true;\n\t\t// 在调用dfs方法时，将当前顶点记录到调用栈中\n\t\tonStack[v] = true;\n\n\t\tfor (int w : di.adj(v))\n\t\t{\n\t\t\tif(hasCycle())\n\t\t\t{\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (!visited[w])\n\t\t\t{\n\t\t\t\tedgeTo[w] = v;\n\t\t\t\tdfs(di, w);\n\t\t\t}\n\t\t\telse if(onStack[w])\n\t\t\t{\n\t\t\t\t// 当w已经被访问，同时w也存在于调用栈中时，即存在环路\n\t\t\t\tcycle = new Stack<Integer>();\n\t\t\t\tcycle.push(w);\n\t\t\t\tfor(int start = v; start != w; start = edgeTo[start])\n\t\t\t\t{\n\t\t\t\t\tcycle.push(v);\n\t\t\t\t}\n\t\t\t\tcycle.push(w);\n\t\t\t}\n\t\t}\n\n\t\t// 在即将退出dfs方法时，将顶点添加到拓扑排序结果集中，同时从调用栈中退出\n\t\treversePost.push(v);\n\t\tonStack[v] = false;\n\t}\n\n\tprivate boolean hasCycle() \n\t{\n\t\treturn (null != cycle);\n\t}\n\t\n\tpublic Iterable<Integer> getReversePost()\n\t{\n\t\tif(!hasCycle())\n\t\t{\n\t\t\treturn reversePost;\n\t\t}\n\t\telse \n\t\t{\n\t\t\tthrow new IllegalArgumentException(\"Has Cycle: \" + getCycle());\n\t\t}\n\t}\n\t\n\tpublic Iterable<Integer> getCycle() \n\t{\n\t\treturn cycle;\n\t}\n}\n\n```\n\n# 拓扑排序解的唯一性：\n\n### 哈密顿路径：\n\n哈密顿路径是指一条能够对图中所有顶点正好访问一次的路径。本文中只会解释一些哈密顿路径和拓扑排序的关系，至于哈密顿路径的具体定义以及应用，可以参见本文开篇给出的链接。\n \n前面说过，当一个DAG中的任何两个顶点之间都存在可以确定的先后关系时，对该DAG进行拓扑排序的解是唯一的。这是因为它们形成了全序的关系，而对存在全序关系的结构进行线性化之后的结果必然是唯一的(比如对一批整数使用稳定的排序算法进行排序的结果必然就是唯一的)。\n \n需要注意的是，非DAG也是能够含有哈密顿路径的，为了利用拓扑排序来实现判断，所以这里讨论的主要是判断DAG中是否含有哈密顿路径的算法，因此下文中的图指代的都是DAG。\n \n那么知道了哈密顿路径和拓扑排序的关系，我们如何快速检测一张图是否存在哈密顿路径呢？\n\n根据前面的讨论，是否存在哈密顿路径的关键，就是确定图中的顶点是否存在全序的关系，而全序的关键，就是任意一对顶点之间都是能够确定先后关系的。因此，我们能够设计一个算法，用来遍历顶点集中的每一对顶点，然后检查它们之间是否存在先后关系，如果所有的顶点对有先后关系，那么该图的顶点集就存在全序关系，即图中存在哈密顿路径。\n \n但是很显然，这样的算法十分低效。对于大规模的顶点集，是无法应用这种解决方案的。通常一个低效的解决办法，十有八九是因为没有抓住现有问题的一些特征而导致的。因此我们回过头来再看看这个问题，有什么特征使我们没有利用的。还是举对整数进行排序的例子：\n\n比如现在有3， 2， 1三个整数，我们要对它们进行排序，按照之前的思想，我们分别对(1,2)，(2,3)，(1,3)进行比较，这样需要三次比较，但是我们很清楚，1和3的那次比较实际上是多余的。我们为什么知道这次比较是多余的呢？我认为，是我们下意识的利用了整数比较满足传递性的这一规则。但是计算机是无法下意识的使用传递性的，因此只能通过其它的方式来告诉计算机，有一些比较是不必要的。所以，也就有了相对插入排序，选择排序更加高效的排序算法，比如归并排序，快速排序等，将n2的算法加速到了nlogn。或者是利用了问题的特点，采取了更加独特的解决方案，比如基数排序等。\n \n扯远了一点，回到正题。现在我们没有利用到的就是全序关系中传递性这一规则。如何利用它呢，最简单的想法往往就是最实用的，我们还是选择排序，排序后对每对相邻元素进行检测不就间接利用了传递性这一规则嘛？所以，我们先使用拓扑排序对图中的顶点进行排序。排序后，对每对相邻顶点进行检测，看看是否存在先后关系，如果每对相邻顶点都存在着一致的先后关系(在有向图中，这种先后关系以有向边的形式体现，即查看相邻顶点对之间是否存在有向边)。那么就可以确定该图中存在哈密顿路径了，反之则不存在。\n\n```java\n/**\n * Hamilton Path Detection for DAG\n */\npublic class DAGHamiltonPath\n{\n\tprivate boolean hamiltonPathPresent;\n\tprivate Digraph di;\n\tprivate KahnTopological kts;\n\t\n\t// 这里使用Kahn算法进行拓扑排序\n\tpublic DAGHamiltonPath(Digraph di, KahnTopological kts)\n\t{\n\t\tthis.di = di;\n\t\tthis.kts = kts;\n\t\tprocess();\n\t}\n\t\n\tprivate void process()\n\t{\n\t\tInteger[] topoResult = kts.getResultAsArray();\n\t\t\n\t\t// 依次检查每一对相邻顶点，如果二者之间没有路径，则不存在哈密顿路径\n\t\tfor(int i = 0; i < topoResult.length - 1; i++)\n\t\t{\n\t\t\tif(!hasPath(topoResult[i], topoResult[i + 1]))\n\t\t\t{\n\t\t\t\thamiltonPathPresent = false;\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\thamiltonPathPresent = true;\n\t}\n\t\n\tprivate boolean hasPath(int start, int end)\n\t{\n\t\tfor(int w : di.adj(start))\n\t\t{\n\t\t\tif(w == end)\n\t\t\t{\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\n\tpublic boolean hasHamiltonPath()\n\t{\n\t\treturn hamiltonPathPresent;\n\t}\n}\n```\n\n# 实际例子：\n\nTestNG中循环依赖的检测：\n\nhttp://blog.csdn.net/dm_vincent/article/details/7631916\n \n以后还会陆续补充一些例子……\n\n# 相关代码请参考这里：\n\nhttps://github.com/destiny1020/algorithm_playground/tree/master/src/main/Java/chap4\n\n---\n\n* Author: [dm_vincent](http://blog.csdn.net/dm_vincent)\n* Link: [拓扑排序的原理及其实现](http://blog.csdn.net/dm_vincent/article/details/7714519)\n","tags":["Topological"],"categories":["Topological"]},{"title":"缓存算法","url":"%2F2011%2F2011-10-28-cache-algorithm%2F","content":"\n**引言**\n\n我们都听过 cache，当你问他们是什么是缓存的时候，他们会给你一个完美的答案，可是他们不知道缓存是怎么构建的，或者没有告诉你应该采用什么标准去选择缓存框架。在这边文章，我们会去讨论缓存，缓存算法，缓存框架以及哪个缓存框架会更好。\n\n**面试**\n\n“缓存就是存贮数据（使用频繁的数据）的临时地方，因为取原始数据的代价太大了，所以我可以取得快一些。”\n\n这就是 programmer one （programmer one 是一个面试者）在面试中的回答（一个月前，他向公司提交了简历，想要应聘要求在缓存，缓存框架，大规模数据操作有着丰富经验的 java 开发职位）。\n\nprogrammer one 通过 hash table 实现了他自己的缓存，但是他知道的只是他的缓存和他那存储着150条记录的 hash table，这就是他认为的大规模数据（缓存 = hashtable，只需要在 hash table 查找就好了），所以，让我们来看看面试的过程吧。\n\n面试官：你选择的缓存方案，是基于什么标准的？\n\nprogrammer one：呃，（想了5分钟）嗯，基于，基于，基于数据（咳嗽……）\n\n面试官：excese me ! 能不能重复一下？\n\nprogrammer one：数据？！\n\n面试官：好的。说说几种缓存算法以及它们的作用\n\nprogrammer one：（凝视着面试官，脸上露出了很奇怪的表情，没有人知道原来人类可以做出这种表情  ）\n\n面试官：好吧，那我换个说法，当缓存达到容量时，会怎么做？\n\nprogrammer one：容量？嗯（思考……hash table 的容量时没有限制的，我能任意增加条目，它会自动扩充容量的）（这是 programmer one 的想法，但是他没有说出来）\n\n面试官对 programmer one 表示感谢（面试过程持续了10分钟），之后一个女士走过来说：谢谢你的时间，我们会给你打电话的，祝你好心情。这是 programmer one 最糟糕的面试（他没有看到招聘对求职者有丰富的缓存经验背景要求，实际上，他只看到了丰厚的报酬  ）。\n\n**说到做到**\n\nprogrammer one 离开之后，他想要知道这个面试者说的问题和答案，所以他上网去查，programmer one 对缓存一无所知，除了：当我需要缓存的时候，我就会用 hash table。\n\n在他使用了他最爱的搜索引擎搜索之后，他找到了一篇很不错的关于缓存文章，并且开始去阅读……\n\n**为什么我们需要缓存？**\n\n很久很久以前，在还没有缓存的时候……用户经常是去请求一个对象，而这个对象是从数据库去取，然后，这个对象变得越来越大，这个用户每次的请求时间也越来越长了，这也把数据库弄得很痛苦，他无时不刻不在工作。所以，这个事情就把用户和数据库弄得很生气，接着就有可能发生下面两件事情：\n\n1. 用户很烦，在抱怨，甚至不去用这个应用了（这是大多数情况下都会发生的）\n\n2. 数据库为打包回家，离开这个应用，然后，就出现了大麻烦（没地方去存储数据了）（发生在极少数情况下）\n\n**上帝派来了缓存**\n\n在几年之后，IBM（60年代）的研究人员引进了一个新概念，它叫“缓存”。\n\n**什么是缓存？**\n\n正如开篇所讲，缓存是“存贮数据（使用频繁的数据）的临时地方，因为取原始数据的代价太大了，所以我可以取得快一些。”\n\n缓存可以认为是数据的池，这些数据是从数据库里的真实数据复制出来的，并且为了能别取回，被标上了标签（键 ID）。太棒了\n\nprogrammer one 已经知道这点了，但是他还不知道下面的缓存术语。\n\n缓存、缓存算法和缓存框架简介\n\n![](/assets/images/2011/10/28/cache-algorithm/caching.jpg)\n\n**命中：**\n\n当客户发起一个请求（我们说他想要查看一个产品信息），我们的应用接受这个请求，并且如果是在第一次检查缓存的时候，需要去数据库读取产品信息。\n\n如果在缓存中，一个条目通过一个标记被找到了，这个条目就会被使用、我们就叫它缓存命中。所以，命中率也就不难理解了。\n\n**Cache Miss：**\n\n但是这里需要注意两点：\n\n1. 如果还有缓存的空间，那么，没有命中的对象会被存储到缓存中来。\n\n2. 如果缓存满了，而又没有命中缓存，那么就会按照某一种策略，把缓存中的旧对象踢出，而把新的对象加入缓存池。而这些策略统称为替代策略（缓存算法），这些策略会决定到底应该提出哪些对象。\n\n**存储成本：**\n\n当没有命中时，我们会从数据库取出数据，然后放入缓存。而把这个数据放入缓存所需要的时间和空间，就是存储成本。\n\n**索引成本：**\n\n和存储成本相仿。\n\n**失效：**\n\n当存在缓存中的数据需要更新时，就意味着缓存中的这个数据失效了。\n\n**替代策略：**\n\n当缓存没有命中时，并且缓存容量已经满了，就需要在缓存中踢出一个老的条目，加入一条新的条目，而到底应该踢出什么条目，就由替代策略决定。\n\n**最优替代策略：**\n\n最优的替代策略就是想把缓存中最没用的条目给踢出去，但是未来是不能够被预知的，所以这种策略是不可能实现的。但是有很多策略，都是朝着这个目前去努力。\n\n**Java 街恶梦：**\n\n当 programmer one 在读这篇文章的时候，他睡着了，并且做了个恶梦（每个人都有做恶梦的时候）。\n\nprogrammer one：nihahha，我要把你弄失效！（疯狂的状态）\n\n缓存对象：别别，让我活着，他们还需要我，我还有孩子。\n\nprogrammer one：每个缓存对象在失效之前都会那样说。你从什么时候开始有孩子的？不用担心，现在就永远消失吧！\n\n哈哈哈哈哈……programmer one 恐怖的笑着，但是警笛打破了沉静，警察把 programmer one 抓了起来，并且控告他杀死了（失效）一个仍需被使用的缓存对象，他被押到了监狱。\n\nprogrammer one 突然醒了，他被吓到了，浑身是汗，他开始环顾四周，发现这确实是个梦，然后赶紧继续阅读这篇文章，努力的消除自己的恐慌。\n\n在programmer one 醒来之后，他又开始阅读文章了。\n\n**缓存算法**\n\n没有人能说清哪种缓存算法优于其他的缓存算法\n\n**Least Frequently Used（LFU）：**\n\n大家好，我是 LFU，我会计算为每个缓存对象计算他们被使用的频率。我会把最不常用的缓存对象踢走。\n\n**Least Recently User（LRU）：**\n\n我是 LRU 缓存算法，我把最近最少使用的缓存对象给踢走。\n\n我总是需要去了解在什么时候，用了哪个缓存对象。如果有人想要了解我为什么总能把最近最少使用的对象踢掉，是非常困难的。\n\n浏览器就是使用了我（LRU）作为缓存算法。新的对象会被放在缓存的顶部，当缓存达到了容量极限，我会把底部的对象踢走，而技巧就是：我会把最新被访问的缓存对象，放到缓存池的顶部。\n\n所以，经常被读取的缓存对象就会一直呆在缓存池中。有两种方法可以实现我，array 或者是 linked list。\n\n我的速度很快，我也可以被数据访问模式适配。我有一个大家庭，他们都可以完善我，甚至做的比我更好（我确实有时会嫉妒，但是没关系）。我家庭的一些成员包括 LRU2 和 2Q，他们就是为了完善 LRU 而存在的。\n\n**Least Recently Used 2（LRU2）：**\n\n我是 Least Recently Used 2，有人叫我最近最少使用 twice，我更喜欢这个叫法。我会把被两次访问过的对象放入缓存池，当缓存池满了之后，我会把有两次最少使用的缓存对象踢走。因为需要跟踪对象2次，访问负载就会随着缓存池的增加而增加。如果把我用在大容量的缓存池中，就会有问题。另外，我还需要跟踪那么不在缓存的对象，因为他们还没有被第二次读取。我比LRU好，而且是 adoptive to access 模式 。\n\n**Two Queues（2Q）：**\n\n我是 Two Queues；我把被访问的数据放到 LRU 的缓存中，如果这个对象再一次被访问，我就把他转移到第二个、更大的 LRU 缓存。\n\n我踢走缓存对象是为了保持第一个缓存池是第二个缓存池的1/3。当缓存的访问负载是固定的时候，把 LRU 换成 LRU2，就比增加缓存的容量更好。这种机制使得我比 LRU2 更好，我也是 LRU 家族中的一员，而且是 adoptive to access 模式 。\n\n**Adaptive Replacement Cache（ARC）：**\n\n我是 ARC，有人说我是介于 LRU 和 LFU 之间，为了提高效果，我是由2个 LRU 组成，第一个，也就是 L1，包含的条目是最近只被使用过一次的，而第二个 LRU，也就是 L2，包含的是最近被使用过两次的条目。因此， L1 放的是新的对象，而 L2 放的是常用的对象。所以，别人才会认为我是介于 LRU 和 LFU 之间的，不过没关系，我不介意。\n\n我被认为是性能最好的缓存算法之一，能够自调，并且是低负载的。我也保存着历史对象，这样，我就可以记住那些被移除的对象，同时，也让我可以看到被移除的对象是否可以留下，取而代之的是踢走别的对象。我的记忆力很差，但是我很快，适用性也强。\n\n**Most Recently Used（MRU）：**\n\n我是 MRU，和 LRU 是对应的。我会移除最近最多被使用的对象，你一定会问我为什么。好吧，让我告诉你，当一次访问过来的时候，有些事情是无法预测的，并且在缓存系统中找出最少最近使用的对象是一项时间复杂度非常高的运算，这就是为什么我是最好的选择。\n\n我是数据库内存缓存中是多么的常见！每当一次缓存记录的使用，我会把它放到栈的顶端。当栈满了的时候，你猜怎么着？我会把栈顶的对象给换成新进来的对象！\n\n**First in First out（FIFO）：**\n\n我是先进先出，我是一个低负载的算法，并且对缓存对象的管理要求不高。我通过一个队列去跟踪所有的缓存对象，最近最常用的缓存对象放在后面，而更早的缓存对象放在前面，当缓存容量满时，排在前面的缓存对象会被踢走，然后把新的缓存对象加进去。我很快，但是我并不适用。\n\n**Second Chance：**\n\n大家好，我是 second chance，我是通过 FIFO 修改而来的，被大家叫做 second chance 缓存算法，我比 FIFO 好的地方是我改善了 FIFO 的成本。我是 FIFO 一样也是在观察队列的前端，但是很FIFO的立刻踢出不同，我会检查即将要被踢出的对象有没有之前被使用过的标志（1一个 bit 表示），没有没有被使用过，我就把他踢出；否则，我会把这个标志位清除，然后把这个缓存对象当做新增缓存对象加入队列。你可以想象就这就像一个环队列。当我再一次在队头碰到这个对象时，由于他已经没有这个标志位了，所以我立刻就把他踢开了。我在速度上比 FIFO 快。\n\n**CLock：**\n\n我是 Clock，一个更好的 FIFO，也比 second chance 更好。因为我不会像 second chance 那样把有标志的缓存对象放到队列的尾部，但是也可以达到 second chance 的效果。\n\n我持有一个装有缓存对象的环形列表，头指针指向列表中最老的缓存对象。当缓存 miss 发生并且没有新的缓存空间时，我会问问指针指向的缓存对象的标志位去决定我应该怎么做。如果标志是0，我会直接用新的缓存对象替代这个缓存对象；如果标志位是1，我会把头指针递增，然后重复这个过程，知道新的缓存对象能够被放入。我比 second chance 更快。\n\n**Simple time-based：**\n\n我是 simple time-based 缓存算法，我通过绝对的时间周期去失效那些缓存对象。对于新增的对象，我会保存特定的时间。我很快，但是我并不适用。\n\n**Extended time-based expiration：**\n\n我是 extended time-based expiration 缓存算法，我是通过相对时间去失效缓存对象的；对于新增的缓存对象，我会保存特定的时间，比如是每5分钟，每天的12点。\n\n**Sliding time-based expiration：**\n\n我是 sliding time-based expiration，与前面不同的是，被我管理的缓存对象的生命起点是在这个缓存的最后被访问时间算起的。我很快，但是我也不太适用。\n\n其他的缓存算法还考虑到了下面几点：\n\n成本：如果缓存对象有不同的成本，应该把那些难以获得的对象保存下来。\n\n容量：如果缓存对象有不同的大小，应该把那些大的缓存对象清除，这样就可以让更多的小缓存对象进来了。\n\n时间：一些缓存还保存着缓存的过期时间。电脑会失效他们，因为他们已经过期了。\n\n根据缓存对象的大小而不管其他的缓存算法可能是有必要的。\n\n**电子邮件！**\n\n在读完这篇文章之后，programmer one 想了一会儿，然后决定给作者发封邮件，他感觉作者的名字在哪听过，但是已经想不起来了。不管怎样，他还是把邮件发送出来了，他询问了作者在分布式环境中，缓存是怎么样工作的。\n\n文章的作者收到了邮件，具有讽刺意味的是，这个作者就是面试 programmer one 的人  ，作者回复了……\n\n在这一部分中，我们来看看如何实现这些著名的缓存算法。以下的代码只是示例用的，如果你想自己实现缓存算法，可能自己还得加上一些额外的工作。\n\n**LeftOver 机制**\n\n在 programmer one 阅读了文章之后，他接着看了文章的评论，其中有一篇评论提到了 leftover 机制——random cache。\n\n**Random Cache**\n\n我是随机缓存，我随意的替换缓存实体，没人敢抱怨。你可以说那个被替换的实体很倒霉。通过这些行为，我随意的去处缓存实体。我比 FIFO 机制好，在某些情况下，我甚至比 LRU 好，但是，通常LRU都会比我好。\n\n**现在是评论时间**\n\n当 programmer one 继续阅读评论的时候，他发现有个评论非常有趣，这个评论实现了一些缓存算法，应该说这个评论做了一个链向评论者网站的链接，programmer one顺着链接到了那个网站，接着阅读。\n\n**看看缓存元素（缓存实体）**\n\n```java\npublic class CacheElement\n {\n     private Object objectValue;\n     private Object objectKey;\n     private int index;\n     private int hitCount;　// getters and setters\n }\n\npublic class CacheElement\n {\n     private Object objectValue;\n     private Object objectKey;\n     private int index;\n     private int hitCount;　// getters and setters\n }\n```\n\n这个缓存实体拥有缓存的key和value，这个实体的数据结构会被以下所有缓存算法用到。\n\n**缓存算法的公用代码**\n\n```java\n public final synchronized void addElement(Object key, Object value)\n {\n     int index;\n     Object obj;\n     // get the entry from the table\n     obj = table.get(key);\n     // If we have the entry already in our table\n     // then get it and replace only its value.\n     obj = table.get(key);\n\n     if (obj != null)\n     {\n         CacheElement element;\n         element = (CacheElement) obj;\n         element.setObjectValue(value);\n         element.setObjectKey(key);\n         return;\n     }\n }\n\n public final synchronized void addElement(Object key, Object value)\n {\n     int index;\n     Object obj;\n     // get the entry from the table\n     obj = table.get(key);\n     // If we have the entry already in our table\n     // then get it and replace only its value.\n     obj = table.get(key);\n \n     if (obj != null)\n     {\n         CacheElement element;\n         element = (CacheElement) obj;\n         element.setObjectValue(value);\n         element.setObjectKey(key);\n         return;\n     }\n }\n```\n\n上面的代码会被所有的缓存算法实现用到。这段代码是用来检查缓存元素是否在缓存中了，如果是，我们就替换它，但是如果我们找不到这个 key 对应的缓存，我们会怎么做呢？那我们就来深入的看看会发生什么吧！\n\n**现场访问**\n\n今天的专题很特殊，因为我们有特殊的客人，事实上他们是我们想要听的与会者，但是首先，先介绍一下我们的客人：Random Cache，FIFO Cache。让我们从 Random Cache开始。\n\n**看看随机缓存的实现**\n\n```java\n public final synchronized void addElement(Object key, Object value)\n {\n     int index;\n     Object obj;\n     obj = table.get(key);\n     if (obj != null)\n     {\n         CacheElement element;// Just replace the value.\n         element = (CacheElement) obj;\n         element.setObjectValue(value);\n         element.setObjectKey(key);\n         return;\n     }// If we haven't filled the cache yet, put it at the end.\n     if (!isFull())\n     {\n         index = numEntries;\n         ++numEntries;\n     }\n     else { // Otherwise, replace a random entry.\n         index = (int) (cache.length * random.nextFloat());\n         table.remove(cache[index].getObjectKey());\n     }\n     cache[index].setObjectValue(value);\n     cache[index].setObjectKey(key);\n     table.put(key, cache[index]);\n }\n\n public final synchronized void addElement(Object key, Object value)\n {\n     int index;\n     Object obj;\n     obj = table.get(key);\n     if (obj != null)\n     {\n         CacheElement element;// Just replace the value.\n         element = (CacheElement) obj;\n         element.setObjectValue(value);\n         element.setObjectKey(key);\n         return;\n     }// If we haven't filled the cache yet, put it at the end.\n     if (!isFull())\n     {\n         index = numEntries;\n         ++numEntries;\n     }\n     else { // Otherwise, replace a random entry.\n         index = (int) (cache.length * random.nextFloat());\n         table.remove(cache[index].getObjectKey());\n     }\n     cache[index].setObjectValue(value);\n     cache[index].setObjectKey(key);\n     table.put(key, cache[index]);\n }\n```\n\n**看看FIFO缓算法的实现**\n\n```java\n public final synchronized void addElement(Objectkey, Object value)\n {\n     int index;\n     Object obj;\n     obj = table.get(key);\n     if (obj != null)\n     {\n         CacheElement element; // Just replace the value.\n         element = (CacheElement) obj;\n         element.setObjectValue(value);\n         element.setObjectKey(key);\n         return;\n     }\n     // If we haven't filled the cache yet, put it at the end.\n     if (!isFull())\n     {\n         index = numEntries;\n         ++numEntries;\n     }\n     else { // Otherwise, replace the current pointer,\n            // entry with the new one.\n         index = current;\n         // in order to make Circular FIFO\n         if (++current >= cache.length)\n             current = 0;\n         table.remove(cache[index].getObjectKey());\n     }\n     cache[index].setObjectValue(value);\n     cache[index].setObjectKey(key);\n     table.put(key, cache[index]);\n }\n\n public final synchronized void addElement(Objectkey, Object value)\n {\n     int index;\n     Object obj;\n     obj = table.get(key);\n     if (obj != null)\n     {\n         CacheElement element; // Just replace the value.\n         element = (CacheElement) obj;\n         element.setObjectValue(value);\n         element.setObjectKey(key);\n         return;\n     }\n     // If we haven't filled the cache yet, put it at the end.\n     if (!isFull())\n     {\n         index = numEntries;\n         ++numEntries;\n     }\n     else { // Otherwise, replace the current pointer,\n            // entry with the new one.\n         index = current;\n         // in order to make Circular FIFO\n         if (++current >= cache.length)\n             current = 0;\n         table.remove(cache[index].getObjectKey());\n     }\n     cache[index].setObjectValue(value);\n     cache[index].setObjectKey(key);\n     table.put(key, cache[index]);\n }\n```\n\n**看看LFU缓存算法的实现**\n\n```java\n public synchronized Object getElement(Object key)\n {\n     Object obj;\n     obj = table.get(key);\n     if (obj != null)\n     {\n         CacheElement element = (CacheElement) obj;\n         element.setHitCount(element.getHitCount() + 1);\n         return element.getObjectValue();\n     }\n     return null;\n }\n public final synchronized void addElement(Object key, Object value)\n {\n     Object obj;\n     obj = table.get(key);\n     if (obj != null)\n     {\n         CacheElement element; // Just replace the value.\n         element = (CacheElement) obj;\n         element.setObjectValue(value);\n         element.setObjectKey(key);\n         return;\n     }\n     if (!isFull())\n     {\n         index = numEntries;\n         ++numEntries;\n     }\n     else\n     {\n         CacheElement element = removeLfuElement();\n         index = element.getIndex();\n         table.remove(element.getObjectKey());\n     }\n     cache[index].setObjectValue(value);\n     cache[index].setObjectKey(key);\n     cache[index].setIndex(index);\n     table.put(key, cache[index]);\n }\n public CacheElement removeLfuElement()\n {\n     CacheElement[] elements = getElementsFromTable();\n     CacheElement leastElement = leastHit(elements);\n     return leastElement;\n }\n public static CacheElement leastHit(CacheElement[] elements)\n {\n     CacheElement lowestElement = null;\n     for (int i = 0; i < elements.length; i++)\n     {\n         CacheElement element = elements[i];\n         if (lowestElement == null)\n         {\n             lowestElement = element;\n         }\n         else {\n             if (element.getHitCount() < lowestElement.getHitCount())\n             {\n                 lowestElement = element;\n             }\n         }\n     }\n     return lowestElement;\n }\n\n public synchronized Object getElement(Object key)\n {\n     Object obj;\n     obj = table.get(key);\n     if (obj != null)\n     {\n         CacheElement element = (CacheElement) obj;\n         element.setHitCount(element.getHitCount() + 1);\n         return element.getObjectValue();\n     }\n     return null;\n }\n public final synchronized void addElement(Object key, Object value)\n {\n     Object obj;\n     obj = table.get(key);\n     if (obj != null)\n     {\n         CacheElement element; // Just replace the value.\n         element = (CacheElement) obj;\n         element.setObjectValue(value);\n         element.setObjectKey(key);\n         return;\n     }\n     if (!isFull())\n     {\n         index = numEntries;\n         ++numEntries;\n     }\n     else\n     {\n         CacheElement element = removeLfuElement();\n         index = element.getIndex();\n         table.remove(element.getObjectKey());\n     }\n     cache[index].setObjectValue(value);\n     cache[index].setObjectKey(key);\n     cache[index].setIndex(index);\n     table.put(key, cache[index]);\n }\n public CacheElement removeLfuElement()\n {\n     CacheElement[] elements = getElementsFromTable();\n     CacheElement leastElement = leastHit(elements);\n     return leastElement;\n }\n public static CacheElement leastHit(CacheElement[] elements)\n {\n     CacheElement lowestElement = null;\n     for (int i = 0; i < elements.length; i++)\n     {\n         CacheElement element = elements[i];\n         if (lowestElement == null)\n         {\n             lowestElement = element;\n         }\n         else {\n             if (element.getHitCount() < lowestElement.getHitCount())\n             {\n                 lowestElement = element;\n             }\n         }\n     }\n     return lowestElement;\n }\n```\n\n今天的专题很特殊，因为我们有特殊的客人，事实上他们是我们想要听的与会者，但是首先，先介绍一下我们的客人：Random Cache, FIFO Cache。让我们从 Random Cache开始。\n\n最重点的代码，就应该是 leastHit 这个方法，这段代码就是把\nhitCount 最低的元素找出来，然后删除，给新进的缓存元素留位置。\n\n**看看LRU缓存算法实现**\n\n```java\n private void moveToFront(int index)\n {\n     int nextIndex, prevIndex;\n     if(head != index)\n     {\n         nextIndex = next[index];\n         prevIndex = prev[index];\n         // Only the head has a prev entry that is an invalid index\n         // so we don't check.\n         next[prevIndex] = nextIndex;\n         // Make sure index is valid. If it isn't, we're at the tail\n         // and don't set prev[next].\n         if(nextIndex >= 0)\n             prev[nextIndex] = prevIndex;\n         else\n             tail = prevIndex;\n         prev[index] = -1;\n         next[index] = head;\n         prev[head] = index;\n         head = index;\n     }\n }\n public final synchronized void addElement(Object key, Object value)\n {\n     int index;Object obj;\n     obj = table.get(key);\n     if(obj != null)\n     {\n         CacheElement entry;\n         // Just replace the value, but move it to the front.\n         entry = (CacheElement)obj;\n         entry.setObjectValue(value);\n         entry.setObjectKey(key);\n         moveToFront(entry.getIndex());\n         return;\n     }\n     // If we haven't filled the cache yet, place in next available\n     // spot and move to front.\n     if(!isFull())\n     {\n         if(_numEntries > 0)\n         {\n             prev[_numEntries] = tail;\n             next[_numEntries] = -1;\n             moveToFront(numEntries);\n         }\n         ++numEntries;\n     }\n     else { // We replace the tail of the list.\n         table.remove(cache[tail].getObjectKey());\n         moveToFront(tail);\n     }\n     cache[head].setObjectValue(value);\n     cache[head].setObjectKey(key);\n     table.put(key, cache[head]);\n }\n\n private void moveToFront(int index)\n {\n     int nextIndex, prevIndex;\n     if(head != index)\n     {\n         nextIndex = next[index];\n         prevIndex = prev[index];\n         // Only the head has a prev entry that is an invalid index\n         // so we don't check.\n         next[prevIndex] = nextIndex;\n         // Make sure index is valid. If it isn't, we're at the tail\n         // and don't set prev[next].\n         if(nextIndex >= 0)\n             prev[nextIndex] = prevIndex;\n         else\n             tail = prevIndex;\n         prev[index] = -1;\n         next[index] = head;\n         prev[head] = index;\n         head = index;\n     }\n }\n public final synchronized void addElement(Object key, Object value)\n {\n     int index;Object obj;\n     obj = table.get(key);\n     if(obj != null)\n     {\n         CacheElement entry;\n         // Just replace the value, but move it to the front.\n         entry = (CacheElement)obj;\n         entry.setObjectValue(value);\n         entry.setObjectKey(key);\n         moveToFront(entry.getIndex());\n         return;\n     }\n     // If we haven't filled the cache yet, place in next available\n     // spot and move to front.\n     if(!isFull())\n     {\n         if(_numEntries > 0)\n         {\n             prev[_numEntries] = tail;\n             next[_numEntries] = -1;\n             moveToFront(numEntries);\n         }\n         ++numEntries;\n     }\n     else { // We replace the tail of the list.\n         table.remove(cache[tail].getObjectKey());\n         moveToFront(tail);\n     }\n     cache[head].setObjectValue(value);\n     cache[head].setObjectKey(key);\n     table.put(key, cache[head]);\n }\n```\n\n这段代码的逻辑如 LRU算法 的描述一样，把再次用到的缓存提取到最前面，而每次删除的都是最后面的元素。\n\n**结论**\n\n我们已经看到 LFU缓存算法 和 LRU缓存算法的实现方式，至于如何实现，采用数组还是 LinkedHashMap，都由你决定，不够我一般是小的缓存容量用数组，大的用 LinkedHashMap。\n\n--- \n\n* 原文链接：[缓存算法](http://www.jtraining.com/component/content/article/35-jtraining-blog/98.html)\n* 翻译链接：[Cache Algorithm](http://www.leexiang.com/cache-algorithm)\n","tags":["Cache"],"categories":["Algorithm"]},{"title":"跳表SkipList","url":"%2F2011%2F2011-05-22-skiplist%2F","content":"\n### 聊一聊作者的其人其事 \n\n跳表是由William Pugh发明。他在 Communications of the ACM June 1990, 33(6) 668-676 发表了Skip lists: a probabilistic alternative to balanced trees，在该论文中详细解释了跳表的数据结构和插入删除操作。\n\nWilliam Pugh同时还是FindBug（没有使用过，这是一款java的静态代码分析工具，直接对java 的字节码进行分析，能够找出java字节码中潜在很多错误。）作者之一。现在是University of Maryland, College Park（马里兰大学伯克分校，位于马里兰州，全美大学排名在五六十名左右的样子）大学的一名教授。他和他的学生所作的研究深入的影响了java语言中内存池实现。\n\n> 又是一个计算机的天才！\n\n### 言归正传，跳表简介 \n\n这是跳表的作者，上面介绍的William Pugh给出的解释：\n\n> Skip lists are a data structure that can be used in place of balanced trees. Skip lists use probabilistic balancing rather than strictly enforced balancing and as a result the algorithms for insertion and deletion in skip lists are much simpler and significantly faster than equivalent algorithms for balanced trees.\n\n跳表是平衡树的一种替代的数据结构，但是和红黑树不相同的是，跳表对于树的平衡的实现是基于一种随机化的算法的，这样也就是说跳表的插入和删除的工作是比较简单的。\n\n下面来研究一下跳表的核心思想：\n\n先从链表开始，如果是一个简单的链表，那么我们知道在链表中查找一个元素I的话，需要将整个链表遍历一次。\n\n![](/assets/images/2011/05/22/skiplist/skiplist_linklist_two_ahead.png)\n\n如果是说链表是排序的，并且节点中还存储了指向前面第二个节点的指针的话，那么在查找一个节点时，仅仅需要遍历N/2个节点即可。\n\n![](/assets/images/2011/05/22/skiplist/skiplist_linklist.png)\n\n这基本上就是跳表的核心思想，其实也是一种通过“空间来换取时间”的一个算法，通过在每个节点中增加了向前的指针，从而提升查找的效率。\n\n### 跳表的数据存储模型 \n\n我们定义：\n\n如果一个基点存在k个向前的指针的话，那么陈该节点是k层的节点。\n\n一个跳表的层MaxLevel义为跳表中所有节点中最大的层数。\n\n下面给出一个完整的跳表的图示：\n\n![](/assets/images/2011/05/22/skiplist/skiplist_linklist_complete.png)\n\n那么我们该如何将该数据结构使用二进制存储呢？通过上面的跳表的很容易设计这样的数据结构：\n\n定义每个节点类型：\n\n```\n// 这里仅仅是一个指针\ntypedef struct nodeStructure *node;\ntypedef struct nodeStructure\n\n{\n    keyType key;\t// key值\n    valueType value;\t// value值\n    // 向前指针数组，根据该节点层数的\n    // 不同指向不同大小的数组\n    node forward[1];\t\n};\n```\n\n![](/assets/images/2011/05/22/skiplist/skiplist_structure.png)\n\n上面的每个结构体对应着图中的每个节点，如果一个节点是一层的节点的话（如7，12等节点），那么对应的forward将指向一个只含一个元素的数组，以此类推。\n\n定义跳表数据类型：\n\n```\n// 定义跳表数据类型\ntypedef struct listStructure{\n   int level; \t  /* Maximum level of the list \n\t\t\t(1 more than the number of levels in the list) */\n   struct nodeStructure * header; /* pointer to header */\n   } * list; \n```\n\n跳表数据类型中包含了维护跳表的必要信息，level表明跳表的层数，header如下所示：\n\n![](/assets/images/2011/05/22/skiplist/skiplist_linklist_header_pointer.png) \n\n定义辅助变量：\n\n定义上图中的NIL变量：node NIL;\n\n```\n#define MaxNumberOfLevels 16\n#define MaxLevel (MaxNumberOfLevels-1) \n```\n\n定义辅助方法：\n\n```\n// newNodeOfLevel生成一个nodeStructure结构体，同时生成l个node *数组指针\n#define newNodeOfLevel(l) (node)malloc(sizeof(struct nodeStructure)+(l)*sizeof(node *))\n```\n\n好的基本的数据结构定义已经完成，接下来来分析对于跳表的一个操作。 \n\n### 跳表的代码实现分析 \n\n1. 初始化\n\n初始化的过程很简单，仅仅是生成下图中红线区域内的部分，也就是跳表的基础结构：\n\n![](/assets/images/2011/05/22/skiplist/skiplist_linklist_init.png)\n\n```\nlist newList()\n{\n  list l;\n  int i;\n  // 申请list类型大小的内存\n  l = (list)malloc(sizeof(struct listStructure));\n  // 设置跳表的层level，初始的层为0层（数组从0开始）\n  l->level = 0;\n  \n  // 生成header部分\n  l->header = newNodeOfLevel(MaxNumberOfLevels);\n  // 将header的forward数组清空\n  for(i=0;i<MaxNumberOfLevels;i++) l->header->forward[i] = NIL;\n  return(l);\n};  \n```\n\n2. 插入操作\n\n由于跳表数据结构整体上是有序的，所以在插入时，需要首先查找到合适的位置，然后就是修改指针（和链表中操作类似），然后更新跳表的level变量。\n\n![](/assets/images/2011/05/22/skiplist/skiplist_insert.png)\n\n```\nboolean insert(l,key,value) \n\tregister list l;\n\tregister keyType key;\n\tregister valueType value;\n{\n  register int k;\n  // 使用了update数组\n  node update[MaxNumberOfLevels];\n  register node p,q;\n  p = l->header;\n  k = l->level;\n  /*******************1步*********************/\n  do {\n\t\t// 查找插入位置\n\t\twhile (q = p->forward[k], q->key < key)\n\t\t\tp = q;\n\t\t\n\t\t// 设置update数组\n\t\tupdate[k] = p;\n\t} while(--k>=0);\t// 对于每一层进行遍历\n\t\n\t// 这里已经查找到了合适的位置，并且update数组已经\n\t// 填充好了元素\n   if (q->key == key)\n   {\n     q->value = value;\n     return(false);\n   };\n\t\n   // 随机生成一个层数\n   k = randomLevel();  \n  if (k>l->level) \n  {\n  \t// 如果新生成的层数比跳表的层数大的话\n    // 增加整个跳表的层数\n\tk = ++l->level;\n\t// 在update数组中将新添加的层指向l->header\n\tupdate[k] = l->header;\n  };\n\t\t\n  /*******************2步*********************/\n  // 生成层数个节点数目\n  q = newNodeOfLevel(k);\n  q->key = key;\n  q->value = value;\n      \n  // 更新两个指针域\n  do \n  {\n\t\tp = update[k];\n\t\tq->forward[k] = p->forward[k];\n\t\tp->forward[k] = q;\n\t} while(--k>=0);\n\t\n\t// 如果程序运行到这里，程序已经插入了该节点\n  return(true);\n} \n```\n\n3. 删除某个节点\n\n和插入是相同的，首先查找需要删除的节点，如果找到了该节点的话，那么只需要更新指针域，如果跳表的level需要更新的话，进行更新。\n\n![](/assets/images/2011/05/22/skiplist/skiplist_delete.png)\n\n```\nboolean delete(l,key) \nregister list l;\nregister keyType key;\n{\n  register int k,m;\n  // 生成一个辅助数组update\n  node update[MaxNumberOfLevels];\n  register node p,q;\n  p = l->header;\n  k = m = l->level;\n  // 这里和查找部分类似，最终update中包含的是：\n  // 指向该节点对应层的前驱节点\n  do \n  {\n\t\twhile (q = p->forward[k], q->key < key) \n\t\t\tp = q;\n\t\t\tupdate[k] = p;\n\t} while(--k>=0);\n\t// 如果找到了该节点，才进行删除的动作\n  if (q->key == key) \n  {\n  \t// 指针运算\n\t\tfor(k=0; k<=m && (p=update[k])->forward[k] == q; k++) \n\t\t\t// 这里可能修改l->header->forward数组的值的 \n\t\t  p->forward[k] = q->forward[k];\n\t\t// 释放实际内存\n\t\tfree(q);\n\t\t\n\t\t// 如果删除的是最大层的节点，那么需要重新维护跳表的\n\t\t// 层数level\n   \twhile( l->header->forward[m] == NIL && m > 0 )\n\t     m--;\n\t\tl->level = m;\n\t\treturn(true);\n\t}\n  else\n  \t// 没有找到该节点，不进行删除动作 \n  \treturn(false);\n} \n```\n\n4. 查找\n\n查找操作其实已经在插入和删除过程中包含，比较简单，可以参考源代码。 \n\n### 论文，代码下载及参考资料 \n\n[SkipList论文](http://files.cnblogs.com/xuqiang/skiplist.pdf)\n\n[skipLists.rar](/assets/images/2011/05/22/skiplist/skipLists.rar)\n\n//--------------------------------------------------------------------------------\n\n增加跳表c#实现代码 2011-5-29下午 \n\n上面给出的数据结构的模型是直接按照跳表的模型得到的，另外还有一种数据结构的模型：\n\n跳表节点类型，每个跳表类型中仅仅存储了左侧的节点和下面的节点：\n\n![](/assets/images/2011/05/22/skiplist/skiplistnode.png)\n\n我们现在来看对于这种模型的操作代码：\n\n1. 初始化完成了如下的操作：\n\n![](/assets/images/2011/05/22/skiplist/skipliststruct.png)\n\n2. 插入操作：和上面介绍的插入操作是类似的，首先查找到插入的位置，生成update数组，然后随机生成一个level，然后修改指针。\n\n3. 删除操作：和上面介绍的删除操作是类似的，查找到需要删除的节点，如果查找不到，抛出异常，如果查找到的需要删除的节点的话，修改指针，释放删除节点的内存。\n\n代码下载：\n\n[skiplist_csharp.rar](/assets/images/2011/05/22/skiplist/skiplist_csharp.rar)\n\n---\n\n* 原文链接：[跳表SkipList](http://www.cnblogs.com/xuqiang/archive/2011/05/22/2053516.html)\n","tags":["SkipList"],"categories":["SkipList"]},{"title":"五大常用算法之一：分治算法","url":"%2F2010%2F2010-05-22-divide-and-conquer-algorithm%2F","content":"\n### 一、基本概念\n\n在计算机科学中，分治法是一种很重要的算法。字面上的解释是“分而治之”，就是**把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并**。这个技巧是很多高效算法的基础，如排序算法(快速排序，归并排序)，傅立叶变换(快速傅立叶变换)……\n\n任何一个可以用计算机求解的问题所需的计算时间都与其规模有关。问题的规模越小，越容易直接求解，解题所需的计算时间也越少。例如，对于n个元素的排序问题，当n=1时，不需任何计算。n=2时，只要作一次比较即可排好序。n=3时只要作3次比较即可，…。而当n较大时，问题就不那么容易处理了。要想直接解决一个规模较大的问题，有时是相当困难的。\n\n### 二、基本思想及策略\n\n分治法的设计思想是：**将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之**。\n\n分治策略是：**对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解**。这种算法设计策略叫做分治法。\n\n如果原问题可分割成k个子问题，1<k≤n，且这些子问题都可解并可利用这些子问题的解求出原问题的解，那么这种分治法就是可行的。由分治法产生的子问题往往是原问题的较小模式，这就为使用递归技术提供了方便。在这种情况下，反复应用分治手段，可以使子问题与原问题类型一致而其规模却不断缩小，最终使子问题缩小到很容易直接求出其解。**这自然导致递归过程的产生。分治与递归像一对孪生兄弟，经常同时应用在算法设计之中**，并由此产生许多高效算法。\n\n### 三、分治法适用的情况\n\n分治法所能解决的问题一般具有以下几个特征：\n\n1. 该问题的规模**缩小**到一定的程度**就可以容易地解决**；\n\n2. 该问题可以分解为若干个规模较小的相同问题，即该问题**具有最优子结构性质**；\n\n3. 利用该问题分解出的子问题的解可以合并为该问题的解；\n\n4. 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题。\n\n第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加；\n\n第二条特征是应用分治法的前提它也是大多数问题可以满足的，此特征反映了递归思想的应用；、\n\n**第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征，如果具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或动态规划法**；\n\n第四条特征涉及到分治法的效率，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但一般用动态规划法较好。\n\n### 四、分治法的基本步骤\n\n分治法在每一层递归上都有三个步骤：\n\n    step1 分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题；\n\n    step2 解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题\n\n    step3 合并：将各个子问题的解合并为原问题的解。\n\n它的一般的算法设计模式如下：\n\n```\n    Divide-and-Conquer(P)\n\n    1. if |P|≤n0\n    2. then return(ADHOC(P))\n    3. 将P分解为较小的子问题 P1 ,P2 ,...,Pk\n    4. for i←1 to k\n    5. do yi ← Divide-and-Conquer(Pi) △ 递归解决Pi\n    6. T ← MERGE(y1,y2,...,yk) △ 合并子问题\n    7. return(T)\n```\n\n其中|P|表示问题P的规模；n0为一阈值，表示当问题P的规模不超过n0时，问题已容易直接解出，不必再继续分解。ADHOC(P)是该分治法中的基本子算法，用于直接解小规模的问题P。因此，当P的规模不超过n0时直接用算法ADHOC(P)求解。算法MERGE(y1,y2,...,yk)是该分治法中的合并子算法，用于将P的子问题P1 ,P2 ,...,Pk的相应的解y1,y2,...,yk合并为P的解。\n\n### 五、分治法的复杂性分析\n\n一个分治法将规模为n的问题分成k个规模为n／m的子问题去解。设分解阀值n0=1，且adhoc解规模为1的问题耗费1个单位时间。再设将原问题分解为k个子问题以及用merge将k个子问题的解合并为原问题的解需用f(n)个单位时间。用T(n)表示该分治法解规模为|P|=n的问题所需的计算时间，则有：\n\n```\nT（n）= k T(n/m)+f(n)\n```\n\n通过迭代法求得方程的解：\n\n递归方程及其解只给出n等于m的方幂时T(n)的值，但是如果认为T(n)足够平滑，那么由n等于m的方幂时T(n)的值可以估计T(n)的增长速度。通常假定T(n)是单调上升的，从而当mi≤n<mi+1时，`T(mi)≤T(n)<T(mi+1)`。 \n\n### 六、可使用分治法求解的一些经典问题\n\n    （1）二分搜索\n    （2）大整数乘法\n    （3）Strassen矩阵乘法\n    （4）棋盘覆盖\n    （5）合并排序\n    （6）快速排序\n    （7）线性时间选择\n    （8）最接近点对问题\n    （9）循环赛日程表\n    （10）汉诺塔\n\n### 七、依据分治法设计程序时的思维过程\n\n实际上就是类似于数学归纳法，找到解决本问题的求解方程公式，然后根据方程公式设计递归程序。\n\n1. 一定是先找到最小问题规模时的求解方法\n2. 然后考虑随着问题规模增大时的求解方法\n3. 找到求解的递归函数式后（各种规模或因子），设计递归程序即可。\n\n---\n\n* Author: [红脸书生](http://www.cnblogs.com/steven_oyj/)\n* Source: [博客园](http://www.cnblogs.com)\n* Link: [五大常用算法之一：分治算法](http://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741370.html)","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"五大常用算法之三：贪心算法","url":"%2F2010%2F2010-05-22-greedy-algorithm%2F","content":"\n### 一、基本概念：\n \n所谓贪心算法是指，在对问题求解时，总是做出**在当前看来是最好的选择**。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的**局部最优解**。\n\n贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。\n\n**所以对所采用的贪心策略一定要仔细分析其是否满足无后效性**。\n\n### 二、贪心算法的基本思路：\n\n    1. 建立数学模型来描述问题。\n    2. 把求解的问题分成若干个子问题。\n    3. 对每一子问题求解，得到子问题的局部最优解。\n    4. 把子问题的解局部最优解合成原来解问题的一个解。\n\n### 三、贪心算法适用的问题\n\n贪心策略适用的前提是：局部最优策略能导致产生全局最优解。\n\n实际上，**贪心算法适用的情况很少**。一般，对一个问题分析是否适用于贪心算法，可以先选择该问题下的几个实际数据进行分析，就可做出判断。\n \n### 四、贪心算法的实现框架\n\n```\n从问题的某一初始解出发；\nwhile （能朝给定总目标前进一步）\n{ \n      利用可行的决策，求出可行解的一个解元素；\n}\n由所有解元素组合成问题的一个可行解；\n```\n  \n### 五、贪心策略的选择\n\n因为用贪心算法只能通过解局部最优解的策略来达到全局最优解，因此，一定要注意判断问题是否适合采用贪心算法策略，找到的解是否一定是问题的最优解。\n \n### 六、例题分析\n\n下面是一个可以试用贪心算法解的题目，贪心解的确不错，可惜不是最优解。\n\n[背包问题]有一个背包，背包容量是M=150。有7个物品，物品可以分割成任意大小。\n\n要求尽可能让装入背包中的物品总价值最大，但不能超过总容量。\n\n    物品 A B C D E F G\n    重量 35 30 60 50 40 10 25\n    价值 10 40 30 50 35 40 30\n\n分析：\n\n目标函数： ∑pi最大\n\n约束条件是装入的物品总重量不超过背包容量：∑wi<=M( M=150)\n\n    （1）根据贪心的策略，每次挑选价值最大的物品装入背包，得到的结果是否最优？\n    （2）每次挑选所占重量最小的物品装入是否能得到最优解？\n    （3）每次选取单位重量价值最大的物品，成为解本题的策略。\n\n值得注意的是，贪心算法并不是完全不可以使用，贪心策略一旦经过证明成立后，它就是一种高效的算法。\n\n贪心算法还是很常见的算法之一，这是由于它简单易行，构造贪心策略不是很困难。\n\n可惜的是，它需要证明后才能真正运用到题目的算法中。\n\n一般来说，**贪心算法的证明围绕着：整个问题的最优解一定由在贪心策略中存在的子问题的最优解得来的**。\n\n对于例题中的3种贪心策略，都是无法成立（无法被证明）的，解释如下：\n\n（1）贪心策略：选取价值最大者。反例：\n\n    W=30\n    物品：A B C\n    重量：28 12 12\n    价值：30 20 20\n\n根据策略，首先选取物品A，接下来就无法再选取了，可是，选取B、C则更好。\n\n（2）贪心策略：选取重量最小。它的反例与第一种策略的反例差不多。\n \n\n（3）贪心策略：选取单位重量价值最大的物品。反例：\n\n    W=30\n    物品：A B C\n    重量：28 20 10\n    价值：28 20 10\n\n    根据策略，三种物品单位重量价值一样，程序无法依据现有策略作出判断，如果选择A，则答案错误。\n\n---\n\n* Author: [红脸书生](http://www.cnblogs.com/steven_oyj/)\n* Source: [博客园](http://www.cnblogs.com)\n* Link: [五大常用算法之三：贪心算法](http://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741375.html)","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"五大常用算法之二：动态规划算法","url":"%2F2010%2F2010-05-22-dynamic-programming-algorithm%2F","content":"\n### 一、基本概念\n\n动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种多阶段最优化决策解决问题的过程就称为动态规划。\n\n### 二、基本思想与策略\n\n基本思想与分治法类似，也是将待求解的问题分解为若干个子问题（阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。\n\n由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。\n\n与分治法最大的差别是：**适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）**。\n \n### 三、适用的情况\n\n能采用动态规划求解的问题的一般要具有3个性质：\n    \n    (1) 最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。\n    (2) 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。\n    (3) 有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（**该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势**）\n \n### 四、求解的基本步骤\n\n动态规划所处理的问题是**一个多阶段决策问题**，一般由初始状态开始，通过对中间阶段决策的选择，达到结束状态。这些决策形成了一个决策序列，同时确定了完成整个过程的一条活动路线(通常是求最优的活动路线)。如图所示。动态规划的设计都有着一定的模式，一般要经历以下几个步骤。\n\n> 初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态\n> 图1 动态规划决策过程示意图\n                      \n    (1) **划分阶段**：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意**划分后的阶段一定要是有序的或者是可排序的，否则问题就无法求解**。\n    (2) **确定状态和状态变量**：将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来。当然，状态的选择要满足无后效性。\n    (3) **确定决策并写出状态转移方程**：因为决策和状态转移有着天然的联系，**状态转移就是根据上一阶段的状态和决策来导出本阶段的状态**。所以如果确定了决策，状态转移方程也就可写出。但事实上常常是反过来做，**根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程**。\n    (4) **寻找边界条件**：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件。\n\n一般，只要解决问题的**阶段、状态和状态转移决策**确定了，就可以写出**状态转移方程（包括边界条件）**。\n\n实际应用中可以按以下几个简化的步骤进行设计：\n\n    （1）分析最优解的性质，并刻画其结构特征。\n    （2）递归的定义最优解。\n    （3）以自底向上或自顶向下的记忆化方式（备忘录法）计算出最优值\n    （4）根据计算最优值时得到的信息，构造问题的最优解\n \n### 五、算法实现的说明\n\n动态规划的主要难点在于理论上的设计，也就是上面4个步骤的确定，一旦设计完成，实现部分就会非常简单。\n\n使用动态规划求解问题，**最重要的就是确定动态规划三要素**：\n\n    （1）**问题的阶段**\n    （2）**每个阶段的状态**\n    （3）**从前一个阶段转化到后一个阶段之间的递推关系**。\n \n递推关系必须是从次小的问题开始到较大的问题之间的转化，从这个角度来说，动态规划往往可以用递归程序来实现，不过**因为递推可以充分利用前面保存的子问题的解来减少重复计算，所以对于大规模问题来说，有递归不可比拟的优势，这也是动态规划算法的核心之处**。\n\n确定了动态规划的这三要素，**整个求解过程就可以用一个最优决策表来描述，最优决策表是一个二维表，其中行表示决策的阶段，列表示问题状态**，表格**需要填写的数据一般对应此问题的在某个阶段某个状态下的最优值**（如最短路径，最长公共子序列，最大价值等），填表的过程就是根据递推关系，从1行1列开始，以行或者列优先的顺序，依次填写表格，最后根据整个表格的数据通过简单的取舍或者运算求得问题的最优解。\n\n```\nf(n,m)=max{f(n-1,m), f(n-1,m-w[n])+P(n,m)}\n```\n\n### 六、动态规划算法基本框架\n\n```c\n代码\nfor(j=1; j<=m; j=j+1) // 第一个阶段\n   xn[j] = 初始值;\n\n for(i=n-1; i>=1; i=i-1)// 其他n-1个阶段\n   for(j=1; j>=f(i); j=j+1)//f(i)与i有关的表达式\n     xi[j]=j=max（或min）{g(xi-1[j1:j2]), ......, g(xi-1[jk:jk+1])};\n\nt = g(x1[j1:j2]); // 由子问题的最优解求解整个问题的最优解的方案\n\nprint(x1[j1]);\n\nfor(i=2; i<=n-1; i=i+1）\n{  \n     t = t-xi-1[ji];\n\n     for(j=1; j>=f(i); j=j+1)\n        if(t=xi[ji])\n             break;\n}\n```\n\n---\n\n* Author: [红脸书生](http://www.cnblogs.com/steven_oyj/)\n* Source: [博客园](http://www.cnblogs.com)\n* Link: [五大常用算法之二：动态规划算法](http://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741374.html)","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"五大常用算法之五：分支限界法","url":"%2F2010%2F2010-05-22-branch-and-bound-algorithm%2F","content":"\n### 一、基本描述\n\n类似于回溯法，也是一种在问题的解空间树T上搜索问题解的算法。但在一般情况下，分支限界法与回溯法的求解目标不同。**回溯法**的求解目标是找出T中**满足约束条件的所有解**，而**分支限界法**的求解目标则是找出**满足约束条件的一个解**，或是在满足约束条件的解中找出使某一目标函数值达到**极大或极小的解**，即在某种意义下的**最优解**。\n\n（1）分支搜索算法\n\n所谓“分支”就是采用广度优先的策略，依次搜索E-结点的所有分支，也就是所有相邻结点，抛弃不满足约束条件的结点，其余结点加入活结点表。然后从表中选择一个结点作为下一个E-结点，继续搜索。\n\n选择下一个E-结点的方式不同，则会有几种不同的分支搜索方式。\n\n    1）FIFO搜索\n    2）LIFO搜索\n    3）优先队列式搜索\n\n（2）分支限界搜索算法 \n\n### 二、分支限界法的一般过程\n\n由于求解目标不同，导致分支限界法与回溯法在解空间树T上的搜索方式也不相同。回溯法以深度优先的方式搜索解空间树T，而分支限界法则以广度优先或以最小耗费优先的方式搜索解空间树T。\n\n分支限界法的搜索策略是：在扩展结点处，先生成其所有的儿子结点（分支），然后再从当前的活结点表中选择下一个扩展对点。为了有效地选择下一扩展结点，以加速搜索的进程，在每一活结点处，计算一个函数值（限界），并根据这些已计算出的函数值，从当前活结点表中选择一个最有利的结点作为扩展结点，使搜索朝着解空间树上有最优解的分支推进，以便尽快地找出一个最优解。\n\n分支限界法常以广度优先或以最小耗费（最大效益）优先的方式搜索问题的解空间树。问题的解空间树是表示问题解空间的一棵有序树，常见的有子集树和排列树。在搜索问题的解空间树时，分支限界法与回溯法对当前扩展结点所使用的扩展方式不同。在分支限界法中，每一个活结点只有一次机会成为扩展结点。活结点一旦成为扩展结点，就一次性产生其所有儿子结点。在这些儿子结点中，那些导致不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被子加入活结点表中。此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程。这个过程一直持续到找到所求的解或活结点表为空时为止。\n\n### 三、回溯法和分支限界法的一些区别\n\n有一些问题其实无论用回溯法还是分支限界法都可以得到很好的解决，但是另外一些则不然。也许我们需要具体一些的分析——到底何时使用分支限界而何时使用回溯呢？\n\n回溯法和分支限界法的一些区别：\n\n    方法  对解空间树的搜索方式  存储结点的常用数据结构  结点存储特性常用应用\n\n    回溯法  深度优先搜索  堆栈  结点的所有可行子结点被遍历后才被从栈中弹出找出满足约束条件的所有解\n\n    分支限界法  广度优先或最小消耗优先搜索  队列、优先队列  每个结点只有一次成为活结点的机会找出满足约束条件的一个解或特定意义下的最优解\n\n---\n\n* Author: [红脸书生](http://www.cnblogs.com/steven_oyj/)\n* Source: [博客园](http://www.cnblogs.com)\n* Link: [五大常用算法之五：分支限界法](http://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741378.html)","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"五大常用算法之四：回溯法","url":"%2F2010%2F2010-05-22-backtracking-algorithm%2F","content":"\n### 1、概念\n\n回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。\n\n回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。\n\n许多**复杂的，规模较大**的问题都可以使用回溯法，有“通用解题方法”的美称。\n\n### 2、基本思想\n\n在包含问题的所有解的解空间树中，按照**深度优先搜索的策略**，从根结点出发深度探索解空间树。当探索到某一结点时，要先判断该结点是否包含问题的解，如果包含，就从该结点出发继续探索下去，如果该结点不包含问题的解，则逐层向其祖先结点回溯。（其实回溯法就是对隐式图的深度优先搜索算法）。\n\n若用回溯法求问题的所有解时，要回溯到根，且根结点的所有可行的子树都要已被搜索遍才结束。\n\n而若使用回溯法求任一个解时，只要搜索到问题的一个解就可以结束。\n\n### 3、用回溯法解题的一般步骤：\n\n（1）针对所给问题，确定问题的解空间：\n\n    首先应明确定义问题的解空间，问题的解空间应至少包含问题的一个（最优）解。\n\n（2）确定结点的扩展搜索规则\n\n（3）以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。\n\n### 4、算法框架\n\n（1）问题框架\n\n设问题的解是一个n维向量(a1,a2,………,an),约束条件是ai(i=1,2,3,…..,n)之间满足某种条件，记为f(ai)。\n\n（2）非递归回溯框架\n\n```\n int a[n],i;\n 初始化数组a[];\n i = 1;\n while (i>0(有路可走)   and  (未达到目标))  // 还未回溯到头\n {\n     if(i > n)                                              // 搜索到叶结点\n     {   \n           搜索到一个解，输出；\n     }\n     else                                                   // 处理第i个元素\n     { \n           a[i]第一个可能的值；\n           while(a[i]在不满足约束条件且在搜索空间内)\n           {\n               a[i]下一个可能的值；\n           }\n           if(a[i]在搜索空间内)\n          {\n               标识占用的资源；\n               i = i+1;                              // 扩展下一个结点\n          }\n          else \n         {\n               清理所占的状态空间；            // 回溯\n               i = i –1; \n          }\n }\n```\n\n（3）递归的算法框架\n\n回溯法是对解空间的深度优先搜索，在一般情况下使用递归函数来实现回溯法比较简单，其中i为搜索的深度，框架如下：\n\n```\n int a[n];\n try(int i)\n {\n     if(i>n)\n        输出结果;\n      else\n     {\n        for(j = 下界; j <= 上界; j=j+1)  // 枚举i所有可能的路径\n        {\n            if(fun(j))                 // 满足限界函数和约束条件\n              {\n                 a[i] = j;\n               ...                         // 其他操作\n                 try(i+1);\n               回溯前的清理工作（如a[i]置空值等）;\n               }\n          }\n      }\n }\n```\n\n---\n\n* Author: [红脸书生](http://www.cnblogs.com/steven_oyj/)\n* Source: [博客园](http://www.cnblogs.com)\n* Link: [五大常用算法之四：回溯法](http://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741376.html)","tags":["Algorithm"],"categories":["Algorithm"]}]