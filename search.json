[{"title":"2018 TODO","url":"%2F2018%2F12%2F2018-12-31-todo%2F","content":"\n### 2018\n\n#### Short Term TODO\n\n* Hive - Transactions, Locks, Authorization\n\n* File Formats, SerDes, Compression\n\n* Scheduling Algorithm\n\n* Data Government, Data Warehouse, Data Mart\n\n* ElasticSearch\n\n* JVM & GC\n\n* Spark\n\n* Flink\n\n* Netty\n\n* Kafka\n\n* HBase(Transaction: Trafodion, Omid, Tephra)\n\n#### Long Term TODO\n\n* Linear Algebra\n\n* Probability and Information Theory\n\n* Dataset Transformations\n\n* Model Selection and Evaluation\n\n* Machine Learning\n\n* Deep Learning\n\n### Links\n\n* [TODO](http://blog.hyperj.net/todo/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[2018 TODO](http://blog.hyperj.net/2018/12/2018-12-31-todo/)","tags":["TODO"],"categories":["TODO"]},{"title":"MySQL Language Definitions","url":"%2F2018%2F06%2F2018-06-25-mysql-language-definitions%2F","content":"\n### DDL (Data Definition Language) refers to the CREATE, ALTER and DROP statements\n\nDDL allows to add / modify / delete the logical structures which contain the data or which allow users to access / maintain the data (databases, tables, keys, views...). DDL is about \"metadata\".\n\n### DML (Data Manipulation Language) refers to the INSERT, UPDATE and DELETE statements\n\nDML allows to add / modify / delete data itself.\n\n### DQL (Data Query Language) refers to the SELECT, SHOW and HELP statements (queries)\n\nSELECT is the main DQL instruction. It retrieves data you need. SHOW retrieves infos about the metadata. HELP... is for people who need help.\n\n### DCL (Data Control Language) refers to the GRANT and REVOKE statements\n\nDCL is used to grant / revoke permissions on databases and their contents. DCL is simple, but MySQL's permissions are rather complex. DCL is about security.\n\n### DTL (Data Transaction Language) refers to the START TRANSACTION, SAVEPOINT, COMMIT and ROLLBACK [TO SAVEPOINT] statements\n\nDTL is used to manage transactions (operations which include more instructions none of which can be executed if one of them fails).\n\n### Links\n\n* [MySQL/Language/Definitions: what are DDL, DML and DQL?](https://en.wikibooks.org/wiki/MySQL/Language/Definitions:_what_are_DDL,_DML_and_DQL%3F)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Service Log](http://blog.hyperj.net/2018/06/2018-06-25-mysql-language-definitions/)","tags":["Definition"],"categories":["MySQL"]},{"title":"Data Dependency","url":"%2F2018%2F06%2F2018-06-19-data-dependency%2F","content":"\nA data dependency in computer science is a situation in which a program statement (instruction) refers to the data of a preceding statement. In compiler theory, the technique used to discover data dependencies among statements (or instructions) is called dependence analysis.\n\n### Data dependencies(数据依赖)\n\n- Flow dependency(流依赖)\n\n- Anti-dependency(反依赖)\n\n- Output dependency(输出依赖)\n\n### Control Dependency(控制依赖)\n\n### Links\n\n* [Data dependency](https://en.wikipedia.org/wiki/Data_dependency)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Dependency](http://blog.hyperj.net/2018/06/2018-06-19-data-dependency/)","tags":["Dependency"],"categories":["Data"]},{"title":"Service Log","url":"%2F2018%2F06%2F2018-06-01-service-log%2F","content":"\n### Log\n\nWho When Where What Content\n\n### Level\n\n- ERROR\n- WARN\n- INFO\n- DEBUG\n\n### Data\n\n- Base Data\n- Service Data\n\n### Component\n\n- SDK/Agent\n- Collector\n- Kafka\n- Gobblin/Spark/Flink\n- ES/Hive/HBase\n\n### Other\n\n- Data Size Limit < 100KB-1MB(Suggest < 1-10KB)\n- Schema: Json/Avro\n\n### Links\n\n* [Apache Logging Log4J2](https://github.com/apache/logging-log4j2)\n* [Apache Gobblin](https://github.com/apache/incubator-gobblin)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Service Log](http://blog.hyperj.net/2018/06/2018-06-01-service-log/)","tags":["Service"],"categories":["Log"]},{"title":"Canal","url":"%2F2018%2F05%2F2018-05-29-canal%2F","content":"\n### 类型\n\n- 全量\n- 增量\n- 快照\n\n### 问题\n\n- 分库分表\n- 库表变更\n- 回溯数据\n- 事务\n- 主键\n- 特殊语句\n\n### Links\n\n* [Canal](https://github.com/alibaba/canal)\n* [Canal Wiki](https://github.com/alibaba/canal/wiki)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Canal](http://blog.hyperj.net/2018/05/2018-05-29-canal/)","tags":["Canal"],"categories":["Canal"]},{"title":"分布式架构","url":"%2F2018%2F03%2F2018-03-01-distributed-architecture%2F","content":"\n### 从集中式到分布式\n\n##### 集中式的特点\n\n##### 分布式的特点\n\n分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。——《分布式系统概念与设计》\n\n- 分布性\n\n- 对等性\n\n- 并发性\n\n- 缺乏全局时钟（事件、消息的顺序）\n\n- 故障总是会发生\n\n##### 分布式环境的各种问题\n\n- 通信异常\n\n- 网络分区（脑裂）\n\n- 三态（成功、失败、超时）\n\n- 节点故障\n\n### 从ACID到CAP/BASE\n\n##### ACID（Transaction）\n\n- 原子性（Atomicity）\n\n- 一致性（Consistency）\n\n- 隔离性（Isolation）\n\n| 隔离级别 | 脏读（Dirty Read） | 不可重复读（NonRepeatable Read） | 幻读（Phantom Read） |\n| ------- | ----------------- | ------------------------------ | ------------------- |\n| 未提交读（Read Uncommitted） | 可能 | 可能 | 可能 |\n| 已提交读（Read Committed） | 不可能 | 可能 | 可能 |\n| 可重复读（Repeatable Read） | 不可能 | 不可能 | 可能 |\n| 可串行化（Serializable ） | 不可能 | 不可能 | 不可能 |\n    \n- 持久性（Durability）\n\n##### 分布式事务\n\n##### CAP和BASE理论\n\n###### CAP\n\n- 一致性（Consistency）\n\n- 可用性（Availability）\n\n- 分区容错性（Partition Tolerance）\n\n###### BASE\n\n- Basically Available（基本可用）\n\n- Soft state（软状态）\n\n- Eventually consistent（最终一致性）\n    \n    - 因果一致性（Causal consistency）\n\n    - 读己之所写（Read your writes）\n\n    - 会话一致性（Session consistency）\n\n    - 单调读一致性（Monotonic read consistency）\n\n    - 单调写一致性（Monotoic write consistency）\n\n### Links\n\n* [从Paxos到Zookeeper：分布式一致性原理与实践](https://book.douban.com/subject/26292004/)\n* [从ACID到CAP到BASE](http://blog.hyperj.net/2016/2016-02-21-acid-cap-base/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[分布式架构](http://blog.hyperj.net/2018/03/2018-03-01-distributed-architecture/)","tags":["Distributed"],"categories":["Distributed"]},{"title":"YARN Fair Scheduler","url":"%2F2018%2F02%2F2018-02-28-yarn-fair-scheduler%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN Fair Scheduler](http://blog.hyperj.net/2018/02/2018-02-28-yarn-fair-scheduler/)","tags":["Fair"],"categories":["YARN"]},{"title":"YARN Capacity Scheduler","url":"%2F2018%2F02%2F2018-02-27-yarn-capacity-scheduler%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN Capacity Scheduler](http://blog.hyperj.net/2018/02/2018-02-27-yarn-capacity-scheduler/)","tags":["Capacity"],"categories":["YARN"]},{"title":"YARN NodeManager","url":"%2F2018%2F02%2F2018-02-26-yarn-nodemanager%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN NodeManager](http://blog.hyperj.net/2018/02/2018-02-26-yarn-nodemanager/)","tags":["NodeManager"],"categories":["YARN"]},{"title":"YARN ResourceManager","url":"%2F2018%2F02%2F2018-02-25-yarn-resourcemanager%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN ResourceManager](http://blog.hyperj.net/2018/02/2018-02-25-yarn-resourcemanager/)","tags":["ResourceManager"],"categories":["YARN"]},{"title":"YARN Overview","url":"%2F2018%2F02%2F2018-02-24-yarn-overview%2F","content":"\n### TODO\n\n### Links\n\n* [Apache Hadoop YARN](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[YARN Overview](http://blog.hyperj.net/2018/02/2018-02-24-yarn-overview/)","tags":["HyperJ"],"categories":["YARN"]},{"title":"HDFS Datanode Overview","url":"%2F2018%2F02%2F2018-02-23-hdfs-datanode-overview%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Datanode Overview](http://blog.hyperj.net/2018/02/2018-02-23-hdfs-datanode-overview/)","tags":["Datanode"],"categories":["HDFS"]},{"title":"HDFS Namenode Overview","url":"%2F2018%2F02%2F2018-02-22-hdfs-namenode-overview%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Namenode Overview](http://blog.hyperj.net/2018/02/2018-02-22-hdfs-namenode-overview/)","tags":["Namenode"],"categories":["HDFS"]},{"title":"HDFS Client Append","url":"%2F2018%2F02%2F2018-02-21-hdfs-client-append%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Client Append](http://blog.hyperj.net/2018/02/2018-02-21-hdfs-client-append/)","tags":["Client"],"categories":["HDFS"]},{"title":"HDFS Client Write","url":"%2F2018%2F02%2F2018-02-20-hdfs-client-write%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Client Write](http://blog.hyperj.net/2018/02/2018-02-20-hdfs-client-write/)","tags":["Client"],"categories":["HDFS"]},{"title":"HDFS Client Read","url":"%2F2018%2F02%2F2018-02-19-hdfs-client-read%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Client Read](http://blog.hyperj.net/2018/02/2018-02-19-hdfs-client-read/)","tags":["Client"],"categories":["HDFS"]},{"title":"HDFS RPC","url":"%2F2018%2F02%2F2018-02-18-hdfs-rpc%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS RPC](http://blog.hyperj.net/2018/02/2018-02-18-hdfs-rpc/)","tags":["RPC"],"categories":["HDFS"]},{"title":"HDFS Overview","url":"%2F2018%2F02%2F2018-02-17-hdfs-overvew%2F","content":"\n### TODO\n\n### Links\n\n* [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Overview](http://blog.hyperj.net/2018/02/2018-02-17-hdfs-overvew/)","tags":["HDFS"],"categories":["HDFS"]},{"title":"Preprocessing Data Practice","url":"%2F2018%2F02%2F2018-02-15-preprocessing-data-practice%2F","content":"\n### Data \n\n* missing\n \n* mismatch\n\n### Preprocessing\n\n* OneHotEncoding\n\n* Standardized\n\n* Normalize\n\n### Links\n\n* [Preprocessing Data](http://scikit-learn.org/stable/modules/preprocessing.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Preprocessing Data Practice](http://blog.hyperj.net/2018/02/2018-02-16-preprocessing-data-practice/)","tags":["Preprocessing"],"categories":["Feature Engineering"]},{"title":"Java Memory Model","url":"%2F2018%2F02%2F2018-02-16-java-memory-model%2F","content":"\n### TODO\n\n### Links\n\n* [The Java Memory Model](http://www.cs.umd.edu/~pugh/java/memoryModel/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Java Memory Model](http://blog.hyperj.net/2018/02/2018-02-16-java-memory-model/)","tags":["Memory Model"],"categories":["Java"]},{"title":"Preprocessing Data","url":"%2F2018%2F02%2F2018-02-14-preprocessing-data%2F","content":"\n### TODO\n\n### Links\n\n* [Preprocessing Data](http://scikit-learn.org/stable/modules/preprocessing.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Preprocessing Data](http://blog.hyperj.net/2018/02/2018-02-14-preprocessing-data/)","tags":["Preprocessing"],"categories":["Feature Engineering"]},{"title":"Feature Extraction","url":"%2F2018%2F02%2F2018-02-13-feature-extraction%2F","content":"\nThe `sklearn.feature_extraction` module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image.\n\n> Note `Feature extraction` is very different from `Feature selection`: the former consists in transforming arbitrary data, such as text or images, into numerical features usable for machine learning. The latter is a machine learning technique applied on these features.\n\n##### DictVectorizer\n\nDictVectorizer implements what is called one-of-K or “one-hot” coding for categorical (aka nominal, discrete) features. \n\n##### FeatureHasher\n\n##### Text feature extraction\n\n###### CountVectorizer, HashingVectorizer\n\n###### Bag of Words(tokenization, counting and normalization)\n\n   Sparsity\n   Tf–idf term weighting\n   Decode\n\n##### Image feature extraction\n\n### Links\n\n* [Feature Extraction](http://scikit-learn.org/stable/modules/feature_extraction.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Feature Extraction](http://blog.hyperj.net/2018/02/2018-02-13-feature-extraction/)","tags":["Extraction"],"categories":["Feature Engineering"]},{"title":"Spark GraphX Overview","url":"%2F2018%2F02%2F2018-02-12-spark-graphx-overview%2F","content":"\n### 分布式图计算\n\n### GraphX点切分存储\n\n### vertices、edges和triplets\n\n### 图的构建\n\n### GraphX的图运算操作\n\n    转换操作\n    结构操作\n    关联操作\n    聚合操作\n    缓存操作\n    \n### GraphX Pregel API\n\n### 图算法实现\n\n    宽度优先遍历\n    单源最短路径\n    连通组件\n    三角计数\n    PageRank\n\n### Links\n\n* [Spark Graphx 的原理及相关操作的源码解析](https://github.com/endymecy/spark-graphx-source-analysis)\n* [Spark GraphX Programming Guide](http://spark.apache.org/docs/latest/graphx-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark GraphX Overview](http://blog.hyperj.net/2018/02/2018-02-12-spark-graphx-overview/)","tags":["Spark GraphX"],"categories":["Spark"]},{"title":"Spark MLlib Overview","url":"%2F2018%2F02%2F2018-02-11-spark-mllib-overview%2F","content":"\n### 数据类型\n\n* Local vector\n* Labeled point\n* Local matrix\n* Distributed matrix\n\n    RowMatrix\n    IndexedRowMatrix\n    CoordinateMatrix\n    BlockMatrix\n\n### 基本统计\n\n* summary statistics（概括统计）\n* correlations（相关性系数）\n* tratified sampling（分层取样）\n* hypothesis testing（假设检验）\n* random data generation（随机数生成）\n* Kernel density estimation（核密度估计）\n\n### 协同过滤\n\n* 交换最小二乘\n\n### 分类和回归\n\n* 线性模型（SVMs(支持向量机)、逻辑回归、线性回归、广义线性回归）\n* 朴素贝叶斯\n* 决策树\n* 组合树（随机森林、梯度提升树）\n* 生存回归\n* 保序回归\n\n### 聚类\n\n* k-means||算法\n* GMM（高斯混合模型）\n* PIC（快速迭代聚类）\n* LDA（隐式狄利克雷分布)\n* 二分k-means算法\n* 流式k-means算法\n\n### 最优化算法\n\n* 梯度下降算法\n* 拟牛顿法\n* NNLS(非负最小二乘)\n* 带权最小二乘\n* 迭代再加权最小二乘\n\n### 降维\n\n* EVD（特征值分解）\n* SVD（奇异值分解）\n* PCA（主成分分析）\n\n### 特征抽取和转换\n\n* 特征抽取\n* 特征转换\n* 特征选择\n\n### Links\n\n* [spark ml 算法原理剖析以及具体的源码实现分析](https://github.com/endymecy/spark-ml-source-analysis)\n* [Spark Machine Learning Library (MLlib) Guide](http://spark.apache.org/docs/latest/ml-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark MLlib Overview](http://blog.hyperj.net/2018/02/2018-02-11-spark-mllib-overview/)","tags":["Spark MLlib"],"categories":["Spark"]},{"title":"Spark Streaming Optimization","url":"%2F2018%2F02%2F2018-02-10-spark-streaming-optimization%2F","content":"\n### Configuration\n\n##### Spark Streaming\n\n###### spark.streaming.backpressure.enabled(false)\n\nEnables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values spark.streaming.receiver.maxRate and spark.streaming.kafka.maxRatePerPartition if they are set (see below).\n\n###### spark.streaming.backpressure.initialRate\n\nThis is the initial maximum receiving rate at which each receiver will receive data for the first batch when the backpressure mechanism is enabled.\n\n###### spark.streaming.blockInterval(200ms)\n                                             \nInterval at which data received by Spark Streaming receivers is chunked into blocks of data before storing them in Spark. Minimum recommended - 50 ms. See the performance tuning section in the Spark Streaming programing guide for more details.\n\n###### spark.streaming.receiver.maxRate\n\nMaximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details.\n\n###### spark.streaming.receiver.writeAheadLog.enable(false)\n                                                             \nEnable write ahead logs for receivers. All the input data received through receivers will be saved to write ahead logs that will allow it to be recovered after driver failures. See the deployment guide in the Spark Streaming programing guide for more details.\n\n###### spark.streaming.unpersist(true)\n                                        \nForce RDDs generated and persisted by Spark Streaming to be automatically unpersisted from Spark's memory. The raw input data received by Spark Streaming is also automatically cleared. Setting this to false will allow the raw data and persisted RDDs to be accessible outside the streaming application as they will not be cleared automatically. But it comes at the cost of higher memory usage in Spark.\n\n###### spark.streaming.stopGracefullyOnShutdown(false)\n                                                     \nIf true, Spark shuts down the StreamingContext gracefully on JVM shutdown rather than immediately.\n\n###### spark.streaming.kafka.maxRatePerPartition\n                                                \nMaximum rate (number of records per second) at which data will be read from each Kafka partition when using the new Kafka direct stream API. See the Kafka Integration guide for more details.\n\n###### spark.streaming.kafka.maxRetries(1)\n                                         \nMaximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the new Kafka direct stream API.\n\n###### spark.streaming.ui.retainedBatches(1000)\n                                                \nHow many batches the Spark Streaming UI and status APIs remember before garbage collecting.\n\n###### spark.streaming.driver.writeAheadLog.closeFileAfterWrite(false)\n                                                                     \nWhether to close the file after writing a write ahead log record on the driver. Set this to 'true' when you want to use S3 (or any file system that does not support flushing) for the metadata WAL on the driver.\n\n###### spark.streaming.receiver.writeAheadLog.closeFileAfterWrite(false)\n\nWhether to close the file after writing a write ahead log record on the receivers. Set this to 'true' when you want to use S3 (or any file system that does not support flushing) for the data WAL on the receivers.\n\n### Links\n\n* [Structured Streaming Programming Guide](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)\n* [Spark Streaming Programming Guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Streaming Scheduling](http://blog.hyperj.net/2018/02/2018-02-10-spark-streaming-optimization/)","tags":["Spark Streaming"],"categories":["Spark"]},{"title":"Spark Structured Streaming","url":"%2F2018%2F02%2F2018-02-09-spark-structured-streaming%2F","content":"\n### Structured Streaming\n\nSource, Sink, StreamExecution, StateStore, EventTimeWatermark\n\n### Links\n\n* [Structured Streaming 源码解析系列](https://github.com/lw-lin/CoolplaySpark/tree/master/Structured%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97)\n* [A Deep Dive into Structured Streaming](http://www.slideshare.net/databricks/a-deep-dive-into-structured-streaming)\n* [Structured Streaming Programming Guide](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)\n* [Spark Streaming Programming Guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Structured Streaming](http://blog.hyperj.net/2018/02/2018-02-09-spark-structured-streaming/)","tags":["Structured Streaming"],"categories":["Spark"]},{"title":"Spark Streaming Architecture","url":"%2F2018%2F02%2F2018-02-08-spark-streaming-architecture%2F","content":"\n### Concepts\n\n* DStream, DStreamGraph（InputDStream, ForEachDStream）\n\n* JobScheduler, JobGenerator\n\n* Receiver, ReceiverSupervisor, BlockGenerator, ReceivedBlockHandler, ReceiverTraker, ReceivedBlockTracker\n\n* Checkpoint, WAL\n\n### Links\n\n* [Spark Streaming 源码解析系列](https://github.com/lw-lin/CoolplaySpark/tree/master/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97)\n* [Structured Streaming Programming Guide](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)\n* [Spark Streaming Programming Guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Streaming Architecture](http://blog.hyperj.net/2018/02/2018-02-08-spark-streaming-architecture/)","tags":["Spark Streaming"],"categories":["Spark"]},{"title":"Spark Streaming Overview","url":"%2F2018%2F02%2F2018-02-07-spark-streaming-overview%2F","content":"\n### Concepts\n\n* DStream\n\n* DStreamGraph\n\n### Operations\n\n* Input、Receivers\n\n* Transformations\n\n* Output\n\n### Links\n\n* [Structured Streaming Programming Guide](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)\n* [Spark Streaming Programming Guide](http://spark.apache.org/docs/latest/streaming-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Streaming Overview](http://blog.hyperj.net/2018/02/2018-02-07-spark-streaming-overview/)","tags":["Spark Streaming"],"categories":["Spark"]},{"title":"Spark SQL Optimization","url":"%2F2018%2F02%2F2018-02-06-spark-sql-optimization%2F","content":"\n### Configuration\n\n##### Application Properties\n\n###### spark.driver.cores(1)\n\nNumber of cores to use for the driver process, only in cluster mode.\n\n###### spark.driver.maxResultSize(1g)\n\nLimit of total size of serialized results of all partitions for each Spark action (e.g. collect). Should be at least 1M, or 0 for unlimited. Jobs will be aborted if the total size is above this limit. Having a high limit may cause out-of-memory errors in driver (depends on spark.driver.memory and memory overhead of objects in JVM). Setting a proper limit can protect the driver from out-of-memory errors.\n\n###### spark.driver.memory(1g)\n\nAmount of memory to use for the driver process, i.e. where SparkContext is initialized. (e.g. 1g, 2g). \nNote: In client mode, this config must not be set through the SparkConf directly in your application, because the driver JVM has already started at that point. Instead, please set this through the --driver-memory command line option or in your default properties file.\n\n###### spark.executor.memory(1g)\n\nA string of extra JVM options to pass to the driver. For instance, GC settings or other logging. Note that it is illegal to set maximum heap size (-Xmx) settings with this option. Maximum heap size settings can be set with spark.driver.memory in the cluster mode and through the --driver-memory command line option in the client mode. \nNote: In client mode, this config must not be set through the SparkConf directly in your application, because the driver JVM has already started at that point. Instead, please set this through the --driver-java-options command line option or in your default properties file.\n\n##### Runtime Environment\n\n###### spark.driver.extraJavaOptions(none)\n\nA string of extra JVM options to pass to the driver. For instance, GC settings or other logging. Note that it is illegal to set maximum heap size (-Xmx) settings with this option. Maximum heap size settings can be set with spark.driver.memory in the cluster mode and through the --driver-memory command line option in the client mode. \n\nNote: In client mode, this config must not be set through the SparkConf directly in your application, because the driver JVM has already started at that point. Instead, please set this through the --driver-java-options command line option or in your default properties file.\n\n###### spark.executor.extraJavaOptions(none)\n\nA string of extra JVM options to pass to the driver. For instance, GC settings or other logging. Note that it is illegal to set maximum heap size (-Xmx) settings with this option. Maximum heap size settings can be set with spark.driver.memory in the cluster mode and through the --driver-memory command line option in the client mode. \nNote: In client mode, this config must not be set through the SparkConf directly in your application, because the driver JVM has already started at that point. Instead, please set this through the --driver-java-options command line option or in your default properties file.\n\n##### Execution Behavior\n\n###### spark.executor.cores(1 in YARN mode, all the available cores on the worker in standalone and Mesos coarse-grained modes.)\n\nThe number of cores to use on each executor. In standalone and Mesos coarse-grained modes, setting this parameter allows an application to run multiple executors on the same worker, provided that there are enough cores on that worker. Otherwise, only one executor per application will run on each worker.\n\n##### Spark Yarn Properties\n\n###### spark.yarn.executor.memoryOverhead(executorMemory * 0.10, with minimum of 384)\n\nThe amount of off-heap memory (in megabytes) to be allocated per executor. This is memory that accounts for things like VM overheads, interned strings, other native overheads, etc. This tends to grow with the executor size (typically 6-10%).\n\n###### spark.yarn.driver.memoryOverhead(driverMemory * 0.10, with minimum of 384)\n\nThe amount of off-heap memory (in megabytes) to be allocated per driver in cluster mode. This is memory that accounts for things like VM overheads, interned strings, other native overheads, etc. This tends to grow with the container size (typically 6-10%).\n\n###### spark.yarn.am.memoryOverhead(AM memory * 0.10, with minimum of 384)\n\nSame as spark.yarn.driver.memoryOverhead, but for the YARN Application Master in client mode.\n\n### Links\n\n* [Spark SQL, DataFrames and Datasets Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n* [Spark Configuration](http://spark.apache.org/docs/latest/configuration.html)\n* [Running Spark on YARN](http://spark.apache.org/docs/latest/running-on-yarn.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark SQL Optimization](http://blog.hyperj.net/2018/02/2018-02-06-spark-sql-optimization/)","tags":["Spark SQL"],"categories":["Spark"]},{"title":"Spark SQL Catalyst","url":"%2F2018%2F02%2F2018-02-05-spark-sql-catalyst%2F","content":"\n### Trees\n\nTreeNode, Expression, LogicalPlan, PhysicalPlan\n\n### Transformations\n\nAnalyzer, Optimizer, Planner\n\n### Rules\n\nRuleExecutor\n\n### Sequence\n\nQuery/Dataset/DataFrame(SessionCatalog) -(Antlr)> Unresolved/Parsed Logical Plan -(Analyser)> Analyzed Logical Plan -(Optimizer)> Optimized Logical Plan -(SparkPlanner)> Physical Plan -> SparkPlan#execute\n\n* 解析(Parse)：将SQL语句通过Parse模块进行词法和语法解析，解析完成后生成未绑定的逻辑执行计划(Unresolved LogicalPlan)，之后步骤在该逻辑执行计划上运用各种规则。\n\n* 绑定(Bind)：使用Analyser中的Analysis规则(Rule)，借助于元数据(Hive Metastore等)，将未绑定的逻辑执行计划转换成绑定元数据的逻辑执行计划(LogicPlan)。\n\n* 优化(Optimizer)：使用Optimization规则(Rule)，将绑定的逻辑执行计划进行合并、列裁剪和过滤器下推等优化后生成优化后的逻辑执行计划(Optimized LogicPlan)。\n\n* 转换(Transform)：使用Planner使用Planning Strategies，对优化后的逻辑执行计划转换(Transform)生成可执行的物理执行计划(PhysicalPlan)。\n\n* 执行(Execution)：调用SparkPlan的execute执行计算RDD。\n\n### Links\n\n* [Deep Dive into Spark SQL’s Catalyst Optimizer](https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html)\n* [Spark SQL: Relational Data Processing in Spark](http://people.csail.mit.edu/matei/papers/2015/sigmod_spark_sql.pdf)\n* [Spark SQL, DataFrames and Datasets Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark SQL Catalyst](http://blog.hyperj.net/2018/02/2018-02-05-spark-sql-catalyst/)","tags":["Catalyst"],"categories":["Spark"]},{"title":"Spark SQL Overview","url":"%2F2018%2F02%2F2018-02-04-spark-sql-overview%2F","content":"\n### Overview\n\nSpark SQL由Core、Catalyst、Hive和Hive-Thriftserver四部分组成，分别对应Spark源码中的spark/sql/core、spark/sql/catalyst、spark/sql/hive和spark/sql/hive-thriftserver。\n\n* Core：用于将Catalyst生成的逻辑执行计划转换为RDD的查询/执行引擎。该组建中还包含一个SQLContext接口，用于对于已经存在的RDD和Parquet文件执行SQL或LINQ语句。\n* Catalyst：负责处理查询语句的整个处理流程，包括解析、绑定、优化、物理计划等。\n* Hive：负责对Hive数据的处理，里面有一个扩展了SQLContext的HiveContext，允许用户使用HQL编写查询语句，并且使用Hive SerDes从Hive Metastore查询数据。还允许你使用UDF、UDAF、UDTF查询。\n* Hive-Thriftserver：提供SQL CLI(bin/spark-sql)和HiveServer2(JDBC/ODBC)兼容服务的支持。\n\nCatalyst是Spark的核心，Spark SQL的执行流程的核心就是Catalyst的执行工作流程。\n\n### Dataset/DataFrame\n\nDataset是从Spark 1.6提供的分布式数据集，它同时提供了RDD(强类型、使用lambda表达式)和Spark SQL(优化执行引擎)各自的优点。Dataset可以通过JVM对象和已有的Dataset转化来构建。Dataset提供了Java和Scala的API。\n\nDataFrame其实要比DataSet出现的早，在Spark1.3版本提供的。DataFrame和DataSet都是在RDD的基础上提供的，DataFrame的使用风格类似R和Pandas风格的DataFrame API，这样大大降低了学习成本。Dataset和DataFrame都是分布式数据集，只不过DataFrame中包含列的命名信息(列的Schema信息)，DataFrame在概念上等同于关系数据库中的表和R/Python中的DataFrame。\n\n在Spark2.0以后，Spark团队就把Dataset和DataFrame进行了合并，把DataFrame作为Dataset中一种具有列Schema信息的Row的集合。所以现在就把DataFrame看作Dataset的一种，只不过包含了列的schema信息。现在DataFrame并没有具体的实现类了，而是把它定义为Dataset中Row组成的集合。Dataset/DataFrame和RDD一样，对于转换操作算子是惰性的，只有遇到action算子才会真正执行，这也使得在构建Dataset/DataFrame的所有操作之间可以进行丰富的优化。\n\n```scala\ntype DataFrame = Dataset[Row]\n```\n\n注：Spark SQL在Spark 1.0版本上线，当时使用的是SchemaRDD，在Spark 1.3版本提供了DataFrame代替了SchemaRDD，在Spark 1.6版本Spark提出了Dataset，在Spark 2.0将DataFrame合并到Dataset中。\n\n### Catalog\n\nSessionCatalog\n\n### Links\n\n* [Spark SQL, DataFrames and Datasets Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark SQL O\\verview](http://blog.hyperj.net/2018/02/2018-02-04-spark-sql-overview/)","tags":["Spark SQL"],"categories":["Spark"]},{"title":"Rancher Overview","url":"%2F2018%2F02%2F2018-02-03-rancher-overview%2F","content":"\n### Overview\n\nRancher is an open source software platform that enables organizations to run and manage Docker and Kubernetes in production. With Rancher, organizations no longer have to build a container services platform from scratch using a distinct set of open source technologies. Rancher supplies the entire software stack needed to manage containers in production.\n\n### INFRASTRUCTURE ORCHESTRATION\n\nRancher takes in raw computing resources from any public or private cloud in the form of Linux hosts. Each Linux host can be a virtual machine or physical machine. Rancher does not expect more from each host than CPU, memory, local disk storage, and network connectivity. From Rancher’s perspective, a VM instance from a cloud provider and a bare metal server hosted at a colo facility are indistinguishable.\n\nRancher implements a portable layer of infrastructure services designed specifically to power containerized applications. Rancher infrastructure services include networking, storage, load balancer, DNS, and security. Rancher infrastructure services are typically deployed as containers themselves, so that the same Rancher infrastructure service can run on any Linux hosts from any cloud.\n\n### CONTAINER ORCHESTRATION AND SCHEDULING\n\nMany users choose to run containerized applications using a container orchestration and scheduling framework. Rancher includes a distribution of all popular container orchestration and scheduling frameworks today, including Docker Swarm, Kubernetes, and Mesos. The same user can create multiple Swarm or Kubernetes clusters. They can then use the native Swarm or Kubernetes tools to manage their applications.\n\nIn addition to Swarm, Kubernetes, and Mesos, Rancher supports its own container orchestration and scheduling framework called Cattle. Cattle is used extensively by Rancher to orchestrate infrastructure services as well as setting up, managing, and upgrading Swarm, Kubernetes, and Mesos clusters.\n\n### APPLICATION CATALOG\n\nRancher users can deploy an entire multi-container clustered application from the application catalog with one click of a button. Users can manage the deployed applications and perform fully automated upgrades when new versions of the application become available. Rancher maintains a public catalog consisting of popular applications contributed by the Rancher community. Rancher users can create their own private catalogs.\n\n### ENTERPRISE-GRADE CONTROL\n\nRancher supports flexible user authentication plugins and comes with pre-built user authentication integration with Active Directory, LDAP, and GitHub. Rancher supports Role-Based Access Control (RBAC) at the level of environments, allowing users and groups to share or deny access to, for example, development and production environments.\n\n### Links\n\n* [Rancher Documentation](http://rancher.com/docs/rancher/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Rancher Overview](http://blog.hyperj.net/2018/02/2018-02-03-rancher-overview/)","tags":["Kubernetes"],"categories":["Rancher"]},{"title":"Kubernetes Overview","url":"%2F2018%2F02%2F2018-02-02-kubernetes-overview%2F","content":"\n### Overview\n\nKubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\n##### Planet Scale\n\nDesigned on the same principles that allows Google to run billions of containers a week, Kubernetes can scale without increasing your ops team.\n\n##### Never Outgrow\n\nWhether testing locally or running a global enterprise, Kubernetes flexibility grows with you to deliver your applications consistently and easily no matter how complex your need is.\n\n##### Run Anywhere\n\nKubernetes is open source giving you the freedom to take advantage of on-premises, hybrid, or public cloud infrastructure, letting you effortlessly move workloads to where it matters to you.\n\n### Features\n\n##### Automatic binpacking\n\nAutomatically places containers based on their resource requirements and other constraints, while not sacrificing availability. Mix critical and best-effort workloads in order to drive up utilization and save even more resources.\n\n##### Self-healing\n\nRestarts containers that fail, replaces and reschedules containers when nodes die, kills containers that don't respond to your user-defined health check, and doesn't advertise them to clients until they are ready to serve.\n\n##### Horizontal scaling\n\nScale your application up and down with a simple command, with a UI, or automatically based on CPU usage.\n\n##### Service discovery and load balancing\n\nNo need to modify your application to use an unfamiliar service discovery mechanism. Kubernetes gives containers their own IP addresses and a single DNS name for a set of containers, and can load-balance across them.\n\n##### Automated rollouts and rollbacks\n\nKubernetes progressively rolls out changes to your application or its configuration, while monitoring application health to ensure it doesn't kill all your instances at the same time. If something goes wrong, Kubernetes will rollback the change for you. Take advantage of a growing ecosystem of deployment solutions.\n\n##### Secret and configuration management\n\nDeploy and update secrets and application configuration without rebuilding your image and without exposing secrets in your stack configuration.\n\n##### Storage orchestration\n\nAutomatically mount the storage system of your choice, whether from local storage, a public cloud provider such as GCP or AWS, or a network storage system such as NFS, iSCSI, Gluster, Ceph, Cinder, or Flocker.\n\n##### Batch execution\n\nIn addition to services, Kubernetes can manage your batch and CI workloads, replacing containers that fail, if desired.\n\n### Links\n\n* [Kubernetes Documentation](https://kubernetes.io/docs/home/)\n* [Kubernetes Concepts](https://kubernetes.io/docs/concepts/)\n* [Kubernetes Tutorials](https://kubernetes.io/docs/tutorials/)\n* [Kubernetes Reference](https://kubernetes.io/docs/reference/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Kubernetes Overview](http://blog.hyperj.net/2018/02/2018-02-02-kubernetes-overview/)","tags":["Kubernetes"],"categories":["Kubernetes"]},{"title":"Docker Overview","url":"%2F2018%2F02%2F2018-02-01-docker-overview%2F","content":"\n### Container\n\n* [What is a Container](https://www.docker.com/what-container)\n\n### Tools\n\n* Docker Compose: Enables you to define, build, and run multi-container applications\n\n* Docker Machine: Enables you to provision and manage Dockerized hosts\n\n* Docker Notary: Allows the signing of container images to enable Docker Content Trust\n\n* Docker Registry: The software that powers Docker Hub and Docker Store, Registry stores and distributes container images\n\n### File formats\n\n* Dockerfile: Defines the contents and startup behavior of a single container\n\n* Compose file: Defines a multi-container application\n\n### Command-line interfaces (CLIs)\n\n* Engine CLI: The main CLI for Docker, includes all docker and dockerd commands\n\n* Compose CLI: The CLI for Docker Compose, which allows you to build and run multi-container applications\n\n* Machine CLI: Manages virtual machines that are pre-configured to run Docker\n\n### Links\n\n* [Docker Documentation](https://docs.docker.com/)\n* [Docker Product and Tool Manuals](https://docs.docker.com/manuals/)\n* [Docker Glossary](https://docs.docker.com/glossary/)\n* [Docker Reference](https://docs.docker.com/reference/)\n* [Docker Samples](https://docs.docker.com/samples/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Docker Overview](http://blog.hyperj.net/2018/02/2018-02-01-docker-overview/)","tags":["Docker"],"categories":["Docker"]},{"title":"Spark Monitoring","url":"%2F2018%2F01%2F2018-01-31-spark-monitoring%2F","content":"\n### Web UI\n\n* WebUI, WebUITab\n\n    SparkUI, SparkUITab\n    WorkerWebUI, MasterWebUI(Standalone)\n    HistoryServer(Yarn or Mesos)\n\n### Restful\n\n* StandaloneRestServer(RestSubmissionServer)\n\n* StandaloneSubmitRequestServlet, StandaloneKillRequestServlet, StandaloneStatusRequestServlet\n\n### Metrics\n\n* MetricsSystem, MetricsConfig\n\n* Source(MasterSource, ApplicationSource, WorkerSource, ExecutorSource, DAGSchedulerSource, ShuffleMetricsSource, BlockManagerSource, StreamingSource, JvmSource)\n\n* Sink(ConsoleSink, CsvSink, GraphiteSink, JmxSink, MetricsServlet<Web UI>, Slf4jSink, StatsdSink)\n\n### Links\n\n* [Spark Documentation - Monitoring and Instrumentation](http://spark.apache.org/docs/latest/monitoring.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Monitoring](http://blog.hyperj.net/2018/01/2018-01-31-spark-monitoring/)","tags":["Monitoring"],"categories":["Spark"]},{"title":"Spark Fault Tolerance","url":"%2F2018%2F01%2F2018-01-30-spark-fault-tolerance%2F","content":"\n### RDD\n\n* Lineage, Dependencies\n\n* Cache, Checkpoint\n\n* Replication\n\n* Partitions\n\n### Cluster\n\n* Master\n\n* Worker\n\n### Application\n\n* Client\n\n* Driver\n\n* Executor\n\n* Task\n\n### Mechanism\n\n* BlacklistTracker, TaskSetBlacklist\n\n### Links\n\n* [Apache Spark源码走读之15 -- Standalone部署模式下的容错性分析](http://www.cnblogs.com/hseagle/p/3791779.html)\n* [Fault Tolerance in Spark: Lessons Learned from Production: Spark Summit East talk by Jose Soltren](https://www.slideshare.net/SparkSummit/fault-tolerance-in-spark-lessons-learned-from-production-spark-summit-east-talk-by-jose-soltren)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Fault Tolerance](http://blog.hyperj.net/2018/01/2018-01-30-spark-fault-tolerance/)","tags":["Fault Tolerance"],"categories":["Spark"]},{"title":"Spark Scheduling - Strategy","url":"%2F2018%2F01%2F2018-01-29-spark-scheduling-strategy%2F","content":"\n### Driver\n\n##### Standalone(Master)\n\n```scala\n  /**\n   * Schedule the currently available resources among waiting apps. This method will be called\n   * every time a new app joins or resource availability changes.\n   */\n  private def schedule(): Unit = {\n    if (state != RecoveryState.ALIVE) {\n      return\n    }\n    // Drivers take strict precedence over executors\n    val shuffledAliveWorkers = Random.shuffle(workers.toSeq.filter(_.state == WorkerState.ALIVE))\n    val numWorkersAlive = shuffledAliveWorkers.size\n    var curPos = 0\n    for (driver <- waitingDrivers.toList) { // iterate over a copy of waitingDrivers\n      // We assign workers to each waiting driver in a round-robin fashion. For each driver, we\n      // start from the last worker that was assigned a driver, and continue onwards until we have\n      // explored all alive workers.\n      var launched = false\n      var numWorkersVisited = 0\n      while (numWorkersVisited < numWorkersAlive && !launched) {\n        val worker = shuffledAliveWorkers(curPos)\n        numWorkersVisited += 1\n        if (worker.memoryFree >= driver.desc.mem && worker.coresFree >= driver.desc.cores) {\n          launchDriver(worker, driver)\n          waitingDrivers -= driver\n          launched = true\n        }\n        curPos = (curPos + 1) % numWorkersAlive\n      }\n    }\n    startExecutorsOnWorkers()\n  }\n```\n\n##### Yarn(AM)\n\n```java\n  @VisibleForTesting\n  public static final class ScheduleTransition\n      implements\n      MultipleArcTransition<RMAppAttemptImpl, RMAppAttemptEvent, RMAppAttemptState> {\n    @Override\n    public RMAppAttemptState transition(RMAppAttemptImpl appAttempt,\n        RMAppAttemptEvent event) {\n      ApplicationSubmissionContext subCtx = appAttempt.submissionContext;\n      if (!subCtx.getUnmanagedAM()) {\n        // Need reset #containers before create new attempt, because this request\n        // will be passed to scheduler, and scheduler will deduct the number after\n        // AM container allocated\n        \n        // Currently, following fields are all hard coded,\n        // TODO: change these fields when we want to support\n        // priority or multiple containers AM container allocation.\n        for (ResourceRequest amReq : appAttempt.amReqs) {\n          amReq.setNumContainers(1);\n          amReq.setPriority(AM_CONTAINER_PRIORITY);\n        }\n\n        int numNodes =\n            RMServerUtils.getApplicableNodeCountForAM(appAttempt.rmContext,\n                appAttempt.conf, appAttempt.amReqs);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Setting node count for blacklist to \" + numNodes);\n        }\n        appAttempt.getAMBlacklistManager().refreshNodeHostCount(numNodes);\n\n        ResourceBlacklistRequest amBlacklist =\n            appAttempt.getAMBlacklistManager().getBlacklistUpdates();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Using blacklist for AM: additions(\" +\n              amBlacklist.getBlacklistAdditions() + \") and removals(\" +\n              amBlacklist.getBlacklistRemovals() + \")\");\n        }\n        // AM resource has been checked when submission\n        Allocation amContainerAllocation =\n            appAttempt.scheduler.allocate(\n                appAttempt.applicationAttemptId,\n                appAttempt.amReqs,\n                EMPTY_CONTAINER_RELEASE_LIST,\n                amBlacklist.getBlacklistAdditions(),\n                amBlacklist.getBlacklistRemovals(),\n                new ContainerUpdates());\n        if (amContainerAllocation != null\n            && amContainerAllocation.getContainers() != null) {\n          assert (amContainerAllocation.getContainers().size() == 0);\n        }\n        return RMAppAttemptState.SCHEDULED;\n      } else {\n        // save state and then go to LAUNCHED state\n        appAttempt.storeAttempt();\n        return RMAppAttemptState.LAUNCHED_UNMANAGED_SAVING;\n      }\n    }\n  }\n```\n\n### Executor\n\n##### Standalone(Master)\n\n```scala\n  /**\n   * Schedule executors to be launched on the workers.\n   * Returns an array containing number of cores assigned to each worker.\n   *\n   * There are two modes of launching executors. The first attempts to spread out an application's\n   * executors on as many workers as possible, while the second does the opposite (i.e. launch them\n   * on as few workers as possible). The former is usually better for data locality purposes and is\n   * the default.\n   *\n   * The number of cores assigned to each executor is configurable. When this is explicitly set,\n   * multiple executors from the same application may be launched on the same worker if the worker\n   * has enough cores and memory. Otherwise, each executor grabs all the cores available on the\n   * worker by default, in which case only one executor per application may be launched on each\n   * worker during one single schedule iteration.\n   * Note that when `spark.executor.cores` is not set, we may still launch multiple executors from\n   * the same application on the same worker. Consider appA and appB both have one executor running\n   * on worker1, and appA.coresLeft > 0, then appB is finished and release all its cores on worker1,\n   * thus for the next schedule iteration, appA launches a new executor that grabs all the free\n   * cores on worker1, therefore we get multiple executors from appA running on worker1.\n   *\n   * It is important to allocate coresPerExecutor on each worker at a time (instead of 1 core\n   * at a time). Consider the following example: cluster has 4 workers with 16 cores each.\n   * User requests 3 executors (spark.cores.max = 48, spark.executor.cores = 16). If 1 core is\n   * allocated at a time, 12 cores from each worker would be assigned to each executor.\n   * Since 12 < 16, no executors would launch [SPARK-8881].\n   */\n  private def scheduleExecutorsOnWorkers(\n      app: ApplicationInfo,\n      usableWorkers: Array[WorkerInfo],\n      spreadOutApps: Boolean): Array[Int] = {\n    val coresPerExecutor = app.desc.coresPerExecutor\n    val minCoresPerExecutor = coresPerExecutor.getOrElse(1)\n    val oneExecutorPerWorker = coresPerExecutor.isEmpty\n    val memoryPerExecutor = app.desc.memoryPerExecutorMB\n    val numUsable = usableWorkers.length\n    val assignedCores = new Array[Int](numUsable) // Number of cores to give to each worker\n    val assignedExecutors = new Array[Int](numUsable) // Number of new executors on each worker\n    var coresToAssign = math.min(app.coresLeft, usableWorkers.map(_.coresFree).sum)\n\n    /** Return whether the specified worker can launch an executor for this app. */\n    def canLaunchExecutor(pos: Int): Boolean = {\n      val keepScheduling = coresToAssign >= minCoresPerExecutor\n      val enoughCores = usableWorkers(pos).coresFree - assignedCores(pos) >= minCoresPerExecutor\n\n      // If we allow multiple executors per worker, then we can always launch new executors.\n      // Otherwise, if there is already an executor on this worker, just give it more cores.\n      val launchingNewExecutor = !oneExecutorPerWorker || assignedExecutors(pos) == 0\n      if (launchingNewExecutor) {\n        val assignedMemory = assignedExecutors(pos) * memoryPerExecutor\n        val enoughMemory = usableWorkers(pos).memoryFree - assignedMemory >= memoryPerExecutor\n        val underLimit = assignedExecutors.sum + app.executors.size < app.executorLimit\n        keepScheduling && enoughCores && enoughMemory && underLimit\n      } else {\n        // We're adding cores to an existing executor, so no need\n        // to check memory and executor limits\n        keepScheduling && enoughCores\n      }\n    }\n\n    // Keep launching executors until no more workers can accommodate any\n    // more executors, or if we have reached this application's limits\n    var freeWorkers = (0 until numUsable).filter(canLaunchExecutor)\n    while (freeWorkers.nonEmpty) {\n      freeWorkers.foreach { pos =>\n        var keepScheduling = true\n        while (keepScheduling && canLaunchExecutor(pos)) {\n          coresToAssign -= minCoresPerExecutor\n          assignedCores(pos) += minCoresPerExecutor\n\n          // If we are launching one executor per worker, then every iteration assigns 1 core\n          // to the executor. Otherwise, every iteration assigns cores to a new executor.\n          if (oneExecutorPerWorker) {\n            assignedExecutors(pos) = 1\n          } else {\n            assignedExecutors(pos) += 1\n          }\n\n          // Spreading out an application means spreading out its executors across as\n          // many workers as possible. If we are not spreading out, then we should keep\n          // scheduling executors on this worker until we use all of its resources.\n          // Otherwise, just move on to the next worker.\n          if (spreadOutApps) {\n            keepScheduling = false\n          }\n        }\n      }\n      freeWorkers = freeWorkers.filter(canLaunchExecutor)\n    }\n    assignedCores\n  }\n```\n\n### Job\n\n```scala\n  def initialize(backend: SchedulerBackend) {\n    this.backend = backend\n    schedulableBuilder = {\n      schedulingMode match {\n        case SchedulingMode.FIFO =>\n          new FIFOSchedulableBuilder(rootPool)\n        case SchedulingMode.FAIR =>\n          new FairSchedulableBuilder(rootPool, conf)\n        case _ =>\n          throw new IllegalArgumentException(s\"Unsupported $SCHEDULER_MODE_PROPERTY: \" +\n          s\"$schedulingMode\")\n      }\n    }\n    schedulableBuilder.buildPools()\n  }\n```\n\n* FIFO\n\n* FAIR\n\n### Task\n\n* Local\n\n* Lazy\n\n### Links\n\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Scheduling - Strategy](http://blog.hyperj.net/2018/01/2018-01-29-spark-scheduling-strategy/)","tags":["Strategy"],"categories":["Spark"]},{"title":"Spark Scheduling - Algorithm","url":"%2F2018%2F01%2F2018-01-28-spark-scheduling-algorithm%2F","content":"\n### SchedulingAlgorithm\n\n* FIFO: FIFO algorithm between TaskSetManagers\n\n* FS: FS algorithm between Pools, and FIFO or FS within Pools\n\n* Schedulable(Pool, TaskSetManager)\n\n```scala\ndef comparator(s1: Schedulable, s2: Schedulable): Boolean\n```\n\n#### FIFOSchedulingAlgorithm\n\n```scala\noverride def comparator(s1: Schedulable, s2: Schedulable): Boolean = {\n    val priority1 = s1.priority\n    val priority2 = s2.priority\n    var res = math.signum(priority1 - priority2)\n    if (res == 0) {\n      val stageId1 = s1.stageId\n      val stageId2 = s2.stageId\n      res = math.signum(stageId1 - stageId2)\n    }\n    res < 0\n}\n```\n\n#### FairSchedulingAlgorithm\n\n```scala\noverride def comparator(s1: Schedulable, s2: Schedulable): Boolean = {\n    val minShare1 = s1.minShare\n    val minShare2 = s2.minShare\n    val runningTasks1 = s1.runningTasks\n    val runningTasks2 = s2.runningTasks\n    val s1Needy = runningTasks1 < minShare1\n    val s2Needy = runningTasks2 < minShare2\n    val minShareRatio1 = runningTasks1.toDouble / math.max(minShare1, 1.0)\n    val minShareRatio2 = runningTasks2.toDouble / math.max(minShare2, 1.0)\n    val taskToWeightRatio1 = runningTasks1.toDouble / s1.weight.toDouble\n    val taskToWeightRatio2 = runningTasks2.toDouble / s2.weight.toDouble\n\n    var compare = 0\n    if (s1Needy && !s2Needy) {\n      return true\n    } else if (!s1Needy && s2Needy) {\n      return false\n    } else if (s1Needy && s2Needy) {\n      compare = minShareRatio1.compareTo(minShareRatio2)\n    } else {\n      compare = taskToWeightRatio1.compareTo(taskToWeightRatio2)\n    }\n    if (compare < 0) {\n      true\n    } else if (compare > 0) {\n      false\n    } else {\n      s1.name < s2.name\n    }\n}\n```\n\n### Links\n\n* [Spark Documentation - Job Scheduling](http://spark.apache.org/docs/latest/job-scheduling.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Scheduling - Algorithm](http://blog.hyperj.net/2018/01/2018-01-28-spark-scheduling-algorithm/)","tags":["Fair"],"categories":["Spark"]},{"title":"Spark Scheduling - Sequence","url":"%2F2018%2F01%2F2018-01-27-spark-scheduling-sequence%2F","content":"\n### Sequence\n\n* Driver: RDD(foreach, foreachPartition, collect, collectPartitions, toLocalIterator, reduce, fold, aggregate, count, take)#runJob -> DAGScheduler#runJob, submitJob -> DAGSchedulerEventProcessLoop<EventLoop>#doOnReceive(JobSubmitted<DAGSchedulerEvent>) -> DAGScheduler#handleJobSubmitted, submitStage(Submits stage, but first recursively submits any missing parents, BFS.), submitMissingTasks -> TaskScheduler#submitTasks(TaskSet) -> CoarseGrainedSchedulerBackend#reviveOffers\n\n* Executor: Executor#launchTask -> TaskRunner#run -> Task#run -> ShuffleMapTask(MapStatus), ResultTask(func():U)#runTask -> CoarseGrainedExecutorBackend#statusUpdate\n\n* Driver: DAGSchedulerEventProcessLoop<EventLoop>#doOnReceive(CompletionEvent<DAGSchedulerEvent>) -> DAGScheduler#handleTaskCompletion\n\n* DAGSchedulerEvent\n\n    AllJobsCancelled$\n    BeginEvent\n    CompletionEvent\n    DAGSchedulerEvent\n    ExecutorAdded\n    ExecutorLost\n    GettingResultEvent\n    JobCancelled\n    JobGroupCancelled\n    JobSubmitted\n    MapStageSubmitted\n    ResubmitFailedStages$\n    SpeculativeTaskSubmitted\n    StageCancelled\n    TaskSetFailed\n    WorkerRemoved\n\n* Task\n\n    ShuffleMapTask\n    ResultTask\n\n### Links\n\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Scheduling - Sequence](http://blog.hyperj.net/2018/01/2018-01-27-spark-job-scheduling/2018-01-27-spark-scheduling-sequence.md)","tags":["Sequence"],"categories":["Spark"]},{"title":"Spark Configuration","url":"%2F2018%2F01%2F2018-01-26-spark-configuration%2F","content":"\n### Configuration\n\n* Spark Properties\n\n    Application Properties\n    Runtime Environment\n    Shuffle Behavior\n    Spark UI\n    Compression and Serialization\n    Memory Management\n    Execution Behavior\n    Networking\n    Scheduling\n    Dynamic Allocation\n    Security\n    TLS / SSL\n    Spark SQL\n    Spark Streaming\n    SparkR\n    GraphX\n    Deploy\n    Cluster Managers\n\n* Environment Variables\n\n* Configuring Logging\n\n* Overriding configuration directory\n\n* Inheriting Hadoop Cluster Configuration\n\n### Priority\n\nSparkSubmit -> val appArgs = new SparkSubmitArguments(args)\n\n```scala\n  // Init parameters\n  var master: String = null\n  var deployMode: String = null\n  var executorMemory: String = null\n  var executorCores: String = null\n  var totalExecutorCores: String = null\n  var propertiesFile: String = null\n  var driverMemory: String = null\n  var driverExtraClassPath: String = null\n  var driverExtraLibraryPath: String = null\n  var driverExtraJavaOptions: String = null\n  var queue: String = null\n  var numExecutors: String = null\n  var files: String = null\n  var archives: String = null\n  var mainClass: String = null\n  var primaryResource: String = null\n  var name: String = null\n  var childArgs: ArrayBuffer[String] = new ArrayBuffer[String]()\n  var jars: String = null\n  var packages: String = null\n  var repositories: String = null\n  var ivyRepoPath: String = null\n  var packagesExclusions: String = null\n  var verbose: Boolean = false\n  var isPython: Boolean = false\n  var pyFiles: String = null\n  var isR: Boolean = false\n  var action: SparkSubmitAction = null\n  val sparkProperties: HashMap[String, String] = new HashMap[String, String]()\n  var proxyUser: String = null\n  var principal: String = null\n  var keytab: String = null\n  // Standalone cluster mode only\n  var supervise: Boolean = false\n  var driverCores: String = null\n  var submissionToKill: String = null\n  var submissionToRequestStatusFor: String = null\n  var useRest: Boolean = true // used internally\n  \n  // Set parameters from command line arguments\n  try {\n    parse(args.asJava)\n  } catch {\n    case e: IllegalArgumentException =>\n      SparkSubmit.printErrorAndExit(e.getMessage())\n  }\n  \n  // Populate `sparkProperties` map from properties file\n  mergeDefaultSparkProperties()\n  \n  // Remove keys that don't start with \"spark.\" from `sparkProperties`.\n  ignoreNonSparkProperties()\n  \n  // Use `sparkProperties` map along with env vars to fill in any missing parameters\n  loadEnvironmentArguments()\n\n  validateArguments()\n```\n\n**Priority**: code > spark-submit options > spark-defaults.conf > spark-env.sh > default\n\n### Links\n\n* [Spark Configuration](http://spark.apache.org/docs/latest/configuration.html)\n\n* [[源码剖析]Spark读取配置](https://www.jianshu.com/p/f86f7b2e8515)\n\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Configuration](http://blog.hyperj.net/2018/01/2018-01-26-spark-configuration/)","tags":["HyperJ"],"categories":["Spark"]},{"title":"Spark Serialization & Compression","url":"%2F2018%2F01%2F2018-01-25-spark-serialization-and-compression%2F","content":"\n### Serialization\n\n* Serializer\n\n#### Java Serialization\n\n* JavaSerializer\n\n* SerializerInstance(JavaSerializerInstance)\n\n* JavaSerializationStream, JavaDeserializationStream\n\n#### Kryo serialization\n\n* KryoSerializer\n\n* SerializerInstance(KryoSerializerInstance)\n\n* JavaIterableWrapperSerializer, KryoInputObjectInputBridge, KryoOutputObjectOutputBridge\n\n* KryoSerializationStream, KryoDeserializationStream\n\n### Compression\n\n* CompressionCodec\n\n* compressedOutputStream, compressedInputStream\n\n#### lz4\n\n* LZ4CompressionCodec\n\n#### lzf\n\n* LZFCompressionCodec\n\n#### snappy\n\n* SnappyCompressionCodec\n\n#### zstd\n\n* ZStdCompressionCodec\n\n### Links\n\n* [Spark Configuration - Compression and Serialization](http://spark.apache.org/docs/latest/configuration.html#compression-and-serialization)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Serialization & Compression](http://blog.hyperj.net/2018/01/2018-01-25-spark-serialization-and-compression/2018-01-25-spark-serialization-and-compression.md)","tags":["Serialization"],"categories":["Spark"]},{"title":"Spark Shared Variables","url":"%2F2018%2F01%2F2018-01-24-spark-shared-variables%2F","content":"\n### Concept\n\n### Broadcast\n\nBroadcast variables allow the programmer to keep a read-only variable cached on each machine rather than shipping a copy of it with tasks.\n\n#### Broadcast(TorrentBroadcast)\n\n* unpersist(TorrentBroadcast.unpersist(id, removeFromDriver = flase, blocking = flase))\n\n* destroy(TorrentBroadcast.unpersist(id, removeFromDriver = true, blocking = true)) \n\n#### BroadcastFactory(TorrentBroadcastFactory)\n\n* BlockManager\n\n* BroadcastManager -> BroadcastFactory(TorrentBroadcastFactory)#newBroadcast\n\n### Accumulators\n\n#### AccumulatorV2\n\nAccumulatorV2 parameterized class represents an accumulator that accumulates IN values to produce OUT result.\n\n* AccumulatorMetadata\n\n* AccumulatorContext\n\n* LongAccumulator, DoubleAccumulator, CollectionAccumulator\n\n* isZero, copy, reset, add, merge, value\n\n> To be on the safe side, always use accumulators inside actions ONLY.\n\n### Links\n\n* [Broadcast](https://spark-internals.books.yourtion.com/markdown/7-Broadcast.html)\n* [AccumulatorV2](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-accumulators.html)\n* [Spark Accumulators Explained: Apache Spark](https://www.edureka.co/blog/spark-accumulators-explained)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Shared Variables](http://blog.hyperj.net/2018/01/2018-01-24-spark-shared-variables/)","tags":["AccumulatorV2"],"categories":["Spark"]},{"title":"Spark Shuffle","url":"%2F2018%2F01%2F2018-01-23-spark-shuffle%2F","content":"\n### Concept\n\n* Task(ShuffleMapTask, ResultTask)\n\n### Shuffle Write\n\n* ShuffleMapTask#runTask -> ShuffleManager(SortShuffleManager)#getWriter -> ShuffleWriter(SortShuffleWriter, UnsafeShuffleWriter)#write\n\n* ShuffleWriter\n\n   SortShuffleWriter(ExternalSorter, Aggregator, ExternalAppendOnlyMap)\n\n   UnsafeShuffleWriter(ShuffleExternalSorter)\n\n### Shuffle Read\n\n* ShuffledRDD#compute -> ShuffleManager(SortShuffleManager)#getReader -> ShuffleReader(BlockStoreShuffleReader)#read\n\n* BlockStoreShuffleReader(ExternalSorter, Aggregator, ExternalAppendOnlyMap)\n\n### Links\n\n* [Spark Architecture: Shuffle](https://0x0fff.com/spark-architecture-shuffle/)\n* [Shuffle 过程](https://spark-internals.books.yourtion.com/markdown/4-shuffleDetails.html)\n* [详细探究Spark的shuffle实现](http://jerryshao.me/2014/01/04/spark-shuffle-detail-investigation/)\n* [Spark Shuffle的技术演进](https://www.jianshu.com/p/4c5c2e535da5)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Shuffle](http://blog.hyperj.net/2018/01/2018-01-23-spark-shuffle/)","tags":["Shuffle"],"categories":["Spark"]},{"title":"Spark Storage","url":"%2F2018%2F01%2F2018-01-22-spark-storage%2F","content":"\n### Concept\n\n#### Stores\n\n* Memory, Disk, and Off-Heap()\n\n#### Levels\n\n* persist(mark), cache(StorageLevel.MEMORY_ONLY)\n\n```scala\nclass StorageLevel private(\n    private var _useDisk: Boolean,\n    private var _useMemory: Boolean,\n    private var _useOffHeap: Boolean,\n    private var _deserialized: Boolean,\n    private var _replication: Int = 1)\n  extends Externalizable {\n\n  // TODO: Also add fields for caching priority, dataset ID, and flushing.\n  private def this(flags: Int, replication: Int) {\n    this((flags & 8) != 0, (flags & 4) != 0, (flags & 2) != 0, (flags & 1) != 0, replication)\n  }\n\n  def this() = this(false, true, false, false)  // For deserialization\n\n  def useDisk: Boolean = _useDisk\n  def useMemory: Boolean = _useMemory\n  def useOffHeap: Boolean = _useOffHeap\n  def deserialized: Boolean = _deserialized\n  def replication: Int = _replication\n  \n  // ...\n}\n\nobject StorageLevel {\n  val NONE = new StorageLevel(false, false, false, false)\n  val DISK_ONLY = new StorageLevel(true, false, false, false)\n  val DISK_ONLY_2 = new StorageLevel(true, false, false, false, 2)\n  val MEMORY_ONLY = new StorageLevel(false, true, false, true)\n  val MEMORY_ONLY_2 = new StorageLevel(false, true, false, true, 2)\n  val MEMORY_ONLY_SER = new StorageLevel(false, true, false, false)\n  val MEMORY_ONLY_SER_2 = new StorageLevel(false, true, false, false, 2)\n  val MEMORY_AND_DISK = new StorageLevel(true, true, false, true)\n  val MEMORY_AND_DISK_2 = new StorageLevel(true, true, false, true, 2)\n  val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false, false)\n  val MEMORY_AND_DISK_SER_2 = new StorageLevel(true, true, false, false, 2)\n  val OFF_HEAP = new StorageLevel(true, true, true, false, 1)\n\n  // ...\n}\n\n```\n\n#### Master/Slave\n\n* Executor(Driver): SparkContext -> SparkEnv -> BlockTransferService(NettyBlockTransferService), BlockManagerMaster(BlockManagerMasterEndpoint), BlockManager\n\n#### RPC\n\n### Update(Read/Write)\n\nRDD -> BlockManager -> Remote: BlockTransferService(fetch/upload), Local: MemoryStore/DiskStore(get/put)\n\n### MemoryManager\n\n* acquire/release, get/set\n\n* MemoryMode(ON_HEAP, OFF_HEAP)\n\n#### StaticMemoryManager\n\n* MaxStorageMemory = systemMaxMemory * spark.storage.memoryFraction * spark.storage.safetyFraction\n\n* MaxExecutionMemory = systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction\n\n#### UnifiedMemoryManager\n\n* MemoryPool(StorageMemoryPool, ExecutionMemoryPool)\n\n* acquireExecutionMemory, acquireStorageMemory, acquireUnrollMemory\n\n* getMaxMemory = (systemMemory - reservedMemory) * spark.memory.fraction\n\n### Links\n\n* [Apache Spark 内存管理详解](https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/)\n* [Spark Storage ① - Spark Storage 模块整体架构](https://www.jianshu.com/p/730eed6a98d2)\n* [Spark Storage ② - BlockManager 的创建与注册](https://www.jianshu.com/p/356db9726d04)\n* [Spark Storage ③ - Master 与 Slave 之间的消息传递与时机](https://www.jianshu.com/p/7a7ff2c19635)\n* [Spark Storage ④ - 存储执行类介绍（DiskBlockManager、DiskStore、MemoryStore）](https://www.jianshu.com/p/19e36d0781b5)\n* [Spark 内存管理的前世今生（上）](https://www.jianshu.com/p/999ef21dffe8)\n* [Spark 内存管理的前世今生（下）](https://www.jianshu.com/p/211505ae3fb3)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Storage](http://blog.hyperj.net/2018/01/2018-01-22-spark-storage/)","tags":["Storage"],"categories":["Spark"]},{"title":"Spark Network","url":"%2F2018%2F01%2F2018-01-21-spark-network%2F","content":"\n### Role\n\nMaster, Worker, Client, Driver, Executor\n\n### Concept\n\n#### RpcCallContext\n\n* NettyRpcCallContext(LocalNettyRpcCallContext, RemoteNettyRpcCallContext)\n\n#### RpcEnv\n\n* NettyRpcEnv(NettyRpcHandler)\n\n* RpcEnvConfig(SparkConf)\n\n* RpcEnvFileServer(NettyStreamManager<jars, files, directories>)\n\n#### RpcEnvFactory\n\n* NettyRpcEnvFactory\n\n#### RpcEndpoint\n\n* ThreadSafeRpcEndpoint(Master, Worker, ClientEndpoint, DriverEndpoint, HeartbeatReceiver, BlockManagerMasterEndpoint, BlockManagerSlaveEndpoint)\n\n* RpcEndpointVerifier\n\n#### RpcEndpointRef\n\n* NettyRpcEndpointRef\n\n#### Dispatcher\n\n* EndpointData\n\n* MessageLoop\n\n#### Inbox\n\n* InboxMessage\n\n#### Outbox\n\n* OutboxMessage\n\n### Others\n\n* Message, MessageEncoder, MessageDecoder\n* RpcAddress, RpcTimeout\n* Reactor, Proactor\n\n### Links\n\n* [Spark RPC](https://smilekevinsovi.github.io/julyhou24/spark/2016/06/19/Spark-RPC.html)\n* [深入解析Spark中的RPC](https://zhuanlan.zhihu.com/p/28893155)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Network](http://blog.hyperj.net/2018/01/2018-01-21-spark-network/)","tags":["Network"],"categories":["Spark"]},{"title":"Spark RDD Characteristics","url":"%2F2018%2F01%2F2018-01-20-spark-rdd-characteristics%2F","content":"\n### RDD\n\nA Resilient Distributed Dataset (RDD), the basic abstraction in Spark. Represents an immutable, partitioned collection of elements that can be operated on in parallel. This class contains the basic operations available on all RDDs, such as `map`, `filter`, and `persist`. \n\n>  Internally, each RDD is characterized by five main properties:\n> \n>   - A list of partitions\n>   - A function for computing each split\n>   - A list of dependencies on other RDDs\n>   - Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)\n>   - Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)\n\n### Operations\n\n#### Creation Operation\n\n#### Transformation Operation\n\n#### Storage Operation\n\nLRU(Least Recently Used)\n\n* Cache\n\n* Persist(unPersist/destroy)\n\n* Checkpoint\n\n#### Action Operation\n\n### Dependencies\n\n#### Narrow Dependencies\n\n#### Shuffle/Wide Dependencies\n\n### Characteristics\n\n#### Partitions\n\n#### PreferredLocations\n\n#### Dependencies\n\n#### Iterator\n\n#### Partitioner\n\n### Stage\n\n#### ResultStage\n\n#### ShuffleMapStage\n\n### Others\n\n* DAG\n\n* Lineage\n\n* Shared Variables\n\n   Broadcast Variables\n   Accumulators\n\n### Links\n\n* [Resilient Distributed Datasets: A Fault-Tolerant Abstraction for\n   In-Memory Cluster Computing](http://people.csail.mit.edu/matei/papers/2012/nsdi_spark.pdf)\n* [Spark Documentation](http://spark.apache.org/docs/latest/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark RDD Characteristics](http://blog.hyperj.net/2018/01/2018-01-20-spark-rdd-characteristics/)","tags":["RDD"],"categories":["Spark"]},{"title":"Data Modeling Paradigm","url":"%2F2018%2F01%2F2018-01-19-data-model-paradigm%2F","content":"\n### Concept\n\n* Business Modeling\n\n* Domain Modeling\n\n* Logical Modeling\n\n* Physical Modeling\n\n### Schema\n\n* Star Schema\n\n* Snowflake Schema\n\n* Fact Constellations Schema\n\n### Paradigm\n\n* Entity-relationship(E-R) Modeling\n\n   3NF, Entity\n\n* Dimension Modeling\n\n   Fact, Dimension\n\n* Data Vault Modeling\n\n   Hub, Link, Satellite\n\n* Anchor Modeling\n\n   Anchors, Attributes, Ties, Knots\n\n### Others\n\n* ETL\n* OLAP, OLTP\n* BI\n\n### Links\n\n* [浅谈数据仓库建设中的数据建模方法](https://www.ibm.com/developerworks/cn/data/library/techarticles/dm-0803zhousb/)\n* [数据仓库](http://www.cnblogs.com/muchen/category/794750.html) \n* [数据仓库之数据模型](http://lxw1234.com/archives/2018/01/890.htm)\n* [数据仓库中的模型设计](http://www.mdjs.info/2017/09/29/data-warehouse/data-model/)\n* [详解维度建模](http://www.mdjs.info/2017/01/05/data-warehouse/dimensona-modeling/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Modeling Paradigm](http://blog.hyperj.net/2018/01/2018-01-19-data-model-paradigm/)","tags":["Paradigm"],"categories":["DataWarehouse"]},{"title":"Data Table","url":"%2F2018%2F01%2F2018-01-18-data-table%2F","content":"\n### Keys\n\n* Natural Key（自然键）\n* Surrogate Key（代理键）\n* Primary Key（主键）\n* Foreign Key（外键）\n* Composite key（组合键）\n* Candidate key（候选键）\n* Alternate key（辅助键）\n\n### Tables\n\n* Integration Table（集成表）\n\n* Dimension Table（维度表）\n\n* Fact Table（事实表）\n\n* Bridge (Fact) Table（桥接表）\n\n* Aggregate (Fact) Table（聚集表）\n\n* Snapshot (Fact) Table（快照表）\n\n* Zipper (Fact) Table（拉链表）\n\n* Related (Fact) Table（连接表）\n\n* Wide Table（宽表）\n\n* Temporary Table（临时表）\n\n   With Table\n   Memory Table\n   Replicated Table\n   \n* External Table（外部表）\n\n### Others\n\n* Index\n* View\n* Data Types(Numeric Types, Date/Time Types, String Types, Misc Types, Complex Types<Array, Map, Struct, Union>)\n* Partitioned\n* Buckets - Clustered[Sorted] - Round Robin, Hash Distributed \n* Skewed\n* Row Format\n* File Format(Orc, Parquet, Avro)\n* Flat\n* Relation\n* Cardinality\n\n### Links\n\n* [Choosing a Primary Key: Natural or Surrogate?](http://www.agiledata.org/essays/keys.html)\n* [Kimball Techniques](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/)\n* [Hive Data Definition Language](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Table](http://blog.hyperj.net/2018/01/2018-01-18-data-table/)","tags":["Table"],"categories":["DataWarehouse"]},{"title":"Data Layer","url":"%2F2018%2F01%2F2018-01-17-data-layer%2F","content":"\n### Concept\n\n#### Source\n\n#### Stage/Buffer\n\n#### SOR(System Of Record)\n\n#### ODS(Operational Data Store)\n\n#### DW(Data Warehouse)\n\n* 维度（Dimension）\n* 字典（Dict）\n* 基数（Cardinality）\n* 度量（Measure）\n* 事实（Fact）\n* 实体（Entity）\n* 指标（Index）\n* 粒度（Granularity）\n* 标准（Standard）\n* 明细（Detail）\n* 计算（Calculate）\n* 聚合（Aggregate）\n* 汇总（Summary）\n* 主题（Topic/Theme）\n* 配置（Config）\n\n##### DWD(Data Warehouse Detail)\n\n##### DIM(Dimension)\n\n##### DWB(Data Warehouse Basis)\n\n##### DWS(Data Warehouse Service)\n\n##### TMP(Temporary)\n\n#### DM(Data Mart)\n\n#### Cude\n\n* OLAP(Online Analytical Process)\n   MOLAP(Multidimensional)\n   ROLAP(Relational)\n   HOLAP(Hybrid)\n* Segment\n* Hierarchy\n* Level\n* Memeber\n* Drill-down\n* Roll-up\n* Slice\n* Dice\n* Pivot\n\n#### APP(Application)\n\n#### ETL(Extract Transform Load)\n\n#### Other\n\n* BI（Business Intelligence）\n* Meta Data\n* Data Manegement\n\n### Links\n\n* [如何优雅地设计数据分层](http://dantezhao.com/2017/05/14/data-warehouse/data-layer/)\n* [数据仓库规范](http://www.cnblogs.com/HondaHsu/p/5314176.html)\n* [IBM数据仓库解决方案(简)](https://wenku.baidu.com/view/8a3d82257375a417866f8f16.html)\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Layer](http://blog.hyperj.net/2018/01/2018-01-17-data-layer/)","tags":["Area"],"categories":["DataWarehouse"]},{"title":"Flink Windows","url":"%2F2018%2F01%2F2018-01-16-flink-window%2F","content":"\n### Lifecycle\n\n### Keyed vs Non-Keyed\n\n### Assigners\n\n#### Tumbling Windows\n\n#### Sliding Windows\n\n#### Session Windows\n\n#### Global Windows\n\n### Window Functions\n\n#### ReduceFunction\n\n#### AggregateFunction\n\n#### FoldFunction\n\n#### ProcessWindowFunction\n\n### Triggers\n\n### Evictors\n\n### Links\n\n* [Flink Windows](https://ci.apache.org/projects/flink/flink-docs-master/dev/stream/operators/windows.html)\n* [Flink 原理与实现：Window 机制](http://wuchong.me/blog/2016/05/25/flink-internals-window-mechanism/)\n* [Flink 原理与实现：Session Window](http://wuchong.me/blog/2016/06/06/flink-internals-session-window/)\n* [Apache Flink源码解析之stream-window](http://vinoyang.com/2016/05/10/flink-stream-window/)\n* [深入理解Apache Flink核心技术](http://geek.csdn.net/news/detail/56272)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Flink Windows](http://blog.hyperj.net/2018/01/2018-01-16-flink-windows/)","tags":["Window"],"categories":["Flink"]},{"title":"卫星系统——酒店后端全链路日志收集工具介绍","url":"%2F2018%2F01%2F2018-01-15-satellite-system%2F","content":"\n# 背景\n\n随着酒店业务的高速发展，我们为用户、商家提供的服务越来越精细，系统服务化程度、复杂度也逐渐上升。微服务化虽然能够很好地解决问题，但也有副作用，比如，问题定位。\n\n![full_link](/assets/images/2018/01/15/satellite-system/full_link.jpeg)\n\n每次问题定位都需要从源头开始找同事帮我人肉查日志，举一个简单的例子：\n\n“这个详情页的价格是怎么算出来的?”\n\n一次用户酒店可订空房页（POI详情页）访问，流量最多需要经过73个服务节点。查问题的时候需要先后找4~5个关键节点的同学帮我们登录十多个不同节点的机器，查询具体的日志，沟通成本极大，效率很低。\n\n为了解决这个问题，基础架构的同学提供了MTrace（详情可以参考技术博客：《[分布式会话跟踪系统架构设计与实践](https://tech.meituan.com/mt-mtrace.html)》）协助业务方排查长链路问题。\n\n但是与此同时，还有许多不确定性因素，使问题排查过程更加艰难，甚至无果而终：\n\n1. 各服务化节点存储日志的时间长度不一致；\n2. 有的服务节点，因为QPS过高，只能不打或者随机打印日志，会导致最终查问题的时候，线索因为没日志断掉；\n3. 有的服务节点，使用了异步逻辑（线程池、Hystrix、异步RPC等）导致日志中缺失Trace ID，无法关联在一起；\n4. 各服务节点的采样率不一样，链路数据的上报率也是随机性的，线索容易断掉；\n5. MTrace上只有链路信息，没有关联各服务节点的日志信息；\n6. [动态扩容](https://tech.meituan.com/hulk-scheduler-introduction.html)节点上的日志，缩容后无法找到。\n\n总结起来如图所示：\n\n![trace_summury](/assets/images/2018/01/15/satellite-system/trace_summery.png)\n\n# 目标\n\n我们的核心诉求有两个：\n\n1. 根据用户行为快速定位到具体的Trace ID，继而查询到这次服务调用链路上所有节点的日志；\n2. 查询的实时性要能做到准实时（秒级输出），相关链路日志要在独立外部存储系统中保存半年以上。\n\n然后我们对诉求做了进一步的拆分：\n\n1. 全量打日志不现实，需要选择性打，打价值最高部分的日志；\n2. 链路数据需要全服务节点都上传，避免因为异步化等原因造成链路数据中断不上传；\n3. 接入方式尽量简单，避免所有服务节点都需要修改具体业务代码来接入。最好是能通过日志拦截的方式，其它保持透明；\n4. 日志格式化，该有的字段（AppKey、hostname、IP、timestamp等）不需要业务RD反复输入，自动补齐；\n5. 在不阻塞原有业务操作的情况下，做到准实时展示链路、日志；\n6. 链路数据和日志数据存储，不依赖各服务节点，需要在独立的存储系统上存储半年以上。\n\n# 系统\n\n搞清了核心诉求后，我们针对性地做了许多调研，最终定了一个系统的整体设计方案，这就是目前已经上线并实践已久的美团点评酒店「**卫星系统**」。\n\n下面，我们就来对系统做详细介绍，包括一些核心细节点。\n\n## 架构\n\n如下图所示，卫星系统从横向分为链路和日志两个部分。\n\n![现状](/assets/images/2018/01/15/satellite-system/article-jiagou.png)\n\n<center>图2 全链路日志系统整体架构</center>\n\n链路部分是以MTrace为基础，用支持超时fallback下Trace信息传递的Hystrix-Trace插件来覆盖全部场景，保证链路被完整采集。\n\n日志部分在接入端有三大核心步骤，首先是依托于日志拦截组件实现对业务代码零侵入的情况下收集系统中所有日志内容，然后根据统一日志规范对日志进行格式化处理，最后通过基于logcenter日志传输机制实现日志到Kafka的传输。\n\n从纵向又分为：\n\n1. 业务接入层，根据策略采集Trace与业务日志；\n\n2. 数据处理层，通过storm流式处理日志信息；\n\n3. 数据存储层，用于支持实时查询的Squirrel（美团点评Redis集群）与持久存储的ES（ElasticSearch），以及面向用户的展示层。\n\n### 日志采样方案\n\n接入端是所有数据之源，所以方案设计极为关键。要解决的问题有：采集策略、链路完整性保障、日志拦截、日志格式化、日志传输。\n\n有的业务单台机器每天日志总量就有百G以上，更有不少业务因为QPS过高而选择平时不打印日志，只在排查问题时通过动态日志级别调整来临时输出。所以，我们在最初收集日志时必须做出取舍。经过分析，发现在排查问题的时候，绝大多数情况下发起人都是自己人（RD、PM、运营），如果我们只将这些人发起的链路日志记下来，那么目标日志量将会极大减少，由日志量过大而造成的存储时间短、查询时效性差等问题自然得到解决。\n\n所以我们制定了这样的采集策略：\n\n通过在链路入口服务判断发起人是否满足特定人群（住宿事业部员工）来决定是否进行日志采集，将采集标志通过MTrace进行全链路传递。这样就能保证链路上所有节点都能行为一致地去选择是否进行日志上报，保证链路上日志的完整性。\n\n### 日志拦截\n\n作为核心要素的日志，如何进行收集是一个比较棘手的问题。让业务方强制使用我们的接口进行日志输出会带来许多麻烦，一方面会影响业务方原有的日志输出策略；另一方面，系统原有的日志输出点众多，涉及的业务也五花八门，改动一个点很简单，但是全面进行改动难保不会出现未知影响。所以，需要尽可能降低对接入方代码的侵入。\n\n由于目前酒店核心业务已全面接入log4j2，通过研究，发现我们可以注册全局Filter来遍历系统所有日志，这一发现，使我们实现了代码零改动的情况下收集到系统所有日志。\n\n![过滤](/assets/images/2018/01/15/satellite-system/article-filter.png)\n\n<center>图3 基于log4j2 filter机制的日志收集策略</center>\n\n### 日志格式化\n\n业务系统输出的日志格式不一，比如有的没有打印TraceID信息，有的没有打印日志位置信息从而很难进行定位。这主要带来两方面的问题，一方面不利于由人主导的排查分析工作，另一方面也不利于后续的系统优化升级，比如对日志的自动化分析报警等等。\n\n针对这些问题，我们设计了统一日志规范，并由框架完成缺失内容的填充，同时给业务方提供了标准化的日志接口，业务方可以通过该接口定义日志的元数据，为后续支持自动化分析打下基础。\n\n由框架填充统一日志信息这一过程利用到了log4j2的Plugins机制，通过Properties、Lookups、ContextMap实现业务无感知的操作。\n\n![现状](/assets/images/2018/01/15/satellite-system/article-log.png)\n\n<center>图4 通过Plugins机制支持格式化日志属性传递</center>\n\n### 日志处理\n\n我们在最终的日志传输环节利用了日志中心的传输机制，使用日志中心的ScribeAppender实现日志传输至本地agent，然后上报到远端Kafka，这样设计有几点好处：\n\n1. 依赖公司成熟的基础服务相对而言更可靠、更稳定，同时也省去了自己搭建服务、保证服务安全这一过程；\n2. 可以将日志直接转存至日志中心ES做持久化存储，同时支持快速灵活的数据检索；\n3. 可以通过Storm对日志进行流式处理，支持灵活的系统扩展，比如：实时检索、基于日志的实时业务检查、报警等等，为后续系统扩展升级打下基础。\n\n我们的数据处理逻辑全部在Storm进行处理，主要包含日志存储Squirrel（美团点评内部基于Redis Cluster研发的纯内存存储）、实时检索与Trace同步。\n\n目前日志中心ES能保证分钟级别实时性，但是对于RD排查问题还是不够，必须支持秒级别实时性。所以我们选择将特定目标用户的日志直接存入Squirrel，失效时间只有半小时，查询日志时结合ES与Squirrel，这样既满足了秒级别实时性，又保证了日志量不会太大，对Squirrel的压力可以忽略不计。\n\n我们的系统核心数据有链路与日志，链路信息的获取是通过MTrace服务获得，但是MTrace服务对链路数据的保存时间有限，无法满足我们的需求。所以，我们通过延时队列从MTrace获取近期的链路信息进行落地存储，这样就实现了数据的闭环，保证了数据完整性。\n\n### 链路完整性保障\n\nMTrace组件的Trace传递功能基于ThreadLocal，而酒店业务大量使用异步化逻辑（线程池、Hystrix），这样会造成传递信息的损失，破坏链路完整性。\n\n一方面，通过Sonar检查和梳理关键链路，来确保业务方使用类似[transmittable-thread-local](https://github.com/alibaba/transmittable-thread-local)中的`ExecutorServiceTtlWrapper.java`、`ExecutorTtlWrapper.java`的封装，来将ThreadLocal里的Trace信息，也传递到异步线程中（前文提到的MTrace也提供这样的封装）。\n\n另一方面，Hystrix的线程池模式会造成线程变量丢失。为了解决这个问题，MTrace提供了Mtrace Hystrix Support Plugin插件实现跨线程调用时的线程变量传递，但是由于Hystrix有专门的timer线程池来进行超时fallback调用，使得在超时情况下进入fallback逻辑以后的链路信息丢失。\n\n针对这个问题，我们深入研究了Hystrix机制，最终结合Hystrix Command Execution Hook、Hystrix ConcurrencyStrategy、Hystrix Request Context实现了覆盖全场景的Hystrix-Trace插件，保障了链路的完整性。\n\n```java\nHystrixPlugins.getInstance().registerCommandExecutionHook(new HystrixCommandExecutionHook() {\n    @Override\n    public <T> void onStart(HystrixInvokable<T> commandInstance) {\n        // 执行command之前将trace信息保存至hystrix上下文，实现超时子线程的trace传递\n        if (!HystrixRequestContext.isCurrentThreadInitialized()) {\n            HystrixRequestContext.initializeContext();\n        }\n        spanVariable.set(Tracer.getServerSpan());\n    }\n\n    @Override\n    public <T> Exception onError(HystrixInvokable<T> commandInstance, HystrixRuntimeException.FailureType failureType, Exception e) {\n        // 执行结束后清空hystrix上下文信息\n        HystrixRequestContext context = HystrixRequestContext.getContextForCurrentThread();\n        if (context != null) {\n            context.shutdown();\n        }\n        return e;\n    }\n\n    @Override\n    public <T> void onSuccess(HystrixInvokable<T> commandInstance) {\n        // 执行结束后清空hystrix上下文信息\n        HystrixRequestContext context = HystrixRequestContext.getContextForCurrentThread();\n        if (context != null) {\n            context.shutdown();\n        }\n    }\n});\n\nHystrixPlugins.getInstance().registerConcurrencyStrategy(new HystrixConcurrencyStrategy() {\n    @Override\n    public <T> Callable<T> wrapCallable(Callable<T> callable) {\n        // 通过自定义callable保存trace信息\n        return WithTraceCallable.get(callable);\n    }\n});\n```\n\n## 效果展示\n\n比如以排查一次用户点击某POI详情页的TraceID为例子：\n\n我们可以看到他在MTrace中的调用链路是这样的：\n\n![mtrace](/assets/images/2018/01/15/satellite-system/mtrace.png)\n\n在卫星系统中，展示为如下效果：\n\n![satellite](/assets/images/2018/01/15/satellite-system/satellite.png)\n\n可见，在保留了链路数据的基础上，系统还将全链路节点日志聚合到了一起，提升了排查效率。\n\n# 后续规划\n\n目前，系统还处于初级阶段，主要用来解决RD在排查问题时的两大痛点：日志信息的不完整与太分散，现在已经满足了这一需求。但是，全链路日志系统能做的不止这些，后续的主要规划有如下几方面：\n\n1. 支持多链路日志关联搜索，比如一次列表页刷新与后续的详情页展示，虽然链路是多个但是实际处在一个关联的场景中。支持关联搜索就可以可以将日志排查目标从单个动作维度扩展到多动作组成的场景维度。\n2. 支持业务方自定义策略规则进行基于日志的自动化业务正确性检查，如果检查出问题可以直接将详细信息通知相关人员，实现实时监测日志、实时发现问题、实时通知到位，免去人工费时费力的低效劳动。\n\n# 作者简介\n\n* 亚辉，2015年加入美团点评，就职于美团点评酒旅事业群技术研发部酒店后台研发组。\n\n* 曾鋆，2013年加入美团点评，就职于美团点评酒旅事业群技术研发部酒店后台研发组。\n\n---\n\n* Author：亚辉 曾鋆\n* Source：[美团点评技术团队](http://tech.meituan.com)\n* Link：[卫星系统——酒店后端全链路日志收集工具介绍](https://tech.meituan.com/satellite_system.html)","tags":["Satellite System"],"categories":["Log"]},{"title":"Metadata","url":"%2F2018%2F01%2F2018-01-15-metadata%2F","content":"\n### Concept\n  \n* 元数据（Meta Data）\n  \n用于描述数据的数据，描述数据及其环境数据，包括：业务元数据、技术元数据、管理元数据\n\n* 元模型（Meta Model）\n  \n描述元数据的结构和关系的数据模型，是用来描述元数据的模型\n\n* 元元模型（Meta-meta Model）\n  \n元模型的模型，也被称为本体（Ontology），是模型驱动的元数据集成体系结构的基础\n \n* 关系（Relation）\n  \n**依赖关系（Dependence）**\n  \n   对于两个相对独立的元数据，当一个元数据引用了另一个元数据时，这两个元数据之间主要体现为依赖关系\n  \n**组合关系（Combination）**\n  \n   一种强关联关系，是整体和个体的关系，且整体和个体分属不同层，且整体的对象负责代表个体对象的生命周期\n\n* 分析（Analytics）\n\n**影响分析（Impact）**\n  \n   指为向用户直观展示元数据之间的流向关系而进行的以目标为起点往后分析\n  \n**血统分析（Lineage）**\n  \n   指为向用户直观展示元数据之间的流向关系而进行的以目标为起点往前分析\n  \n**全链分析（Link）**\n  \n   指为向用户直观展示元数据之间的流向关系而进行的以目标为起点往前后总体分析\n\n### Other\n\n* CWM（公共仓库元模型）\n* Graph（图谱）\n* Quality（质量）\n* Audit（审计）\n* Collection（采集）\n* Schedule（调度）\n* Adapter（适配器）\n* Template（模版）\n* Mapping（映射）\n* Model（模型）\n* Lifecycle（生命周期）\n* Version（版本）\n* Monitor（监控）\n* Statistics（统计）\n\n### Links\n\n* [元数据集成体系结构](https://www.ibm.com/developerworks/cn/data/library/bd-1503bigdatagovernance2/index.html)\n* [DMBOK：元数据管理](http://www.cnblogs.com/zhoujg/archive/2011/12/26/2301661.html)\n* [THE COMMON WAREHOUSE METAMODEL SPECIFICATION](http://www.omg.org/spec/CWM/)\n* [Common warehouse metamodel](https://en.wikipedia.org/wiki/Common_warehouse_metamodel)\n* [MetaCube Manual](http://doc.primeton.com/display/MetaCube62)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Metadata](http://blog.hyperj.net/2018/01/2018-01-15-metadata/)","tags":["MetaModel"],"categories":["Metadata"]},{"title":"Data Analytics Models","url":"%2F2018%2F01%2F2018-01-14-data-analytics-models%2F","content":"\n### Base Data Analytics Models\n\n#### Event Analysis Model\n\n* Who、When、Where、What、How\n* OLAP\n   \n#### Funnel Analysis Model\n   \n#### Retained Analysis Model\n   \n#### Distribution Analysis Model\n   \n#### Path Analysis Model\n   \n#### Sequence Analysis Model\n   \n#### Group Analysis Model\n   \n#### Attribute analysis Model\n\n### Links\n\n* [Sensors Analytics Manual](https://www.sensorsdata.cn/manual/use_guide.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Analytics Models](http://blog.hyperj.net/2018/01/2018-01-14-data-analytics-models/)","tags":["Models"],"categories":["Analytics"]},{"title":"Kylin Optimization","url":"%2F2018%2F01%2F2018-01-13-kylin-optimization%2F","content":"\n### Cube Optimization\n\n#### Aggregation Group\n\n#### TopN\n\n#### Count Distinct\n\n#### Count Distinct(Precise)\n\n### Dimension Optimization\n\n#### Aggregation Group（聚合组）\n\n#### Hierarchy Dimension（层级维度）\n\n#### Mandatory Dimension（必要维度）\n\n#### Derived Dimension（派生维度）\n\n#### Joint Dimension（联合维度）\n\n#### Extended Dimension（扩展维度）\n\n#### Cardinality Dimension（基数维度）\n\n### Links\n\n* [Kylin Docs](http://kylin.apache.org/docs21/)\n* [KAP Manual](http://docs.kyligence.io/v2.4/en/)\n* [Kylin Category](http://lxw1234.com/archives/category/kylin)\n* [Apache Kylin 维度优化指南](https://blog.bcmeng.com/post/kylin-dimension.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Kylin Optimization](http://blog.hyperj.net/2018/01/2018-01-13-kylin-optimization/)","tags":["Kylin"],"categories":["Optimization"]},{"title":"Data Masking","url":"%2F2018%2F01%2F2018-01-12-data-masking%2F","content":"\n### Concept\n\nData involved in any data-masking or obfuscation must remain meaningful at several levels:\n\n* The data must remain meaningful for the application logic. \n* The data must undergo enough changes so that it is not obvious that the masked data is from a source of production data.\n\n#### Keyword\n\n* PII: Personally Identifiable Information.\n* EI: explicit identifiers.\n* QI: Quasi-identifiers. \n* SD: Sensitive data.\n* NSD: Nonsensitive data.\n\n#### Algorithm\n\n* Randomization\n* Generalization\n* K-Anonimization\n* L-Diversity\n* T-Closeness\n\n#### Static data masking (SDM)\n\ndata at rest.\n\n#### Dynamic data masking (DDM)\n\ndata in transit.\n\n### Techniques\n\n* Substitution\n\n* Shuffling\n\n* Number and date variance\n\n* Encryption\n \n* Nulling out or deletion\n\n* Masking out\n\n* Additional complex rules\n\n### Other\n\n* Management\n* Rule\n* Audit\n\n### Links \n\n* [Data masking](https://en.wikipedia.org/wiki/Data_masking)\n* [Static Versus Dynamic Data Masking](https://www.imperva.com/blog/2017/07/static-versus-dynamic-data-masking/)\n* [美团数据仓库-数据脱敏](http://blog.hyperj.net/2014/2014-04-08-data-mask/)\n* [大数据与数据脱敏](https://zhuanlan.zhihu.com/p/20824603)\n* [Data privacy、Principle and Practices精简（一）](http://blog.csdn.net/sculvlv/article/details/70624625)\n* [Data privacy、Principle and Practices精简（二）](http://blog.csdn.net/sculvlv/article/details/70791169)\n* [k-anonimity、l-diversity 和 t-closeness](http://blog.csdn.net/sculvlv/article/details/71077689)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Masking](http://blog.hyperj.net/2018/01/2018-01-12-data-masking/)\n","tags":["HyperJ"],"categories":["DataMasking"]},{"title":"Slowly Changing Dimensions (SCDs)","url":"%2F2018%2F01%2F2018-01-11-slowly-changing-dimensions%2F","content":"\n### Concept\n\nDimensions in data management and data warehousing contain relatively static data about such entities as geographical locations, customers, or products. Data captured by Slowly Changing Dimensions (SCDs) change slowly but unpredictably, rather than according to a regular schedule.\n\n### Type\n\n![Slowly Changing Dimensions (SCDs)](/assets/images/2018/01/11/slowly-changing-dimensions/slowly-changing-dimensions.png)\n\n#### Type 0: Retain Original\n\nAs Date/Area Dimension Attributes\n\n#### Type 1: Overwritten\n\n#### Type 2: Add New Row\n\n#### Type 3: Add New Attribute\n\n#### Type 4: Add Mini-Dimension\n\n#### Type 5: Add Mini-Dimension and Type 1 Outrigger\n\n#### Type 6: Add Type 1 Attributes to Type 2 Dimension\n\n#### Type 7: Dual Type 1 and Type 2 Dimensions\n\n#### Other\n\n* History / Snapshot / Zipper Table\n\n### Links \n\n* [Slowly changing dimension](https://en.wikipedia.org/wiki/Slowly_changing_dimension)\n* [Slowly Changing Dimensions Are Not Always as Easy as 1, 2, 3](https://www.kimballgroup.com/2005/03/slowly-changing-dimensions-are-not-always-as-easy-as-1-2-3/)\n* [ Design Tip #152 Slowly Changing Dimension Types 0, 4, 5, 6 and 7](https://www.kimballgroup.com/2013/02/design-tip-152-slowly-changing-dimension-types-0-4-5-6-7/)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Slowly Changing Dimensions (SCDs)](http://blog.hyperj.net/2018/01/2018-01-11-slowly-changing-dimensions/)\n","tags":["SCD"],"categories":["DataWarehouse"]},{"title":"A/B Testing","url":"%2F2018%2F01%2F2018-01-10-abtesting%2F","content":"\n### Concept\n\n#### APP, Page, Module, Layer\n\n#### Bucket\n\n* Benchmark\n* Fallback\n* Parent\n* Isolation area, parallel area\n\n#### Flow & Strategy\n\n* Orthogonal experiment\n* Mutual exclusion experiment\n* Correlation experiment\n\n#### Task\n\n* Management\n* Mapping\n\n#### Other\n\n* Gray Release\n* Client & Server\n* White List\n* IP/UUID/CityID\n* App Version\n* Period\n* Platform\n\n### Hypothesis Testing\n\n### Links\n\n* [A/B testing](https://en.wikipedia.org/wiki/A/B_testing)\n* [Twitter的A/B测试实践（一）：为什么要测试以及测试的意义](http://www.infoq.com/cn/articles/twitter-ab-test-practise-part01)\n* [Twitter的A/B测试实践（二）：技术概述](http://www.infoq.com/cn/articles/twitter-ab-test-practise-part02)\n* [Twitter的A/B测试实践（三）：检测和避免 A/B Test中 bucket不平衡问题](http://www.infoq.com/cn/articles/twitter-ab-test-practise-part03)\n* [Twitter的A/B测试实践（四）：A/B Test中使用多个控制的启示](http://www.infoq.com/cn/articles/twitter-ab-test-practise-part04)\n* [谈谈A/B Test](http://blog.csdn.net/u012160689/article/details/16343875)\n* [AB测试和灰度发布平台架构设计和实践](http://topic.it168.com/factory/adc2013/doc/oucheng.pdf)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[A/B Testing](http://blog.hyperj.net/2018/01/2018-01-10-abtesting/)","tags":["Bucket Testing"],"categories":["Testing"]},{"title":"Data Development & Testing","url":"%2F2018%2F01%2F2018-01-09-data-development-testing%2F","content":"\n### Workflow Item\n\n#### Check the amount of data\n\n#### Check the diff of data\n\n#### Check the specification & legality of data\n\n#### Check the type of data\n\n#### Check the distribution of data\n\n#### Check the logic of business & data\n\n#### Sampling check\n\n#### Performance check\n\n### Other\n\n* Requirement\n* Business\n* Data caliber\n* Data quality\n* Data granularity\n* Benchmark\n* Review\n* Rerun\n* Update\n* Rollback\n* Important\n* Impact on upstream & downstream data.\n\n### Table Case\n\n| No. | Case | Type | Step | Reason | Status | Result | Summary |\n| --- | ---- | ---- | ---- | ------ | ------ | ------ | ------- |\n| #c1 | desc | logic | 1. 2. 3. 4. | logic | fixed | result | summary |\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Data Development & Testing](http://blog.hyperj.net/2018/01/2018-01-09-data-development-testing/)\n","tags":["Testing"],"categories":["DataWarehouse"]},{"title":"Hive Optimization","url":"%2F2018%2F01%2F2018-01-08-hive-optimization%2F","content":"\n### Hive\n\n#### Configuration Properties\n\nMore [Hive Configuration Properties](https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties)\n\n##### dynamic partition\n\n###### hive.exec.dynamic.partition\n\n    Default Value: false prior to Hive 0.9.0; true in Hive 0.9.0 and later (HIVE-2835)\n    Added In: Hive 0.6.0\n    Whether or not to allow dynamic partitions in DML/DDL.\n    set hive.exec.dynamic.partition = true\n\n###### hive.exec.dynamic.partition.mode\n\n    Default Value: strict\n    Added In: Hive 0.6.0\n    In strict mode, the user must specify at least one static partition in case the user accidentally overwrites all partitions. In nonstrict mode all partitions are allowed to be dynamic.\n    Set to nonstrict to support INSERT ... VALUES, UPDATE, and DELETE transactions (Hive 0.14.0 and later). For a complete list of parameters required for turning on Hive transactions, see hive.txn.manager.\n    set hive.exec.dynamic.partition.mode = nonstrict\n\n###### hive.exec.max.dynamic.partitions\n\n    Default Value: 1000\n    Added In: Hive 0.6.0\n    Maximum number of dynamic partitions allowed to be created in total.\n    set hive.exec.max.dynamic.partitions = 1000\n\n###### hive.exec.max.dynamic.partitions.pernode\n\n    Default Value: 100\n    Added In: Hive 0.6.0\n    Maximum number of dynamic partitions allowed to be created in each mapper/reducer node.\n    set hive.exec.max.dynamic.partitions.pernode = 100\n\n##### parallel\n\n###### hive.exec.parallel\n\n    Default Value: false\n    Added In: Hive 0.5.0\n    Whether to execute jobs in parallel.  Applies to MapReduce jobs that can run in parallel, for example jobs processing different source tables before a join.  As of Hive 0.14, also applies to move tasks that can run in parallel, for example moving files to insert targets during multi-insert.\n    set hive.exec.parallel = true\n\n###### hive.exec.parallel.thread.number\n\n    Default Value: 8\n    Added In: Hive 0.6.0\n    How many jobs at most can be executed in parallel.\n    set hive.exec.parallel.thread.number = 12\n\n##### merge\n\n###### hive.merge.mapfiles\n\n    Default Value: true\n    Added In: Hive 0.4.0\n    Merge small files at the end of a map-only job.\n    set hive.merge.mapfiles = true\n\n###### hive.merge.mapredfiles\n\n    Default Value: false\n    Added In: Hive 0.4.0\n    Merge small files at the end of a map-reduce job.\n    set hive.merge.mapredfiles = true\n\n##### optimize\n\n###### hive.optimize.groupby\n\n    Default Value: true\n    Added In: Hive 0.5.0\n    Whether to enable the bucketed group by from bucketed partitions/tables.\n    set hive.optimize.groupby = true\n\n#### Deprecated Properties\n\nSee [Hadoop Deprecated Properties](http://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-common/DeprecatedProperties.html)\n\n#### Design \n\n#### Program\n\n##### pruning\n\n##### join\n\n##### count distinct\n\n##### group by\n\n##### (not) in/exists\n\n##### multi insert、union all\n\n#### Other\n\n### Hadoop \n\n#### Core\n\n#### HDFS\n\n#### YARN\n\n#### MapReduce\n\n### Spark\n\n### Server & OS\n\n### Links \n\n* [Hive Wiki](https://cwiki.apache.org/confluence/display/Hive/Home)\n* [Hive Configuration Properties](https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties)\n* [Hadoop Deprecated Properties](http://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-common/DeprecatedProperties.html)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Hive Optimization](http://blog.hyperj.net/2018/01/2018-01-08-hive-optimization/)\n","tags":["HyperJ"],"categories":["Optimization"]},{"title":"Spark Optimization","url":"%2F2018%2F01%2F2018-01-07-spark-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Spark Optimization](http://blog.hyperj.net/2018/01/2018-01-07-spark-optimization/)","tags":["HyperJ"],"categories":["Optimization"]},{"title":"MapReduce Optimization","url":"%2F2018%2F01%2F2018-01-06-mapreduce-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[MapReduce Optimization](http://blog.hyperj.net/2018/01/2018-01-06-mapreduce-optimization/)","tags":["MapReduce"],"categories":["Optimization"]},{"title":"HBase Optimization","url":"%2F2018%2F01%2F2018-01-05-hbase-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HBase Optimization](http://blog.hyperj.net/2018/01/2018-01-05-hbase-optimization/)","tags":["HyperJ"],"categories":["Optimization"]},{"title":"HDFS Optimization","url":"%2F2018%2F01%2F2018-01-04-hdfs-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[HDFS Optimization](http://blog.hyperj.net/2018/01/2018-01-04-hdfs-optimization/)","tags":["HDFS"],"categories":["Optimization"]},{"title":"Yarn Optimization","url":"%2F2018%2F01%2F2018-01-03-yarn-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Yarn Optimization](http://blog.hyperj.net/2018/01/2018-01-03-yarn-optimization/)","tags":["Yarn"],"categories":["Optimization"]},{"title":"ElasticSearch Optimization","url":"%2F2018%2F01%2F2018-01-02-elasticsearch-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[ElasticSearch Optimization](http://blog.hyperj.net/2018/01/2018-01-02-elasticsearch-optimization/)","tags":["ES"],"categories":["Optimization"]},{"title":"Java Optimization","url":"%2F2018%2F01%2F2018-01-01-java-optimization%2F","content":"\n### TODO\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[Java Optimization](http://blog.hyperj.net/2018/01/2018-01-01-java-optimization/)\n","tags":["HyperJ"],"categories":["Optimization"]},{"title":"UTM 整理","url":"%2F2017%2F2017-12-07-utm%2F","content":"\n`UTM`是“Urchin Tracking Module”——追踪网址成效表现的简写。通过向在广告系列中使用的目标网址添加广告系列参数，可以收集这些广告系列整体效果的相关信息，还可以了解广告系列在何处投放时效果更好。例如，在“夏季特惠”广告系列可能带来了大量收入，但如果在几个不同的社交应用中投放该广告系列，那么想要知道在哪个应用中投放的广告系列带来了产生最多收益的客户。或者，如果通过电子邮件、视频广告和应用内广告投放不同版本的广告系列，则可以比较具体成效，以了解使用何种方式时的营销举措效果最好。\n\n可以向网址中添加下列 5 个参数：\n\n* `utm_source`：标识媒体资源带来流量的广告客户、网站、出版物等，例如：google、newsletter4、billboard。\n* `utm_medium`：广告媒介或营销媒介，例如：每次点击费用、横幅广告和电子邮件简报。\n* `utm_campaign`：产品的具体广告系列名称、标语、促销代码等。\n* `utm_term`：标识付费搜索关键字。如果采用人工方式标记付费关键字广告系列，那么还应使用 `utm_term` 来指定相应关键字。\n* `utm_content`：用于区分相似内容或同一广告内的链接。例如，如果在同一封电子邮件中使用了两个号召性用语链接，就可以使用 `utm_content` 并为每个链接设置不同的值，以便判断哪个版本的效果更好。\n\n每个参数都必须对应一个分配的值。每个参数-值对都包含广告系列相关信息。\n\n例如，可以对自己的“夏季特惠”广告系列使用下列参数-值对：\n\n`utm_source = summer-mailer` 可标识来自“夏季特惠”电子邮件广告系列的流量\n\n`utm_medium = email` 可标识来自电子邮件广告系列与应用内广告系列的流量\n\n`utm_campaign = summer-sale` 可标识整个广告系列\n\n如果使用了这些参数，则您的自定义广告系列网址会如下所示：\n\n`https://www.example.com/?utm_source=summer-mailer&utm_medium=email&utm_campaign=summer-sale`\n\n向网址中添加参数时，应当始终使用 utm_source、utm_medium 和 utm_campaign。\n\n`utm_term` 和 `utm_content` 是可选项。\n\n`utm_` 只是这些参数的必需前缀。\n\n### Links \n\n* [自定义广告系列](https://support.google.com/analytics/answer/1033863)\n* [自定义自然搜索来源](https://support.google.com/analytics/answer/2795821)\n* [广告系列和流量来源](https://support.google.com/analytics/answer/6205762)\n* [词汇表](https://support.google.com/analytics/topic/6083659)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[UTM 整理](http://blog.hyperj.net/2017/2017-12-07-utm/)\n","tags":["UTM"],"categories":["UTM"]},{"title":"《数据湖架构(Data Lake Architecture)》——读书笔记","url":"%2F2017%2F2017-09-06-data-lake-architecture%2F","content":"\n### 数据湖 基础组件\n\n#### 元数据（metadata）\n\n元数据被分析师用来解密在数据湖中发现的初始数据。元数据是栖息在数据湖中的数据的基本轨迹图。\n\n#### 整合图谱（integration mapping）\n\n整合图谱是数据湖中的数据如何被整合的详细规范。它阐述了如何解决仓罐数据的隔绝性问题。\n\n#### 语境（context）\n\n如果你想把文本放入数据湖，那么你必须把文本语境也放置在其中。或者至少提供找到文本语境的方法。\n\n#### 元过程（metaprocess）\n\n元过程标签是关于数据湖中的数据处理的信息。\n\n### 数据湖 数据分类\n\n模拟信号数据（analog data）和应用程序数据（application data）是具有重复性的，而文本数据则是非重复性的。\n\n#### 模拟信号数据（analog data）\n\n#### 应用程序数据（application data）\n\n#### 文本数据（texture data）\n\n### 数据湖 数据池\n\n初始数据 -> 数据修整 -> 模拟信号数据 | 应用程序数据 | 文本数据 -> 数据池 -> 归档数据池\n\n### Links \n\n* [从数据仓库到数据湖——浅谈数据架构演进(加强版)](http://zhuanlan.51cto.com/art/201701/529077.htm)\n* [漫谈大数据(zhaodedong)](http://blog.csdn.net/column/details/16038.html)\n* [数据仓库（dazheng）](http://blog.csdn.net/dazheng/article/category/5667637)\n\n---\n\n* Author：HyperJ\n* Source：[HyperJ's Blog](http://blog.hyperj.net)\n* Link：[《数据湖架构(Data Lake Architecture)》——读书笔记](http://blog.hyperj.net/2017/2017-09-06-data-lake-architecture/)\n","tags":["Data-Lake"],"categories":["Data-Lake"]},{"title":"美团点评数据平台融合实践","url":"%2F2017%2F2017-08-25-dataplat-coalesce%2F","content":"\n**本文根据作者在2017年ArchSummit的分享记录整理而成。**\n\n### 背景\n\n互联网格局复杂多变，大规模的企业合并重组不时发生。原来完全独立甚至相互竞争的两家公司，有着独立的技术体系、平台和团队，如何整合，技术和管理上的难度都很大。2015年10月，美团与大众点评合并为今天的“美团点评”，成为全球规模最大的生活服务平台。主要分布在北京和上海两地的两支技术团队和两套技术平台，为业界提供了一个很好的整合案例。\n\n本文将重点讲述数据平台融合项目的实践思路和经验，并深入地讨论Hadoop多机房架构的一种实现方案，以及大面积SQL任务重构的一种平滑化方法。最后介绍这种复杂的平台系统如何保证平稳平滑地融合。\n\n两家公司融合之后，从业务层面上，公司希望能做到“1+1&gt;2”，所以决定将美团和大众点评两个App的入口同时保留，分别做出各自的特色，但业务要跨团队划分，形成真正的合力。比如丽人、亲子、结婚和休闲娱乐等综合业务以及广告、评价UGC等，都集中到上海团队；而餐饮、酒店旅游等业务集中到北京团队。为了支撑这种整合，后台服务和底层平台也必须相应融合。\n\n点评App和美团App的数据，原来会分别打到上海和北京两地的机房，业务整合之后，数据的生产地和数据分析的使用地可能是不一样的。同时，随着公司的融合，我们跨团队、跨业务线的分析会越来越多，并且还需要一些常态化的集团级报表，包括流量的分析表、交易的数据表，而这些在原来都是独立的。\n\n举个例子，原点评侧的分析师想要分析最近一年访问过美团和大众点评两个App的重合用户数，他需要经过这样一系列的过程：如下图所示，首先他要想办法找到数据，这样就需要学习原美团侧数据平台元数据的服务是怎么用的，然后在元数据服务上去找到数据，才能开始做分析。而做分析其实是一个人工去做SQL分解的过程，他需要把原点评侧的去重购买用户数拉下来，然后发到原美团侧的数据平台，这个环节需要经历一系列的操作，包括申请账号、下载数据、上传数据，可能还会踩到各种上传数据限制的坑等等。最终，如果在这些都走完之后想做一个定期报表，那他可能每天都要去人工处理一回。如果他的分析条件变了怎么办？可能还要再重新走一遍这个流程。\n\n![1](/assets/images/2017/08/25/dataplat_coalesce/1.png)\n\n所以他们特别痛苦，最终的结果是，分析师说：“算了，我们不做明细分析了，我们做个抽样分析吧！”最后他做了一个在Excel里就能做的去重数据量的分析。我们作为平台开发的同学来说，看到这个事情是非常羞愧的。那怎么办呢？\n\n在经过一些磨合后，我们得出一个结论，就是必须进行数据口整合。\n\n### 融合实践\n\n#### 确立目标\n\n我们定了一个整体的目标，希望最终是能做到一个集群、一套数据平台的工具、一套开发规范。但是这个目标有点大，怎么把它变的可控起来呢？首先至少看来是一个集群，也就是说从用户访问的角度上来讲，他通过一个Client或一套用户视图就能访问。工具方面至少明确已有的两套，哪些是新的员工进来之后还需要学，哪些是未来会抛弃掉的。最终，让大家认同我们有了一套数据平台规范，虽然这套规范短期内还没有办法做到完美。我们做的这些权衡其实是为了从整体上能将问题收敛。\n\n但即使我们把这个目标缩小了，想要达到也是很难的。难点在哪呢？\n\n#### 难点\n\n##### 架构复杂，基础设施限制\n\n![2](/assets/images/2017/08/25/dataplat_coalesce/2.png)\n\n如上图所示，整个数据平台基本上分为数据接入、数据开发、数据分析、数据输出等等几个阶段。我这里只列了其中涉及到跨机房、跨地域的部分，还有很多数据平台产品的融合，在这里就不赘述了。在两个公司融合之前，原点评侧和美团侧都已经在同地域进行多机房的部署了，也都很&quot;默契&quot;地抽象出了离线的机房是相对独立的。在线的业务机房不管是通过消息队列还是原点评自己当时做的Blackhole（一个类似DataX的产品），都会有一系列数据收集的过程、对应任务的调度系统和对应的开发工具，也会有一些不在数据开发体系内的、裸的开源客户端的跳板机。虽然架构大体一致，但是融合项目会牵扯整套系统，同时我们有物理上的限制，就是当时跨机房带宽只有10Gb。\n\n##### 可靠性要求\n\n由于团购网站竞争激烈，两家公司对于用数据去优化线上的一些运营策略以控制运营成本，以及用数据指导销售团队的管理与支撑等场景，都有极强的数据驱动意识，管理层对于数据质量的要求是特别高的。我们每天从零点开始进行按天的数据生产，工作日9点，老板们就坐在一起去开会，要看到昨天刚刚发生过什么、昨天的运营数据怎么样、昨天的销售数据怎么样、昨天的流量数据怎么样；工作日10点，分析师们开始写临时查询，写SQL去查数据，包括使用Presto、Hive，一直到22点；同时数据科学家开始去调模型。如果我们集群不能work，几千人每天的工作就只能坐在电脑面前看着Excel……\n\n当时的分析是这样，如果考虑回滚的情况下，我们运维的时间窗口在平日只有一个小时，而且要对全公司所有用数据的同学进行通告，这一个小时就是他们下班之后，晚上6点至7点的时候开始，做一个小时，如果一个小时搞不定，回滚还有一个小时。周末的话好一点，可以做4小时之内，然后做全面的通告，相当于整个周末大家都没法加班了，他们是非常不开心的。\n\n![3](/assets/images/2017/08/25/dataplat_coalesce/3.png)\n![4](/assets/images/2017/08/25/dataplat_coalesce/4.png)\n\n##### 体量\n\n虽然没有到BAT几万台节点的规模，但是也不算小了，融合时原点评的节点数是500个，数据量是11个P；原美团的节点数是3000个，现在整体已经上6000了。这里有一个比较关键的数据就是每天生成的数据量，由于我们的集群上面以数仓的场景为主，会有很多重新计算，比如说我要看去年每月的去重，这些都是经过一些时间变化之后会进行重算的。它对于分析数据的迭代速度要求很高，我每天可能都会有新的需求，如果原来的数据表里面要加一个字段，这个字段是一个新的统计指标，这个时候我就要看历史上所有的数据，就得把这些数据重新跑一遍。这里的生成数据量其中有50%是对历史的替换，50%是今天新增的。这对于后面我们拷数据、挪数据是比较大的挑战。\n\n##### 平台化与复杂度\n\n两家公司其实都已经慢慢变成一个平台，也就是说数据平台团队是平台化的，没法对数据的结果分析负责，数据平台团队其实对外暴露了数据表和计算任务这两种概念。平台化以后，这些数据表的owner和这些数据任务的owner都是业务线的同学们，我们对他们的掌控力其实是非常差的。我们想要改一个表的内容、一个数据任务的逻辑，都是不被允许的，都必须是由业务侧的同学们来做。两侧的平台融合难免存在功能性的差异，数据开发平台的日活跃就有100和240，如果查询就是每天作分析的日活跃的话，原点评和美团加起来有1000多。所以在平台融合过程中，能让这么多用户觉得毫无违和感是非常有挑战的。\n\n综上，我们做了一个项目拆解。\n\n### 项目拆解\n\n#### 数据互访打通\n\n数据互访打通其实是最早开始的，早在公司宣布融合以后，我们两侧平台团队坐在一起讨论先做什么，当时做了一个投入产出比的权衡，首要任务是用相对少的开发，先保障两边分析师至少有能在我们平台上进行分析的能力。接着是让用户可以去配置一些定时任务，通过配置一些数据拷贝任务把两地数据关联起来。\n\n在这方面我们总共做了三件事。\n\n##### 原始层数据收集\n\n![5](/assets/images/2017/08/25/dataplat_coalesce/5.png)\n\n在原美团侧把原点评侧线上业务机房一些DB数据以及Server的log数据同步过来。这个时候流式数据是双跑的，已经可以提供两边数据合在一起的分析能力了。\n\n##### 集群数据互拷\n\n集群数据互拷，也就是DistCp。这里稍微有一点挑战的是两边的调度系统分别开了接口，去做互相回调。如果我们有一份数据，我想它ready之后就立即拷到另外一边，比如原点评侧有个表，我要等它ready了之后拷到原美团侧，这个时候我需要在原美团侧这边配一个任务去依赖原点评侧某一个任务的完成，就需要做调度系统的打通。本文主要讨论大数据框架的部分，所以上面的调度系统还有开发平台的部分都是我们工具链团队去做的，就不多说了，下文重点描述DistCp。\n\n其实Hadoop原生支持DistCp，就是我起一个MapReduce在A集群，然后并行地去从B集群拖数据到A集群，就这么简单。只要你网络是通的，账号能认（比如说你在A集群跑的任务账号能被B集群认），并且有对应的读权限，执行端有计算资源，用开源版本的DistCp就可以搞定。\n\n这方面我们做了一些权衡：\n\n首先是因为涉及到带宽把控的问题，所以同步任务是由平台团队来统一管理，业务侧的同学们提需求。\n\n然后我们两侧集群分别建立一个用于同步的账号，原则是在读的那一端提交任务。什么叫“读的一端”？比如说我想把一个原点评侧的数据同步到原美团侧，原美团侧就是要读的那端，我在原美团侧起这个任务去读原点评侧的数据，然后写到原美团侧。这里的主要考虑是读端更多是需求端，所以，他要在他的资源池里去跑。另外，对集群的影响读小于写，我们希望对于被读集群的影响能尽量减少。\n\n当然，这都是一些临时的项目，投入较小，但收益是磨合了两地团队。\n\n##### Kerberos跨域认证架构\n\n接着介绍一下认证部分是怎么打通的。原美团侧和点评侧恰好都用了Kerberos去做认证服务，这个Kerberos在这我不去详细展开，只是简单介绍一下。首先是KDC会拥有所有的Client和Server，Client就是HDFS Client，Server就是Name Node，KDC会有Client和Server的密钥，然后Client和Server端都会保有自己的密钥，这两个甚至都是明文的。所有的密钥都不在传输过程中参与，只拿这个密钥来进行加密。基于你能把我用你知道的密钥加密的信息解出来，这一假设去做认证。这也是Kerberos架构设计上比较安全的一点。\n\nKerberos不细讲了，下面详细讲一下Kerberos跨域认证架构。\n\n![6](/assets/images/2017/08/25/dataplat_coalesce/6.png)\n\n一般公司都不会需要这个，只有像我们这种两地原来是两套集群的公司合并了才需要这种东西。我们当时做了一些调研，原来的认证过程是Client和KDC去发一个请求拿到对应Server的ticket，然后去访问Server，就结束了。但是如上图所示，在这里它需要走3次，原来是请求2次。大前提是两边的Kerberos服务，KDC其中的TGS部分，下面存储的内容部分分别要有一个配置叫krbtgt，它有A realm依赖 @ B realm这样的一个配置。两边的KDC基于这个配置是要一致的，包括其中的密码，甚至是包括其中的加密方式。那这个时候我们认为这两个KDC之间实际上是相互信任的。\n\n流程是Client发现要请求的Server是在另外一个域，然后需要先去跟Client所属的KDC发请求，拿一个跨域的ticket，就是上图中1右边那个回来的部分，他拿到了这个krbtgt CREALM @ REALM。然后Client拿着跨域的ticket去请求对应它要访问Service那一个域的KDC，再去拿对应那个域的Service的ticket，之后再去访问这个Service。这个流程上看文档相对简单，实则坑很多，下面就讲一下这个。\n\n![7](/assets/images/2017/08/25/dataplat_coalesce/7.png)\n\n上图是Kerberos跨域认证的一些要求。\n\n首先第一个比较大的要求就是密钥的编码一致，这有一个大坑，就是你必须让两个KDC拿到的信息是一样的，它们基于这个信息去互信，去互相访问。然后krb5.conf里面有一些比较诡异的domain_realm策略，这个在你网络环境不一致的时候会有一定的影响，包括DNS也会影响这个。在你的网络环境比较不可知的时候，你需要做做测试，尝试去怎么配，然后在Hadoop端有两个配置需要做，分别在Server端和Client端配置即可。其中比较恶心的是说，在测试的过程当中，需要去看Hadoop的详细日志，需要开一下它的Debug，然后去看一下它真正请求的那个域是什么样的。因为我们翻代码发现，Hadoop底层有对log，Client去请求realm的隐改，就是说我认为我应该是这个realm啊，它为什么传出来的是另外一个realm？这个是比较坑的一点。\n\n我们做完这个项目之后，分析师就可以愉快地配置一些调度任务去同步数据，然后在对应的集群上去关联他们的数据进行分析了。做完这个项目之后，我们两边的团队也相互磨合，相互形成了一定的认可。因为这个小项目涉及到了数据平台的每一个领域，包括工具链、实时计算、离线的团队都做了一些磨合。\n\n#### 集群融合\n\n粗看起来，打通了数据平台，我们的大目标似乎已经完成了：一个集群、一套数据平台的工具、一套开发规范。把数据拷过来，然后重新改它的任务，就可以形成在统一的一套工具和规范里面用一个集群，然后慢慢把原来团队维护的服务都下掉就好了。事实上不是这样的，这里面有大量的坑。如果接下来我们什么都不做的话，会发生什么情况呢？\n\n数据RD会需要在迁移的目标平台重建数据，比如说我们都定了，以后把原美团侧平台砍掉，那么好，以后都在原点评侧的平台，包括平台的上传工具、平台的集群去使用、去开发。这个时候，至少原美团侧的同学会说：“原点评那边平台的那些概念、流程，可能都跟我不一样啊，我还需要有学习的时间，这都还好”。但他们怎么迁移数据呢？只能从源头开始迁移，因为对端什么都没有，所以要先做数据的拷贝，把上游所有的表都拷贝过去。然后一层一层地去改，一整套任务都要完全重新构建一遍。\n\n那我们有多少任务呢？\n\n![8](/assets/images/2017/08/25/dataplat_coalesce/8.png)\n\n我们当时有7000个以上，后来超过8000个任务，然后我们平均深度有10层。也就是说上游先迁过来，然后下游才能迁。整个流程会变成数据表的拷贝，然后上线任务进行双跑。因为必须得有数据的校验，我才能放心地切过来，花的时间大概是拷贝数据1~4天，然后改代码加测试再加双跑，可能要3~5天。这里我们有一个流水线的问题，如上图所示，蓝色的部分只有一层依赖的，当然我把这个左边的ODS都迁完了之后，1层依赖的Task 1、Task 2、Task 3、Task 8中，Task 1、2、3就可以迁了，但是Task 8 还是不能迁的，因为Task 8依赖的Task 7还没过来。我再走一层，Task 4的负责人要等上游相关任务都迁完了之后才能干活，那整个这个迁移就纯线性化，我们大概估了一下，并行度不会超过50。如果是两地两份数据，这个项目的周期会变成特别长，会有长期的两份数据、两份任务。这个时候，第一是我们真存的下吗？第二是如果我要迁移出来那个方向的业务有需求的变更，我怎么改？我要两边都再改一遍？所以这个是非常不可控的。\n\n那这个时候怎么办？\n\n##### 集群融合的问题本质\n\n反思一下这个问题的本质，首先我们是不能双跑的，因为一旦双跑，我们必须有常态化的两份数据，然后衍生一系列的校验、存储量、切换策略等问题。所以我们必须得有一套数据，一套任务执行机制。后续任务的改变，不管是替换工具链上的东西，替换计算引擎，比如说让两边Hive、Spark和UDF去做一致化的时候，其实本质上是说对单个任务的修改，对每个任务灰度的修改就好了。\n\n所以我们推断出，必须自底向上地去进行融合，先合集群，然后后续再推动上游平台和引擎的融合。\n\n##### 集群融合的解决思路\n\n整体我们融合的思路是这样的，集群融合先行，两边的Hadoop的服务架构和代码先进行统一，其次拷贝原点评侧集群的Block，同步到原美团侧机房的两个副本。这里有一个大的前提，第一个是原点评侧的集群节点数相对来讲确实小，再一个就是原点评侧的机房确实放不下了，它当时只能扩容到10月，再往后扩就装不下机器了。\n\n所以我们将原点评侧的集群，合并到原美团侧机房，然后进行拷贝和切换。我们让整个这个集群变成在原美团侧机房一样的样子，然后进行融合。我们会把上面的客户端和元数据统一，使得访问任何一个集群的时候，都可以用一套客户端来做。一旦我们做到这个样子之后，基于统一的数据、集群的元数据和访问入口之后，我们上面的工具链就可以慢慢地去做一个一个机制，一个一个模块的融合了。\n\n简单总结下来就是四步：统一、拷贝、切换、融合，下面我们来展开说一下这四步。\n\n![9](/assets/images/2017/08/25/dataplat_coalesce/9.png)\n\n###### 统一\n\n第一优先级要解决的是上图中标红的部分，两边的Hadoop版本是不一样的，我们需要将原上海侧的版本变成我们的2.7.1带着跨机房架构的版本。同时因为我们后面要持续地去折腾Hadoop集群，所以必须先把原上海侧的HDFS架构改全，改成高可用的。\n\n这里有一个小经验就是，我们自研的patch对改的bug或者是加的feature，一定要有一个机制能够管理起来，我们内部是用Git去管理的，然后我们自研的部分会有特殊的标签，能一下拉出来。我们当时其实互相review了上百个patch，因为当时两个团队都有对集群，包括Hive等等这些开源软件的修改。这是统一的阶段，相对容易，就是一个梳理和上线的过程。接下来是拷贝的阶段。\n\n![10](/assets/images/2017/08/25/dataplat_coalesce/10.png)\n\n###### 拷贝\n\n上图是最终的效果图，同步在运行的打通任务还是用DistCp，然后先把原点评侧的HDFS跨机房部署。但是这个时候原点评侧的YARN还是在上海机房。在这个过程当中，因为HDFS跨机房部署了，所以原新上线的DataNode可以承载更多在原点评侧集群的冷数据。这个过程是慢慢进行拷贝的，大概持续了4个月，中间长期都是10Gbps的小管子。\n\n###### 切换\n\n这个相当于把原点评侧的NameNode（这个时候还没有彻底下线）切换到原美团侧机房，然后把对应的YARN重新启动起来。这里有一个小trick就是原美团侧机房的承载能力，大概是1000多台节点，是原点评侧的两倍，所以我们才能做这个事，最近我们刚刚把上海机房的节点迁完。\n\n那整个集群的拷贝和切换是怎么做的呢？其实就是用我们自研的一套Hadoop多机房架构。可能做Hadoop集群维护管理的同学们对这个有深刻的体会，就是不时地就要从一个机房搬到另一个机房。设计目标是说我们一个Hadoop集群可以跨机房去部署，然后在块的力度上能控制数据副本的放置策略，甚至是进行主动迁移。\n\n设计是怎么做的呢？整个Hadoop原生的架构其实没有机房这个概念，只支持Rack也就是机架，所有服务器都被认为是在同一个机房的。这个时候不可避免地就会有很多跨机房的流量，就如果你真的什么都不干，就把Hadoop跨机房去部署的话，那么不好意思，你中间有好多的调用和带宽都会往这儿走，最大的瓶颈是中间机房网络带宽的资源受限。\n\n我们梳理了一下跨机房部署的时候大概都有哪些场景会真正引发跨机房流量，基本上就这3~4个。首先是写数据的时候，大家知道会3副本，3个DataNode去建pipeline，这个时候由于是机器和机器之间建连接，然后发数据的，如果我要分机房部署的话，肯定会跨机房。那我要怎么应对呢？我们在NameNode专门增加zone的概念，相当于在Rack上面又加了一层概念，简单改了一些代码。然后修改了一下NameNode逻辑。当它去建立pipeline的时候，在那个调用里面hack了一下。建pipeline的时候，我只允许你选当前这个Client所属的zone，这样写数据时就不会跨机房了。\n\n这些Application在调度的时候有可能会在两个机房上，比如说mapper在A机房，reducer在B机房，那么中间的带宽会非常大。我们怎么做的呢？在YARN的队列里面，也增加zone的概念，我们用的是Fair Scheduler。在队列配置里面，对于每一个叶子队列，都增加了一个zone的概念。一个叶子队列，其实就是对应了这个叶子队列下面的所有任务，它在分配资源的时候就只能拿到这个zone的节点。读取数据的时候有可能是跨机房的，那这个时候没有办法，我们只有在读取块选择的时候本地优先。我们有一些跨机房提交job的情况，提交job的时候会把一些job里面的数据进行上传，这个时候加了一些任务的临时文件上传的是任务所在的目标机房。这里做一些简单的改动，最重要的是提供了一个功能，就是我们在拷贝数据的时候，其实用balancer所用的那一套接口，我们在此基础之上做了一层Hack，一层封装。形成了一个工具，我们叫ZoneTransfer，又由它来按照我们一系列的策略配置去驱动DataNode之间的跨机房的block粒度的拷贝。\n\n![11](/assets/images/2017/08/25/dataplat_coalesce/11.png)\n\n上图是我们跨机房架构的架构图，下面的Slave里面有DN(DataNode)和NM(NodeManager)，上面跑的同颜色的是一个App。我们在RM(ResourceManager)里面的叶子队列里配置了zone的概念，然后在调度的时候如大家所见，一个App只会在一个机房。然后下面黑色的线条都是写数据流程，DN之间建立的pipeline也会在一个机房，只有通过root去做的，DN之间做数据transfer的时候才会跨机房进行，这里我们基本上都卡住了这个跨机房的带宽，它会使用多少都是在我们掌控之内的。\n\n在上线和应用这个多机房架构的时候，我们有一些应用经验。\n\n首先在迁移的过程当中我们需要评估一点就是带宽到底用多少，或者说到底多长时间之内能完成这个整体数据的拷贝。这里需要面对的一个现实就是，我们有很多数据是会被持续更新的。比如我昨天看到这个块还在呢，今天可能由于更新被删，那昨天已经同步过来的数据就白费了。那我昨天已经同步过来的数据就白费了。所以我们定义了一个概念叫拷贝留存率。经过4个月的整体拷贝，拷贝留存率大概是70%多，也就是说我们只有70%的带宽是有效的，剩下的30%拷过去的数据，后面都被删了。\n\n第二个是我们必须得有元数据的分析能力，比如说有一个方法能抓到每一个块，我要拷的块当前分布是什么样子。我们最开始是用RPC直接裸抓Active NameNode，其实对线上的影响还是蛮大的。后面变成了我们通过FsImage去拉文件的列表，形成文件和块的列表，然后再到把请求发到standby，那边开了一个小口子，允许它去读。因为FsImage里面是没有block在哪一个DataNode的元信息的。\n\n这里需要注意的一点就是，我们每天都会有一个按天的数据生产，为了保证它的一致性，必须在当天完成。在切换之前，让被切换集群的NN（NameNode）进入SafeMode的状态，然后就不允许写了，所有的写请求停止，所有的任务停止。我们当时上线大概花了5~6个小时吧，先停，然后再去拷贝数据，把当天的所有新生产的数据都拷过来，然后再去做操作。这里最基本的要做到一点就是，我们离线的大数据带宽不能跟线上的服务的带宽抢资源，所以一定要跟基础设施团队去商量，让他们做一些基于打标签的带宽隔离策略。\n\n###### 融合\n\n当我们把集群搬到了原美团侧的机房之后，又做了一层融合。想让它看起来像一个集群的样子，基本上只需要3步。首先是“把冰箱门打开”，把原点评侧集群的那个NN作为一个federation合到原美团侧的集群，只需要改cluster ID，去客户端改mount table配置，cluster ID是在元数据里面。第二个是对Hive进行元数据的融合。我们恰好两侧元数据存储都是用MySQL的，把对应的表导出来，灌到这边，然后持续建一个同步的pipeline。它是长期活动的，到时候把上传的服务一切就可以。\n\n前面说的那个做了跨域认证的配置我们还是要拆掉的，必须进行服务认证的统一，不然的话以后没法看起来像一个集群，这个时候把原来的KDC里面的账号进行导出，之后逐步地去切换每一个配置，让它慢慢切到新的KDC。切的过程当中，我们各种请求还是有跨域情况的，我们认为两个域是一体的，是一样的。等切干净之后，也就是原来的KDC没有请求了之后，我们再把它干掉。\n\n#### 开发工具融合\n\n集群融合结束后，我们就做了开发工具的融合。由于这个跟大数据基础架构这个主题关系不是特别大，开发工具都是我们内部自研的，涉及的程序也很复杂，是一个特别大的项目，涉及一系列复杂的工具，每个模块的融合、打通。所以这个暂时不讲了。另外我觉得比较有意思的是下面这一点，就是原点评侧的一个拆库，这个在很多公司的数据平台慢慢扩大的过程当中可能会用到。\n\n#### 原点评侧拆库\n\n##### 难点\n\n![12](/assets/images/2017/08/25/dataplat_coalesce/12.png)\n\n先说一下背景，由于原点评和原美团整体历史上发展经验、周期和阶段不同，如上图所示，原点评侧的数据仓库是先有的Hadoop集群，后有的数据仓库平台，因此有很多平台完全没法掌控的私有库，但是他们对于数仓所在库的掌控是非常强的，所有的任务都在这一个大的Hive库里面，里面有七八千张表。而原美团侧是先有的数据平台，后来因为数据平台整个体量撑不住了，底层改成了Hadoop。同时在平台化的演进过程中，已经慢慢把各个业务进行独立拆分了，每个业务都有一个独立的私有库，简单来说就是库名和库名的规范不一样。我们希望能让这两套规范进行统一。\n\n我们如何去做呢？\n\n原来任务的内容大概是insert into一个BI库里面的一张表，接着select from BI库里面的某两张表，然后where group by。像这样的任务我们有七八千个，它们在我们平台上配置着每天的依赖调度。我们希望把它都改成下图中的样子。所有涉及到的这些表都需要改名字，说白了就是一个批量改名字的事儿。\n\n![20](/assets/images/2017/08/25/dataplat_coalesce/20.png)\n\n改名字听起来很简单，实际上并不是，我们有近8000个这样的任务需要改，同时这些任务相互之间都有非常复杂的依赖。下图是我随便找的一个，原美团侧某一个任务所有上游和下游的依赖关系图，如此复杂，任务的平均深度大概有10层，这还是平均数，最严重的可能要有大几十层。如果我们改这里面的任务表达，就只能分层推动。但是，当我们每改其中一个的时候，可能上下游都得跟着改，具体是什么样子的呢？\n\n![13](/assets/images/2017/08/25/dataplat_coalesce/13.png)\n\n下图是我们的原始结构，首先这里有一个大前提是每一个任务只对一个结果表。原始的结构中，a表只依赖o1表，b表依赖o1、o2，然后c表只依赖o2，它们之间相互关联。这时候我希望可以对库名和表名进行一次性的修改。那如果我们逐层地去改写怎么办呢？首先要先把最上层的mart表改了，而我一旦改上游的某一个表，所有跟对它有依赖的表都必须改任务内容。每推动一层改动，下面一层都要变动多次，这样一来，我们这个流程就非常受限。\n\n![14](/assets/images/2017/08/25/dataplat_coalesce/14.png)\n\n刚刚那个情况基本上是类似的，就是说我们对它们的改动没法批量化、信息化、流水线化，所有的用户和数据开发们，需要跟我们去聊，最近改了多少，然后谁谁谁没改完，谁谁谁又说要依赖他，整个依赖图是非常大的，我们整个项目又不可控了。那怎么办呢？\n\n##### 解决方案\n\n![15](/assets/images/2017/08/25/dataplat_coalesce/15.png)\n\n很简单，我们只干了一件事情，就是在Hive层面上进行了一波Hack。比如说我要让原来叫bi.o2的表未来会变成mart_b.o2，我就同时允许你以mart_b.o2和bi.o2这两种方式去访问bi.o2这张表就好了。不管是写入还是读取，我们只需要在Hive的元数据层面去做一层Hack，然后做一个对应表，这个对应表我们是有规范的、能梳理出来的。在这之后，任何一个人都可以把他的任务改写成他希望的样子而不受任何影响，他写的那些表还是原来的那些表，真正在物理上的存在还是bi.什么什么这样的表，我们整个项目就run起来了。\n\n具体的实施流程是这样，首先先梳理业务，确定整体的映射关系。然后Hive元数据入口上去做别名能力，我们是在Hive metaserver里面去改的，大部分请求都在这里面，包括Spark的、Presto的、Hive的等，都能兼容掉，推动分批次改写，单任务内以及任务链条内完全不需要做依赖关系的约束，最终真正实现的是自动化地把SQL文本替换掉了。业务的同学们只需要批量看一个检测报告，比如说数据对应上有没有什么问题，然后一键就切了。\n\n我们用了一个季度业务侧来磨合、尝试练习和熟练，同时做工具的开发。然后第二个季度结束后，我们就完成了7000多个任务中90%SQL任务批量的改写。当任务都切完了之后，我们还有手段，因为所有的请求都是从Hive的metaserver去访问的，当你还有原有的访问模式的时候，我就可以找到你，你是哪一个任务来的，然后你什么东西改没改，改完了之后我们可以去进行物理上的真正切分，干掉这种元数据对应关系。\n\n物理上的真正切分其实就是把原来都统一的库，按照配置去散到真实的物理上对应的库上，本质还是改NN一个事情。\n\n### 总结与展望\n\n#### 未来——常态化多机房方案\n\n我们目前正在做的一个项目，就是常态化地把集群跨机房去跑，其中最核心的就是我们需要对跨机房的数据进行非常强的管理能力，本质上是一个Block粒度Cache的事情，比如说Cache的击穿、Cache的预热或者Cache的等待等等，都是一个Cache管理的事情。我们会引入一个新的server，叫zone Server，所有的Client请求，NameNode进行块分布的时候，调整和修改。之后大家会在[美团点评技术博客](tech.meitaun.com)上看到我们的方案。\n\n#### 反思——技术换运营\n\n数据平台做起来是很痛苦的，痛苦在哪儿呢？第一，数据平台对上层提供的不只是RPC接口，它要管的是数据表和计算任务。所以我们做SLA很难，但是我们还在努力去做。第二，就是最开始的时候一定是基于开源系统拼接出来的，然后再到平台化，这一定是一个规范的收敛，也是限制增多的过程。在这个过程中，我们必须去推动上面应用的、不符合规范的部分，推动他们去符合新的规范。平台的变更即使做到兼容，我们的整体收尾还是要尽快扫清的，不然整个平台就会出现同时进行大量灰度、每一个模块当前都有多种状态的情况，这是不可维护的。\n\n综上，我们定义了一个概念叫“可运营性”，推动用户去做迁移、做改动是一个&quot;运营的事情&quot;。可运营性基本上的要求如下。\n\n*   可灰度。任务的改动是可灰度的。\n*   可关门。当某一刻，我不允许你再新增不符合新规范的任务、表或者配置，我们内部叫“关门打狗”，就是说先把新增的部分限制住，然后再去慢慢清理老的。\n*   进度可知。清理老的我们需要有一个进度可知，需要有手段去抓到还有哪些任务不符合我们新的规范。\n*   分工可知。抓到任务的分工是谁，推动相关团队去改动。\n*   变更兼容/替代方案。我们肯定过程中会遇到一些人说：不行，我改不动了，你deadline太早了，我搞不定。这时候得有一些降级或者兼容变更的一些方案。\n\n那我们什么时候去使用技术降低运营成本呢？前面已经有两个例子，就集群的迁移和融合，还有Hive表别名去帮助他们改任务名，这都是用技术手段去降低运营成本的。\n\n怎么做到呢？\n\n第一是找核心问题，我们能否彻底规避运营、能不能自动化？在集群融合的过程当中，其实已经彻底避免了运营的问题，用户根本都不需要感知，相当于在这一层面都抽象掉了。第二，是即使我没法规避，那我能不能让运营变得批量化、并行化、流水线化、自动化？然后当你抓核心问题有了一个方案之后，就小范围去迭代、去测试。最后还有一点，引入架构变更的复杂度最终要能清理掉，新增的临时功能最后是可被下线的。\n\n#### 体会——复杂系统重构与融合\n\n最后稍微聊一下复杂系统的重构与融合。从项目管理的角度上来讲，怎么去管控？复杂系统的重构还有融合本质上最大的挑战其实是一个复杂度管理的事情，我们不可能不出问题，关键是出问题后，对影响的范围可控。\n\n从两个层面去拆分，第一个层面是，先明确定义目标，这个目标是能拆到一个独立团队里去做的，比如说我们最开始那四个大的目标，这样保证团队间能并行地进行推动，其实是一点流水线的思路。第二，我们在团队内进行目标的拆分，拆分就相对清晰了，先确定我要变更什么，然后内部brainstorming，翻代码去查找、测试、分析到底会对什么东西产生影响，然后去改动、测试、制定上线计划。\n\n内部要制定明确的上线流程，我记得当时在做的时候从11月到12月我们拆分了应该是有11次上线，基本上每次大的上线都是在周末做的，10、11、12月总共有12个周末，一共上线11次，大的上线应该是占了7到8个周末吧。要提前准备好如何管理依赖，如何串行化，然后准备上线，上线完怎么管理，这些都是在整个项目管理过程当中需要考虑的。\n\n其中，两个可能大家都持续提的东西，第一个是监控，要知道改完了之后发生了什么，在改的时候就像加测试用例一样把改动部分的监控加好。第二要有抓手，如果我线上垮了，这个时候重复恢复的成本太高，也就是完全重启、完全回滚的成本太高，我能不能线上进行一些改动？\n\n![16](/assets/images/2017/08/25/dataplat_coalesce/16.png)\n\n最后这张图，献给大家，希望大家在对自己系统改动的时候，都能像这哥们一样从容。\n\n---\n\n* Author: 语宸\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [美团点评数据平台融合实践](https://tech.meituan.com/dataplat_coalesce.html)\n","tags":["Coalesce"],"categories":["Data-Platform"]},{"title":"人工智能在线特征系统中的数据存取技术","url":"%2F2017%2F2017-07-06-online-feature-system%2F","content":"\n### 一、在线特征系统\n\n主流互联网产品中，不论是经典的计算广告、搜索、推荐，还是垂直领域的路径规划、司机派单、物料智能设计，建立在人工智能技术之上的策略系统已经深入到了产品功能的方方面面。相应的，每一个策略系统都离不开大量的在线特征，来支撑模型算法或人工规则对请求的精准响应，因此特征系统成为了支持线上策略系统的重要支柱。美团点评技术博客之前推出了多篇关于特征系统的文章，如[《机器学习中的数据清洗与特征处理综述》](http://tech.meituan.com/machinelearning-data-feature-process.html)侧重于介绍特征生产过程中的离线数据清洗、挖掘方法，[《业务赋能利器之外卖特征档案》](http://tech.meituan.com/waimai_data_feature_service.html)侧重于用不同的存储引擎解决不同的特征数据查询需求。而[《外卖排序系统特征生产框架》](http://tech.meituan.com/feature_pipeline.html)侧重介绍了特征计算、数据同步和线上查询的特征生产Pipeline。\n\n本文以美团酒旅在线特征系统为原型，重点从线上数据存取角度介绍一些实践中的通用技术点，以解决在线特征系统在高并发情形下面临的问题。\n\n#### 1.1 在线特征系统框架——生产、调度、服务一体化\n\n在线特征系统就是通过系统上下文，获得相关特征数据的在线服务。其功能可以是一个简单的Key-Value（KV）型存储，对线上提供特征查询服务，也可以辐射到通用特征生产、统一特征调度、实时特征监控等全套特征服务体系。可以说，几个人日就可以完成一个简单能用的特征系统，但在复杂的业务场景中，把这件事做得更方便、快速和稳定，却需要一个团队长期的积累。\n\n![](/assets/images/2017/07/06/online-feature-system/2-1.png)\n\n以上结构图为一体化特征系统的概貌，自底向上为数据流动的方向，各部分的功能如下：\n\n*   **数据源**：用于计算特征的原始数据。根据业务需求，数据来源可能是分布式文件系统（如Hive），关系型数据库（如MySQL），消息队列（如Kafka）等。\n*   **特征生产**：该部分负责从各种数据源读取数据，提供计算框架用于生产特征。生产框架需要根据数据源的类型、不同的计算需求综合设计，因此会有多套生产框架。\n*   **特征导入**：该部分负责将计算好的特征写入到线上存储供特征服务读取。该部分主要关注导入作业之间的依赖、并发写入的速度与一致性等问题。\n*   **特征服务**：该部分为整个特征系统的核心功能部分，提供在线特征的存取服务，直接服务于上层策略系统。\n\n特征的生命周期按照上述过程，可以抽象为五个步骤：读、算、写、存、取。整个流程于特征系统框架内成为一个整体，作为特征工程的一体化解决方案。本文主要围绕特征服务的核心功能“**存**”、“**取**”，介绍一些通用的实践经验。特征系统的延伸部分，如特征生产、系统框架等主题会在后续文章中做详细介绍。\n\n#### 1.2 特征系统的核心——存与取\n\n简单来说，可以认为特征系统的核心功能是一个大号的HashMap，用于存储和快速提取每次请求中相关维度的特征集合。然而实际情况并不像HashMap那样简单，以我们的通用在线特征系统（Datahub）的系统指标为例，它的核心功能主要需面对**存储**与**读取**方面的挑战：\n\n1.  **高并发**：策略系统面向用户端，服务端峰值QPS超过1万，数据库峰值QPS超过100万（批量请求造成）。\n2.  **高吞吐**：每次请求可能包含上千维特征，网络IO高。服务端网络出口流量均值500Mbps，峰值为1.5Gbps。\n3.  **大数据**：虽然线上需要使用的特征数据不会像离线Hive库那样庞大，但数据条数也会超过10亿，字节量会达到TB级。\n4.  **低延迟**：面对用户的请求，为保持用户体验，接口的延迟要尽可能低，服务端TP99指标需要在10ms以下。\n\n以上指标数字仅是以我们系统作为参考，实际各个部门、公司的特征系统规模可能差别很大，但无论一个特征系统的规模怎样，其系统核心目标必定是考虑：高并发、高吞吐、大数据、低延迟，只不过各有不同的优先级罢了。当系统的优化方向是多目标时，我们不可能独立的用任何一种方式，在有限资源的情况下做到面面俱到。留给我们的是业务最重要的需求特性，以及对应这些特性的解决方案。\n\n### 二、在线特征存取技术\n\n本节介绍一些在线特征系统上常用的存取技术点，以丰富我们的武器库。主要内容也并非详细的系统设计，而是一些常见问题的通用技术解决方案。但如上节所说，如何根据策略需求，利用合适的技术，制定对应的方案，才是各位架构师的核心价值所在。\n\n#### 2.1 数据分层\n\n特征总数据量达到TB级后，单一的存储介质已经很难支撑完整的业务需求了。高性能的在线服务内存或缓存在数据量上成了杯水车薪，分布式KV存储能提供更大的存储空间但在某些场景又不够快。开源的分布式KV存储或缓存方案很多，比如我们用到的就有Redis/Memcache，HBase，Tair等，这些开源方案有大量的贡献者在为它们的功能、性能做出不断努力，本文就不更多着墨了。\n\n对构建一个在线特征系统而言，实际上我们需要理解的是我们的特征数据是怎样的。有的数据非常热，我们通过内存副本或者是缓存能够以极小的内存代价覆盖大量的请求。有的数据不热，但是一旦访问要求稳定而快速的响应速度，这时基于全内存的分布式存储方案就是不错的选择。对于数据量级非常大，或者增长非常快的数据，我们需要选择有磁盘兜底的存储方案——其中又要根据各类不同的读写分布，来选择存储技术。\n\n当业务发展到一定层次后，单一的特征类型将很难覆盖所有的业务需求。所以在存储方案选型上，需要根据特征类型进行数据分层。分层之后，不同的存储引擎统一对策略服务提供特征数据，这是保持系统性能和功能兼得的最佳实践。\n\n#### 2.2 数据压缩\n\n海量的离线特征加载到线上系统并在系统间流转，对内存、网络带宽等资源都是不小的开销。数据压缩是典型的以时间换空间的例子，往往能够成倍减少空间占用，对于线上珍贵的内存、带宽资源来说是莫大的福音。数据压缩本质思想是减少信息冗余，针对特征系统这个应用场景，我们积累了一些实践经验与大家分享。\n\n##### 2.2.1 存储格式\n\n特征数据简单来说即特征名与特征值。以用户画像为例，一个用户有年龄、性别、爱好等特征。存储这样的特征数据通常来说有下面几种方式：\n\n1.  JSON格式，完整保留特征名-特征值对，以JSON字符串的形式表示。\n2.  元数据抽取，如Hive一样，特征名（元数据）单独保存，特征数据以String格式的特征值列表表示。\n3.  元数据固化，同样将元数据单独保存，但是采用强类型定义每个特征，如Integer、Double等而非统一的String类型。\n\n三种格式各有优劣：\n\n1.  JSON格式的优点在特征数量可以是变长的。以用户画像为例，A用户可能有年龄、性别标签。B用户可以有籍贯、爱好标签。不同用户标签种类可以差别很大，都能便捷的存储。但缺点是每组特征都要存储特征名，当特征种类同构性很高时，会包含大量冗余信息。\n2.  元数据抽取的特点与JSON格式相反，它只保留特征值本身，特征名作为元数据单独存放，这样减少了冗余特征名的存储，但缺点是数据格式必须是同构的，而且如果需要增删特征，需要更改元数据后刷新整个数据集。\n3.  元数据固化的优点与元数据抽取相同，而且更加节省空间。然而其存取过程需要实现专有序列化，实现难度和读写速度都有成本。\n\n特征系统中，一批特征数据通常来说是完全同构的，同时为了应对高并发下的批量请求，我们在实践中采用了元数据抽取作为存储方案，相比JSON格式，有2~10倍的空间节约（具体比例取决于特征名的长度、特征个数以及特征值的类型）。\n\n##### 2.2.2 字节压缩\n\n提到数据压缩，很容易就会想到利用无损字节压缩算法。无损压缩的主要思路是将频繁出现的**模式**（Pattern）用较短的字节码表示。考虑到在线特征系统的读写模式是一次全量写入，多次逐条读取，因此压缩需要针对单条数据，而非全局压缩。目前主流的Java实现的短文本压缩算法有Gzip、Snappy、Deflate、LZ4等，我们做了两组实验，主要从单条平均压缩速度、单条平均解压速度、压缩率三个指标来对比以上各个算法。\n\n**数据集**：我们选取了2份线上真实的特征数据集，分别取10万条特征记录。记录为纯文本格式，平均长度为300~400字符（600~800字节）。\n\n**压缩算法**：Deflate算法有1~9个压缩级别，级别越高，压缩比越大，操作所需要的时间也越长。而LZ4算法有两个压缩级别，我们用0，1表示。除此之外，LZ4有不同的实现版本：JNI、Java Unsafe、Java Safe，详细区别参考 [https://github.com/lz4/lz4-java](https://github.com/lz4/lz4-java) ，这里不做过多解释。\n\n![](/assets/images/2017/07/06/online-feature-system/compress-alg-cmp.png)\n\n实验结果图中的毫秒时间为单条记录的压缩或解压缩时间。压缩比的计算方式为压缩前字节码长度/压缩后字节码长度。可以看出，所有压缩算法的压缩/解压时间都会随着压缩比的上升而整体呈上升趋势。其中LZ4的Java Unsafe、Java Safe版由于考虑平台兼容性问题，出现了明显的速度异常。\n\n从使用场景（一次全量写入，多次逐条读取）出发，特征系统主要的服务指标是特征高并发下的响应时间与特征数据存储效率。因此特征压缩关注的指标其实是：快速的解压速度与较高的压缩比，而对压缩速度其实要求不高。因此综合上述实验中各个算法的表现，Snappy是较为合适我们的需求。\n\n##### 2.2.3 字典压缩\n\n压缩的本质是利用共性，在不影响信息量的情况下进行重新编码，以缩减空间占用。上节中的字节压缩是单行压缩，因此只能运用到同一条记录中的共性，而无法顾及全局共性。举个例子：假设某个用户维度特征所有用户的特征值是完全一样的，字节压缩逐条压缩不能节省任何的存储空间，而我们却知道实际上只有一个重复的值在反复出现。即便是单条记录内部，由于压缩算法窗口大小的限制，长Pattern也很难被顾及到。因此，对全局的特征值做一次字典统计，自动或人工的将频繁Pattern加入到字典并重新编码，能够解决短文本字节压缩的局限性。\n\n#### 2.3 数据同步\n\n当每次请求，策略计算需要大量的特征数据时（比如一次请求上千条的广告商特征），我们需要非常强悍的在线数据获取能力。而在存储特征的不同方法中，访问本地内存毫无疑问是性能最佳的解决方式。想要在本地内存中访问到特征数据，通常我们有两种有效手段：**内存副本**和**客户端缓存**。\n\n##### 2.3.1 内存副本技术\n\n当数据总量不大时，策略使用方可以在本地完全镜像一份特征数据，这份镜像叫内存副本。使用内存副本和使用本地的数据完全一致，使用者无需关心远端数据源的存在。内存副本需要和数据源通过某些协议进行同步更新，这类同步技术称为内存副本技术。在线特征系统的场景中，数据源可以抽象为一个KV类型的数据集，内存副本技术需要把这样一个数据集完整的同步到内存副本中。\n\n###### 推拉结合——时效性和一致性\n\n一般来说，数据同步为两种类型：**推**（Push）和**拉**（Pull）。Push的技术比较简单，依赖目前常见的消息队列中间件，可以根据需求做到将一个数据变化传送到一个内存副本中。但是，即使实现了不重不漏的高可靠性消息队列通知（通常代价很大），也还面临着初始化启动时批量数据同步的问题——所以，Push只能作为一种提高内存副本时效性的手段，本质上内存副本同步还得依赖Pull协议。Pull类的同步协议有一个非常好的特性就是幂等，一次失败或成功的同步不会影响下一次进行新的同步。\n\nPull协议有非常多的选择，最简单的每次将所有数据全量拉走就是一种基础协议。但是在业务需求中需要追求数据同步效率，所以用一些比较高效的Pull协议就很重要。为了缩减拉取数据量，这些协议本质上来说都是希望高效的计算出尽量精确的_数据差异_（Diff），然后同步这些必要的数据变动。这里介绍两种我们曾经在工程实践中应用过的Pull型数据同步协议。\n\n###### 基于版本号同步——**回放日志**（RedoLog）和退化算法\n\n在数据源更新时，对于每一次数据变化，基于版本号的同步算法会为这次变化分配一个唯一的递增版本号，并使用一个更新队列记录所有版本号对应的数据变化。\n\n内存副本发起同步请求时，会携带该副本上一次完成同步时的最大版本号，这意味着所有该版本号之后的数据变化都需要被拉取过来。数据源方收到请求后，从更新队列中找到大于该版本号的所有数据变化，并将数据变化汇总，得到最终需要更新的Diff，返回给发起方。此时内存副本只需要更新这些Diff数据即可。\n\n![](/assets/images/2017/07/06/online-feature-system/version-diff.png)\n\n对于大多数的业务场景，特征数据的生成会收口到一个统一的更新服务中，所以递增版本号可以串行的生成。如果在分布式的数据更新环境中，则需要利用分布式id生成器来获取递增版本号。\n\n另一个问题则是更新队列的长度。如果不进行任何优化，更新队列理论上是无限长的，甚至会超过数据集的大小。一个优化方法是我们限制住更新队列的最大长度，一旦长度超过限制，则执行**合并**（Merge）操作。Merge操作将队列中的数据进行两两合并，合并后的版本号以较大的版本号为准，合并后的更新数据集是两个数据集的并。Merge后，新的队列长度下降为原更新队列的一半。\n\n![](/assets/images/2017/07/06/online-feature-system/version-merge.png)\n\nMerge之后的更新队列，我们依然可以使用相同的算法进行同步Diff计算：在队列中找到大于上一次更新版本号的所有数据集。可以看到由于版本号的合并，算出的Diff不再是完全精准的更新数据，在队列中最早的更新数据集有可能包含部分已经同步过的数据——但这样的退化并不影响同步正确性，仅仅会造成少量的同步冗余，冗余的量取决于Diff中最早的数据集经过Merge的次数。\n\n![](/assets/images/2017/07/06/online-feature-system/version-merge-diff.png)\n\n###### MerkleTree同步——数据集对比算法\n\n基于版本号的同步使用的是类似RedoLog的思想，将业务变动的历史记录下来，并通过回放未同步的历史记录得到Diff。由于记录不断增长的RedoLog需要不小的开销，所以采用了Merge策略来退化原始**日志**（Log）。对于批量或者微批量的更新来说，基于版本号的同步算法能较好的工作；相反，若数据是实时更新的，将会出现大量的RedoLog，并快速的退化，影响同步的效率。\n\nMerkle Tree同步算法走的是另一条路，简单来说就是通过每次直接比较两个数据集的差异来获取Diff。首先看一个最简单的算法：每次内存副本将所有数据的Hash值发送给数据源，数据源比较整个数据集，对于Hash值不同的数据执行同步操作——这样就精确计算出了两个数据集之间的Diff。但显而易见的问题，是每次传输所有数据的Hash值可能并不比多传几个数据轻松。Merkle Tree同步算法就是使用Merkle Tree数据结构来优化这一比较过程。\n\nMerkle Tree简单来说是就是把所有数据集的hash值组织成一棵树，这棵树的叶子节点描述一个（或一组）数据的Hash值。而中间节点的值由其所有儿子的Hash值再次Hash得到，描述了以它为根的子树所包含的数据的整体Hash。显然，在不考虑Hash冲突的情况下，如果两颗Merkle Tree根节点相同，代表这是两个完全相同的数据集。\n\n![](/assets/images/2017/07/06/online-feature-system/merkle-tree.png)\n\nMerkle Tree同步协议由副本发起，将副本根节点值发送给数据源，若与数据源根节点hash值一致，则没有数据变动，同步完成。否则数据源将把根结点的所有儿子节点的hash发送给副本，进行递归比较。对于不同的hash值，一直持续获取直到叶子节点，就可以完全确定已经改变的数据。以二叉树为例，所有的数据同步最多经过LogN次交互完成。\n\n![](/assets/images/2017/07/06/online-feature-system/merkle-tree-protocal.png)\n\n##### 2.3.2 客户端缓存技术\n\n当数据规模大，无法完全放入到内存中，冷热数据分明，对于数据时效性要求又不高的时候，通常各类业务都会采用客户端缓存。客户端缓存的集中实现，是特征服务延伸的一部分。通用的缓存协议和使用方式不多说，从在线特征系统的业务角度出发，这里给出几个方向的思考和经验。\n\n###### 接口通用化——缓存逻辑与业务分离\n\n一个特征系统要满足各类业务需求，它的接口肯定是丰富的。从数据含义角度分有用户类、商户类、产品类等等，从数据传输协议分有Thrift、HTTP，从调用方式角度分有同步、异步，从数据组织形式角度分有单值、List、Map以及相互嵌套等等……一个良好的架构设计应该尽可能将数据处理与业务剥离开，抽象各个接口的通用部分，一次缓存实现，多处接口同时受益复用。下面以同步异步接口为例介绍客户端接口通用化。\n\n同步接口只有一步：\n\n1.  向服务端发起请求得到结果。\n\n异步接口分为两步：\n\n1.  向服务端发起请求得到Future实例。\n2.  向Future实例发起请求，得到数据。\n\n同步和异步接口的数据处理只有顺序的差别，只需要梳理好各个步骤的执行顺序即可。引入缓存后，数据处理流程对比如下：\n\n![](/assets/images/2017/07/06/online-feature-system/client-cache-sync-and-async.png)\n\n不同颜色的处理框表示不同的请求。异步流程需要使用方的两次请求才能获取到数据。像图中“用服务端数据更新缓存”（update cache）、“服务端数据与缓存数据汇总”（merge data）步骤在异步流程里是在第二次请求中完成的，区别于同步流程第一次请求就完成所有步骤。将数据流程拆分为这些子步骤，同步与异步只是这些步骤的不同顺序的组合。因此读写缓存（search cache、update cache）这两个步骤可以抽象出来，与其余逻辑解耦。\n\n###### 数据存储——时间先于空间，客户端与服务端分离\n\n客户端之于服务端，犹如服务端之于数据库，其实数据存储压缩的思路是完全一样的。具体的数据压缩与存储策略在上文数据压缩章节已经做了详细介绍，这里主要想说明两点问题：\n\n客户端压缩与服务端压缩由于应用场景的不同，其目标是有差异的。服务端压缩使用场景是一次性高吞吐写入，逐条高并发低延迟读取，它主要关注的是读取时的解压时间和数据存储时的压缩比。而客户端缓存属于数据存储分层中最顶端的部分，由于读写的场景都是高并发低延迟的本地内存操作，因此对压缩速度、解压速度、数据量大小都有很高要求，它要做的权衡更多。\n\n其次，客户端与服务端是两个完全独立的模块，说白了，虽然我们会编写客户端代码，但它不属于服务的一部分，而是调用方服务的一部分。客户端的数据压缩应该尽量与服务端解耦，切不可为了贪图实现方便，将两者的数据格式耦合在一起，与服务端的数据通信格式应该理解为一种独立的协议，正如服务端与数据库的通信一样，数据通信格式与数据库的存储格式没有任何关系。\n\n###### 内存管理——缓存与分代回收的矛盾\n\n缓存的目标是让热数据（频繁被访问的数据）能够留在内存，以便提高缓存命中率。而JVM**垃圾回收**（GC）的目标是释放失去引用的对象的内存空间。两者目标看上去相似，但细微的差异让两者在高并发的情景下很难共存。缓存的淘汰会产生大量的内存垃圾，使Full GC变得非常频繁。这种矛盾其实不限于客户端，而是所有JVM堆内缓存共同面临的问题。下面我们仔细分析一个场景：\n\n随着请求产生的数据会不断加入缓存，QPS较高的情形下，Young GC频繁发生，会不断促使缓存所占用的内存从新生代移向老年代。缓存被填满后开始采用Least Recently Used（LRU）算法淘汰，冷数据被踢出缓存，成为垃圾内存。然而不幸的是，由于频繁的Young GC，有很多冷数据进入了老年代，淘汰老年代的缓存，就会产生老年代的垃圾，从而引发Full GC。\n\n![](/assets/images/2017/07/06/online-feature-system/client-cache-full-gc.png)\n\n可以看到，正是由于缓存的淘汰机制与新生代的GC策略目标不一致，导致了缓存淘汰会产生很多老年代的内存垃圾，而且产生垃圾的速度与缓存大小没有太多关系，而与新生代的GC频率以及堆缓存的淘汰速度相关。而这两个指标均与QPS正相关。因此堆内缓存仿佛成了一个通向老年代的垃圾管道，QPS越高，垃圾产生越快！\n\n因此，对于高并发的缓存应用，应该避免采用JVM的分带管理内存，或者可以说，GC内存回收机制的开销和效率并不能满足高并发情形下的内存管理的需求。由于JVM虚拟机的强制管理内存的限制，此时我们可以将对象序列化存储到**堆外**（Off Heap），来达到绕开JVM管理内存的目的，例如Ehcache，BigMemory等第三方技术便是如此。或者改动JVM底层实现（类似[之前淘宝的做法](http://www.infoq.com/cn/presentations/ms-jvm-taobao)），做到堆内存储，免于GC。\n\n### 三、结束语\n\n本文主要介绍了一些在线特征系统的技术点，从系统的高并发、高吞吐、大数据、低延迟的需求出发，并以一些实际特征系统为原型，提出在线特征系统的一些设计思路。正如上文所说，特征系统的边界并不限于数据的存储与读取。像数据导入作业调度、实时特征、特征计算与生产、数据备份、容灾恢复等等，都可看作为特征系统的一部分。本文是在线特征系统系列文章的第一篇，我们的特征系统也在需求与挑战中不断演进，后续会有更多实践的经验与大家分享。一家之言，难免有遗漏和偏颇之处，但是他山之石可以攻玉，若能为各位架构师在面向自己业务时提供一些思路，善莫大焉。\n\n### 作者简介\n\n杨浩，美团平台及酒旅事业群数据挖掘系统负责人，2011年毕业于北京大学，曾担任107间联合创始人兼CTO，2016年加入美团点评。长期致力于计算广告、搜索推荐、数据挖掘等系统架构方向。\n\n伟彬，美团平台及酒旅事业群数据挖掘系统工程师，2015年毕业于大连理工大学，同年加入美团点评，专注于大数据处理技术与高并发服务。\n\n【思考题】\n\n文中提到高QPS下Java堆内缓存容易产生Full GC问题从而影响系统性能，其实GC是Java的一把双刃剑。“Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的‘高墙’，墙外面的人想进去，墙里的人想出来”。聊一聊你在工作中遇到的GC问题，以及如何解决的吧~\n\n---\n\n* Author: 杨浩 伟彬\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [人工智能在线特征系统中的数据存取技术](https://tech.meituan.com/online-feature-system.html)","tags":["Feature"],"categories":["Feature"]},{"title":"孵化业务快速落地与优化","url":"%2F2017%2F2017-06-29-fuhua-haiwai%2F","content":"\n海外酒店是酒旅事业群第一个孵化的业务，从2016年9月份开始到现在已经半年多的时间。在业务后台搭建、成长、优化过程中，经历了很多的思考与选择。\n\n主要分为下面几个阶段：\n\n**初建**：调研、落地，合理复用，高效自建。\n**优化**：量化、决策，寻找瓶颈，优化性能。\n**展望**：梳理、规划，业务展望，未雨绸缪。\n\n本文将分别介绍这几个阶段后台系统相关的思考，此外还会在最后总结**团队建设**方面的经验。  \n\n### 初建\n\n海外酒店作为一个孵化项目，属于新的业务场景，没有完整的学习对象。从业务细节上来讲，孵化业务的属性、流程、发展方向均有自己的特点；但从宏观上考虑，它是已有业务的拓展，各方面也存在一些相似点。从发展速度来讲，新兴业务发展初期，迭代速度非常快，需求变更会非常频繁，业务压力在一段时间内会持续出现。 \n\n综上，在系统后台建设初期需要详细思考：已有后台服务的调研与复用，谨慎合理创建新的业务后台，优先选择成熟框架与技术组件。 \n\n#### 已有后台服务的调研与复用\n\n最终目的：合理的复用资源，避免重复造轮子。 \n\n什么样的系统或者服务可以复用？复用与否从两方面考虑：服务平台能力、涉及需求量。总体的复用判断方案如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/001.png) \n\n基于以上原则，海外酒店在复用抉择时候的判断如下：\n\n① 公司级别基础服务或业务平台\n\n*   基础服务可以复用：如异步消息中心、缓存中心、风控平台等。\n*   业务平台可以复用：如订单平台、支付中心、客服平台等。\n\n② 部门级别已有业务平台化系统\n\n*   部门内已有基础业务平台。如POI中心、订单交易平台、促销平台等。\n*   业务耦合性不高，已建业务支持能力的平台。如UGC中心、主搜平台等。\n\n在部门级的业务平台是复用+定制来完成需求的支持。因为这块有一部分需求内容，现有的能力可能无法满足新业务的要求，所以需要做部分定制。 \n\n#### 合理谨慎的创建新业务后台\n\n思考清楚如何避免重复造轮后，接下来就是孵化业务后台系统的搭建工作。 \n\n孵化业务后台建设有哪些挑战和风险？ \n\n第一：孵化业务需求迭代速度非常快，需要快速落地支持；\n第二：业务需求变更非常频繁，甚至推翻重来；\n第三：系统建设速度非常快，整体架构方式有挑战。\n\n面对上面这些挑战，海外酒店后台系统建设过程中要尽量做到简单、灵活、可扩展。\n\n**简单**：工程目录，代码结构都从简单入手，避免太多复杂设计和复杂代码耦合带来的压力。\n**灵活**：根据前期的需求以及中短期的规划，将系统根据业务划清界限，做到尽可能的微服务化，将系统设计内聚合、外解耦。\n**可扩展**：简单、灵活的同时必须思考可扩展性，为业务持续发展做到未雨绸缪。 \n\n可扩展有资源的预备储备，系统架构的无缝扩展，服务间的扩展交互。 \n\n基于上面的思考，海外酒店后台初期自建的系统如下： \n\nC端系统：API中心、产品中心、报价中心、订单中心、POI缓存中心、黑名单服务。\n\nB端系统：三方直连系统，三方数据同步系统。\n\n每个系统间界限划分清楚，哪些是提供给用户C端展示，哪些是B端三方接口访问，哪些是线下静态数据同步等。 \n\n海外后台初期整体架构落地形式如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/002.png) \n\n##### 优先选择成熟框架与技术组件\n\n业务前期在技术选型方面可能更加偏向于成熟框架，成熟技术组件。这需要我们从两方面考虑：\n\n① 新的技术框架和组件存在风险\n\n*   技术文档支持可能存在不足。*   技术问题解决方案缺失，排查困难程度不可预知。\n\n② 选择成熟框架和组件的好处\n\n*   项目搭建比较迅速。\n*   问题排查解决有经验的积累和参考。*   人员backup比较方便，招聘也比较方便。\n\n### 优化\n\n系统快速搭建的同时，需要考虑前期的必要优化，从而提高系统的健壮性、可用性等方面内容。\n\n海外酒店在建设初期从下面几个内容进行了初期思考：\n\n1.  可用性\n2.  系统性能3.  扩展性\n\n首先介绍一下可用性相关内容。\n\n#### 可用性\n\n可用性是衡量系统服务的一个重要指标。在这里重点介绍海外酒店后台系统前期考虑的几个方面：容灾降级， 限流控制，服务备份，监控覆盖。 \n\n##### 容灾降级\n\n降级策略根据不同的业务场景有不同的方式，例如超时降级、失败次数统计降级、限流降级等。 \n\n目前，降级按方式不同分为：自动降级、手动降级。 \n\n海外酒店后台目前都是采用的手动降级的策略。自动降级策略需要对监控数据有特别高的感知能力和预判能力，这块还需要继续建设完善。 \n\n对于海外酒店后台来讲目前有两块降级的要求。\n\n**业务场景一**\n\n产品售卖可降级，读服务降级。\n\n产品售卖可降级是一种人工开关，当发现大量的产品售卖出现异常时，我们将停止某个产品供应商的产品展示，从而避免造成更大的损失。然后从业务代码来进行相关的开关配置，提供一个可修改的降级开关控制接口。目前海外酒店的降级方案是通过MCC（美团点评公司级的统一配置中心）的配置信息下发来实现整个工程的手动降级。在产品展示信息的接口，通过MCC的Key来进行设置开关的状态。\n\nMCC底层实现组件是ZooKeeper（以下简称“ZK&quot;)，通过对ZK节点信息修改的监听，来进行属性的同步。由于自动降级目前存在很多技术上的不确定性，因此没有考虑根据业务数据的突变，后者如果出现监控数据的异常，会自动触发各种降级开关。 \n\n**业务场景二**\n\nAPI层接口熔断降级，使用Hystrix。\n\n对于API层来说，主要是提供前端展示所需的数据内容。上层直接面向用户需要可靠的服务以及快速的请求响应，下层依赖各种不同的服务然后进行信息的组合拼装。 \n\n所以为了提高接口的稳定性，海外酒店API层接口接入Hystrix实现熔断和降级策略。Hystrix原理可以简单描述为：\n\n1.  对多个依赖服务调用采用线程池分组，达到流量高峰互不影响的目的。\n2.  当某个或某些依赖服务发生故障，采取短时间内熔断方案（快速失败），当熔断一小段时间后，会继续访问出现故障的依赖服务，如果正常则恢复依赖调用，如失败则继续熔断循环这个过程。\n3.  针对依赖方或单依赖方多个接口设置超时，并自动调用异常或超时的灾备处理方案，实现降级。\n再详细的使用方式和底层实现可以参考网上更加详细的[资料](https://github.com/Netflix/Hystrix/wiki)。\n\n##### 限流控制\n\n限流是利用有限的资源，保障业务系统核心流程的高可用。限流本身是通过一种有损的方式来提高可用性。\n\n从限流的机器维度方面来说有单机限流和分布式限流两种，限流算法目前有熟知的令牌桶算法、漏桶算法。\n\n从应用的角度来说，限流可以针对总的并发数、连接数、请求数限流，也可以对某个共享资源来限流，以及针对某个接口请求数来进行平滑限流。 \n\n**单机限流**\n\n从单机维度的限流，我们可以采用Java提供的semaphore来进行简单的支持，或者采用Guava RateLimiter来进行单机限流。\n\n**分布式限流**\n\n而对于分布式服务的限流，就需要采用一个公共资源服务来进行流量的统一控制，目前美团点评内部提供了一个组件，基本原理利是用Tair的资源管理和主键失效策略来进行流量控制。 \n\n分布式流控系统实现原理可以利用Tair或者Redis的原子性加减操作，来进行资源的管理，同时利用失效时间来进行管理一段频率内的资源消耗情况。 \n\n为了提高开发效率，海外酒店使用了公司统一限流组件，该组件利用了Tair的原子性加减功能，进行限流功能的实现。 \n\n**海外酒店限流的业务场景**\n\n某些服务提供商，要求后台访问他们接口频率的总和不能超过 40次/秒、75000次/小时，否则会进行相应的惩罚策略（返回假数据等）。\n\n从这个要求来看，业务场景是针对第三方接口访问的限制，需要的是对接口总体访问量的控制，所以单机的限流策略无法满足这个业务场景，必须采用分布式限流。海外酒店整个限流场景下做了报警功能，并没有做直接禁止接口的访问。这是基于海外酒店前期的流量大小来综合考虑的结果。按照目前的海外酒店访问量级来说，供应商提供的接口访问次数，一段时间内可以满足当前的用户访问量。 \n\n如果超过限制，很可能有异常流量进入，而这种流量必须经过人工排查才能确定，前期如果真的出现这种流量异常，也不会太影响用户的交易行为，综合考虑之后，我们针对限流场景，做了触发报警的策略。 \n\n##### 服务备份\n\n对于分布式系统来讲，虽然其特征决定了整个服务的不可用性大大降低，但对于核心系统我们必须考虑整个系统的容灾备份能力。对于业务系统来讲，容灾能力分为两种需要考虑：\n\n1.  自身服务的容灾特征，如何保证自身服务的高可用状态。\n2.  依赖服务的容灾特征，即依赖的服务出现不可用状态时候，对于业务方来说如何进行灾备。\n\n这种分布式系统容灾的方法有： \n\n1.  跨机房部署、异地多活、防止机房不可用灾备。\n2.  依赖方替换方案，防止依赖方服务不可用状态。\n\n对于海外酒店业务来说：\n\n1.  每个服务都会在两到三个机房进行部署，根据需要可以多申请（也要考虑公司资源）几台备用。\n2.  POI缓存中心强依赖于Redis缓存系统，因此做了一层灾备，也将缓存数据同步了一份到Tair集群。\n\nPOI缓存中心灾备模型如下：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/003.png) \n\n既然是两个缓存中心，那么服务的数据类型接口也都存在差异，就存储信息来说，如果两者都完全保持同步，会造成后期的维护成本比较高。因此作为备份容灾的缓存服务，仅仅存储必要的信息，而且是基本不会变动的数据结构。避免由于业务的修改，造成双缓存中心数据结构的修改适配。 \n\n##### 监控覆盖\n\n海外酒店初期，在监控方面进行了详细的领域拆分，并结合公司的公共日志监控平台来进行相关的监控报警工作。监控方面从监控内容上来分有：网络监控、机器监控、业务监控、日志统计等。\n\n整体的后台监控体系，如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/004.png) \n\n随着业务系统的增加，以及服务的拆分，各个系统间日志的统一查看比较困难，给问题排查带来很多都不便。比如订单交易平台下单异常， 需要排查自身系统的问题，如果发现依赖服务存在问题，就需要依赖服务（产品中心、直连中心、报价中心等等）分别确定排查，查看自身的监控情况，从而协助确定问题。 \n\n因此未来需要将各个业务统计，监控信息统一到一个监控大盘里面，可以一目了然的观察各个维度的信息，从而优化问题排查效率，提高系统可用性。 \n\n#### 系统性能\n\n孵化业务前期，访问量的绝对值虽然还不是太高，但我们仍然需要持续关注接口的性能与响应时间。特别是业务推广初期，用户的第一印象将直接影响其对业务的心理评判。\n\n这些方面业务前期自然需要重点关注和考虑。海外酒店后台在每个环境中都考虑了性能优化相关内容，主要涉及到并发请求，异步解耦，缓存使用。\n\n##### 并发请求\n\n海外酒店POI详情页需要展示产品列表信息，产品列表信息是实时调用多家供应商接口来进行获取，同时还要从POI缓存中心获取房型的图片链接，然后进行结果的聚合组装然后返回。\n\n如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/005.png) \n\n通过并发请求获取，来提高接口的响应时间，在进行并发任务操作时，需要注意线程池的配置和管理。这块内容很多地方都有详解，在这里就不展开介绍了。 \n\n##### 异步解耦\n\n除了用并发请求来优化响应时间以外，还有一种方式是异步解耦。 \n\n异步解耦可以描述为将非主业务功能进行拆分，对返回结果没有影响的功能，进行异步化操作。\n\n异步化的方式常见的有：\n\n1.  启动新的线程，异步化执行。\n2.  通过异步消息，拆分服务执行。\n\n**启动新线程进行异步解耦**\n\n海外酒店业务举例来说，用户进行下单操作：\n\n1.  订单交易平台需要将下单信息同步到直连订单系统。\n2.  然后由直连订单系统去第三方供应商进行下单。\n3.  第三方供应商下单接口很多时候是非实时返回结果，需要定时去拉取结果，然后将结果同步给订单交易平台。\n\n这三步操作如果同步执行，那么结果耗时会很久，用户等待时间非常长。为了提高用户体验，在直连订单系统存储成功下单信息之后，就返回给用户一个结果等待的中间状态，避免用户长时间等待。与此同时后台会启动一个新线程，进行到第三方下单的操作，这就是启动新线程进行异步解耦的过程。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/006.png) \n\n**通过异步消息，拆分服务解耦**\n\n用户在获取产品信息时候，需要将实时获取到的产品信息进行相关的梳理计算并同步到统计中心，进行数据的采集。这块数据梳理同步任务和用户访问主要目的没有太多直接关系，因此可以采用异步消息的方式发送给数据梳理服务，然后由该服务进行相关的数据整理工作，从而实现业务的解耦，优化了接口的响应时间。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/007.png) \n\n##### 缓存使用\n\n缓存的使用分为两种：一种本机缓存，一种是分布式缓存。都是将数据加载到缓存，以此来减轻数据库查询或者接口访问的压力，以及优化服务响应时间。 \n\n###### 本地缓存使用\n\n本地缓存比较合适的使用场景：\n\n1.  数据量比较小（内存资源有限）。\n2.  经常被访问相对稳定信息（效果突出，数据变动小）。\n\n在海外酒店直连工程中，床型映射信息属于比较稳定的存储数据，同时数据量级非常小，但访问量相对比较大，因此符合使用本地缓存的场景。\n\n本地缓存熟知的实现方式：Ehcache、Guava Cache。\n\n在本地缓存使用方面需要注意：本地缓存涉及到多机之间数据不同步风险或者内存消耗方面的影响。因此使用时候需要详细考虑数据的场景。 \n\n###### 分布式缓存使用\n\n当前服务一般都是分布式服务，因此使用比较多的也是分布式缓存来进行相关的优化。下面介绍一下海外酒店对于分布式缓存的使用。\n\n**避免数据库访问压力**\n\n大量的DB访问会造成DB的压力，同时DB的查询效率会随着数据量的增加逐步变差，因此比较常规的做法，是将部分数据同步到缓存中，通过缓存作为中间层，减少DB的访问，与此同时优化服务响应时间。 \n\nDB和缓存数据的同步一般有访问时同步、定时预热同步等。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/008.png) \n\n**避免第三方服务访问压力**\n\n场景一\n\n海外酒店产品信息是实时的调用第三方接口来获取，三方接口性能和稳定性均可能存在未知风险，因此为了提升内部系统整体的性能与稳定性，同时为了避免大访问量对三方接口造成压力， 采用了产品信息缓存的策略，同时根据第三方的要求，进行缓存内容过期时间的合理设定。  \n\n场景二\n\n海外酒店搜索列表页、详情页、下单填写页均需要进行POI（酒店信息）相关信息的展示，对于POI查询接口来说访问量非常大，因此为了避免对POI中心造成流量的冲击，海外酒店POI缓存中心将所有的POI信息每天定时全量的同步到缓存中，同时进行相关信息的整体聚合，提供给业务访问，从而避免了服务接口的压力。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/009.png) \n\n使用分布式缓存的时候需要注意的一点：**数据一致性的问题**。对于海外酒店POI缓存中心通过两种方式来进行数据一致性的保证:\n\n1.  通过接收异步消息，监听缓存信息的变更记录，从而将变更信息同步到缓存；\n2.  间隔一段周期，进行全量缓存数据的更新操作，从而保证数据的准确性。\n\n###### 缓存使用的梳理\n\n缓存使用时候需要注意缓存的雪崩、更改策略问题。\n\n**雪崩**\n\n雪崩的概念可以简单描述为：缓存由于某些原因造成大量的缓存数据失效，大量的访问请求直接打到数据库或者服务接口，造成底层数据源的压力。\n\n有一种常见情况的雪崩，就是在短时间内大量的同步数据到缓存，到了过期时间，导致大量的缓存数据失效，从而形成雪崩现象。 \n\n海外酒店在大量同步POI数据到缓存的时候，采用了少线程、缓慢同步的策略。这块虽然增加了整个缓存的同步总时间，但也让数据的同步进行了有效的分散，从而避免了雪崩现象的产生。\n\n还有一种方式，就是让每个缓存内容的过期时间设置进行不同的赋值，不要统一设定过期时间，使用一个区间内（比如一个小时）随机的选择失效时间，从而可以避免雪崩的危险。 \n\n**穿透**\n\n什么是缓存穿透？一般使用缓存查询的时候，如果在缓存中查询不到结果，就会去DB或者服务中再次查询。但如果大量的访问是因为查询了缓存和数据库中均不存在的数据，从而造成每次查询都要去DB或者服务访问验证一次，就会对后端DB或者服务造成压力。如下图所示：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/010.png) \n\n**海外酒店业务场景**\n\n海外酒店的搜索列表页，会进行酒店最低价的查询，海外酒店的最低价需要准实时（每天两次）从第三方来同步产品最低价信息，然后存储到数据库提供给搜索服务使用。 \n\n搜索列表页是所有服务页面中流量最大，访问最多的页面，因此需要将访问的最低价数据同步到缓存，然后提供服务。\n\n在现实业务中，很多酒店在某些时期没有产品售卖，也就不存在最低价属性，因此在大量访问的时候，就会造成一定的缓存穿透情况。为了避免这种情况，采取如下策略。\n\n**前期**\n\n将所有的没有数据的访问，也存储到缓存当中，防止缓存访问的穿透；同时存储这些无值默认数据的key，也要保持和数据库或者服务数据的一致性。\n\n问题：随着数据量的增加，可能造成缓存空间的严重浪费。 \n\n**后期**\n\n后续再次使用Bloom Filter来进行简单的优化。Bloom Filter算法采用的是部分错误代价、换取空间优化的特点。具体的原理在这里不做过多的介绍。 \n\n#### 扩展性\n\n对于新的业务系统来讲，扩展性的考虑主要有前期的容量评估和服务粒度的拆分。\n\n##### 前期的容量评估\n\n作为新项目，必须进行项目前期的容量评估，从而决定前期项目需要申请的资源，以及未来一段时间需要扩充的资源。容量评估的内容一般包括：访问量评估、数据量评估、带宽/CPU/内存相关的评估。 \n\n访问量评估主要考虑三方面内容：\n\n1.  初期业务访问量的PV有多少，正常的每天访问密集时间段；2.  是否会有促销相关的运营活动，能带来多少流量的增长；\n3.  存储数据的量级范围，包含两个方面：第一是数据库存储数据的量级，第二个是缓存存储的量级。\n\n拿海外酒店举例：\n\n1.  海外业务本身访问量属于缓和类型，与业务方沟通大概的PV量级，以及访问密集程度明显的时间段，根据能够支持正常流量的峰值3倍能力来确定机器的资源。\n2.  海外酒店会有促销运营活动的配置，但不属于短时间内的高并发促销业务，因此促销带来的流量峰值，可以通过简单的机器备份来进行预备。3.  海外酒店后台数据库容量评估方面：主要根据POI存储量级，产品信息存储量级，以及每天信息存储的大小，计算总和。基于5倍容量的评估进行数据库大小的申请。\n4.  缓存存储主要用于POI静态数据存储和部分产品属性的存储，整体量级假设在30G之内，考虑后期的扩展，申请30G*2，方便未来的数据扩展。\n\n##### 服务粒度的拆分\n\n服务的拆分应该遵循单服务高内聚，多服务低耦合。服务的划分应该将经常一起发生变化，业务模型处理相同的模块放在一起，从而实现内聚性； 服务间可以独立部署，负责业务或者功能可以通过接口清晰调用，服务间部署，发布均可以独立进行，从而实现服务间松耦合。\n\n海外酒店后台服务可以从上文中看出：\n\n> POI缓存中心：负责POI相关静态数据的缓存管理；\n> 产品中心：负责同步三方产品数据 同时进行部分缓存操作；\n> 订单中心：负责订单相关的服务，进行交易相关的服务；\n> 报价中心：价格相关展示计算进行服务拆分，统一价格计算，避免同一价格，多出计算逻辑问题。\n\n服务科学的拆分方便系统间处理业务界限清晰，同时管理起来统一方便。 \n\n### 展望\n\n上面总结了项目发展初期一般遇到的问题和思考以及部分解决方案。后续随着业务的发展，还会遇到中期的问题与挑战。根据不同的发展阶段，需要做出不同的规划与策略，未雨绸缪，让系统在业务不断发展的过程中，迭代优化，提早准备，避免系统能力支持出现瓶颈。\n\n海外酒店后台后续的系统建设与优化思路，总体来说可以参考下面的模型：\n\n![](/assets/images/2017/06/29/fuhua-haiwai/011.png) \n\nX轴可以理解为数据库的主从复制，机器的扩充，缓存的扩充。侧重节点能力的无差别复制。\n\nY轴可以理解为将部分目前业务逻辑耦合比较复杂的系统，根据业务特点进行垂直拆分，让系统服务负责业务更加精简明确。\n\nZ轴可以理解为根据用户不同特点或者特殊需求方面进行系统扩展；例如，为了提高在海外的用户访问效率，进行海外服务节点的部署搭建。 \n\n总体来说保证业务需求快速迭代的同时，优化系统架构，保证系统的各方面指标。 \n\n### 团队建设\n\n在文章的最后简单梳理一下孵化业务团队建设相关的内容。\n\n**团队如何建设？**\n\n一般孵化业务面临的问题：项目成员新，组内技术积累弱，业务了解程度浅。 \n\n**面对这种问题如何解决？** \n\n快速招聘、大量进人？这样存在团队管理方面的风险，会造成业务开发过程中沟通、理解方面的偏差不同问题扩大，甚至产生团队的不稳定因素，造成团队整体效率偏低；因此越是孵化项目，越是初创团队，就更需要循序渐进进行人员的扩充，在团队成长的过程中形成自己的文化和节奏，后期进入的员工能快速的从身边老员工身上体会与学习到这些文化和节奏。从而形成统一的团队相处模式。在一个稳定的团队扩建速度下逐步凝聚，提高效率，提升整体战斗力。 \n\n**规范如何树立？**\n\n技术团队建设成长的过程中，技术规范的建设起到很重要的作用，规范建设越迅速、越完整，那么业务开发过程中的风险也就更少。\n海外酒店在团队建设过程中不断加强技术规范的建设，在半年的时间里分别进行了八个技术规范的落地。\n\n![](/assets/images/2017/06/29/fuhua-haiwai/012.png) \n\n这些技术方案的持续建设，大大降低了初创团队的工程风险，同时也让新加入的同学，快速的了解团队开发习惯，迅速进入到生产角色。后续海外酒店后台还需要进行：单元测试规范、监控报警规范等一系列的建设任务。 \n\n### 总结\n\n上面根据孵化业务现实的技术思考，从初建、优化、展望、团队四个方面进行相关的介绍。 整体来看基本上都是根据业务不同发展需求，做出合理的技术选型与设计。 后续随着业务的成长，系统建设与技术架构都会有不同程度的迭代思考与修整。 从各个方面去思考系统对于业务支持的合理性与前瞻性，尽量做到合理演进、灵活扩展、科学设计等各方面的要求。 \n\n### 作者简介\n\n宗起，后台技术专家，2015年加入美团点评，目前负责海外酒店后台研发团队。之前曾在阿里巴巴、腾讯、中国移动研究院从事后台研发工作。\n\n关飞，高级技术专家。之前在阿里、创新工场孵化项目从事研发工程师职位，现在负责酒店后台ehome组，负责酒店核心通路、孵化业务的系统建设、维护工作。\n\n---\n\n* Author: 关飞 宗起\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [孵化业务快速落地与优化](https://tech.meituan.com/fuhua-haiwai.html)","tags":["Business"],"categories":["Business"]},{"title":"Neural Network Zoo Prequel: Cells And Layers","url":"%2F2017%2F2017-05-31-neural-network-zoo-prequel-cells-layers%2F","content":"\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/neuralnetworkcells.png)\n\n### Cells\n\n[The Neural Network Zoo](http://www.asimovinstitute.org/neural-network-zoo/) shows different types of cells and various layer connectivity styles, but it doesn&#8217;t really go into how each cell type works. A number of cell types I originally gave different colours to differentiate the networks more clearly, but I have since found out that these cells work more or less the same way, so you&#8217;ll find descriptions under the basic cell images.\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/ffcell.png)\n\n**A basic neural network cell**, the type one would find in a regular feed forward architecture, is quite simple. The cell is connected to other neurons via weights, i.e. it can be connected to all the neurons in the previous layer. Each connection has its own weight, which is often just a random number at first. A weight can be negative, positive, very small, very big or zero. The value of each of the cells it&#8217;s connected to is multiplied by its respective connection weight. The resulting values are all added together. On top of this, a bias is also added. A bias can prevent a cell from getting stuck on outputting zero and it can speed up some operations, reducing the amount of neurons required to solve a problem. The bias is also a number, sometimes constant (often -1 or 1) and sometimes variable. This total sum is then passed through an activation function, the resulting value of which then becomes the value of the cell.\n\n**Convolutional cells** are much like feed forward cells, except they&#8217;re typically connected to only a few neurons from the previous layer. They are often used to preserve spatial information, because they are connected not to a few random cells but to all cells in a certain proximity. This makes them practical for data with lots of localised information, such as images and sound waves (but mostly images). Deconvolutional cells are just the opposite: these tend to decode spatial information by being locally connected to the next layer. Both cells often have a lot of clones which are trained independently; each clone having it&#8217;s own weights but connected exactly the same way. These clones can be thought of as being located in separate networks which all have the same structure. Both are essentially the same as regular cells, but they are used differently.\n\n**Pooling and interpolating cells** are frequently combined with convolutional cells. These cells are not really cells, more just raw operations. Pooling cells take in the incoming connections and decide which connection gets passed through. In images, this can be thought of as zooming out on a picture. You can no longer see all the pixels, and it has to learn which pixels to keep and which to discard. Interpolating cells perform the opposite operation: they take in some information and map it to more information. The extra information is made up, like if one where to zoom in on a small resolution picture. Interpolating cells are not the only reverse operation of pooling cells, but they are relatively common as they are fast and simple to implement. They are respectively connected much like convolutional and deconvolutional cells.\n\n**Mean and standard deviation cells** (almost exclusively found in couples as probabilistic cells) are used to represent probability distributions. The mean is the average value and the standard deviation represents how far to deviate from this average (in both directions). For example, a probabilistic cell used for images could contain the information on how much red there is in a particular pixel. The mean would say for example 0.5, and the standard deviation 0.2. When sampling from these probabilistic cells, one would enter these values in a Gaussian random number generator, resulting in anything between 0.4 and 0.6 being quite likely results, with values further away from 0.5 being less and less likely (but still possible). They are often fully connected to either the previous or the next layer and they do not have biases.\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/rnncell.png)\n\n**Recurrent cells** have connections not just in the realm of layers, but also over time. Each cell internally stores its previous value. They are updated just like basic cells, but with extra weights: connected to the previous values of the cells and most of the time also to all the cells in the same layer. These weights between the current value and the stored previous value work much like a volatile memory (like RAM), inheriting both properties of having a certain &#8220;state&#8221; and vanishing if not fed. Because the previous value is a value passed through an activation function, and each update passes this activated value along with the other weights through the activation function, information is continually lost. In fact, the retention rate is so low, that only four or five iterations later, almost all of the information is lost.\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/lstmcell.png)\n\n**Long short term memory cells** are used to combat the problem of the rapid information loss occurring in recurrent cells. LSTM cells are logic circuits, copied from how memory cells were designed for computers. Compared to RNN cells which store two states, LSTM cells store four: the current and last value of the output and the current and last values of the state of the &#8220;memory cell&#8221;. They have three &#8220;gates&#8221;: input, output, forget, and they also have just the regular input. Each of these gates has its own weight meaning that connecting to this type of cell entails setting up four weights (instead of just one). The gates function much like flow gates, not fence gates: they can let everything through, just a little bit, nothing, or, anything in between. This works by multiplying incoming information by a value ranging from 0 to 1, which is stored in this gate value. The input gate, then, determines how much of the input is allowed to be added to the cell value. The output gate determines how much of the output value can be seen by the rest of the network. The forget gate is not connected to the previous value of the output cell, but rather connected to the previous memory cell value. It determines how much of the last memory cell state to retain. Because it&#8217;s not connected to the output, much less information loss occurs, because no activation function is placed in the loop.\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/grucell.png)\n\n**Gated recurrent units** (cells) are a variation of LSTM cells. They too use gates to combat information loss, but do so with just 2 gates: update and reset. This makes them slightly less expressive but also slightly faster, as they use less connections everywhere. In essence there are two differences between LSTM cells and GRU cells: GRU cells do not have a hidden cell state protected by an output gate, and they combine the input and forget gate into a single update gate. The idea is that if you want to allow a lot of new information, you can probably forget some old information (and the other way around).\n\n### Layers\n\nThe most basic way of connecting neurons to form graphs is by connecting everything to absolutely everything. This is seen in Hopfield networks and Boltzmann machines. Of course, this means the number of connections grows exponentially, but the expressiveness is uncompromised. This is referred to as completely (or fully) connected.\n\nAfter a while it was discovered that breaking the network up into distinct layers is a useful feature, where the definition of a layer is a set or group of neurons which are not connected to each other, but only to neurons from other group(s). This concept is for instance used in Restricted Boltzmann Machines. The idea of **using layers** is nowadays generalised for any number of layers and it can be found in almost all current architectures. This is (perhaps confusingly) also called fully connected or completely connected, because actually completely connected networks are quite uncommon.\n\n**Convolutionally connected layers** are even more constrained than fully connected layers: we connect every neuron only to neurons in other groups that are close by. Images and sound waves contain a very high amount of information if used to feed directly one-to-one into a network (e.g. using one neuron per pixel). The idea of convolutional connections comes from the observation that spatial information is probably important to retain. It turned out that this is a good guess, as it&#8217;s used in many image and sound wave based neural network applications. This setup is however less expressive than fully connected layers. In essence it is a way of &#8220;importance&#8221; filtering, deciding which of the tightly grouped information packets are important; convolutional connections are great for dimensionality reduction. At what spatial distance neurons can still be connected depends on the implementation, but ranges higher than 4 or 5 neurons are rarely used. Note that &#8220;spatial&#8221; often refers to two-dimensional space, which is why most representations show three-dimensional sheets of neurons being connected; the connection range is applied in all dimensions.\n\nAnother option is of course to **randomly connected neurons**. This comes in two main variations as well: by allowing for some percentage of all possible connections, or to connect some percentage of neurons between layers. Random connections help to linearly reduce the performance of the network and can be useful in large networks where fully connected layers run into performance problems. A slightly more sparsely connected layer with slightly more neurons can perform better in some cases, especially where a lot of information needs to be stored but not as much information needs to be exchanged (a bit similar to the effectiveness of convolutionally connected layers, but then randomised). Very sparsely connected systems (1 or 2%) are also used, as seen in ELMs, ESNs and LSMs. Especially in the case of spiking networks this makes a lot of sense, because the more connections a neuron has, the less energy each weight will carry over, meaning less propagating and repeating patterns.\n\n**Time delayed connections** are connections between neurons (often from the same layer, and even connected with themselves) that don&#8217;t get information from the previous layer, but from a layer from the past (previous iteration, mostly). This allows temporal (time, sequence or order) related information to be stored. These types of connections are often manually reset from time to time, to clear the &#8220;state&#8221; of the network. The key difference with regular connections is that these connections are continuously changing, even when the network isn&#8217;t being trained.\n\nThe following image shows some small sample networks of the types described above, and their connections. I use it when I get stuck on just exactly what is connected to what (which is particularly likely when working with LSTM or GRU cells):\n\n![](/assets/images/2017/05/31/neural-network-zoo-prequel-cells-layers/neuralnetworkgraphs.png)\n\n---\n\n* Author: [FJODOR VAN VEEN](http://www.asimovinstitute.org/author/fjodorvanveen/)\n* Source: [THE ASIMOV INSTITUTE](http://www.asimovinstitute.org/)\n* Link: [NEURAL NETWORK ZOO PREQUEL: CELLS AND LAYERS](http://www.asimovinstitute.org/neural-network-zoo-prequel-cells-layers/)\n","tags":["Layers"],"categories":["Deep-Learning"]},{"title":"美团点评酒旅数据仓库建设实践","url":"%2F2017%2F2017-05-26-hotel-dw-layer-topic%2F","content":"\n在美团点评酒旅事业群内，业务由传统的团购形式转向预订、直连等更加丰富的产品形式，业务系统也在迅速的迭代变化，这些都对数据仓库的扩展性、稳定性、易用性提出了更高要求。对此，我们采取了分层次、分主题的方式，本文将分享这一过程中的一些经验。\n\n### 技术架构\n\n随着美团点评整体的系统架构调整，我们在分层次建设数据仓库的过程中，不断优化并调整我们的层次结构，下图展示了技术架构的变迁。\n\n![酒旅数据仓库分层](/assets/images/2017/05/26/hotel_dw_layer_topic/001.png)\n\n我们把它们简称为三代数仓模型层次。在第一代数仓模型层次中，由于当时美团整体的业务系统所支持的产品形式比较单一（团购），业务系统中包含了所有业务品类的数据，所以由平台的角色来加工数据仓库基础层是非常合适的，平台统一建设，支持各个业务线使用，所以在本阶段中我们酒旅只是建立了一个相对比较简单的数据集市。\n\n但随着美团原本集中的业务系统不能快速响应各个业务线迅速的发展与业务变化时，酒旅中的酒店业务线开始有了自己的业务系统来支持预订、房惠、团购、直连等产品形式，境内度假业务线也开始有了自己的业务系统来支持门票预订、门票直连、跟团游等复杂业务。我们开始了第二代数仓模型层次的建设，由建设数据集市的形式转变成了直接建设酒旅数据仓库，成为了酒旅自身业务系统数据的唯一加工者。由于系统调整初期给我们带来的重构、修改以及新增等数据处理工作非常大，我们采用了比较短平快的Kimball所提的维度建模的方式建设了酒旅数据仓库。\n\n在第二代数仓模型层次运转一段时间后，我们的业务又迎来了一个巨大的变化，上海团队和我们融合了，同时我们酒旅自身的业务系统重构的频率相对较高，对我们的数仓模型稳定性造成了非常大的影响，原本的维度模型非常难适配这么迅速的变化。下图就是我们数仓模型当时所面临的挑战：\n\n![基础层背景](/assets/images/2017/05/26/hotel_dw_layer_topic/002.png)\n\n于是我们在ODS与多维明细层中间加入了数据整合层，参照Bill Inmon所提出的企业信息工厂建设的模式，基本按照三范式的原则来进行数据整合，由业务驱动调整成了由技术驱动的方式来建设数据仓库基础层。下图是该层次的一些描述：\n\n![基础层](/assets/images/2017/05/26/hotel_dw_layer_topic/003.png)\n使用本基础层的最根本出发点还是在于我们的供应链、业务、数据它们本身的多样性，如果业务、数据相对比较单一、简单，本层次的架构方案很可能将不再适用。\n\n### 业务架构\n\n下面介绍我们的主题建设，实际上在传统的一些如银行、制造业、电信、零售等行业里，都有一些比较成熟的模型，如耳熟能详的BDWM、FS-LDM、MLDM等等模型，它们都是经过一些具有相类似行业的企业在二三十年数据仓库建设中所积累的行业经验，不断的优化并通用化。但我们所处的O2O行业本身就没有可借鉴的成熟的数据仓库主题以及模型，所以，我们在摸索建设两年的时间里，我们目前总结了下面比较适合我们现状的七大主题（后续可能还会新增）：\n\n![数据仓库主题](/assets/images/2017/05/26/hotel_dw_layer_topic/004.png)\n\n#### 参与人主题\n\n用户子主题：使用我们服务的所有人都是我们的用户，这是我们数据中至关重要的实体，也是我们数仓中非常重要的一个主题，对用户数据的系统化建设能够很好的帮助我们企业快速的发展，不断提高用户的体验、扩大我们的用户群。\n\nBD子主题：通过BD的业务扩展，建立我们与商户之间的关系，让用户通过我们的服务访问到商户所发布的信息，对BD数据的建设，能够让我们的商户覆盖更加迅速、让我们和商户之间的关系更加紧密。\n\n供应商子主题：供应商无论作为直签还是作为三方签约对象，对我们的业务发展都非常重要，通过对其数据的建设，可以让我们彼此双赢，通过我们的平台让双方的业务迅速发展。\n\n#### 流量主题\n\n用户通过App或PC或I版、微信等等形式访问我们的服务，形成了对我们企业至关重要的流量，本主题也是比较具有互联网特色的主题，对于流量的数据建设能够让我们不断优化我们的产品、服务，给我们带来更多的流量、更快的扩张。\n\n#### 订单主题\n\n当用户给我们带来流量的同时，他们也会产生交易，订单主题的独立建设以及其重要性我这里就不再赘述了，在所有的互联网以及传统公司里，该主题都是至关重要的。\n\n#### POI主题\n\n这个主题也具有我们自身的O2O特色，实际上这个主题与阿里的商家主题比较类似但又具备自己的特点，对于POI自身的重要性就不再过多介绍，通过对POI的数据集中建设能够让我们给POI带去更好的服务与回报。\n\n#### 产品主题\n\n与POI强相关的就是产品了，如何让产品能够更加的贴近用户的需求以及产生更多的交易、流量，产品数据主题的建设及目的的意义就在于此。\n\n#### 运营主题\n\n我们的业务发展将不再依靠粗暴的补贴式的扩张发展模式，需要依赖现在的精细化运营方式，运营数据主题的建设就有了非常强的必要性，通过数据进行精细化运营已经成为我们运营的主要发展趋势。\n\n#### 结算主题\n\n实际上，这个主题在传统企业里面如银行、电信等等都是至关重要的，对我们酒旅而言，建设它的意义能够不断优化商家体验、提高财务结算与管理能力。\n\n### 整体架构\n\n我们的七个主题基本上都采用6层结构的方式来建设，划分主题更多是从业务的角度出发，而层次划分则是基于技术，实质上我们就是基于业务与技术的结合完成了整体的数据仓库架构。下面介绍一下具体的一些主题案例：\n\n![数据仓库架构](/assets/images/2017/05/26/hotel_dw_layer_topic/005.png)\n\n#### 订单主题\n\n 在订单主题的建设过程中，我们是按照由分到总的结构思路来进行建设，首先分供应链建设订单相关实体（数据整合中间层3NF），然后再进行适度抽象把分供应链的相关订单实体进行合并后生成订单实体（数据整合层3NF），后续在数据整合层的订单实体基础上再扩展部分维度信息来完成后续层次的建设。\n\n![订单主题](/assets/images/2017/05/26/hotel_dw_layer_topic/006.png)\n\n#### 流量主题\n\n流量主题与订单主题的区别是非常大的，它的数据来源具有一定的特殊性，我们的总体建设思路是总-分-总的思路，首先从总的日志数据中剥离出来属于酒旅事业群的数据，后续再从这些数据中分拆到各个具体的页面（可以适当补充些各个页面中所具有的B端信息，如POI详情页中增加POI品类信息），最后再把各个页面进行合并生成总的日志主题表（最终这张表会满足80%以上的相关流量统计需求）。\n\n![流量主题](/assets/images/2017/05/26/hotel_dw_layer_topic/007.png)\n\n#### 运营主题\n\n运营主题与订单、流量主题相比也具有自身的特殊性，主要原因也在于其数据来源本身的特殊性，关于它的建设思路总体也是总-分-总，但我们本身的数据来源大多已经不是最底层的ODS数据，而是一些已经加工过的事实表或维度表，所以我们整体的建模原则基本上都是维度建模。\n\n![运营主题1](/assets/images/2017/05/26/hotel_dw_layer_topic/008.png)\n\n![运营主题2](/assets/images/2017/05/26/hotel_dw_layer_topic/009.png)\n\n基于上面介绍的几个主题，我们实际上在做分主题的层次架构时也是基于本主题的业务、数据特点作为最终的判断条件，没有绝对的一种层次架构适用于所有的主题，需要综合各项要素来进行综合判断才能设计比较合适的层次架构。\n\n### 作者简介\n\n德臣，美团点评酒旅事业群数据仓库专家，2003年毕业于湖南大学，2015年加入美团，整体负责酒旅事业群的离线数据仓库、实时数据仓库建设。\n\n酒旅数据仓库团队，结合酒旅业务的发展，灵活利用大数据生态链的相关技术，致力于离线数据仓库与实时数据仓库的建设，为业务提供多样化的数据服务。\n\n**最后发个广告，美团点评酒旅数据仓库团队长期招聘数据仓库、大数据开发、数据产品开发等方向的技术专家，有兴趣的同学可以发送简历到yangdechen#meituan.com。**\n\n---\n\n* Author: 德臣\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [美团点评酒旅数据仓库建设实践](https://tech.meituan.com/hotel_dw_layer_topic.html)\n","tags":["Topic"],"categories":["Warehouse"]},{"title":"磁盘I/O那些事","url":"%2F2017%2F2017-05-19-about-desk-io%2F","content":"\n### **背景**\n\n计算机硬件性能在过去十年间的发展普遍遵循摩尔定律，通用计算机的CPU主频早已超过3GHz，内存也进入了普及DDR4的时代。然而传统硬盘虽然在存储容量上增长迅速，但是在读写性能上并无明显提升，同时SSD硬盘价格高昂，不能在短时间内完全替代传统硬盘。传统磁盘的I/O读写速度成为了计算机系统性能提高的瓶颈，制约了计算机整体性能的发展。\n\n硬盘性能的制约因素是什么？如何根据磁盘I/O特性来进行系统设计？针对这些问题，本文将介绍硬盘的物理结构和性能指标，以及操作系统针对磁盘性能所做的优化，最后讨论下基于磁盘I/O特性设计的技巧。\n\n### **硬盘的物理结构**\n\n硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：\n\n![磁盘结构](/assets/images/2017/05/19/about-desk-io/001.jpg)\n\n由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区，硬盘中每个扇区的大小固定为512字节。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示：\n\n![磁盘垂直视角](/assets/images/2017/05/19/about-desk-io/002.png)\n\n早期的硬盘每磁道扇区数相同，此时由磁盘基本参数可以计算出硬盘的容量：存储容量=磁头数*磁道（柱面）数*每道扇区数*每扇区字节数。由于每磁道扇区数相同，外圈磁道半径大，里圈磁道半径小，外圈和里圈扇区面积自然会不一样。同时，为了更好的读取数据，即使外圈扇区面积再大也只能和内圈扇区一样存放相同的字节数（512字节）。这样一来，外圈的记录密度就要比内圈小，会浪费大量的存储空间。\n\n如今的硬盘都使用ZBR（Zoned Bit Recording，区位记录）技术，盘片表面由里向外划分为数个区域，不同区域的磁道扇区数目不同，同一区域内各磁道扇区数相同，盘片外圈区域磁道长扇区数目较多，内圈区域磁道短扇区数目较少，大体实现了等密度，从而获得了更多的存储空间。此时，由于每磁道扇区数各不相同，所以传统的容量计算公式就不再适用。实际上如今的硬盘大多使用LBA（Logical Block Addressing）逻辑块寻址模式，知道LBA后即可计算出硬盘容量。\n\n### **影响硬盘性能的因素**\n\n影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。\n\n#### 1. 寻道时间\n\nTseek是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3-15ms。\n\n#### 2. 旋转延迟\n\nTrotation是指盘片旋转将请求数据所在的扇区移动到读写磁盘下方所需要的时间。旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的1/2表示。比如：7200rpm的磁盘平均旋转延迟大约为60*1000/7200/2 = 4.17ms，而转速为15000rpm的磁盘其平均旋转延迟为2ms。\n\n#### 3. 数据传输时间\n\nTtransfer是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前IDE/ATA能达到133MB/s，SATA II可达到300MB/s的接口数据传输率，数据传输时间通常远小于前两部分消耗时间。简单计算时可忽略。\n\n### **衡量性能的指标**\n\n机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。\n\n#### 1. IOPS\n\nIOPS（Input/Output Per Second）即每秒的输入输出量（或读写次数），即指每秒内系统能处理的I/O请求数量。随机读写频繁的应用，如小文件存储等，关注随机读写性能，IOPS是关键衡量指标。可以推算出磁盘的IOPS = 1000ms / (Tseek + Trotation + Transfer)，如果忽略数据传输时间，理论上可以计算出随机读写最大的IOPS。常见磁盘的随机读写最大IOPS为：\n\n*   7200rpm的磁盘 IOPS = 76 IOPS\n*   10000rpm的磁盘IOPS = 111 IOPS\n*   15000rpm的磁盘IOPS = 166 IOPS\n\n#### 2. 吞吐量\n\n吞吐量（Throughput），指单位时间内可以成功传输的数据数量。顺序读写频繁的应用，如视频点播，关注连续读写性能、数据吞吐量是关键衡量指标。它主要取决于磁盘阵列的架构，通道的大小以及磁盘的个数。不同的磁盘阵列存在不同的架构，但他们都有自己的内部带宽，一般情况下，内部带宽都设计足够充足，不会存在瓶颈。磁盘阵列与服务器之间的数据通道对吞吐量影响很大，比如一个2Gbps的光纤通道，其所能支撑的最大流量仅为250MB/s。最后，当前面的瓶颈都不再存在时，硬盘越多的情况下吞吐量越大。\n\n### **操作系统层的优化**\n\n虽然15000rpm的磁盘计算出的理论最大IOPS仅为166，但在实际运行环境中，实际磁盘的IOPS往往能够突破200甚至更高。这其实就是在系统调用过程中，操作系统进行了一系列的优化。\n\n那么操作系统是如何操作硬盘的呢？类似于网络的分层结构，下图显示了Linux系统中对于磁盘的一次读请求在核心空间中所要经历的层次模型。从图中看出：对于磁盘的一次读请求，首先经过虚拟文件系统层（VFS Layer），其次是具体的文件系统层（例如Ext2），接下来是Cache层（Page Cache Layer）、通用块层（Generic Block Layer）、I/O调度层（I/O Scheduler Layer）、块设备驱动层（Block Device Driver Layer），最后是物理块设备层（Block Device Layer）。\n\n![系统调用在核心空间中的处理层次](/assets/images/2017/05/19/about-desk-io/003.png)\n\n#### 虚拟文件系统层（VFS Layer）\n\nVFS（Virtual File System）虚拟文件系统是一种软件机制，更确切的说扮演着文件系统管理者的角色，与它相关的数据结构只存在于物理内存当中。它的作用是：屏蔽下层具体文件系统操作的差异，为上层的操作提供一个统一的接口。正是因为有了这个层次，Linux中允许众多不同的文件系统共存并且对文件的操作可以跨文件系统而执行。\n\nVFS中包含着向物理文件系统转换的一系列数据结构，如VFS超级块、VFS的Inode、各种操作函数的转换入口等。Linux中VFS依靠四个主要的数据结构来描述其结构信息，分别为超级块、索引结点、目录项和文件对象。\n\n1.  超级块（Super Block）：超级块对象表示一个文件系统。它存储一个已安装的文件系统的控制信息，包括文件系统名称（比如Ext2）、文件系统的大小和状态、块设备的引用和元数据信息（比如空闲列表等等）。VFS超级块存在于内存中，它在文件系统安装时建立，并且在文件系统卸载时自动删除。同时需要注意的是对于每个具体的文件系统来说，也有各自的超级块，它们存放于磁盘。\n\n2.  索引结点（Inode）：索引结点对象存储了文件的相关元数据信息，例如：文件大小、设备标识符、用户标识符、用户组标识符等等。Inode分为两种：一种是VFS的Inode，一种是具体文件系统的Inode。前者在内存中，后者在磁盘中。所以每次其实是将磁盘中的Inode调进填充内存中的Inode，这样才是算使用了磁盘文件Inode。当创建一个文件的时候，就给文件分配了一个Inode。一个Inode只对应一个实际文件，一个文件也会只有一个Inode。\n\n3.  目录项（Dentry）：引入目录项对象的概念主要是出于方便查找文件的目的。不同于前面的两个对象，目录项对象没有对应的磁盘数据结构，只存在于内存中。一个路径的各个组成部分，不管是目录还是普通的文件，都是一个目录项对象。如，在路径/home/source/test.java中，目录 /, home, source和文件 test.java都对应一个目录项对象。VFS在查找的时候，根据一层一层的目录项找到对应的每个目录项的Inode，那么沿着目录项进行操作就可以找到最终的文件。\n\n4.  文件对象（File）：文件对象描述的是进程已经打开的文件。因为一个文件可以被多个进程打开，所以一个文件可以存在多个文件对象。一个文件对应的文件对象可能不是惟一的，但是其对应的索引节点和目录项对象肯定是惟一的。\n\n#### Ext2文件系统\n\nVFS的下一层即是具体的文件系统，本节简要介绍下Linux的Ext2文件系统。\n\n一个文件系统一般使用块设备上一个独立的逻辑分区。对于Ext2文件系统来说，硬盘分区首先被划分为一个个的Block，一个Ext2文件系统上的每个Block都是一样大小的。但是不同Ext2文件系统，Block大小可能不同，这是在创建Ext2系统决定的，一般为1k或者4k。由于Block数量很多，为了方便管理，Ext2将这些Block聚集在一起分为几个大的块组（Block Group），每个块组包含的等量的物理块，在块组的数据块中存储文件或目录。Ext2文件系统存储结构如下图所示：\n\n![ext2文件系统存储结构](/assets/images/2017/05/19/about-desk-io/004.png)\n\nExt2中的Super Block和Inode Table分别对应VFS中的超级块和索引结点，存放在磁盘。每个块组都有一个块组描述符GDT（Group Descriptor Table），存储一个块组的描述信息，例如在这个块组中从哪里开始是Inode表，从哪里开始是数据块等等。Block Bitmap和Inode Bitmap分别表示Block和Inode是否空闲可用。Data Block数据块是用来真正存储文件内容数据的地方，下面我们看一下具体的存储规则。\n\n在Ext2文件系统中所支持的Block大小有1K、2K、4K三种。在格式化时Block的大小就固定了，且每个Block都有编号，方便Inode的记录。每个Block内最多只能够放置一个文件的数据，如果文件大于Block的大小，则一个文件会占用多个Block；如果文件小于Block，则该Block的剩余容量就不能够再被使用了，即磁盘空间会浪费。下面看看Inode和Block的对应关系。\n\nInode要记录的数据非常多，但大小仅为固定的128字节，同时记录一个Block号码就需要4字节，假设一个文件有400MB且每个Block为4K时，那么至少也要十万笔Block号码的记录。Inode不可能有这么多的记录信息，因此Ext2将Inode记录Block号码的区域定义为12个直接、一个间接、一个双间接与一个三间接记录区。Inode存储结构如下图所示：\n\n![inode结构示意图](/assets/images/2017/05/19/about-desk-io/005.png)\n\n最左边为Inode本身（128 bytes），里面有12个直接指向Block号码的对照，这12笔记录能够直接取得Block号码。至于所谓的间接就是再拿一个Block来当作记录Block号码的记录区，如果文件太大时，就会使用间接的Block来记录编号。如上图当中间接只是拿一个Block来记录额外的号码而已。 同理，如果文件持续长大，那么就会利用所谓的双间接，第一个Block仅再指出下一个记录编号的Block在哪里，实际记录的在第二个Block当中。依此类推，三间接就是利用第三层Block来记录编号。\n\n#### Page Cache层\n\n引入Cache层的目的是为了提高Linux操作系统对磁盘访问的性能。Cache层在内存中缓存了磁盘上的部分数据。当数据的请求到达时，如果在Cache中存在该数据且是最新的，则直接将数据传递给用户程序，免除了对底层磁盘的操作，提高了性能。Cache层也正是磁盘IOPS为什么能突破200的主要原因之一。\n\n在Linux的实现中，文件Cache分为两个层面，一是Page Cache，另一个Buffer Cache，每一个Page Cache包含若干Buffer Cache。Page Cache主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有read/write操作的时候。Buffer Cache则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。\n\n磁盘Cache有两大功能：预读和回写。预读其实就是利用了局部性原理，具体过程是：对于每个文件的第一个读请求，系统读入所请求的页面并读入紧随其后的少数几个页面（通常是三个页面），这时的预读称为同步预读。对于第二次读请求，如果所读页面不在Cache中，即不在前次预读的页中，则表明文件访问不是顺序访问，系统继续采用同步预读；如果所读页面在Cache中，则表明前次预读命中，操作系统把预读页的大小扩大一倍，此时预读过程是异步的，应用程序可以不等预读完成即可返回，只要后台慢慢读页面即可，这时的预读称为异步预读。任何接下来的读请求都会处于两种情况之一：第一种情况是所请求的页面处于预读的页面中，这时继续进行异步预读；第二种情况是所请求的页面处于预读页面之外，这时系统就要进行同步预读。\n\n回写是通过暂时将数据存在Cache里，然后统一异步写到磁盘中。通过这种异步的数据I/O模式解决了程序中的计算速度和数据存储速度不匹配的鸿沟，减少了访问底层存储介质的次数，使存储系统的性能大大提高。Linux 2.6.32内核之前，采用pdflush机制来将脏页真正写到磁盘中，什么时候开始回写呢？下面两种情况下，脏页会被写回到磁盘：\n\n1.  在空闲内存低于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。\n2.  当脏页在内存中驻留超过一定的阈值时，内核必须将超时的脏页写会磁盘，以确保脏页不会无限期地驻留在内存中。\n\n回写开始后，pdflush会持续写数据，直到满足以下两个条件：\n\n1.  已经有指定的最小数目的页被写回到磁盘。\n2.  空闲内存页已经回升，超过了阈值。\n\nLinux 2.6.32内核之后，放弃了原有的pdflush机制，改成了bdi_writeback机制。bdi_writeback机制主要解决了原有fdflush机制存在的一个问题：在多磁盘的系统中，pdflush管理了所有磁盘的Cache，从而导致一定程度的I/O瓶颈。bdi_writeback机制为每个磁盘都创建了一个线程，专门负责这个磁盘的Page Cache的刷新工作，从而实现了每个磁盘的数据刷新在线程级的分离，提高了I/O性能。\n\n回写机制存在的问题是回写不及时引发数据丢失（可由sync|fsync解决），回写期间读I/O性能很差。\n\n#### 通用块层\n\n通用块层的主要工作是：接收上层发出的磁盘请求，并最终发出I/O请求。该层隐藏了底层硬件块设备的特性，为块设备提供了一个通用的抽象视图。\n\n对于VFS和具体的文件系统来说，块（Block）是基本的数据传输单元，当内核访问文件的数据时，它首先从磁盘上读取一个块。但是对于磁盘来说，扇区是最小的可寻址单元，块设备无法对比它还小的单元进行寻址和操作。由于扇区是磁盘的最小可寻址单元，所以块不能比扇区还小，只能整数倍于扇区大小，即一个块对应磁盘上的一个或多个扇区。一般来说，块大小是2的整数倍，而且由于Page Cache层的最小单元是页（Page），所以块大小不能超过一页的长度。\n\n大多情况下，数据的传输通过DMA方式。旧的磁盘控制器，仅仅支持简单的DMA操作：每次数据传输，只能传输磁盘上相邻的扇区，即数据在内存中也是连续的。这是因为如果传输非连续的扇区，会导致磁盘花费更多的时间在寻址操作上。而现在的磁盘控制器支持“分散/聚合”DMA操作，这种模式下，数据传输可以在多个非连续的内存区域中进行。为了利用“分散/聚合”DMA操作，块设备驱动必须能处理被称为段（segments）的数据单元。一个段就是一个内存页面或一个页面的部分，它包含磁盘上相邻扇区的数据。\n\n通用块层是粘合所有上层和底层的部分，一个页的磁盘数据布局如下图所示：\n\n![页内磁盘数据布局](/assets/images/2017/05/19/about-desk-io/006.png)\n\n#### I/O调度层\n\nI/O调度层的功能是管理块设备的请求队列。即接收通用块层发出的I/O请求，缓存请求并试图合并相邻的请求。并根据设置好的调度算法，回调驱动层提供的请求处理函数，以处理具体的I/O请求。 \n\n如果简单地以内核产生请求的次序直接将请求发给块设备的话，那么块设备性能肯定让人难以接受，因为磁盘寻址是整个计算机中最慢的操作之一。为了优化寻址操作，内核不会一旦接收到I/O请求后，就按照请求的次序发起块I/O请求。为此Linux实现了几种I/O调度算法，算法基本思想就是通过合并和排序I/O请求队列中的请求，以此大大降低所需的磁盘寻道时间，从而提高整体I/O性能。\n\n常见的I/O调度算法包括Noop调度算法（No Operation）、CFQ（完全公正排队I/O调度算法）、DeadLine（截止时间调度算法）、AS预测调度算法等。\n\n*   Noop算法：最简单的I/O调度算法。该算法仅适当合并用户请求，并不排序请求。新的请求通常被插在调度队列的开头或末尾，下一个要处理的请求总是队列中的第一个请求。这种算法是为不需要寻道的块设备设计的，如SSD。因为其他三个算法的优化是基于缩短寻道时间的，而SSD硬盘没有所谓的寻道时间且I/O响应时间非常短。\n\n*   CFQ算法：算法的主要目标是在触发I/O请求的所有进程中确保磁盘I/O带宽的公平分配。算法使用许多个排序队列，存放了不同进程发出的请求。通过散列将同一个进程发出的请求插入同一个队列中。采用轮询方式扫描队列，从第一个非空队列开始，依次调度不同队列中特定个数（公平）的请求，然后将这些请求移动到调度队列的末尾。\n\n*   Deadline算法：算法引入了两个排队队列分别包含读请求和写请求，两个最后期限队列包含相同的读和写请求。本质就是一个超时定时器，当请求被传给电梯算法时开始计时。一旦最后期限队列中的超时时间已到，就想请求移至调度队列末尾。Deadline算法避免了电梯调度策略（为了减少寻道时间，会优先处理与上一个请求相近的请求）带来的对某个请求忽略很长一段时间的可能。\n\n*   AS算法：AS算法本质上依据局部性原理，预测进程发出的读请求与刚被调度的请求在磁盘上可能是“近邻”。算法统计每个进程I/O操作信息，当刚刚调度了由某个进程的一个读请求之后，算法马上检查排序队列中的下一个请求是否来自同一个进程。如果是，立即调度下一个请求。否则，查看关于该进程的统计信息，如果确定进程p可能很快发出另一个读请求，那么就延迟一小段时间。\n\n前文中计算出的IOPS是理论上的随机读写的最大IOPS，在随机读写中，每次I/O操作的寻址和旋转延时都不能忽略不计，有了这两个时间的存在也就限制了IOPS的大小。现在如果我们考虑在读取一个很大的存储连续分布在磁盘的文件，因为文件的存储的分布是连续的，磁头在完成一个读I/O操作之后，不需要重新寻址，也不需要旋转延时，在这种情况下我们能到一个很大的IOPS值。这时由于不再考虑寻址和旋转延时，则性能瓶颈仅是数据传输时延，假设数据传输时延为0.4ms，那么IOPS=1000 / 0.4 = 2500 IOPS。\n\n在许多的开源框架如Kafka、HBase中，都通过追加写的方式来尽可能的将随机I/O转换为顺序I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高IOPS。\n\n#### 块设备驱动层\n\n驱动层中的驱动程序对应具体的物理块设备。它从上层中取出I/O请求，并根据该I/O请求中指定的信息，通过向具体块设备的设备控制器发送命令的方式，来操纵设备传输数据。这里不再赘述。\n\n### **基于磁盘I/O特性设计的技巧**\n\n在上一节中我们了解了Linux系统中请求到达磁盘的一次完整过程，期间Linux通过Cache以及排序合并I/O请求来提高系统的性能。其本质就是由于磁盘随机读写慢、顺序读写快。本节针对常见开源系统阐述一些基于磁盘I/O特性的设计技巧。\n\n#### 采用追加写\n\n在进行系统设计时，良好的读性能和写性能往往不可兼得。在许多常见的开源系统中都是优先在保证写性能的前提下来优化读性能。那么如何设计能让一个系统拥有良好的写性能呢？一个好的办法就是采用追加写，每次将数据添加到文件。由于完全是顺序的，所以可以具有非常好的写操作性能。但是这种方式也存在一些缺点：从文件中读一些数据时将会需要更多的时间：需要倒序扫描，直到找到所需要的内容。当然在一些简单的场景下也能够保证读操作的性能：\n\n*   数据是被整体访问，比如HDFS\n\n*   HDFS建立在一次写多次读的模型之上。在HDFS中就是采用了追加写并且设计为高数据吞吐量；高吞吐量必然以高延迟为代价，所以HDFS并不适用于对数据访问要求低延迟的场景；由于采用是的追加写，也并不适用于任意修改文件的场景。HDFS设计为流式访问大文件，使用大数据块并且采用流式数据访问来保证数据被整体访问，同时最小化硬盘的寻址开销，只需要一次寻址即可，这时寻址时间相比于传输时延可忽略，从而也拥有良好的读性能。HDFS不适合存储小文件，原因之一是由于NameNode内存不足问题，还有就是因为访问大量小文件需要执行大量的寻址操作，并且需要不断的从一个datanode跳到另一个datanode，这样会大大降低数据访问性能。\n\n*   知道文件明确的偏移量，比如Kafka\n\n*   在Kafka中，采用消息追加的方式来写入每个消息，每个消息读写时都会利用Page Cache的预读和后写特性，同时partition中都使用顺序读写，以此来提高I/O性能。虽然Kafka能够根据偏移量查找到具体的某个消息，但是查找过程是顺序查找，因此如果数据很大的话，查找效率就很低。所以Kafka中采用了分段和索引的方式来解决查找效率问题。Kafka把一个patition大文件又分成了多个小文件段，每个小文件段以偏移量命名，通过多个小文件段，不仅可以使用二分搜索法很快定位消息，同时也容易定期清除或删除已经消费完的文件，减少磁盘占用。为了进一步提高查找效率，Kafka为每个分段后的数据建立了索引文件，并通过索引文件稀疏存储来降低元数据占用大小。一个段中数据对应结构如下图所示：\n\n![kafka中一个段的物理结构](/assets/images/2017/05/19/about-desk-io/007.png)\n\n在面对更复杂的读场景（比如按key）时，如何来保证读操作的性能呢？简单的方式是像Kafka那样，将文件数据有序保存，使用二分查找来优化效率；或者通过建索引的方式来进行优化；也可以采用hash的方式将数据分割为不同的桶。以上的方法都能增加读操作的性能，但是由于在数据上强加了数据结构，又会降低写操作的性能。比如如果采用索引的方式来优化读操作，那么在更新索引时就需要更新B-tree中的特定部分，这时候的写操作就是随机写。那么有没有一种办法在保证写性能不损失的同时也提供较好的读性能呢？一个好的选择就是使用LSM-tree。LSM-tree与B-tree相比，LSM-tree牺牲了部分读操作，以此大幅提高写性能。\n\n*   日志结构的合并树LSM（The Log-Structured Merge-Tree）是HBase，LevelDB等NoSQL数据库的存储引擎。Log-Structured的思想是将整个磁盘看做一个日志，在日志中存放永久性数据及其索引，每次都添加到日志的末尾。并且通过将很多小文件的存取转换为连续的大批量传输，使得对于文件系统的大多数存取都是顺序的，从而提高磁盘I/O。LSM-tree就是这样一种采用追加写、数据有序以及将随机I/O转换为顺序I/O的延迟更新，批量写入硬盘的数据结构。LSM-tree将数据的修改增量先保存在内存中，达到指定的大小限制后再将这些修改操作批量写入磁盘。因此比较旧的文件不会被更新，重复的纪录只会通过创建新的纪录来覆盖，这也就产生了一些冗余的数据。所以系统会周期性的合并一些数据，移除重复的更新或者删除纪录，同时也会删除上述的冗余。在进行读操作时，如果内存中没有找到相应的key，那么就是倒序从一个个磁盘文件中查找。如果文件越来越多那么读性能就会越来越低，目前的解决方案是采用页缓存来减少查询次数，周期合并文件也有助于提高读性能。在文件越来越多时，可通过布隆过滤器来避免大量的读文件操作。LSM-tree牺牲了部分读性能，以此来换取写入的最大化性能，特别适用于读需求低，会产生大量插入操作的应用环境。\n\n##### 文件合并和元数据优化\n\n目前的大多数文件系统，如XFS/Ext4、GFS、HDFS，在元数据管理、缓存管理等实现策略上都侧重大文件。上述基于磁盘I/O特性设计的系统都有一个共性特点就是都运行在这些文件系统之上。这些文件系统在面临海量时在性能和存储效率方面都大幅降低，本节来探讨下海量小文件下的系统设计。\n\n常见文件系统在海量小文件应用下性能表现不佳的根本原因是磁盘最适合顺序的大文件I/O读写模式，而非常不适合随机的小文件I/O读写模式。主要原因体现在元数据管理低效和数据布局低效：\n\n*   元数据管理低效：由于小文件数据内容较少，因此元数据的访问性能对小文件访问性能影响巨大。Ext2文件系统中Inode和Data Block分别保存在不同的物理位置上，一次读操作需要至少经过两次的独立访问。在海量小文件应用下，Inode的频繁访问，使得原本的并发访问转变为了海量的随机访问，大大降低了性能。另外，大量的小文件会快速耗尽Inode资源，导致磁盘尽管有大量Data Block剩余也无法存储文件，会浪费磁盘空间。\n\n*   数据布局低效：Ext2在Inode中使用多级指针来索引数据块。对于大文件，数据块的分配会尽量连续，这样会具有比较好的空间局部性。但是对于小文件，数据块可能零散分布在磁盘上的不同位置，并且会造成大量的磁盘碎片，不仅造成访问性能下降，还大量浪费了磁盘空间。数据块一般为1KB、2KB或4KB，对于小于4KB的小文件，Inode与数据的分开存储破坏了空间局部性，同时也造成了大量的随机I/O。\n\n对于海量小文件应用，常见的I/O流程复杂也是造成磁盘性能不佳的原因。对于小文件，磁盘的读写所占用的时间较少，而用于文件的open()操作占用了绝大部分系统时间，导致磁盘有效服务时间非常低，磁盘性能低下。针对于问题的根源，优化的思路大体上分为：\n\n1.  针对数据布局低效，采用小文件合并策略，将小文件合并为大文件。\n2.  针对元数据管理低效，优化元数据的存储和管理。针对这两种优化方式，业内也出现了许多优秀的开源软件。\n\n**小文件合并**\n\n小文件合并为大文件后，首先减少了大量元数据，提高了元数据的检索和查询效率，降低了文件读写的I/O操作延时。其次将可能连续访问的小文件一同合并存储，增加了文件之间的局部性，将原本小文件间的随机访问变为了顺序访问，大大提高了性能。同时，合并存储能够有效的减少小文件存储时所产生的磁盘碎片问题，提高了磁盘的利用率。最后，合并之后小文件的访问流程也有了很大的变化，由原来许多的open操作转变为了seek操作，定位到大文件具体的位置即可。如何寻址这个大文件中的小文件呢？其实就是利用一个旁路数据库来记录每个小文件在这个大文件中的偏移量和长度等信息。其实小文件合并的策略本质上就是通过分层的思想来存储元数据。中控节点存储一级元数据，也就是大文件与底层块的对应关系；数据节点存放二级元数据，也就是最终的用户文件在这些一级大块中的存储位置对应关系，经过两级寻址来读写数据。\n\n*   淘宝的TFS就采用了小文件合并存储的策略。TFS中默认Block大小为64M，每个块中会存储许多不同的小文件，但是这个块只占用一个Inode。假设一个Block为64M，数量级为1PB。那么NameServer上会有 1 _ 1024 _ 1024 * 1024 / 64 = 16.7M个Block。假设每个Block的元数据大小为0.1K，则占用内存不到2G。在TFS中，文件名中包含了Block ID和File ID，通过Block ID定位到具体的DataServer上，然后DataServer会根据本地记录的信息来得到File ID所在Block的偏移量，从而读取到正确的文件内容。TFS一次读过程如下图所示：\n\n![tfs_read](/assets/images/2017/05/19/about-desk-io/008.png)\n\n**元数据管理优化**\n\n一般来说元数据信息包括名称、文件大小、设备标识符、用户标识符、用户组标识符等等，在小文件系统中可以对元数据信息进行精简，仅保存足够的信息即可。元数据精简可以减少元数据通信延时，同时相同容量的Cache能存储更多的元数据，从而提高元数据使用效率。另外可以在文件名中就包含元数据信息，从而减少一个元数据的查询操作。最后针对特别小的一些文件，可以采取元数据和数据并存的策略，将数据直接存储在元数据之中，通过减少一次寻址操作从而大大提高性能。\n\n*   TFS中文件命名就隐含了位置信息等部分元数据，从而减少了一个元数据的查询操作。在Rerserfs中，对于小于1KB的小文件，Rerserfs可以将数据直接存储在Inode中。\n\n### **总结**\n\n本文从磁盘性能指标出发，探究了操作系统与磁盘的交互以及对磁盘读写的优化，最后列举了一些常用开源系统中基于磁盘I/O特性的设计特点。期望通过展现磁盘I/O的特性，为存储系统设计和解决一些系统性能问题提供一种新思路。 \n\n### **作者介绍**\n\n喻枭，2016年加入美团点评，就职于美团点评酒店旅游事业群境内度假研发组。专注Java后台开发，对并发编程和大数据有浓厚兴趣。\n\n**最后发个广告，美团点评酒旅事业群境内度假研发组长期招聘Java后台、架构方面的人才，有兴趣的同学可以发送简历到jinmengzhe#meituan.com。**\n\n### **参考**\n\n1.  IBM developerWorks，[AIX 下磁盘 I/O 性能分析](https://www.ibm.com/developerworks/cn/aix/library/1203_weixy_aixio/)，2012。\n2.  CSDN博客频道，[磁盘性能评价指标—IOPS和吞吐量](http://blog.csdn.net/hanchengxi/article/details/19089589)，2014。\n3.  IBM developerWorks，[read 系统调用剖析](https://www.ibm.com/developerworks/cn/linux/l-cn-read/)，2008。\n4.  IBM developerWorks，[从文件 I/O 看 Linux 的虚拟文件系统](https://www.ibm.com/developerworks/cn/linux/l-cn-vfs/)，2007。\n5.  CSDN博客频道，[Linux文件系统预读](http://blog.csdn.net/kai_ding/article/details/17322787)，2013。\n6.  Linux Kernel Exploration，[Linux通用块设备层](http://www.ilinuxkernel.com/files/Linux.Generic.Block.Layer.pdf)。\n7.  CSDN博客频道，[Linux块设备的IO调度算法和回写机制](http://blog.csdn.net/hustyangju/article/details/40507647)，2014。\n8.  Apache，[Kafka](http://kafka.apache.org/)。\n9.  Taobao，[Taobao File System](http://tfs.taobao.org/)。\n\n---\n\n* Author: 喻枭\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [磁盘I/O那些事](https://tech.meituan.com/about-desk-io.html)\n","tags":["IO"],"categories":["IO"]},{"title":"从Google白皮书看企业安全最佳实践","url":"%2F2017%2F2017-02-21-google-infrastructure-security-design-overview%2F","content":"\n前不久Google发布了一份安全方面的白皮书[_Google Infrastructure Security Design Overview_](https://cloud.google.com/security/security-design/)，直译的版本可以参考“网路冷眼”这版《[Google基础设施安全设计概述](http://mp.weixin.qq.com/s/ZeWIcLb414J3tlIB-TSbbw)》，直译+点评的版本可以参考“职业欠钱”的《[Google基础设施安全设计概述翻译和导读](https://security.tencent.com/index.php/blog/msg/114)》。\n\n此前Google在安全领域披露的信息一直很少，适逢其大力发展云计算业务，需要展示云安全方面的实力，才有了这份白皮书。它从系统的角度描述了自己安全体系的设计与实现，对广大互联网、云计算公司的安全小伙伴而言可谓一大福利。本文中，笔者将从一个企业安全建设者的角度，说说自己的感想，并做一些解读。\n\n### 几点感想\n\n1.  国内很多公司的安全团队都是游离在产品研发、基础架构和SRE团队之外的，HIDS、WAF、大数据的SOC，说到底这些东西安全团队自己就可以搞定，基本不需要其他部门的支援和介入，这和乙方安全公司提供的一套外科手术般的解决方案的思路是一脉相承的。而Google的安全体系给人的感觉是跟基础设施深度融合，完全内置于产品设计和研发过程之中，从顶层设计的视角看完全是两种流派：内置的安全机制vs外挂的防护体系。\n\n2.  没有业界安全大会上那些花俏的概念和名词，全都是正统的安全设计思路，以既有的简单的安全手段解决复杂的问题，有如教科书般的绅士风格。\n\n3.  工程化大于单点技术突破。尽管Google有Project Zero、有不少牛人，不过似乎没有特别强调单点技术，更多体现的是在一个海量的规模下解决安全问题的工程化能力。\n\n4.  在产品服务基础架构层面可以看到Google有一个清晰的顶层架构设计，例如全局的IAM和Borg服务。尽管可能这个看似完整的体系也是一路迭代而来，但至少从现有的积累看，从全局的层次抽象，全局资源鉴权，收敛统一用户和流量入口，收敛分散的认证&amp;鉴权点，在每一个对应的抽象层次上做纵深防御，全局的访问控制模型等等看上去更像是精心规划和设计出来的。\n\n5.  得益于Google自研的技术栈范围实在太广，因为一切皆自研，所以一切安全皆可DIY，对其他公司而言这反而是一个封闭的王国，因为不太可复制。\n\n6.  能否追的上这个安全体系，已经不取决于单点技术亦或是攻防技术是否ready，甚至不取决于安全团队的强弱，而是取决于公司所处的阶段和整体技术实力。\n\n### 整体安全体系图解\n\nGoogle原来的图有点类似于ISO27001，框架性很好，但也终归是一个对外的版本，信息披露上比较粗线条，对于更想在实践层面模仿的同学来说比较抽象，所以笔者以自己的理解重新归纳了两张图。第一张图展示了Google的整体IT环境，包括办公网络、生产网络以及交互通道的整体安全视图：\n\n![](/assets/images/2017/02/21/google-infrastructure-security-design-overview/1.jpg)\n\n假如一开始不好理解也没关系，先有个框架性认识。总体上可以抽象为办公网络和IDC都有纵深防御体系，研发环境属于办公网络之上的一个特殊子集（这里并没有披露内部IT的其它系统怎么建设的），办公网络和IDC生产环境之间有限的数据通道都做了风险控制，采用“2+2结构（2个纵深防体系+2个数据通道）”。\n\n第二张图再单独分解一下IDC的纵深防御体系：\n\n![](/assets/images/2017/02/21/google-infrastructure-security-design-overview/2.jpg)\n\n更具体的实现在后面的章节里展开，最后可以再回过头来看这张图。\n\n接下来，我们按照白皮书原文的顺序一一解读。\n\n#### CIO视角（宏观）\n\n关于CIO视角，我们要Get几个点：\n\n1.  Google有一个全球范围的基础架构，除了表达IDC基础设施的广泛程度外，也暗含了拥有全球范围的合规性。国内有少数比较大的互联网公司正在国际化的进程中，海外的合规性可能会成为一大挑战，国内公司中拥有成熟的全球合规性及全球化安全运营经验的大约只有华为和联想，其中华为又因为云计算和海外的手机云服务在这方面积累了其它国内公司暂时不可比拟的经验。Google有很多细微之处都提到了隐私保护，国内的因为法制不太成熟，没有太多的强制合规性以及公民隐私数据保护的压力，所以接下去对很多业务开始向海外扩展的公司，这些都会成为安全部门日历表上的待办事项。题外话：笔者在《互联网企业安全高级指南》一书中“隐私保护”一章写的其实是数据保护，意义有所偏差，打算第二版重写，有可能在美团点评技术博客先发表，敬请关注。\n\n2.  安全设计覆盖全生命周期，别提那些连SDL都没有实施的公司了，G厂显然是比SDL更高级的版本，强调“设计”二字。而国内拥有安全设计能力的从业者比较稀少，所以业界的话题和氛围上这方面都相对欠缺。\n\n3.  成本：500个专职工程师，其它方面也都是大手笔，但不确定在安全的投入上是不是“不计成本”的态度。\n\n#### 物理安全\n\nGoogle自有IDC的物理安全手段：生物识别、金属检测、摄像头、路障、激光入侵检测，同时Google要求使用的第三方IDC的物理安全措施对其完全可控。\n\n物理安全这件事哪怕在很多安全从业者心里也不过是ISO27001的一些章节和控制点，并非是很多人对于安全体系建设发自肺腑的真实需求，很多人对安全建设的认知往往是对抗线上入侵者。然而这也暗示了，不同的人、不同的厂商所建立的安全体系用来对抗的目标和范畴是完全不一样的。类似Google、Amazon、Apple这类公司他们的安全体系用来对抗的几大场景可以归纳为：黑客、第三方、雇员、IDC/云服务提供商、商业间谍、政府机构，对抗的强度依次上升。换言之，可以举例翻译为：即便我使用第三方的云服务，仍然可以保证自己的数据不被偷窥。对于成为国家基础设施的服务而言，实际上另一种不能明说的需求就是介于民用领域和军用领域之间的对抗需求。\n\n大量公司的安全体系主要是用来御外而不是防内的，所以供应链安全、数据泄露这等事情都很头疼。基于此推断，即便修完了所有的漏洞，做了入侵检测，也不足以对抗很多威胁，安全这件事做的好不好，更多的还是看你拿什么尺子来衡量。看完Google安全体系，笔者推测大多数人的反应是还是它做的已经远超出一般意义上的防黑客。\n\n#### 硬件安全\n\n对绝大多数公司而言都不会涉及这个章节，因为大多数公司也就顶多白牌服务器，而不是从主板到芯片全都自研。以前觉得华为、Apple这类公司用TC（可信计算）的概念还是用的比较多，但是感觉BAT都不玩这些，到后来分析iOS就一下明白了这个其实是由产品和服务所涉及的技术栈深度决定的，因为华为、Apple这类公司的产品线横跨硬件、OS和上层应用，而BAT等公司造轮子（自研）的范畴大多止于软件，所以很少涉及，甚至在这些公司早期的安全团队里大多数是由Web安全技能的人组成的业务驱动使然。\n\n从描述上看，Google硬件到底层软件栈的安全设计跟iOS基本是一致的，都是基于可信的思路，上一层（软件）验证下一层（硬件/固件）的完整性，并区分唯一标识。用唯一标识+信任链来鉴别是否合法的硬件来源（而不是IDC提供商在机房里偷梁换柱换了台服务器）。\n\n更上层的部分，例如引导程序、内核、启动镜像的完整性都是启动信任链的一般实现，有兴趣的同学可以参考一下iOS的设计与实现。硬件唯一标识会成为后面提到的全局访问控制体系的前提之一。\n\n这里还有一条很重要的信息：Google在自己的生产网络引入了NAC（网络接入控制）机制，这个安全手段本来是为OA办公网络的终端管理场景设计的，目的是区分不信任的终端不能接入（相对可信）的公司网络。这样做可以想象几个场景：假如机房管理员从回收垃圾那儿找到了废弃的服务器，数据也没被删除，即便进入了机房重新插网线也接入不了网络；甚至进一步推测，第三方供应商跑到IDC接上自己的MacBook想用Nmap扫描一把估计也不行。\n\n#### 服务部署\n\nGoogle在IDC内部服务治理上最大的不同是：不信任IDC内网（注明：尽管思路上可能有相似之处，但与G厂自家在办公网络的安全解决方案BeyondCorp不是一件事）。很多公司的IDC生产服务网络被设计为私有云模式（单租户），在安全上相对的信任IDC内网通信，通过2层/3层隔离或者类似IP白名单的方式来建立IDC内网的弱访问控制体系和信任模型。而Google则是天生设计成多租户（公有云）模式，把原本用于对终端用户（2C端）的认证鉴权机制完全用于IDC内网的服务间通讯，服务间通讯有完整的双向鉴权，是一个强访问控制体系。笔者推测这样做可能是有几方面的原因：\n\n*   同一个服务的不同实例可能被部署为跨物理机、跨机架甚至跨IDC，与其它的服务实例混合部署，原来相对集中的通过IP的访问控制模型已经不太适用于完全分布式的架构，过于分散的多点对多点的ACL规则想象一下就头疼，于是就出现一个情况：要么访问控制很粗很大条效果不明显，要么很细但是规则几乎没法写。\n\n*   第二个原因可能是由于server和服务实例规模数巨大引起的海量ACL条目难以维护的问题，干脆扔了，用完全的鉴权。\n\n*   如果用传统的访问控制手段，例如VXLAN隔离、交换机ACL、主机iptables规则会无法维持一个巨大的弹性内部网络，服务扩容时都会受到阻碍，监控、调试和诊断都会更难。之前有同学提出通过主机安全agent动态生成白名单的内网隔离思路，现在Google则在这个问题上给出了自己的解，这也揭开了我在《互联网企业安全高级指南》中没有写出来的部分:)。本质上这是由规模量变到质变引发的问题，如果你的IDC内网只有几台机器真没必要那么做。Google也强调了自己有做网络隔离和防止IP欺骗，但没有把这个当成主要手段。\n\n发布安全：Google的所有代码存储于一个集中的代码仓库，同时保留当前和过去的版本，每一个发布的二进制文件都能关联到构建时的源代码版本，这里暗示了Google有做白名单和完整性校验，其实Google和Amazon都有白名单，但这要求基础架构高度统一。发布时需要至少1人review同意（可以理解为在构建/发布系统中的workflow），任何对某个系统的更改需要系统的owner同意。统一的代码仓库，意味着发布的入口是唯一可控的，版本可唯一追溯，同时交叉的code review可以部分矫正一些内部的不良行为：例如开发人员安置后门，恶意彩蛋等。这实际上是Google研发文化的一部分，不一定是出于安全的原因，不过总而言之，安全是这个流程的受益者。以前有boss问过我离职程序员安置后门程序如何检测的问题，海量Web下不具有webshell &amp; sqli的特征，当初想到结对编程，交叉review，觉得有点理论化。Google给出了的解正好，防止钓鱼，同时防止内鬼，不只是简单的防外，而是防内外，覆盖整个价值链。\n\n同一个机器间的服务隔离，主要通过：Linux原生的用户空间隔离（Android的appid的原理），程序语言和kernel的沙箱，以及硬件虚拟化手段。对于涉及用户提交代码或文件的高风险服务例如Google App Engine &amp; Google Compute Engine会使用多层次隔离和纵深防御（如下图所示），另外对于集群管理和KMS等服务会使用专门的物理机。实际上一般情况下密钥管理会使用专有硬件HSM，至于集群管理服务使用专用机器推测一方面可能有一些完整性校验的安全强相关功能，另一方便可能跟集群管理服务本身的可用性要求及failover机制有关。\n\n![](/assets/images/2017/02/21/google-infrastructure-security-design-overview/3.jpg)\n\n业内一直有HIDS（Host-based Intrusion Detection System，主机入侵检测）的技术路线之争，大规模容器时代即将到来，技术路线的选择更是迫在眉睫。业界的一种看法是私有云以Linux用户态为主，关注运维需求，软件兼容性和server本身的可用性需求；另一种则是内核态，以纯安全视角的强掌控型实现为主。从Google的实现里似乎也可以得到启示：G厂走的是公有云，天然多租户模式，使用了内核态路线。当然对于效仿者而言，前提是：\n\n*   你有很强的保证kernel代码工程质量的能力。\n*   内部基础架构、组件高度统一，否则很可能会东施效颦。\n\nGoogle的内部服务访问控制可配置为特定的服务只允许指定的API或者指定的人才可以访问的模式，实现上通过Machine ID、Service ID、User ID放在一个全局命名空间来做访问控制的基础（注：2C端的访问控制是另外一套体系），支持Group对Group来做多对多的访问控制，同时提供了“two-party control”，即一个变更提交后需要由同group的另外一个管理员approve才能生效，这其实跟分布式事务中二阶段式提交是一个原理，为了保证最终一致性。Google在这些流程的问题上直接套用了工程理论。\n\nGoogle自身的工程师访问内部API需要通过这种认证鉴权模式，实际上暗含了另外一个课题：数据安全。这部分在业界比较受重视，但需求往往比较抽象，而在实现方式上更是没有统一的标准，Google的这种方式貌似歪打正着，把2C的鉴权模式用在生产网络和后台系统，实际上是对原来运维通道获取数据途径的更进一步收敛，保留强审计和日志，这样一并连数据安全也算解决了一部分，虽然不是全部。\n\nGoogle的内部服务提供全加密通讯的能力，例如HTTP封装成RPC，而RPC默认提供几种不同的加密强度：低价值数据只做完整性校验，高价值的用更强壮的加密等级，跨IDC传输流量自动加密。\n\n最后举了一个Gmail服务访问联系簿（contacts服务）例子来说明RPC调用的鉴权细粒度，如果ACL设置为允许Gmail访问联系簿这种细粒度是不够的，因为用户A可以越权访问用户B的联系簿，水平权限的这类问题扫描器不容易覆盖，干脆在架构设计上一并解决：RPC请求带用户的ticket走一个内部的SSO（单点认证鉴权）以验证是否可以访问对应的数据，这样就相当于内部的API调用在用户这个细粒度上做了一次全流量的鉴权，从架构上避免了水平权限类的问题。再次回到安全架构的顶层设计，Google的思路就是把所有分散的鉴权点集中起来，在一个高度抽象的层次上做好一件事，最大程度的隔离。\n\n#### 数据安全\n\nGoogle在数据安全（狭义的，指在IDC侧的部分）上实践的几点：\n\n*   Google是做静态数据全盘加密的。\n*   不直接写硬盘，而是通过BigTable、Spanner这种存储服务间接写持久化数据。\n*   数据加密与KMS关联，可以理解为用了对称加密，密钥中的一部分来自KMS。\n*   与用户ticket相关，可以推测为加密密钥链的顶层密钥每个用户唯一，且动态转换（rotate）。\n*   为了加解密性能采用硬件加速。\n*   数据销毁流程会使用两道独立的流程来验证（是否删除），不经过此流程的直接物理粉碎。\n*   Google说自己可以追踪每一块硬盘全生命周期的状态。\n\n上面的内容里除了文件加密那块会有一些技术复杂度，其他都是工程化的问题，想象一下随便去机房拔块硬盘偷数据应该是没戏了，但是对于绝大多数公司而言，能在IDC实现全盘加密而且很可能用的不是文件系统加密，这个是一个很大的工程，实现起来比较困难，所以Google能把这些方案都落地，说明领先了很多年。对于很多公司来说，全盘数据加密会导致IOPS大幅下降，依赖KMS服务可用性指标又会下降，数据丢失和恢复又成问题，所以能实施这些方案背后是整体技术的依赖。\n\n#### Internet通讯安全\n\n暴露在互联网通讯的安全部分总结一下就是几个点：\n\n*   有一个统一的接入层GFE（Google Front End）。\n*   接入层统一做TLS加密以及证书管理，避免业务各自为政。\n*   接入层解决了端口暴露外网的问题，虽然选择不信任IDC内网，但是内网仍然是比外网更安全的地方。\n*   接入层拥有规模优势，具备抗DDOS能力。\n*   骨干网传输、4层、7层流量负载均衡都有流量监测和上报流量行为数据的能力（可以理解为Google自己在这些环节实现了Anti-DDOS）。\n*   有一个中央流控服务，负责丢弃流量或限制阈值。\n*   接入层有一定的人机识别能力（根据设备、登录IP等做判断，大概是风控服务的基础组件）。\n*   因为OTP的2FA认证方式容易被钓鱼，所以现在转而用FIDO联盟的U2F的方式代替OTP。\n\n#### 运维安全\n\n1.  Google有一套完整的SDL机制来尽可能的保证交付的代码是安全的，这些手段包括：\n\n*   内部：集中代码管理，交叉review，安全的代码框架和Lib库、fuzzer、静态代码扫描、Web安全扫描器，有Web安全、密码学、操作系统安全等各领域的专家团负责安全设计review＆威胁建模，并且会持续的将这些安全经验沉淀为通用的安全库和工具等。\n*   外部：高额的漏洞奖励计划。\n*   开源软件：大多数公司对待开源软件的态度可能是跟随策略，即社区发布了补丁我跟着patching，而Google表现出的态度则是，将开源软件和自研软件同等对待，都实施SDL那套安全审计，在例如OpenSSL，KVM等软件上发现了不少CVE漏洞。\n\n2.  Google投入很多来保证自己的雇员设备不被黑：\n\n*   其中最重要的就是BeyondCorp项目，对办公网络进行改造、取消内网、整个OA系统云化，把原来基于物理位置的信任模型（公司办公网络的内网或者VPN接入到内网）改成根据雇员设备状态，用户生命周期内的行为动态的生成访问控制策略，访问控制的细粒度从VLAN/IP收敛为应用级别，例如到一个系统中的某些URL这样的权限。这种访问控制模型可以抑制被APT后横向渗透的受害范围，同时基于云化的方案可以为监控提供更多的数据来源。\n*   为了抵抗钓鱼攻击，雇员认证从OTP改成U2F。\n*   大量的终端管理行为：包括OS最新补丁、限制客户端软件安装、监控下载、浏览器扩展、访问的内容等。\n\n3.  降低内部风险：\n\n*   监控有基础设施访问权限的雇员（SRE、DBA……）的终端行为，持续评估并赋予工作所需要的最小权限。\n*   数据安全的场景再次出现：Google对生产环境debug数据脱敏，并且雇员对线上用户数据的访问会被底层hook的日志追踪，是否异常行为由安全团队监控，底层的hook在这里大约可以理解为劫持了一些终端和访问通道以及命令执行的信息，而数据脱敏则是一个很大的课题，尤其是海量数据。\n\n4.  入侵检测\n\n*   Google有成熟的基于各种设备、主机、网络、服务的日志监控，这个大约得益于Google自研的技术栈比较深，所以日志“打点”这块是不愁了，而对于很多其他公司而言还要自研一堆安全产品，可惜的是Google在这块几乎没怎么开源过。\n*   红蓝军对抗，基本上大公司的标配，有钱就可以玩的起来。\n\n#### Google云平台安全\n\nGCP（Google Cloud Platform）继承前述所有的安全能力。除此之外云平台特有的一些安全属性包括：\n\n*   给VM和VMM分配两个独立的服务ID，这样就可以区分哪些流量来自VM而哪些来自VMM。\n*   GCE（Google Compute Engine）持久化磁盘的静态数据会使用KMS产生的密钥自动加密。\n*   VM广域网之间的流量可自动加密。\n*   计划推VM内网的流量自动加密。\n*   KVM定制过，把一些控制和硬件模拟从内核转移到用户态进程中。\n*   对KVM做过模糊测试、静态扫描和人工审计，大部分KVM的漏洞都由Google发现。\n*   Google承诺不碰用户数据，但除了通篇提及的方式外好像也没特殊说明不碰用户数据的保证手段是什么。\n\n### 如何才能赶上Google\n\n尽管这有可能是一个伪命题，不过从积极的角度不妨来分析一下：\n\n首先这是一个公司规模强相关的命题，如果你的IT整体投入还比较小，或者IDC规模仍然不大的情况，上述安全体系方法论应该是不适用的，因为这是一个依靠大量自研，大型安全团队才能做起来的事情。在规模更小的情况下，很多场景会有TCO更低，更简单的解。但对于从业者来说显然还是大规模下的经验更有利于自身价值提升，所以后面还是要打个小广告。\n\n其次，跟公司所处的阶段强相关，如果公司处于相对早期，或者野蛮生长阶段，目标基本都是为了满足业务需求，风险偏好会更倾向于接受风险，同时公司所处的阶段会侧面反映出工程技术整体的成熟度，安全要做到Google那样是工程技术整体领先的结果，而不是安全单个职能突出的结果。\n\n第三方面跟文化和基因也有很大的关系，基因上看公司整体是由产品、运营还是技术驱动，由技术驱动或者有工程师文化的公司比较容易实现这一点，这点不展开想必读者也能理解。文化方面，长期有耐心的公司文化比经常拥抱变化的公司更容易实现，Google的安全建设体现的都是大工程，也许你会发现，把其中的技术点单拉出来很多都没有遥不可及，甚至在大一点的国内互联网公司单点技术都是ready的，但是要全面落地却要花上几年的时间，所以最大的差距不在于单点技术，而在于G厂已经all done并且很可能已经在新技术和新方向的路上。如同Apple在业务相对早期的时候就把iOS的整套安全体系都落地了，这才是最大的挑战。如果在一个需要短期见效，不行则拥抱变化的环境里，安全团队要推行这种工程化改造需要长期忍受绩效中下，对Leader和成员来说压力都会很大。\n\n第四点是工程技术团队的整体能力，因为技术团队整体很弱单安全团队特别强的存在本身就是一个伪命题。\n\n更多因素全都写在《互联网企业安全高级指南》这本书里了，不再赘述。\n\n---\n\n* Author: 赵彦\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [从Google白皮书看企业安全最佳实践](http://tech.meituan.com/GoogleSecurity_ayazero.html)","tags":["Security"],"categories":["Security"]},{"title":"深度学习在美团点评的应用","url":"%2F2017%2F2017-02-10-meituan-deeplearning-application%2F","content":"\n### 前言\n\n近年来，深度学习在语音、图像、自然语言处理等领域取得非常突出的成果，成了最引人注目的技术热点之一。美团点评这两年在深度学习方面也进行了一些探索，其中在自然语言处理领域，我们将深度学习技术应用于文本分析、语义匹配、搜索引擎的排序模型等；在计算机视觉领域，我们将其应用于文字识别、目标检测、图像分类、图像质量排序等。下面我们就以语义匹配、图像质量排序及文字识别这三个应用场景为例，来详细介绍美团点评在深度学习技术及应用方面的经验和方法论。\n\n### 基于深度学习的语义匹配\n\n语义匹配技术，在信息检索、搜索引擎中有着重要的地位，在结果召回、精准排序等环节发挥着重要作用。\n\n传统意义上讲的语义匹配技术，更加注重文字层面的语义吻合程度，我们暂且称之为语言层的语义匹配；而在美团点评这样典型的O2O应用场景下，我们的结果呈现除了和用户表达的语言层语义强相关之外，还和用户意图、用户状态强相关。\n\n用户意图即用户是来干什么的？比如用户在百度上搜索“关内关外”，他的意图可能是想知道关内和关外代表的地理区域范围，“关内”和“关外”被作为两个词进行检索，而在美团上搜索“关内关外”，用户想找的就是“关内关外”这家饭店，“关内关外”被作为一个词来对待。\n\n再说用户状态，一个在北京和另一个在武汉的用户，在百度或淘宝上搜索任何一个词条，可能得到的结果不会差太多；但是在美团这样与地理位置强相关的场景下就会完全不一样。比如我在武汉搜“黄鹤楼”，用户找的可能是景点门票，而在北京搜索“黄鹤楼”，用户找的很可能是一家饭店。\n\n如何结合语言层信息和用户意图、状态来做语义匹配呢？\n\n我们的思路是在短文本外引入部分O2O业务场景特征，融合到所设计的深度学习语义匹配框架中，通过点击/下单数据来指引语义匹配模型的优化方向，最终把训练出的点击相关性模型应用到搜索相关业务中。下图是针对美团点评场景设计的点击相似度框架ClickNet，是比较轻量级的模型，兼顾了效果和性能两方面，能很好地推广到线上应用。   \n\n![图1 clicknet框架](/assets/images/2017/02/10/meituan-deeplearning-application/clicknet_framework.png)\n\n#### 表示层\n\n对Query和商家名分别用语义和业务特征表示，其中语义特征是核心，通过DNN/CNN/RNN/LSTM/GRU方法得到短文本的整体向量表示，另外会引入业务相关特征，比如用户或商家的相关信息，比如用户和商家距离、商家评价等，最终结合起来往上传。\n\n#### 学习层\n\n通过多层全连接和非线性变化后，预测匹配得分，根据得分和Label来调整网络以学习出Query和商家名的点击匹配关系。\n\n在该算法框架上要训练效果很好的语义模型，还需要根据场景做模型调优：首先，我们从训练语料做很多优化，比如考虑样本不均衡、样本重要度、位置Bias等方面问题。其次，在模型参数调优时，考虑不同的优化算法、网络大小层次、超参数的调整等问题。经过模型训练优化，我们的语义匹配模型已经在美团点评平台搜索、广告、酒店、旅游等召回和排序系统中上线，有效提升了访购率/收入/点击率等指标。\n\n#### 小结\n\n深度学习应用在语义匹配上，需要针对业务场景设计合适的算法框架，此外，深度学习算法虽然减少了特征工程工作，但模型调优上难度会增加，因此可以从框架设计、业务语料处理、模型参数调优三方面综合起来考虑，实现一个效果和性能兼优的模型。\n\n### 基于深度学习的图像质量排序\n\n国内外各大互联网公司（比如腾讯、阿里和Yelp）的线上广告业务都在关注展示什么样的图像能吸引更多点击。在美团点评，商家的首图是由商家或运营人工指定的，如何选择首图才能更好地吸引用户呢？图像质量排序算法目标就是做到自动选择更优质的首图，以吸引用户点击。\n\n传统的图像质量排序方法主要从美学角度进行质量评价，通过颜色统计、主体分布、构图等来分析图片的美感。但在实际业务场景中，用户对图片质量优劣的判断主观性很强，难以形成统一的评价标准。比如:  \n\n1.  有的用户对清晰度或分辨率更敏感；\n2.  有的用户对色彩或构图更敏感；\n3.  有的用户偏爱有视觉冲击力的内容而非平淡无奇的环境图。\n\n因此我们使用深度学习方法，去挖掘图片的哪些属性会影响用户的判断，以及如何有效融合这些属性对图片进行评价。\n\n我们使用AlexNet去提取图片的高层语义描述，学习美感、可记忆度、吸引度、品类等High Level特征，并补充人工设计的Low Level特征（比如色彩、锐度、对比度、角点）。在获得这些特征后，训练一个浅层神经网络对图像整体打分。该框架（如图2所示）的一个特点是联合了深度学习特征与传统特征，既引入高层语义又保留了低层通用描述，既包括全局特征又有局部特征。 \n\n![图2 图像质量排序技术框架](/assets/images/2017/02/10/meituan-deeplearning-application/image-quality-sorting-technology-framework.png)\n\n对于每个维度图片属性的学习，都需要大量的标签数据来支撑，但完全通过人工标记代价极大，因此我们借鉴了美团点评的图片来源和POI标签体系。关于吸引度属性的学习，我们选取了美团Deal相册中点击率高的图片（多数是摄影师通过单反相机拍摄）作为正例，而选取UGC相册中点击率低的图片（多数是低端手机拍摄）作为负例。关于品类属性的学习，我们将美团一级品类和常见二级品类作为图片标签。基于上述质量排序模型，我们为广告POI挑选最合适的优质首图进行展示，起到吸引用户点击，提高业务指标的目的。图3给出了基于质量排序的首图优选结果。\n\n![图3 基于图像质量排序的首图优选](/assets/images/2017/02/10/meituan-deeplearning-application/optimization-based-image-quality-ranking.png)\n\n### 基于深度学习的OCR\n\n为了提升用户体验，O2O产品对OCR技术的需求已渗透到上单、支付、配送和用户评价等环节。OCR在美团点评业务中主要起着两方面作用。一方面是辅助录入，比如在移动支付环节通过对银行卡卡号的拍照识别，以实现自动绑卡，又如辅助BD录入菜单中菜品信息。另一方面是审核校验，比如在商家资质审核环节对商家上传的身份证、营业执照和餐饮许可证等证件照片进行信息提取和核验以确保该商家的合法性，比如机器过滤商家上单和用户评价环节产生的包含违禁词的图片。相比于传统OCR场景（印刷体、扫描文档），美团的OCR场景主要是针对手机拍摄的照片进行文字信息提取和识别，考虑到线下用户的多样性，因此主要面临以下挑战：\n\n> *   成像复杂：噪声、模糊、光线变化、形变；\n> *   文字复杂：字体、字号、色彩、磨损、笔画宽度不固定、方向任意；\n> *   背景复杂：版面缺失，背景干扰。\n\n对于上述挑战，传统的OCR解决方案存在着以下不足：\n\n1.  通过版面分析（二值化，连通域分析）来生成文本行，要求版面结构有较强的规则性且前背景可分性强（例如文档图像、车牌），无法处理前背景复杂的随意文字（例如场景文字、菜单、广告文字等）。\n2.  通过人工设计边缘方向特征（例如HOG）来训练字符识别模型，此类单一的特征在字体变化，模糊或背景干扰时泛化能力迅速下降。\n3.  过度依赖字符切分的结果，在字符扭曲、粘连、噪声干扰的情况下，切分的错误传播尤其突出。\n\n针对传统OCR解决方案的不足，我们尝试基于深度学习的OCR。\n\n#### 1. 基于Faster R-CNN和FCN的文字定位\n\n首先，我们根据是否有先验信息将版面划分为受控场景（例如身份证、营业执照、银行卡）和非受控场景（例如菜单、门头图）。\n\n对于受控场景，我们将文字定位转换为对特定关键字目标的检测问题。主要利用Faster R-CNN进行检测，如下图所示。为了保证回归框的定位精度同时提升运算速度，我们对原有框架和训练方式进行了微调:  \n\n> *   考虑到关键字目标的类内变化有限，我们裁剪了ZF模型的网络结构，将5层卷积减少到3层。*   训练过程中提高正样本的重叠率阈值，并根据业务需求来适配RPN层Anchor的宽高比。\n\n![图4 基于Faster R-CNN的受控场景文字定位](/assets/images/2017/02/10/meituan-deeplearning-application/faster_rcnn.png)  \n\n对于非受控场景，由于文字方向和笔画宽度任意变化，目标检测中回归框的定位粒度不够，我们利用语义分割中常用的全卷积网络（FCN）来进行像素级别的文字/背景标注，如下图所示。为了同时保证定位的精度和语义的清晰，我们不仅在最后一层进行反卷积，而且融合了深层Layer和浅层Layer的反卷积结果  \n\n![图5 基于FCN的非受控场景文字定位](/assets/images/2017/02/10/meituan-deeplearning-application/norestrict_fcnn.png)\n\n#### 2. 基于序列学习框架的文字识别\n\n为了有效控制字符切分和识别后处理的错误传播效应，实现端到端文字识别的可训练性，我们采用如下图所示的序列学习框架。框架整体分为三层：卷积层，递归层和翻译层。其中卷积层提特征，递归层既学习特征序列中字符特征的先后关系，又学习字符的先后关系，翻译层实现对时间序列分类结果的解码。  \n\n![图6 基于序列学习的端到端识别框架](/assets/images/2017/02/10/meituan-deeplearning-application/e2e_framework.png)  \n\n由于序列学习框架对训练样本的数量和分布要求较高，我们采用了真实样本+合成样本的方式。真实样本以美团点评业务来源（例如菜单、身份证、营业执照）为主，合成样本则考虑了字体、形变、模糊、噪声、背景等因素。基于上述序列学习框架和训练数据，在多种场景的文字识别上都有较大幅度的性能提升，如下图所示。  \n\n![图7 深度学习OCR和传统OCR的性能比较](/assets/images/2017/02/10/meituan-deeplearning-application/ocr_compare.png)\n\n### 总结\n\n本文主要以深度学习在自然语言处理、图像处理两个领域的应用为例进行了介绍，但深度学习在美团点评可能发挥的价值远远不限于此。未来，我们将继续在各个场景深入挖掘，比如在智能交互、配送调度、智能运营等，在美团点评产品的智能化道路上贡献一份力量。\n\n### 作者简介\n\n文竹，美团点评美团平台与酒旅事业群智能技术中心负责人，2010年从清华硕士毕业后，加入百度，先后从事机器翻译的研发及多个技术团队的管理工作。2015年4月加入美团，负责智能技术中心的管理工作，致力于推动自然语言处理、图像处理、机器学习、用户画像等技术在公司业务上的落地。\n\n李彪，美团点评美团平台及酒旅事业群NLP技术负责人，曾就职搜狗、百度。2015年加入美团点评，致力于NLP技术积累和业务的落地，负责的工作包括深度学习平台和模型，文本分析在搜索、广告、推荐等业务上应用，智能客服和交互。\n\n晓明，美团点评平台及酒旅事业群图像技术负责人，曾就职于三星研究院。2015年加入美团点评，主要致力于图像识别技术的积累和业务落地，作为技术负责人主导了图像机审、首图优选和OCR等项目的上线，推进了美团产品的智能化体验和人力成本的节省。\n\n---\n\n* Author: 文竹 李彪 晓明\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [深度学习在美团点评的应用](http://tech.meituan.com/deeplearning_application.html)","tags":["Deep-Learning"],"categories":["Deep-Learning"]},{"title":"MTDDL——美团点评分布式数据访问层中间件","url":"%2F2016%2F2016-12-19-meituan-distributed-data-layer%2F","content":"\n# 背景\n\n2016年Q3季度初，在美团外卖上单2.0项目上线后，商家和商品数量急速增长，预估商品库的容量和写峰值QPS会很快遇到巨大压力。随之而来也会影响线上服务的查询性能、DB（数据库，以下统一称DB）主从延迟、表变更困难等一系列问题。\n\n要解决上面所说的问题，通常有两种方案。第一种方案是直接对现有的商品库进行垂直拆分，可以缓解目前写峰值QPS过大、DB主从延迟的问题。第二种方案是对现有的商品库大表进行分库分表，从根本上解决现有问题。方案一实施起来周期较短，但只能解决一时之痛，由此可见，分库分表是必然的。\n\n在确定分库分表的方案之后，我们调研了外卖订单、结算以及主站等业务的分库分表实现方案，也调研了业界很多分库分表中间件。在综合考虑性能、稳定性及实现成本的前提下，最终决定自主研发客户端分库分表中间件MTDDL来支撑外卖商品分库分表项目，这也就是MTDDL的由来。\n\n当然，在MTDDL的设计研发过程中，我们充分考虑了MTDDL的通用性、可扩展性、功能的全面性和接入的便利性。到目前为止一共开发了四期，实现了MySQL动态数据源、读写分离、分布式唯一主键生成器、分库分表、连接池及SQL监控、动态化配置等一系列功能，支持分库分表算法、分布式唯一主键生成算法的高可扩展性，而且支持全注解的方式接入，业务方不需要引入任何配置文件。\n\n下面就部分业界方案及MTDDL的设计目标详细展开下，然后从源码的角度来剖析下MTDDL的整个逻辑架构和具体实现。\n\n# 业界调研\n\n\n| 业界组件 | 简介 | 实现方案 | 功能特性 | 优点 | 缺点 |\n| ------- | --- | ------- | ------- | --- | ---- |\n| Atlas | Qihoo 360开发维护的一个基于MySQL协议的数据中间层项目。它实现了MySQL的客户端与服务端协议，作为服务端与应用程序通信，同时作为客户端与MySQL通信 | proxy-based | 实现读写分离、单库分表 | 功能简单，性能跟稳定性较好 | 不支持分库分表 |\n| MTAtlas | 原美团DBA团队在开源Atlas基础上做的一系列升级改造 | proxy-based | 在读写分离、单库分表的基础上，完成了分库分表的功能开发 | 在Atlas基础上支持了分库分表 | 当时还处于测试阶段，暂不推荐业务方使用 |\n| TDDL | 淘宝根据自己的业务特点开发了TDDL框架，主要解决了分库分表对应用的透明化以及异构数据库之间的数据复制，它是一个基于集中式配置的JDBC datasource实现 | client-based | 实现动态数据源、读写分离、分库分表 | 功能齐全 | 分库分表功能还未开源，当前公布文档较少，并且需要依赖diamond（淘宝内部使用的一个管理持久配置的系统） |\n| Zebra | Zebra是原点评内部使用数据源、DAO以及监控等和数据库打交道的中间件集 | client-based | 实现动态数据源、读写分离、分库分表、CAT监控 | 功能齐全且有监控 | 接入较为复杂，当时只支持c3p0、Druid、Tomcat JDBC等连接池，且分库分表算法只支持Groovy表达式不易扩展 |\n\n# 设计目标\n\nMTDDL（Meituan Distributed Data Layer），美团点评分布式数据访问层中间件，旨在为全公司提供一个通用数据访问层服务，支持MySQL动态数据源、读写分离、分布式唯一主键生成器、分库分表、动态化配置等功能，并且支持从客户端角度对数据源的各方面（比如连接池、SQL等）进行监控，后续考虑支持NoSQL、Cache等多种数据源。\n\n# 功能特性\n\n*   动态数据源\n*   读写分离\n*   分布式唯一主键生成器\n*   分库分表\n*   连接池及SQL监控\n*   动态化配置\n\n# 逻辑架构\n\n下图是一次完整的DAO层insert方法调用时序图，简单阐述了MTDDL的整个逻辑架构。其中包含了分布式唯一主键的获取、动态数据源的路由以及SQL埋点监控等过程：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/001.png)\n\n# 具体实现\n\n## 动态数据源及读写分离\n\n在Spring JDBC AbstractRoutingDataSource的基础上扩展出MultipleDataSource动态数据源类，通过动态数据源注解及AOP实现。\n\n### 动态数据源\n\nMultipleDataSource动态数据源类，继承于Spring JDBC AbstractRoutingDataSource抽象类，实现了determineCurrentLookupKey方法，通过setDataSourceKey方法来动态调整dataSourceKey，进而达到动态调整数据源的功能。其类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/002.png)\n\n### 动态数据源AOP\n\nShardMultipleDataSourceAspect动态数据源切面类，针对DAO方法进行功能增强，通过扫描DataSource动态数据源注解来获取相应的dataSourceKey，从而指定具体的数据源。具体流程图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/003.png)\n\n### 配置和使用方式举例\n\n```xml\n    <!-- 参考配置 -->\n    <bean id=\"multipleDataSource\" class=\"com.sankuai.meituan.waimai.datasource.multi.MultipleDataSource\">\n        /** 数据源配置 */\n        <property name=\"targetDataSources\">\n            <map key-type=\"java.lang.String\"> \n                /** 写数据源 */\n                <entry key=\"dbProductWrite\" value-ref=\"dbProductWrite\"/>\n                /** 读数据源 */\n                <entry key=\"dbProductRead\" value-ref=\"dbProductRead\"/>\n            </map>\n        </property>  \n    </bean>\n```\n\n```java\n    /**\n     * DAO使用动态数据源注解\n     */\n    public interface WmProductSkuDao {\n\n        /** 增删改走写数据源 */\n        @DataSource(\"dbProductWrite&quot\")\n        public void insert(WmProductSku sku);\n\n        /** 查询走读数据源 */\n        @DataSource(\"dbProductRead\")\n        public void getById(long sku_id);\n    }\n```\n\n## 分布式唯一主键生成器\n\n众所周知，分库分表首先要解决的就是分布式唯一主键的问题，业界也有很多相关方案：\n\n\n| 序号 | 实现方案 | 优点 | 缺点 |\n| --- | -------- | --- | --- |\n| 1 | UUID | 本地生成，不需要RPC，低延时；扩展性好，基本没有性能上限 | 无法保证趋势递增；UUID过长128位，不易存储，往往用字符串表示 |\n| 2 | Snowflake或MongoDB ObjectId | 分布式生成，无单点；趋势递增，生成效率快 | 没有全局时钟的情况下，只能保证趋势递增；当通过NTP进行时钟同步时可能会出现重复ID；数据间隙较大 |\n| 3 | proxy服务+数据库分段获取ID | 分布式生成，段用完后需要去DB获取，同server有序 | 可能产生数据空洞，即有些ID没有分配就被跳过了，主要原因是在服务重启的时候发生；无法保证有序，需要未来解决，可能会通过其他接口方案实现 |\n\n综上，方案3的缺点可以通过一些手段避免，但其他方案的缺点不好处理，所以选择第3种方案。目前该方案已由美团点评技术工程部实现——分布式ID生成系统Leaf，MTDDL集成了此功能。\n\n### 分布式ID生成系统Leaf\n\n美团点评分布式ID生成系统Leaf，其实是一种基于DB的Ticket服务，通过一张通用的Ticket表来实现分布式ID的持久化，执行update更新语句来获取一批Ticket，这些获取到的Ticket会在内存中进行分配，分配完之后再从DB获取下一批Ticket。整体架构图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/004.png)\n\n每个业务tag对应一条DB记录，DB MaxID字段记录当前该Tag已分配出去的最大ID值。\n\nIDGenerator服务启动之初向DB申请一个号段，传入号段长度如 genStep = 10000，DB事务置 MaxID = MaxID + genStep，DB设置成功代表号段分配成功。每次IDGenerator号段分配都通过原子加的方式，待分配完毕后重新申请新号段。\n\n### 唯一主键生成算法扩展\n\nMTDDL不仅集成了Leaf算法，还支持唯一主键算法的扩展，通过新增唯一主键生成策略类实现IDGenStrategy接口即可。IDGenStrategy接口包含两个方法：getIDGenType用来指定唯一主键生成策略，getId用来实现具体的唯一主键生成算法。其类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/005.png)\n\n## 分库分表\n\n在动态数据源AOP的基础上扩展出分库分表AOP，通过分库分表ShardHandle类实现分库分表数据源路由及分表计算。ShardHandle关联了分库分表上下文ShardContext类，而ShardContext封装了所有的分库分表算法。其类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/006.png)\n\n分库分表流程图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/007.png)\n\n### 分库分表取模算法\n\n分库分表目前默认使用的是取模算法，分表算法为 (#shard_key % (group_shard_num * table_shard_num))，分库算法为 (#shard_key % (group_shard_num * table_shard_num)) / table_shard_num，其中group_shard_num为分库个数，table_shard_num为每个库的分表个数。\n\n例如把一张大表分成100张小表然后散到2个库，则0-49落在第一个库、50-99落在第二个库。核心实现如下：\n\n```java\npublic class ModStrategyHandle implements ShardStrategy {\n\n        @Override\n        public String getShardType() {\n            return \"mod\";\n        }\n\n        @Override\n        public DataTableName handle(String tableName, String dataSourceKey, int tableShardNum, \n            int dbShardNum, Object shardValue) {\n\n            /** 计算散到表的值 */\n            long shard_value = Long.valueOf(shardValue.toString());\n            long tablePosition = shard_value % tableShardNum;\n            long dbPosition = tablePosition / (tableShardNum / dbShardNum);\n            String finalTableName = new StringBuilder().append(tableName).append(\"_\").append(tablePosition).toString();\n            String finalDataSourceKey = new StringBuilder().append(dataSourceKey).append(dbPosition).toString();\n\n            return new DataTableName(finalTableName, finalDataSourceKey);\n        }\n    }\n```\n\n### 分库分表算法扩展\n\nMTDDL不仅支持分库分表取模算法，还支持分库分表算法的扩展，通过新增分库分表策略类实现ShardStrategy接口即可。ShardStrategy接口包含两个方法：getShardType用来指定分库分表策略，handle用来实现具体的数据源及分表计算逻辑。其类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/008.png)\n\n### 全注解方式接入\n\n为了尽可能地方便业务方接入，MTDDL采用全注解方式使用分库分表功能，通过ShardInfo、ShardOn、IDGen三个注解实现。\n\nShardInfo注解用来指定具体的分库分表配置：包括分表名前缀tableName、分表数量tableShardNum、分库数量dbShardNum、分库分表策略shardType、唯一键生成策略idGenType、唯一键业务方标识idGenKey；ShardOn注解用来指定分库分表字段；IDGen注解用来指定唯一键字段。具体类图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/009.png)\n\n### 配置和使用方式举例\n\n```java\n    // 动态数据源\n    @DataSource(\"dbProductSku\")\n\n    // tableName：分表名前缀，tableShardNum：分表数量，dbShardNum：分库数量，shardType：分库分表策略，idGenType：唯一键生成策略，idGenKey：唯一键业务方标识\n    @ShardInfo(tableName=\"wm_food\", tableShardNum=100, dbShardNum=1, shardType=\"mod\", idGenType=IDGenType.LEAF, idGenKey=LeafKey.SKU)  \n\n    @Component\n    public interface WmProductSkuShardDao {\n\n        // @ShardOn(\"wm_poi_id\") 将该注解修饰的对象的wm_poi_id字段作为shardValue\n        // @IDGen(\"id\")  指定要设置唯一键的字段\n        public void insert(@ShardOn(\"wm_poi_id\") @IDGen(\"id\") WmProductSku sku);\n\n        // @ShardOn 将该注解修饰的参数作为shardValue\n        public List<WmProductSku> getSkusByWmPoiId(@ShardOn long wm_poi_id);\n    }\n```\n\n## 连接池及SQL监控\n\nDB连接池使用不合理容易引发很多问题，如连接池最大连接数设置过小导致线程获取不到连接、获取连接等待时间设置过大导致很多线程挂起、空闲连接回收器运行周期过长导致空闲连接回收不及时等等，如果缺乏有效准确的监控，会造成无法快速定位问题以及追溯历史。\n\n再者，如果缺乏SQL执行情况相关监控，会很难及时发现DB慢查询等潜在风险，而慢查询往往就是DB服务端性能恶化乃至宕机的根源（关于慢查询，推荐阅读[《MySQL索引原理及慢查询优化》](http://tech.meituan.com/mysql-index.html)一文）。MTDDL从1.0.2版本开始正式引入连接池及SQL监控等相关功能。\n\n### 连接池监控\n\n#### 实现方案\n\n结合Spring完美适配c3p0、dbcp1、dbcp2、mtthrift等多种方案，自动发现新加入到Spring容器中的数据源进行监控，通过美团点评统一监控组件JMonitor上报监控数据。整体架构图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/010.png)\n\n#### 连接数量监控\n\n监控连接池active、idle、total连接数量，Counter格式：（连接池类型.数据源.active/idle/total_connection），效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/011.png)\n\n#### 获取连接时间监控\n\n监控获取空闲连接时间，Counter格式：（ds.getConnection.数据源.time），效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/012.png)\n\n### SQL监控\n\n#### 实现方案\n\n采用Spring AOP技术对所有DAO方法进行功能增强处理，通过美团点评分布式会话跟踪组件MTrace进行SQL调用数据埋点及上报，进而实现从客户端角度对SQL执行耗时、QPS、调用量、超时率、失败率等指标进行监控。整体架构图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/013.png)\n\n#### 实现效果\n\n登录美团点评的服务治理平台OCTO选择服务查看去向分析，效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/014.png)\n\n## 动态化配置\n\n为了满足业务方一些动态化需求，如解决线上DB紧急事故需动态调整数据源或者分库分表相关配置，要求无需重启在线修改立即生效，MTDDL从1.0.3版本开始正式引入动态化配置相关功能。\n\n### 实现方案\n\n在Spring容器启动的时候自动注册数据源及分库分表相关配置到美团点评的统一配置中心MCC，在MCC配置管理页面可以进行动态调整，MCC客户端在感知到变更事件后会刷新本地配置，如果是数据源配置变更会根据新的配置构造出一个新数据源来替换老数据源，最后再将老的数据源优雅关闭掉。具体流程图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/015.png)\n\n### 动态化数据源\n\n目前支持dbcp、dbcp2、c3p0等数据源，效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/016.png)\n\n### 分库分表动态化\n\n支持动态化配置分库分表数量、分库分表策略、唯一键生成策略、唯一键业务方标识等，效果图如下：\n\n![](/assets/images/2016/12/19/meituan-distributed-data-layer/017.png)\n\n# 版本迭代\n\nMTDDL到目前为止总共开发了四期，后续考虑逐步开源，具体版本迭代如下：\n\n| 项目名 | 功能 | 开始时间 | 结束时间 | 正式版本 | 快照版本 | 版本备注 |\n| ------ | ---- | -------- | -------- | -------- | -------- | -------- |\n| MTDDL一期 | 动态数据源；读写分离；分布式唯一主键生成器；分库分表 | 2016.05.30 | 2016.06.16 | 0.0.1 | 0.0.1-SNAPSHOT | MTDDL第一版 |\n| MTDDL二期 | 分布式唯一主键生成算法可扩展；支持零配置接入MTDDL；优化shardkey配置方式 | 2016.08.23 | 2016.09.05 | 1.0.1 | 1.0.1-SNAPSHOT | MTDDL接入优化 |\n| MTDDL三期 | 连接池及SQL监控；缓存优化 | 2016.09.06 | 2016.09.20 | 1.0.2 | 1.0.2-SNAPSHOT | MTDDL监控完善 |\n| MTDDL四期 | 唯一主键生成注解化；动态化配置 | 2016.10.11 | 2016.11.08 | 1.0.3 | 1.0.3-SNAPSHOT | MTDDL配置动态化 |\n\n---\n\n* Author: 刘军\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [MTDDL——美团点评分布式数据访问层中间件](http://tech.meituan.com/mtddl.html)","tags":["Data-Access"],"categories":["Distributed"]},{"title":"HDFS NameNode内存详解","url":"%2F2016%2F2016-12-09-namenode-memory-detail%2F","content":"\n## 前言\n\n《[HDFS NameNode内存全景](http://tech.meituan.com/namenode.html)》中，我们从NameNode内部数据结构的视角，对它的内存全景及几个关键数据结构进行了简单解读，并结合实际场景介绍了NameNode可能遇到的问题，还有业界进行横向扩展方面的多种可借鉴解决方案。\n\n事实上，对NameNode实施横向扩展前，会面临常驻内存随数据规模持续增长的情况，为此需要经历不断调整NameNode内存的堆空间大小的过程，期间会遇到几个问题：\n\n*   当前内存空间预期能够支撑多长时间。\n*   何时调整堆空间以应对数据规模增长。\n*   增加多大堆空间。\n\n另一方面NameNode堆空间又不能无止境增加，到达阈值后（与机型、JVM版本、GC策略等相关）同样会存在潜在问题：\n\n*   重启时间变长。\n*   潜在的FGC风险。\n\n由此可见，对NameNode内存使用情况的细粒度掌控，可以为优化内存使用或调整内存大小提供更好的决策支持。\n\n本文在前篇《[HDFS NameNode内存全景](http://tech.meituan.com/namenode.html)》文章的基础上，针对前面的几个问题，进一步对NameNode核心数据结构的内存使用情况进行详细定量分析，并给出可供参考的内存预估模型。根据分析结果可有针对的优化集群存储资源使用模式，同时利用内存预估模型，可以提前对内存资源进行合理规划，为HDFS的发展提供数据参考依据。  \n\n## 内存分析\n\n### NetworkTopology\n\nNameNode通过NetworkTopology维护整个集群的树状拓扑结构，当集群启动过程中，通过机架感知（通常都是外部脚本计算）逐渐建立起整个集群的机架拓扑结构，一般在NameNode的生命周期内不会发生大变化。拓扑结构的叶子节点DatanodeDescriptor是标识DataNode的关键结构，该类继承关系如图1所示。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/datanodeextend.png)\n\n图1 DatanodeDescriptor继承关系\n\n在64位JVM中，DatanodeDescriptor内存使用情况如图2所示（除特殊说明外，后续对其它数据结构的内存使用情况分析均基于64位JVM）。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/datanodedescriptor.png)\n\n图2 DatanodeDescriptor内存使用详解\n\n由于DataNode节点一般会挂载多块不同类型存储单元，如HDD、SSD等，图2中storageMap描述的正是存储介质DatanodeStorageInfo集合，其详细数据结构如图3所示。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/datanodestorageinfo.png)\n\n图3 DatanodeStorageInfo内存使用详解\n\n除此之外，DatanodeDescriptor还包括一部分动态内存对象，如replicateBlocks、recoverBlocks和invalidateBlocks等与数据块动态调整相关的数据结构，pendingCached、cached和pendingUncached等与集中式缓存相关的数据结构。由于这些数据均属动态的形式临时存在，随时会发生变化，所以这里没有做进一步详细统计（结果存在少许误差）。\n\n根据前面的分析，假设集群中包括2000个DataNode节点，NameNode维护这部分信息需要占用的内存总量：\n\n（64 + 114 + 56 + 109 &lowast; 16）&lowast; 2000 = ~4MB\n\n在树状机架拓扑结构中，除了叶子节点DatanodeDescriptor外，还包括内部节点InnerNode描述集群拓扑结构中机架信息。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/innernode.png)\n\n图4 NetworkTopology拓扑结构内部节点内存使用详解\n\n对于这部分描述机架信息等节点信息，假设集群包括80个机架和2000个DataNode节点，NameNode维护拓扑结构中内部节点信息需要占用的内存总量：\n\n（44 + 48) &lowast; 80 + 8 &lowast; 2000 = ~25KB\n\n从上面的分析可以看到，为维护集群的拓扑结构NetworkTopology，当集群规模为2000时，需要的内存空间不超过5MB，按照接近线性增长趋势，即使集群规模接近10000，这部分内存空间~25MB，相比整个NameNode JVM的内存开销微乎其微。\n\n### NameSpace\n\n与传统单机文件系统相似，HDFS对文件系统的目录结构也是按照树状结构维护，NameSpace保存的正是整个目录树及目录树上每个目录/文件节点的属性，包括：名称（name），编号（id），所属用户（user），所属组（group），权限（permission），修改时间（mtime），访问时间（atime），子目录/文件（children）等信息。  \n\n下图5为Namespace中INode的类图结构，从类图可以看出，文件INodeFile和目录INodeDirectory的继承关系。其中目录在内存中由INodeDirectory对象来表示，并用List<INode> children成员列表来描述该目录下的子目录或文件；文件在内存中则由INodeFile来表示，并用BlockInfo[] blocks数组表示该文件由哪些Blocks组成。其它属性由继承关系的各个相应子类成员变量标识。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/inodeextend.png)\n\n图5 文件和目录继承关系\n\n目录和文件结构在继承关系中各属性的内存占用情况如图6所示。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/inodeinfo.png)\n\n图6 目录和文件内存使用详解\n\n除图中提到的属性信息外，一些附加如ACL等非通用属性，没有在统计范围内。在默认场景下，INodeFile和INodeDirectory.withQuotaFeature是相对通用和广泛使用到的两个结构。\n\n根据前面的分析，假设HDFS目录和文件数分别为1亿，Block总量在1亿情况下，整个Namespace在JVM中内存使用情况：\n\nTotal(Directory) = (24 + 96 + 44 + 48) &lowast; 100M + 8 &lowast; num(total children)\nTotal(Files) = (24 + 96 + 48) &lowast; 100M + 8 &lowast; num(total blocks)\nTotal = (24 + 96 + 44 + 48) &lowast; 100M + 8 &lowast; num(total children) +  (24 + 96 + 48) &lowast; 100M + 8 &lowast; num(total blocks) = ~38GB\n\n关于预估方法的几点说明：\n\n1.  对目录树结构中所有的Directory均按照默认INodeDirectory.withQuotaFeature结构进行估算，如果集群开启ACL/Snapshotd等特性，需增加这部分内存开销。\n2.  对目录树结构中所有的File按照INodeFile进行估算。\n3.  从整个目录树的父子关系上看，num(total children)就是目录节点数和文件节点数之和。\n4.  部分数据结构中包括了字符串，按照均值长度为8进行预估，实际情况可能会稍大。\n\nNamespace在JVM堆内存空间中常驻，在NameNode的整个生命周期一直在内存存在，同时为保证数据的可靠性，NameNode会定期对其进行Checkpoint，将Namespace物化到外部存储设备。随着数据规模的增加，文件数/目录树也会随之增加，整个Namespace所占用的JVM内存空间也会基本保持线性同步增加。\n\n### BlocksMap\n\nHDFS将文件按照一定的大小切成多个Block，为了保证数据可靠性，每个Block对应多个副本，存储在不同DataNode上。NameNode除需要维护Block本身的信息外，还需要维护从Block到DataNode列表的对应关系，用于描述每一个Block副本实际存储的物理位置，BlockManager中BlocksMap结构即用于Block到DataNode列表的映射关系。BlocksMap内部数据结构如图7所示。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/blockdetail.png)\n\n图7 BlockInfo继承关系\n\nBlocksMap经过多次优化形成当前结构，最初版本直接使用HashMap解决从Block到BlockInfo的映射。由于在内存使用、碰撞冲突解决和性能等方面存在问题，之后使用重新实现的LightWeightGSet代替HashMap，该数据结构本质上也是利用链表解决碰撞冲突的HashTable，但是在易用性、内存占用和性能等方面表现更好。关于引入LightWeightGSet细节可参考[HDFS-1114](https://issues.apache.org/jira/browse/HDFS-1114)。\n\n与HashMap相比，为了尽可能避免碰撞冲突，BlocksMap在初始化时直接分配整个JVM堆空间的2%作为LightWeightGSet的索引空间，当然2%不是绝对值，如果2%内存空间可承载的索引项超出了Integer.MAX_VALUE/8（注：Object.hashCode()结果是int，对于64位JVM的对象引用占用8Bytes）会将其自动调整到阈值上限。限定JVM堆空间的2%基本上来自经验值，假定对于64位JVM环境，如果提供64GB内存大小，索引项可超过1亿，如果Hash函数适当，基本可以避免碰撞冲突。\n\nBlocksMap的核心功能是通过BlockID快速定位到具体的BlockInfo，关于BlockInfo详细的数据结构如图8所示。BlockInfo继承自Block，除了Block对象中BlockID，numbytes和timestamp信息外，最重要的是该Block物理存储所在的对应DataNode列表信息triplets。\n\n![](/assets/images/2016/12/09/namenode-memory-detail/blocksmap.png)\n\n图8 BlocksMap内存使用详解\n\n其中LightWeightGSet对应的内存空间全局唯一。尽管经过LightWeightGSet优化内存占用，但是BlocksMap仍然占用了大量JVM内存空间，假设集群中共1亿Block，NameNode可用内存空间固定大小128GB，则BlocksMap占用内存情况：  \n\n16 + 24 + 2% &lowast; 128GB +（ 40 + 128 ）&lowast; 100M = ~20GB\n\nBlocksMap数据在NameNode整个生命周期内常驻内存，随着数据规模的增加，对应Block数会随之增多，BlocksMap所占用的JVM堆内存空间也会基本保持线性同步增加。\n\n### 小结\n\nNameNode内存数据结构非常丰富，除了前面详细分析的核心数据结构外，其实还包括如LeaseManager/SnapShotManager/CacheManager等管理的数据，由于内存使用非常有限，或特性未稳定没有开启，或没有通用性，这里都不再展开。\n\n根据前述对NameNode内存的预估，对比Hadoop集群历史实际数据：文件目录总量~140M，数据块总量~160M，NameNode JVM配置72GB，预估内存使用情况：\n\nNamespace：(24 + 96 + 44 + 48) &lowast; 70M + 8 &lowast; 140M +  (24 + 96 + 48) &lowast; 70M + 8 &lowast; 160M = ~27GB\nBlocksMap：16 + 24 + 2% &lowast; 72GB +（ 40 + 128 ）&lowast; 160M = ~26GB\n\n_说明：这里按照目录文件数占比1:1进行了简化，基本与实际情况吻合，且简化对内存预估结果影响非常小。_\n\n二者组合结果~53GB，结果与监控数据显示常驻内存~52GB基本相同，符合实际情况。\n\n从前面讨论可以看出，整个NameNode堆内存中，占空间最大的两个结构为Namespace和BlocksMap，当数据规模增加后，巨大的内存占用势必会给JVM内存管理带来挑战，甚至可能制约NameNode服务能力边界。  \n\n针对Namespace和BlocksMap的空间占用规模，有两个优化方向：\n\n*   合并小文件。使用Hive做数据生产时，为避免严重的数据倾斜、人为调小分区粒度等一些特殊原因，可能会在HDFS上写入大量小文件，会给NameNode带来潜在的影响。及时合并小文件，保持稳定的目录文件增长趋势，可有效避免NameNode内存抖动。\n*   适当调整BlockSize。如前述，更少的Block数也可降低内存使用，不过BlockSize调整会间接影响到计算任务，需要进行适当的权衡。\n\n对比其他Java服务，NameNode场景相对特殊，需要对JVM部分默认参数进行适当调整。比如Young/Old空间比例，为避免CMS GC降级到FGC影响服务可用性，适当调整触发CMS GC开始的阈值等等。关于JVM相关参数调整策略的细节建议参考官方使用文档。  \n\n这里，笔者根据实践提供几点NameNode内存相关的经验供参考：\n\n*   根据元数据增长趋势，参考本文前述的内存空间占用预估方法，能够大体得到NameNode常驻内存大小，一般按照常驻内存占内存总量~60%调整JVM内存大小可基本满足需求。*   为避免GC出现降级的问题，可将CMSInitiatingOccupancyFraction调整到~70。\n*   NameNode重启过程中，尤其是DataNode进行BlockReport过程中，会创建大量临时对象，为避免其晋升到Old区导致频繁GC甚至诱发FGC，可适当调大Young区（-XX:NewRatio）到10~15。\n\n据了解，针对NameNode的使用场景，使用CMS内存回收策略，将HotSpot JVM内存空间调整到180GB，可提供稳定服务。继续上调有可能对JVM内存管理能力带来挑战，尤其是内存回收方面，一旦发生FGC对应用是致命的。这里提到180GB大小并不是绝对值，能否在此基础上继续调大且能够稳定服务不在本文的讨论范围。结合前述的预估方法，当可用JVM内存达180GB时，可管理元数据总量达~700M，基本能够满足中小规模以下集群需求。\n\n## 总结\n\n本文在《[HDFS NameNode内存全景](http://tech.meituan.com/namenode.html)》基础上，对NameNode内存使用占比较高的几个核心数据结构进行了详细的介绍。在此基础上，提供了可供参考的NameNode内存数据空间占用预估模型：\n\n**Total = 198 &lowast; num(Directory + Files) + 176 &lowast; num(blocks) + 2% &lowast; size(JVM Memory Size)**\n\n通过对NameNode内存使用情况的定量分析，可为HDFS优化和发展规划提供可借鉴的数据参考依据。\n\n## 参考文献\n\n[1] Apache Hadoop. [https://hadoop.apache.org/](https://hadoop.apache.org/). 2016.\n[2] Apache Issues. [https://issues.apache.org/](https://issues.apache.org/). 2016.\n[3] Apache Hadoop Source Code. [https://github.com/apache/hadoop/tree/branch-2.4.1/](https://github.com/apache/hadoop/tree/branch-2.4.1/). 2014.\n[4] HDFS NameNode内存全景. [http://tech.meituan.com/namenode.html](http://tech.meituan.com/namenode.html). 2016.\n[5] Java HotSpot VM Options. [http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html](http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html).\n\n---\n\n* Author: 小桥\n* Source: [美团点评技术团队](http://tech.meituan.com/)\n* Link: [HDFS NameNode内存详解](http://tech.meituan.com/namenode-memory-detail.html)","tags":["Memory"],"categories":["Namenode"]},{"title":"外卖排序系统特征生产框架","url":"%2F2016%2F2016-12-09-sorting-system-feature-production-framework%2F","content":"\n# 背景\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/001.png)\n\n图1 外卖排序系统框架\n\n外卖的排序策略是由机器学习模型驱动的，模型迭代效率制约着策略优化效果。如上图所示，在排序系统里，特征是最为基础的部分：有了特征之后，我们离线训练出模型，然后将特征和模型一起推送给线上排序服务使用。特征生产Pipeline对于策略迭代的效率起着至关重要的作用。经过实践中的积累和提炼，我们整理出一套通用的特征生产框架，大大节省开发量，提高策略迭代效率。\n\n外卖排序系统使用GBDT（Gradient Boosting Decision Tree）树模型，比较复杂。受限于计算能力，除了上下文特征（如时间、地域、终端类型、距离等）之外，目前使用的主要是一些宽泛的统计特征，比如商家销量、商家单均价、用户的品类偏好等。这些特征的生产流程包括：离线的统计、离线到在线的同步、在线的加载等。\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/002.png)\n\n图2 特征生产流程\n\n如上图，目前外卖排序的特征生产流程主要有：\n\n1.  **特征统计**：基于基础数据表（如曝光表、点击表、订单表等），统计若干时段内特定维度的总量、分布等，如商家月均销量、用户不同品类下单占比。统计结果存储于Hive表。这部分工作，简单的可基于ETL，复杂的可基于Spark。产出的特征可供离线训练和线上预测，**本文主要围绕线上展开**。\n\n2.  **特征推送**：Hive表里的数据需要存入KV，以便线上实时使用。这一步，首先要将Hive表里的记录映射成POJO类（称为**Domain**类），然后将其序列化，最后将序列化串存入KV。这部分工作比较单一，基于MapReduce实现。\n\n3.  **特征获取**：在线服务根据需求，从KV中取出数据，并反序列化为Domain对象。\n\n4.  **特征加载**：针对模型所需特征列表，取得对应的Domain对象。这步通过调用特征获取实现。\n\n前两步为离线操作，后两步为在线操作。特征同步由离线推送和在线获取共同完成。离线生产流程是一个周期性的Pipeline，目前是以天为周期。\n\n为此，我们设计了一套通用的框架，基于此框架，只需要简单的配置和少量代码开发，就可以新增一组特征。下文将详细介绍框架的各个部分。\n\n# 特征统计\n\n排序模型用到的特征大部分是统计特征。有些特征比较简单，如商家的月均销量、商家单均价等，可用ETL统计(GROUP BY + SUM/AVG)；有些特征稍微复杂，如用户的品类偏好（在不同品类上的占比）、用户的下单额分布（不同金额区段的占比），用ETL就比较繁琐。针对后一种情况，我们开发了一套Spark程序来统计。我们发现，这种统计需求可以规约成一种范式：针对某些**统计对象**（用户、商家）的一些**维度**（品类、下单额），基于某些**度量值**（点击、下单）做**统计**（比例/总和）。\n\n同一对象，可统计不同维度；同一维度，有不同的度量角度；同一度量角度，有不同的统计方式。如下图：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/003.png)\n\n图3 特征统计范式\n\n\n例如，对于用户点击品类偏好、用户下单品类偏好、用户下单额分布、用户下单总额等特征，可做范式分解：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/004.png)\n\n图4 特征统计范式示例\n\n其中，\n\n*   **统计对象、统计维度、度量值**对应于Hive表中的字段（维度一般来自维度表，度量值一般来自事实表，主要是曝光、点击、下单）。为了增加灵活性，我们还允许对原始Hive字段做加工，加工后的值作为统计维度、度量值（加工的接口我们分别称为维度算子和度量算子）。\n\n*   **统计量**基于度量值做的一些聚合操作，如累加、求均值、拼接、求占比、算分位点（分布）。前两者输出一个数值，后三者输出形如&quot;Key1:Value1,Key2:Value2&quot;的KeyValue列表。\n\n另外，统计通常是在一定时间窗口内进行的，由于不同时期的数据价值不同（新数据比老数据更有价值），我们引入了**时间衰减**，对老数据降权。\n\n基于以上考虑，整个统计流程可以分解为（基于Spark）：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/005.png)\n\n图5 特征统计流程\n\n1.  按统计对象字段做聚合（GROUP BY）。统计对象字段由配置给定。对于外卖排序主要为uuid、poi_id。这一步可能会有数据倾斜，需要更多优化。\n\n2.  计算维度。支持维度算子，可以对原始维度字段做处理，如对金额字段做分段处理，以分段后的金额作为维度。\n\n3.  按统计维度聚合（GROUP BY）。这是在对象聚合的基础上做的二次聚合。维度字段由配置给定，可以有多个字段，表示交叉特征统计，如不同时段的品类偏好，维度字段为：时段、品类。\n\n4.  时间衰减并累加。衰减各个时间的度量值，并把所有时间的度量值累加，作为加权后的度量值。时间字段和度量字段由配置给定。时间字段主要为日期，度量字段主要为曝光、点击、下单。经过维度聚合后，度量值都在特定维度值对应的记录集上做累加，每个维度对应一个度量值，维度和度量值是一个KeyValue的映射关系。\n\n5.  计算度量值。度量字段也可以通过度量算子做进一步处理，算子得到的结果作为度量值。也可以有多个字段，如点击和曝光字段，配合除法算子，可以得到点击率作为度量值。\n\n6.  计算统计量。经过对象和维度聚合后，对象、维度、度量值建立了二级映射关系：对象维度度量值，相当于一个二维Map：Map&lt;对象, Map&lt;维度, 度量值&gt;&gt;。统计量是对Map&lt;维度, 度量值&gt;做一个聚合操作。每个统计量对应输出Hive表中的一个字段。现在主要支持如下几种算子：\n\n> *   累加：对该维度的所有度量值求和；\n> *   求均值：该维度所有取值情况对应的度量值的均值；\n> *   拼接：把Map&lt;维度, 度量值&gt;序列化为&quot;Key1:Value1, Key2:Value2&quot;形式，以便以字符串的形式存储于一个输出字段内。为了防止序列化串太长，可通过配置设定只保留度量值最大的top N；\n> *   求占比：该维度所有取值情况对应的度量值占度量值总和的比重，即Map&lt;维度, 度量值/Sum(度量值)&gt;。然后再做拼接输出；\n> *   算分位点：有时候想直到某些维度的分布情况，比如用户下单金额的分布以考察用户的消费能力。分位点可以作为分布的一种简单而有效的表示方法。该算子输出每个分位点的维度值，形如&quot;分位点1:维度值1, 分位点2:维度值2&quot;。此时，度量值只是用来算比值。\n\n**维度算子**、**度量算子**、**统计算子**都可以通过扩展接口的方式实现自定义。\n\n如下是统计用户点击品类偏好、用户下单品类偏好、用户下单额分布的配置文件和Hive表示例([Toml]<sup>[1]</sup>格式)\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/006.png)\n\n图6 特征统计配置示例\n\n相对于ETL，这套Spark统计框架更为简单清晰，还可以同时统计多个相关的特征。通过简单的配置就可以实现特征的统计，开发量比较小。\n\n# 特征同步\n\n离线统计得到的特征存储在Hive表中，出于性能的考虑，不能在线上直接访问。我们需要把特征从Hive中推送到更为高效的KV数据库中，线上服务再从KV中获取。整个同步过程可以分为如下步骤：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/007.png)\n\n图7 特征推送流程\n\n1.  ORM：将Hive表中的每行记录映射为Domain对象（类似于[Hibernate]<sup>[2]</sup>的功能）\n\n2.  **序列化**：将Domain对象序列化，然后存储到KV中。一个Domain类包含一组相关的、可同时在一个任务中统计的特征数据。每个Domain对象都有一个key值来作为自己唯一的标志—实现key()接口。同时，由于不同类型的Domain都会存储在一起，我们还需要为每种类型的Domain设定一个Key值前缀prefix以示区别。因此，KV中的Key是Domain.prefix + Domain.key，Value是序列化串。我们支持json和protostuff两种序列化方式。\n\n3.  **反序列化**：在线服务根据key和Domain.prefix从KV中得到序列化串，并反序列化为Domain对象。\n\n前两步为离线操作，第三步为在线操作（在预测代码中被调用）。\n\n我们针对Hive开发了一套ORM库（见图8），主要基于Java反射，除了支持基本类型(int/long/float/double/String等)，还支持POJO类型和集合类型(List/Map)。因为ETL不支持json拼接，为了兼容基于ETL统计的特征数据，我们的POJO以及集合类型是基于自定义的规范做编解码。针对Spark统计的特征数据，后续我们可以支持json格式的编解码。\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/008.png)\n\n图8 Hive ORM示意\n\n特征序列化和反序列我们统一封装为通用的**KvService**：负责序列化与反序列，以及读写KV。如下图：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/009.png)\n\n图9 KvService\n\n对于新特征，只需要定义一个Domain类，并实现接口key()即可，KvService自动完成Key值的拼接（以Domain的类名作为Key的prefix），序列化和反序列化，读写KV。\n\n我们通过周期性的离线MapReduce任务，读取Hive表的记录，并调用KvService的put接口，将特征数据推送到KV中。由于KvService能够统一处理各种Domain类型，MapReduce任务也是通用的，无需为每个特征单独开发。\n\n对于特征同步，只需要开发Domain类，并做少量配置，开发量也很小。目前，我们为了代码的可读性，采用Domain这种强类型的方式来定义特征，如果可以弱化这种需求的话，还可以做更多的框架优化，省去Domain类开发这部分工作。\n\n# 特征加载\n\n通过前面几步，我们已经准备好特征数据，并存储于KV中。线上有诸多模型在运行，不同模型需要不同的特征数据。特征加载这一步主要解决怎么高效便捷地为模型提供相应的特征数据。\n\n离线得到的只是一些原始特征，在线还可能需要基于原始特征做更多的处理，得到高阶特征。比如离线得到了商家和用户的下单金额分布，在线我们可能需要基于这两个分布计算一个匹配度，以表征该商家是否在用户消费能力的承受范围之内。\n\n我们把在线特征抽象为一个特征算子：**FeatureOperator**。类似的，一个特征算子包含了一组相关的在线特征，且可能依赖一组相关的离线特征。它除了封装了在线特征的计算过程，还通过两个Java Annotation声明该特征算子产出的特征清单(@**Features**)和所需要的数据清单(@**Fetchers**)。所有的数据获取都是由**DataFetcher**调用**KvService**的get接口实现，拿到的**Domain**对象统一存储在**DataPortal**对象中以便后续使用。\n\n服务启动时，会自动扫描所有的FeatureOperator的Annotation（@Features、@Fetchers），拿到对应的特征清单和数据清单，从而建立起映射关系：FeatureFeatureOperatorDataFetcher。而每个模型通过配置文件给定其所需要的特征清单，这样就建立起模型到特征的映射关系（如图9）： \n\n> **Model → Feature → FeatureOperator → DataFetcher**\n\n不同的在线特征可能会依赖相同的离线特征，也就是FeatureOperatorDataFetcher是多对多的关系。为了避免重复从KV读取相同的数据以造成性能浪费，离线特征的获取和在线特征的抽取被划分成两步：先汇总所有离线特征需求，统一获取离线特征；得到离线特征后，再进行在线特征的抽取。这样，我们也可以在离线特征加载阶段采用并发以减少网络IO延时。整个流程如图10所示：\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/010.png)\n\n图10 模型和特征数据的映射关系\n\n![](/assets/images/2016/12/09/sorting-system-feature-production-framework/011.png)\n\n图11 特征加载流程\n\n对于新特征，我们需要实现对应的FeatureOperator、DataFetcher。DataFetcher主要封装了Domain和DataPortal的关系。类似的，如果我们不需要以强类型的方式来保证代码的业务可读性，也可以通过优化框架省去DataFetcher和DataPortal的定制开发。\n\n# 总结\n\n我们在合理抽象特征生产过程的各个环节后，设计了一套较为通用的框架，只需要少量的代码开发（主要是自定义一些算子）以及一些配置，就可以很方便地生产一组特征，有效地提高了策略迭代效率。\n\n## _参考文献_\n\n1.  [TOML](https://github.com/toml-lang/toml).\n2.  [Hibernate ORM](http://hibernate.org/orm/).\n\n---\n\n* Author: 海文\n* Source: [美团点评技术团队](http://tech.meituan.com/)\n* Link: [外卖排序系统特征生产框架](http://tech.meituan.com/feature_pipeline.html)\n","tags":["Feature"],"categories":["Machine-Learning"]},{"title":"Linux沙箱技术","url":"%2F2016%2F2016-11-23-linux-sandbox%2F","content":"\n## Linux沙箱技术介绍\n\n在计算机安全领域，沙箱(Sandbox)是一种程序的隔离运行机制，其目的是限制不可信进程的权限。沙箱技术经常被用于执行未经测试的或不可信的客户程序。为了避免不可信程序可能破坏其它程序的运行，沙箱技术通过为不可信客户程序提供虚拟化的磁盘、内存以及网络资源，而这种虚拟化手段对客户程序来说是透明的。由于沙箱里的资源被虚拟化（或被间接化），所以沙箱里的不可信程序的恶意行为往往会被限制在沙箱中。\n\n沙箱技术一直是系统安全领域的挑战，不存在说哪一种方案是足够安全的。沙箱技术方案通常是需要结合多种系统安全技术来实现，采用防御纵深(Defence in Depth)的设计原则，筑建多道防御屏障，尽可能地将安全风险将为最低。下面我们主要讨论如何利用Linux kernel所提供的安全功能来建立有效的沙箱技术。\n\n在讨论之前，我们简单回顾一下Linux安全模型相关的内容（假设读者已经非常熟悉）：\n\n  (1) 每个进程都有自己的地址空间；\n  \n  (2) MMU硬件机制来保证地址空间的隔离；\n  \n  (3) Kernel是系统的TCB(Trusted Computing Base)，是安全策略的制定者和执行者；\n  \n  (4) 进程是最小的权限边界；\n  \n  (5) root具有最高权限，它能控制一切；\n  \n  (6) 其它用户受DAC(Discretionary Access Control)限制，如文件系统的UGO权限控制。\n\n进程是最小的权限边界，其根本原因是MMU能保证进程地址空间的隔离。\n\nLinux Kernel还提供了与进程降权(drop privilege)相关的一些功能：\n\n1. setuid\n2. POSIX.1e capability\n3. chroot jail\n4. Quota control (eg, cgroup, namespace)\n5. Linux Container\n6. Linux Security Module (LSM)\n\n下面我们会介绍如何在实践中利用这些诀窍来构建一个有效的sandbox.\n\n## setuid sandbox\n\nSetuid Sandbox主要是基于Linux Kernel所提供的安全机制(eg,DAC)来实现。简单地说就是利用 random uid/gid + chroot() + capability的组合出击来达到目标。其实现非常简单，无需修改Kernel。下面分别悉数之：\n\n1. Linux中每个进程都会有一个uid，uid=0则为root用户进程（privileged），uid>0则为普通用户进程（unprivileged）。不同uid进程之间（不包括root进程）是相互隔离的，各自都有自己独立的权限，互不干扰。而root进程具有特权，它能干任何事情。Linux uid/gid机制主要是用于进程的权限隔离。如果你打算执行不可信的程序，那么你可以在启动该程序时为其分配一个random uid。一个可能的执行流程如下：fork() -> setuid() -> {设置相关的进程资源限制, eg, RLIMIT_NPROC (0,0)} -> execv()。注意，setuid()只能由root权限（或拥有 CAP_SETUID capability）才能成功调用，所以这个执行流程需要借助某个拥有root权限的helper。比如，将helper程序设置为setuid root。\n\n2. Chroot是Linux kernel提供的另一个安全功能，它用于修改进程的根目录。比如执行chroot(\"/tmp/sandbox/1/\")则可以设置当前进程的根目录为\"/tmp/sandbox/1/\"，那么该进程的文件操作将被限制在\"/tmp/sandbox/1/\"中。注意，chroot()只能由root权限（或拥有CAP_SYS_CHROOT capability）才能成功调用。也许你马上会想到：在前面的执行流程中，先让具有root权限的helper去执行\"chroot()\"后再调用setuid() -> {...} -> execve()，但这样做是行不通的，因为execve()本要执行的binary文件已经不可用了（进程的根目录已经被重定位了）。Google的一篇文章里给出了一个解决此问题的简单方法：\n\n  (1) Helper创建一个子进程H，注意要用clone()和CLONE_FS，使得Helper和H可以共享根目录、当前目录、等等；\n  \n  (2) Helper降权后执行execve(\"Worker\")；\n  \n  (3) Worker(原Helper进程)请求H去执行chroot()；\n  \n  (4) H执行chroot()，新的根目录会对H和Worker同时生效。\n  \n  (5) H退出。\n\n  这个方法听起来不错，前提是Helper需要设置RLIMIT_NOFILE为(0,0)，并且对于不可信的Worker进程来说，在执行第4步之前应是可控的。\n\n  另外，对于Helper程序来说，由于它是以root身份运行，那么就可能会成为攻击点，比如confused deputy问题。下面我们介绍如何用capability机制来解这个问题。\n\n3. Linux Capability 主要是解决 confused deputy problem. 这类问题的典型代表之一是 CSRF(cross-site request forgery).给一个简单的例子来描述: 假如你刚刚用浏览器访问过你的网上银行，而同时又在逛水木BBS。这时BBS上的某个坏蛋可能正好猜到你在访问网上银行，于是那个坏蛋就编写一个在你的网上银行站点进行转帐的form提交的链接，并将该链接作为他在BBS上传的图片的tag。如果此时你点击了他的图片，并且你的网上银行在cookie中保存的授权信息还没有过期，那么你就倒霉了。此时的你就被称为\"confused deputy\"，因为你糊里糊涂地就授权了那个坏蛋所诱导的这次交易事务。\n\n  Linux支持Capability的主要目的是细化root的特权，以避免confused deputy problem. 比如拿ping程序来说，它需要使用raw_sockets所以需要root特权才能运行；如果有了Capability机制，由于该程序只需要一个CAP_NET_RAW的Capability即可运行，那么根据最小权限原则，该程序运行时可以丢弃所有多余的Capability，以防止被误用或被攻击。所以，Capability机制可以将root特权进行很好的细分，当前kernel(2.6.18)已支持30多种不同的Capability。注意在之前的kernel实现中，Capability只能由root进程持有，非root进程是不能保持任何Capability的。但是在2.6.24及以上的kernel版本中一个普通用户进程也将可以持有capability。\n\n小结：可以看出，setuid sandbox实现是简单易行。在一定程度上，它可以用于隔离不可信的程序。由于它完全依赖于kernel所提供的安全机制，除非攻击者能找到kernel的0-day漏洞并通过攻击获得root权限，否则setuid sandbox所提供的安全隔离是可以保证的。不可信代码的隔离一直都是操作系统安全领域的挑战之一，面对这种挑战，我们应当采用防御纵深（in depth）的方法来解决。而最近，我们发现setuid sandbox已被Google用作Chromium系统的第一道隔离屏障。\n\n## seccomp sandbox\n\nSeccomp(secure computing)是Linux kernel （自从2.6.23版本之后）所支持的一种简洁的sandboxing机制。它能使一个进程进入到一种“安全”运行模式，该模式下的进程只能调用4种系统调用（system calls），即read(), write(), exit()和sigreturn()，否则进程便会被终止。\n\nSeccomp是Andrea Arcangeli在2005年设计的，其目的是解决grid computing中的安全问题，比如你打算出租你的CPU资源，但又担心不可信的代码会破坏你的系统。那么，Seccomp则可以为“不可信的纯计算型代码”提供一个“安全（SAFE, not SECURE）”的运行环境，以保护你的系统和应用程序的正常运行不受不可信代码的干扰。\n\n据说Google Chrome浏览器的开发人员曾经考虑过使用Seccomp来建立Chrome Sandbox，但考虑到Seccomp的一些不足而“另辟蹊径”—— Native Client 。『据了解，Google Chrome 4 在今年 CanSecWest Applied Security 大会上是唯一没有被当场攻破的浏览器，而IE8 on Windows7/Vista/XP, Mozilla Firefox 3 和 Apple Safari 4 都相继被攻破。』\n\n简洁、优美是Seccomp的优点，但只能支持“纯计算型”代码却使得其应用受到很大限制。比如，Seccomp模式的进程不能动态分配内存、不能与其它进程使用共享内存、不能使用新的文件描述符、等等。如果要支持具有丰富功能的应用程序，则需要另外的方法来截获并处理其它系统调用。\n\n有人提议对seccomp进行改进使其支持对系统调用提供更细粒度的控制。比如，对seccomp增加一个新的mode，使用一个bitmap来精确描述哪些系统调用是可以被访问的，而哪些是被禁止的。而进程自己还可以丢弃（但不能重新获取）它所具有的访问哪些系统调用的能力（这种工作方法有点像Linux capability安全机制，尽管这两者是完全正交的）。但是到今天为止，还没有看到相关的进展，据说是因为ftrace也支持类似的功能，如何裁定还需要进一步讨论。\n\n通过截获系统调用来实现sandbox是一贯的做法，它假设Kernel是好人，而User不一定是好人。在现代操作系统中，User和Kernel的空间是隔离的，一个进程只能通过系统调用才能从user空间进入kernel空间。如果一个进程不需要执行系统调用（即不需要kernel提供的丰富功能），那么我们的系统被攻击的风险就小。当然假设进程不使用系统调用是不切实际的，但对今天的多数系统来说，为用户程序提供的丰富功能是以牺牲安全性为代价的。但是，“仅仅通过截获并处理系统调用的方法去实现sandbox”是否是正确的技术方向呢？我们知道，当系统调用的参数保存在用户空间的时候，要想验证该参数是否“安全”是非常困难的，比如TOC2TOU问题便是一个挑战：一个恶意进程可能会在“参数被安全检查”之后、而在“实际使用参数”之前将该参数换掉，这便使截获系统调用时所做的参数检查变得没有意义。要解决这个问题，我们也许不应当只将目光锁定在系统调用的入口处。\n\nsandboxing一直以来都是一个大难题，对于今天的COTS OS来说还不存在一个通用的安全方案。如何去做满足自己需要的sandbox，则需要量体裁衣。\n\n## ptrace sandbox\n\n暂无\n\n## vm sandbox\n\n暂无\n\n## 参考链接：\n\n* [Linux沙箱技术介绍](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=362087)\n* [Linux沙箱(1): setuid sandbox](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=382146)\n* [Linux沙箱(2): seccomp sandbox](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=382621)\n* [Linux沙箱(3): ptrace() sandbox](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=382622)\n* [Linux沙箱(4): vm sandbox](http://plaintext.blog.edu.cn/home.php?mod=space&uid=1557851&do=blog&id=382623)\n\n---","tags":["Linux"],"categories":["Linux"]},{"title":"java安全沙箱","url":"%2F2016%2F2016-11-23-java-sandbox%2F","content":" \n参考链接：\n\n* [java安全沙箱（一）之ClassLoader双亲委派机制](https://my.oschina.net/xionghui/blog/501225)\n* [java安全沙箱（二）之.class文件检验器 ](https://my.oschina.net/xionghui/blog/501154)\n* [java安全沙箱（三）之内置于Java虚拟机（及语言）的安全特性](https://my.oschina.net/xionghui/blog/501165)\n* [java安全沙箱（四）之安全管理器及Java API](https://my.oschina.net/xionghui/blog/501225)\n\n---","tags":["Sandbox"],"categories":["Java"]},{"title":"深度解读最流行的优化算法：梯度下降","url":"%2F2016%2F2016-11-21-dl-optimization-gradient-descent%2F","content":"\n梯度下降法，是当今最流行的优化（optimization）算法，亦是至今最常用的优化神经网络的方法。本文旨在让你对不同的优化梯度下降法的算法有一个直观认识，以帮助你使用这些算法。我们首先会考察梯度下降法的各种变体，然后会简要地总结在训练（神经网络或是机器学习算法）的过程中可能遇到的挑战。\n\n## 目录：\n\n* 梯度下降的各种变体\n\n  1. 批量梯度下降（Batch gradient descent）\n  2. 随机梯度下降（Stochastic gradient descent）\n  3. 小批量梯度下降（Mini-batch gradient descent）\n\n* 面临的挑战\n* 梯度下降的优化算法\n\n  1. Momentum法\n  2. Nesterov加速梯度法\n  3. Adagrad法\n  4. Adadelta法\n  5. RMSprop法\n  6. 适应性动量估计法（Adam）\n  7. 几种算法的可视化\n  8. 该选择哪种优化器\n\n* 对SGD进行平行或分布式运算\n\n  1. Hogwild!\n  2. Downpour SGD\n  3. 容忍延迟的SGD算法\n  4. TensorFlow\n  5. 弹性平均梯度下降法（Elastic Averaging SGD）\n\n* 优化SGD的其他手段\n\n  1. 重排（Shuffling ）和递进学习（Curriculum Learning）\n  2. 批量标准化（Batch normalization）\n  3. 早停（Early Stopping）\n  4. 梯度噪声（Gradient noise）\n\n* 结论\n\n* 参考资料\n\n梯度下降法，是当今最流行的优化（optimization）算法，亦是至今最常用的优化神经网络的方法。与此同时，最新的深度学习程序库都包含了各种优化梯度下降的算法（可以参见如lasagne、caffe及Kera等程序库的说明文档）。但它们的算法则不被公开，都作为黑箱优化器被使用，这也就是为什么它们的优势和劣势往往难以被实际地解释。\n\n本文旨在让你对不同的优化梯度下降法的算法有一个直观认识，以帮助你使用这些算法。我们首先会考察梯度下降法的各种变体，然后会简要地总结在训练（神经网络或是机器学习算法）的过程中可能遇到的挑战。接着，我们将会讨论一些最常见的优化算法，研究它们的解决这些挑战的动机及推导出更新规律（update rules）的过程。我们还会简要探讨一下，在平行计算或是分布式处理情况下优化梯度下降法的算法和架构。最后，我们会考虑一下其他有助于优化梯度下降法的策略。\n\n梯度下降法的核心，是最小化目标函数J(θ)，其中θ是模型的参数，θ∈Rd。它的方法是，在每次迭代中，对每个变量，按照目标函数在该变量梯度的相反方向，更新对应的参数值。其中，学习率η决定了函数到达（局部）最小值的迭代次数。换句话说，我们在目标函数的超平面上，沿着斜率下降的方向前进，直到我们遇到了超平面构成的「谷底」。如果你不熟悉梯度下降法的话，你可以在这里找到一个很好的关于优化神经网络的介绍。\n\n## **梯度下降法变体**\n\n本文讨论了三种梯度下降法的变体——它们的不同之处在于，一次性使用多少数据来计算目标函数的梯度。对于不同的数据量，我们需要在参数更新准确性和参数更新花费时间两方面做出权衡。\n\n### **批量梯度下降法（Batch Gradient Descent）**\n\nVanilla 梯度下降法（译者注：Vanilla 是早期机器学习算法相关的名词，也是如今一个机器学习 python 程序库的名字，在该处指的是后者，参见：https://github.com/vinhkhuc/VanillaML，也就是大家所熟知的批量梯度下降法，在整个数据集上求出罚函数 J(θ 并）对每个参数 θ 求目标函数 J(θ) 的偏导数：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/001.png)\n\n在该方法中，每次更新我们都需要在整个数据集上求出所有的偏导数。因此批量梯度下降法的速度会比较慢，甚至对于较大的、内存无法容纳的数据集，该方法都无法被使用。同时，梯度下降法不能以「在线」的形式更新我们的模型，也就是不能再运行中加入新的样本进行运算。\n\n批量梯度下降法的实现代码，如下所示：\n\n```python\nfor i in range(nb_epochs):\n  params_grad = evaluate_gradient(loss_function, data, params)\n  params = params - learning_rate * params_grad\n```\n\n对于给定的迭代次数，我们首先基于输入的罚函数 loss_function 对输入的参数向量 params 计算梯度向量 params_grad。注意，最新的深度学习程序库中，提供了自动求导的功能，能够高效、快速地求给定函数对于特定参数的导数。如果你希望自己写代码求出梯度值，那么「梯度检查」会是一个不错的注意。（你可以参考这里，了解关于如何检查梯度的相关建议。）\n\n然后，我们对参数减去梯度值乘学习率的值，也就是在反梯度方向，更新我们参数。当目标函数 J(θ) 是一凸函数时，则批量梯度下降法必然会在全局最小值处收敛；否则，目标函数则可能会局部极小值处收敛。\n\n### **随机梯度下降法（Stochastic Gradient Descent）**\n\n相比批量梯度下降法，随机梯度下降法的每次更新，是对数据集中的一个样本（x，y）求出罚函数，然后对其求相应的偏导数：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/002.png)\n\n因为批量梯度下降法在每次更新前，会对相似的样本求算梯度值，因而它在较大的数据集上的计算会有些冗余（redundant）。而随机梯度下降法通过每次更新仅对一个样本求梯度，去除了这种冗余的情况。因而，它的运行速度被大大加快，同时也能够「在线」学习。\n\n随机梯度下降法更新值的方差很大，在频繁的更新之下，它的目标函数有着如下图所示的剧烈波动。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/003.png)\n\n_SGD 函数波动，来源：Wikipedia_\n\n相比批量梯度下降法的收敛会使目标函数落入一个局部极小值，SGD 收敛过程中的波动，会帮助目标函数跳入另一个可能的更小的极小值。另一方面，这最终会让收敛到特定最小值的过程复杂化，因为该方法可能持续的波动而不停止。但是，当我们慢慢降低学习率的时候，SGD 表现出了与批量梯度下降法相似的收敛过程，也就是说，对非凸函数和凸函数，必然会分别收敛到它们的极小值和最小值。\n\n相比批量梯度下降法的代码，在如下的代码中，我们仅仅加入了一个循环，用以遍历所有的训练样本并求出相应的梯度值。注意，如这里所说，在每次迭代中，我们会打乱训练数据集。\n\n```python\nfor i in range(nb_epochs):\n  np.random.shuffle(data)\n  for example in data:\n    params_grad = evaluate_gradient(loss_function, example, params)\n    params = params - learning_rate * params_grad\n```\n\n### **小批量梯度下降法（Mini-Batch Gradient Descent）**\n\n小批量梯度下降法集合了上述两种方法的优势，在每次更新中，对 n 个样本构成的一批数据，计算罚函数 J(θ)，并对相应的参数求导：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/004.png)\n\n这种方法，(a) 降低了更新参数的方差（variance），使得收敛过程更为稳定；(b) 能够利用最新的深度学习程序库中高度优化的矩阵运算器，能够高效地求出每小批数据的梯度。通常一小批数据含有的样本数量在 50 至 256 之间，但对于不同的用途也会有所变化。小批量梯度下降法，通常是我们训练神经网络的首选算法。同时，有时候我们也会使用随机梯度下降法，来称呼小批量梯度下降法（译者注：在下文中，我们就用 SGD 代替随机梯度下降法）。注意：在下文对于随机梯度法优化的介绍中，为方便起见，我们会省略式子中的参数 x(i:i+n),y(i:i+n)。\n\n如下的代码所示，我们不再对每个样本进行循环，而是对每批带有 50 个样本的小批数据进行循环：\n\n```python\nfor i in range(nb_epochs):\n  np.random.shuffle(data)\n  for batch in get_batches(data, batch_size=50):\n    params_grad = evaluate_gradient(loss_function, batch, params)\n    params = params - learning_rate * params_grad\n```\n\n## **面临的挑战**\n\n由于 Vanilla 小批量梯度下降法并不能保证良好地收敛，这给我们留下了如下待解决的挑战：\n\n* 选择适当的学习率是一个难题。太小的学习率会导致较慢的收敛速度，而太大的学习率则会阻碍收敛，并会引起罚函数在最小值处震荡，甚至有可能导致结果发散；\n* 我们可以设置一个关于学习率地列表，通过如退火的方法，在学习过程中调整学习率——按照一个预先定义的列表、或是当每次迭代中目标函数的变化小于一定阈值时来降低学习率。但这些列表或阈值，需要根据数据集地特性，被提前定义。\n* 此外，我们对所有的参数都采用了相同的学习率。但如果我们的数据比较稀疏，同时特征有着不同的出现频率，那么我们不希望以相同的学习率来更新这些变量，我们希望对较少出现的特征有更大的学习率。\n\n在对神经网络最优化非凸的罚函数时，另一个通常面临的挑战，是如何避免目标函数被困在无数的局部最小值中，以导致的未完全优化的情况。Dauphin 及其他人 [19] 认为，这个困难并不来自于局部最小值，而是来自于「鞍点」，也就是在一个方向上斜率是正的、在一个方向上斜率是负的点。这些鞍点通常由一些函数值相同的面环绕，它们在各个方向的梯度值都为 0，所以 SGD 很难从这些鞍点中脱开。\n\n## **梯度下降的优化算法**\n\n在如下的讨论中，我们将会列举一些应对上述问题的算法，它们被广泛应用于深度学习社区。同时，我们不会讨论那些不能应用于高维数据集的方法，例如牛顿法等针对二阶问题的方法。\n\n### **动量法**\n\nSGD 很难在陡谷——一种在一个方向的弯曲程度远大于其他方向的表面弯曲情况——中找到正确更新方向。而这种陡谷，经常在局部极值中出现。在这种情况下，如图 2 所示，SGD 在陡谷的周围震荡，向局部极值处缓慢地前进。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/005.png)\n\n动量法 [2]，如图 3 所示，则帮助 SGD 在相关方向加速前进，并减少它的震荡。他通过修改公式中，在原有项前增加一个折损系数γ，来实现这样的功能：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/006.png)\n\n注意：在其他的一些算法实现中，公式中的符号也许有所不同。动量项 γ 往往被设置为 0.9 或为其他差不多的值。\n\n从本质上说，动量法，就仿佛我们从高坡上推下一个球，小球在向下滚动的过程中积累了动量，在途中他变得越来越快（直到它达到了峰值速度，如果有空气阻力的话，γ&lt;1）。在我们的算法中，相同的事情发生在我们的参数更新上：动量项在梯度指向方向相同的方向逐渐增大，对梯度指向改变的方向逐渐减小。由此，我们得到了更快的收敛速度以及减弱的震荡。\n\n### **Nesterov 加速梯度法**\n\n但当一个小球从山谷上滚下的时候，盲目的沿着斜率方向前行，其效果并不令人满意。我们需要有一个更「聪明」的小球，它能够知道它再往哪里前行，并在知道斜率再度上升的时候减速。\n\nNesterov 加速梯度法（NAG）是一种能给予梯度项上述「预测」功能的方法。我们知道，我们使用动量项γvt-1 来「移动」参数项θ。通过计算θ-γvt-1，我们能够得到一个下次参数位置的近似值——也就是能告诉我们参数大致会变为多少。那么，通过基于未来参数的近似值而非当前的参数值计算相得应罚函数 J(θ-γvt-1) 并求偏导数，我们能让优化器高效地「前进」并收敛：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/007.png)\n\n在该情况下，我们依然设定动量系数γ 在 0.9 左右。如下图 4 所示，动量法首先计算当前的梯度值（小蓝色向量），然后在更新的积累向量（大蓝色向量）方向前进一大步。但 NAG 法则首先（试探性地）在之前积累的梯度方向（棕色向量）前进一大步，再根据当前地情况修正，以得到最终的前进方向（绿色向量）。这种基于预测的更新方法，使我们避免过快地前进，并提高了算法地响应能力（responsiveness），大大改进了 RNN 在一些任务上的表现 [8]。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/008.png)\n\n_Nesterov Update 法，来源：G. Hinton's lecture 6c_\n\n参考这里，以查看 Ilya Sutskever 在它博士论文中，对 NAG 机理的更为详尽的解释 [9]。\n\n因为我们现在能根据我们罚函数的梯度值来调整我们的更新，并能相应地加速 SGD，我们也希望能够对罚函数中的每个参数调整我们的更新值，基于它们的重要性以进行或大或小的更新。\n\n### **Adagrad法**\n\nAdagrad[3] 是一个基于梯度的优化算法，它的主要功能是：它对不同的参数调整学习率，具体而言，对低频出现的参数进行大的更新，对高频出现的参数进行小的更新。因此，他很适合于处理稀疏数据。Dean 等人 [14] 发现，Adagrad 法大大提升了 SGD 的鲁棒性，并在谷歌使用它训练大规模的神经网络，其诸多功能包括识别 Youtube 视频中的猫。此外，Pennington 等人 [5] 使用它训练 GloVe 单词向量映射（Word Embedding），在其中不频繁出现的词语需要比频繁出现的更大的更新值。\n\n在这之前，我们对于所有的参数使用相同的学习率进行更新。但 Adagrad 则不然，对不同的训练迭代次数 t，adagrad 对每个参数都有一个不同的学习率。我们首先考察 adagrad 每个参数的的更新过程，然后我们再使之向量化。为简洁起见，我们记在迭代次数 t 下，对参数θi 求目标函数梯度的结果为 gt,i：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/009.png)\n\n那么普通 SGD 的更新规则为：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/010.png)\n\n而 adagrad 将学习率η进行了修正，对迭代次数 t，基于每个参数之前计算的梯度值，将每个参数的学习率η按如下方式修正：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/011.png)\n\n其中 是一个对角阵，其中对角线上的元素是从一开始到 时刻目标函数对于参数 梯度的平方和。是一个平滑项，以避免分母为 0 的情况，它的数量级通常在。有趣的是，如果不开方的话，这个算法的表现会变得很糟。\n\n因为 在其对角线上，含有过去目标函数对于参数 梯度的平方和，我们可以利用一个元素对元素的向量乘法，将我们的表达式向量化：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/012.png)\n\nAdagrad 主要优势之一，是它不需要对每个学习率手工地调节。而大多数算法，只是简单地使用一个相同地默认值如 0.1，来避免这样地情况。\n\nAdagrad 地主要劣势，是他在分母上的项中积累了平方梯度和。因为每次加入的项总是一个正值，所以累积的和将会随着训练过程而增大。因而，这会导致学习率不断缩小，并最终变为一个无限小值——此时，这个算法已经不能从数据中学到额外的信息。而下面的算法，则旨在解决这个问题。\n\n### **Adadelta 法**\n\nAdadelta 法 [6] 是 Adagrad 法的一个延伸，它旨在解决它学习率不断单调下降的问题。相比计算之前所有梯度值的平方和，Adadelta 法仅计算在一个大小为 的时间区间内梯度值的累积和。\n\n但该方法并不会存储之前 个梯度的平方值，而是将梯度值累积值按如下的方式递归地定义：它被定义为关于过去梯度值的衰减均值（decade average），当前时间的梯度均值是基于过去梯度均值和当前梯度值平方的加权平均，其中是类似上述动量项的权值。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/013.png)\n\n与动量项的设定类似，我们设定 为以 0.9 左右的值。为明确起见，我们将我们的 SGD 更新规则写为关于参数更新向量 的形式：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/014.png)\n\n由此，我们刚刚在 Adagrad 法中推导的的参数更新规则的向量表示，变为如下形式：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/015.png)\n\n我们现在将其中的对角矩阵 用上述定义的基于过去梯度平方和的衰减均值 替换：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/016.png)\n\n因为分母表达式的形式与梯度值的方均根（root mean squared,RMS）形式类似，因而我们使用相应的简写来替换：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/017.png)\n\n作者还注意到，在该更新中（在 SGD、动量法或者 Adagrad 也类似）的单位并不一致，也就是说，更新值的量纲与参数值的假设量纲并不一致。为改进这个问题，他们定义了另外一种指数衰减的衰减均值，他是基于参数更新的平方而非梯度的平方来定义的：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/018.png)\n\n因此，对该问题的方均根为：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/019.png)\n\n因为 值未知，所以我们使用 时刻的方均根来近似。将前述规则中的学习率 替换为，我们最终得到了 Adadelta 法的更新规则：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/020.png)\n\n借助 Adadelta 法，我们甚至不需要预设一个默认学习率，因为它已经从我们的更新规则中被删除了。\n\n### **RMSprop 法**\n\nRMSprop 是由 Geoff Hinton 在他 Coursera 课程中提出的一种适应性学习率方法，至今仍未被公开发表。\n\nRMSprop 法和 Adadelta 法几乎同时被发展出来。他们 解决 Adagrad 激进的学习率缩减问题。实际上，RMSprop 和我们推导出的 Adadelta 法第一个更规则相同：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/021.png)\n\nRMSprop 也将学习率除以了一个指数衰减的衰减均值。Hinton 建议设定 为 0.9，对 而言，0.001 是一个较好的默认值。\n\n### **Adam**\n\n适应性动量估计法（Adam）[15] 是另一种能对不同参数计算适应性学习率的方法。除了存储类似 Adadelta 法或 RMSprop 中指数衰减的过去梯度平方均值 外，Adam 法也存储像动量法中的指数衰减的过去梯度值均值 ：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/022.png)\n\n和 分别是梯度的一阶矩（均值）和二阶矩（表示不确定度的方差），这也就是该方法名字的来源。因为当 和 一开始被初始化为 0 向量时，Adam 的作者观察到，该方法会有趋向 0 的偏差，尤其是在最初的几步或是在衰减率很小（即 和 接近 1）的情况下。\n\n他们使用偏差纠正系数，来修正一阶矩和二阶矩的偏差：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/023.png)\n\n他们使用这些来更新参数，更新规则很我们在 Adadelta 和 RMSprop 法中看到的一样，服从 Adam 的更新规则： \n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/024.png)\n\n作者认为参数的默认值应设为：0.9 for β1, 0.999 for β2, and 10−8 for ϵ. 。他们的经验表明，Adam 在实践中表现很好，和其他适应性学习算法相比也比较不错。\n\n### **算法可视化**\n\n如下的两个动画（图像版权：Alec Radford）给了我们关于特定优化算法在优化过程中行为的直观感受。你可以参见这里，以获取 Karpathy 对相同图像的一些描述，及另关于一些相关算法的细致讨论。\n\n在图 5 中，我们可以看到，在罚函数的等高线图中，优化器的位置随时间的变化情况。注意到，Adagrad、 Adadelta 及 RMSprop 法几乎立刻就找到了正确前进方向并以相似的速度很快收敛。而动量法和 NAG 法，则找错了方向，如图所示，让小球沿着梯度下降的方向前进。但 NAG 法能够很快改正它的方向向最小指出前进，因为他能够往前看并对前面的情况做出响应。\n\n图 6 展现了各算法在鞍点附近的表现。如上面所说，这对对于 SGD 法、动量法及 NAG 法制造了一个难题。他们很难打破」对称性「带来的壁垒，尽管最后两者设法逃脱了鞍点。而 Adagrad 法、RMSprop 法及 Adadelta 法都能快速的沿着负斜率的方向前进。\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/025.gif)\n\n_图5：SGD optimization on loss surface contours_\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/026.gif)\n\n_图6：SGD optimization on saddle point 10 − 8\n\n如我们所见，适应性学习率方法，也就是 Adagrad 法、Adadelta 法 、RMSprop 法及 Adam 法最适合处理上述情况，并有最好的收敛效果。\n\n### **如何选择优化器？**\n\n那么，我们该如何选择优化器呢？如果你的输入数据较为稀疏（sparse），那么使用适应性学习率类型的算法会有助于你得到好的结果。此外，使用该方法的另一好处是，你在不调参、直接使用默认值的情况下，就能得到最好的结果。\n\n总的来说，RMSprop 法是一种基于 Adagrad 法的拓展，他从根本上解决学习率骤缩的问题。Adadelta 法于 RMSprop 法大致相同，除了前者使用了。而 Adam 法，则基于 RMSprop 法添加了偏差修正项和动量项。在我们地讨论范围中，RMSprop、Adadelta 及 Adam 法都是非常相似地算法，在相似地情况下都能做的很好。Kingma 及其他人 [15] 展示了他们的偏差修正项帮助 Adam 法，在最优化过程快要结束、梯度变得越发稀疏的时候，表现略微优于 RMSprop 法。总的来说，Adam 也许是总体来说最好的选择。\n\n有趣的是，很多最新的论文，都直接使用了（不带动量项的）Vanilla SGD 法，配合一个简单的学习率（退火）列表。如论文所示，这些 SGD 最终都能帮助他们找到一个最小值，但会花费远多于上述方法的时间。并且这些方法非常依赖于鲁棒的初始化值及退火列表。因此，如果你非常在你的模型能快速收敛，或是你需要训练一个深度或复杂模型，你可能需要选择上述的适应性模型。\n\n## **对 SGD 进行平行计算或分布式计算**\n\n现如今，大规模数据集随处可见、小型计算机集群也易于获得。因而，使用分布式方法进一步加速 SGD 是一个惯常的选择。\n\nSGD 它本事是序列化的：通过一步一步的迭代，我们最终求到了最小值。运行它能够得到不错的收敛结果，但是特别是对于大规模的数据集，它的运行速度很慢。相比而言，异步 SGD 的运行速度相对较快，但在不同的工作机之间的关于非完全优化的沟通可能会导致较差的收敛结果。此外，我们能够对 SGD 进行平行运算而不需要一个计算机集群。下文讨论了相关的算法或架构，它们或关于平行计算或者对其进行了分布式优化。\n\n### **Hogwild!**\n\nNiu 等人提出了一种叫做 Hogwild! 的更新规则，它允许在平行 GPU 上进行 SGD 更新。处理器。这仅能在输入数据集是稀疏的时起效，在每次更新过程中仅会修正一部分的参数值。他们展示了，在这种情况下，这个更新规则达到了最优化的收敛速度，因为处理器不太会覆盖有用的信息。\n\n### **Downpour SGD**\n\nDownpour SGD 是一个异步的 SGD 法变体，它被 Dean 等人 [4] 用在了谷歌的 DistBelief 架构中（它是 TensorFlow 的前身）。他对训练集地子集同步地运行模型的多个副本。这些模型将它们的更新值发送到参数服务器，服务器被分为了许多台主机。每一台主机都负责存储和上载模型的一部分参数。但是，副本之间却没有相互的通信——例如，共享权重值或者更新值——其参数面临着发散的风险，会阻止收敛。\n\n### **容忍延迟的 SGD 算法**\n\nMcMahan 和 Streeter [12] 改良了 AdaGrad 法使之能够用于平行运算的场景。通过实现延迟容忍的算法，它不仅能能够适应于过去的梯度，还能够适应于更新的延迟。在实践中，它的表现很好。\n\n### **TensorFlow**\n\nTensorFlow[13] 是谷歌最近开源的一个实现和部署大规模机器学习模型的架构。它基于他们之前对于使用 DistBelief 的经验，并已在内部被部署在一系列的移动设备及大规模的分布式系统上进行计算。为了分布式执行，一个计算图被分为了许多子图给不同的设备，设备之间的通信使用了发送和接受节点对。2016 年 4 月 13 日更新：一个分布式 TensorFlow 的版本已经被发布。\n\n### **弹性平均梯度下降法（Elastic Averaging SGD）**\n\n张等人 [14] 提出了弹性平均梯度下降法（EASGD），他使不同工作机之间不同的 SGD 以一个「弹性力」连接，也就是一个储存于参数服务器的中心变量。这允许局部变量比中心变量更大地波动，理论上允许了对参数空间更多的探索。他们的经验表明，提高的探索能力有助于在寻找新的局部极值中提升（优化器的）表现。\n\n## **优化 SGD 的其他手段**\n\n最后，我们将讨论一些其他手段，他们可以与前述的方法搭配使用，并能进一步提升 SGD 的效果。你可以参考 [22]，以了解一些其他常用策略。\n\n重排法（Shuffling）和递进学习（Curriculum Learning）\n\n总体而言，我们希望避免训练样本以某种特定顺序传入到我们的学习模型中，因为这会向我们的算法引入偏差。因此，在每次迭代后，对训练数据集中的样本进行重排（shuffling），会是一个不错的注意。\n\n另一方面，在某些情况下，我们会需要解决难度逐步提升的问题。那么，按照一定的顺序遍历训练样本，会有助于改进学习效果及加快收敛速度。这种构建特定遍历顺序的方法，叫做递进学习（Curriculum Learning）[16]。*这个词目前没有标准翻译，我根据表意和意义翻译成这个。\n\nZaremba 和 Sutskever [17] 仅使用了递进学习法训练 LSTMs 来学习简单的项目，但结果表明，递进学习法使用的混合策略的表现好于朴素策略——后者不断地重排数据，反而增加了学习过程的难度。\n\n### **批量标准化（Batch Normalization）**\n\n我们通常设置我们参数初值的均值和方差分别为 0 和单位值，以帮助模型进行学习。随着学习过程的进行，每个参数被不同程度地更新，相应地，参数的正则化特征也随之失去了。因此，随着训练网络的越来越深，训练的速度会越来越慢，变化值也会被放大。\n\n批量标准化 [18] 对每小批数据都重新进行标准化，并也会在操作中逆传播（back-propgate）变化量。在模型中加入批量标准化后，我们能使用更高的学习率且不要那么在意初始化参数。此外，批量正则化还可以看作是一种正则化手段，能够减少（甚至去除）留出法的使用。\n\n### **早停（Early Stopping）**\n\n诚如 Geoff Hinton 所言：「Early stopping (is) beautiful free lunch（早停是美妙的免费午餐，又简单效果又好）」（NIPS 2015 Tutorial Sildes, Slide 63）。在训练过程中，你应该时刻关注模型在验证集上的误差情况，并且在改误差没有明显改进的时候停止训练。\n\n### **梯度噪声（Gradient Noise）**\n\nNeelakentan 等人 [21] 在每次梯度的更新中，向其中加入一个服从合高斯分布 N(0,σ^2) 的噪声值：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/027.png)\n\n并按照如下的方式修正方差：\n\n![](/assets/images/2016/11/21/dl-optimization-gradient-descent/028.png)\n\n他们指出，这种方式能够提升神经网络在不良初始化前提下的鲁棒性，并能帮助训练特别是深层、复杂的神经网络。他们发现，加入噪声项之后，模型更有可能发现并跳出在深度网络中频繁出现的局部最小值。\n\n## **结论**\n\n在本文中，我们首先分析了梯度下降法的三个变体，在其中小批量梯度下降法最受欢迎。接着，我们研究了常用的优化 SGD 的算法，包括：动量法、Nesterov accelerated gradient 法、Adagrad 法、Adadelta 法、RMSprop 法、Adam 法及其他优化异步 SGD 的算法。最终，我们讨论了另外一些改进 SGD 的策略，包括样本重排法（shuffling）、递进学习（curriculum learning）、批量标准化（Batch Normali&middot;zation）及早停（early stopping）等。\n\n我希望本文能增进读者关于这些优化算法的认识，能对这些算法的行为与动机有一个了解。也许我遗漏了一些常用的优化 SGD 的算法，或是你有一些自己使用 SGD 训练的技巧。如果有的话，请在下方留言区留言让我知道。\n\n## 参考文献\n\n* 原文连接查看：[http://sebastianruder.com/optimizing-gradient-descent/](http://sebastianruder.com/optimizing-gradient-descent/)\n\n---\n\n* Source: [机器之心](http://www.jiqizhixin.com)\n* Link: [深度解读最流行的优化算法：梯度下降](http://www.jiqizhixin.com/article/1857)","tags":["Deep-Learning"],"categories":["Deep-Learning"]},{"title":"服务容错模式","url":"%2F2016%2F2016-11-11-service-fault-tolerant-mode%2F","content":"\n# 背景\n\n随着美团点评服务框架和服务治理体系的逐步成熟，服务化已成为公司内部系统设计的趋势。本着大系统小做、职责单一的原则，我们度假技术团队对业务系统进行了不少服务化拆分工作。随着业务复杂度的增加，依赖的服务也逐步增加，出现了不少由于服务调用出现异常问题而导致的重大事故，如：\n\n1. 系统依赖的某个服务发生延迟或者故障，数秒内导致所有应用资源（线程，队列等）被耗尽，造成所谓的雪崩效应 ([Cascading Failure](https://en.wikipedia.org/wiki/Cascading_failure))，导致整个系统拒绝对外提供服务。\n\n2. 系统遭受恶意爬虫袭击，在放大效应下没有对下游依赖服务做好限速处理，最终导致下游服务崩溃。\n\n容错是一个很大的话题，受篇幅所限，本文将介绍仅限定在服务调用间常用的一些容错模式。\n\n# 设计原则\n\n服务容错的设计有个基本原则，就是“Design for Failure”。为了避免出现“千里之堤溃于蚁穴”这种情况，在设计上需要考虑到各种边界场景和对于服务间调用出现的异常或延迟情况，同时在设计和编程时也要考虑周到。这一切都是为了达到以下目标：\n\n1. 一个依赖服务的故障不会严重破坏用户的体验。\n\n2. 系统能自动或半自动处理故障，具备自我恢复能力。\n\n基于这个原则和目标，衍生出下文将要介绍的一些模式，能够解决分布式服务调用中的一些问题，提高系统在故障发生时的存活能力。\n\n# 一些经典的容错模式\n\n所谓模式，其实就是某种场景下一类问题及其解决方案的总结归纳，往往可以重用。模式可以指导我们完成任务，作出合理的系统设计方案，达到事半功倍的效果。而在服务容错这个方向，行业内已经有了不少实践总结出来的解决方案。\n\n## 超时与重试（Timeout and Retry）\n\n超时模式，是一种最常见的容错模式，在美团点评的工程实践中大量存在。常见的有设置网络连接超时时间，一次RPC的响应超时时间等。在分布式服务调用的场景中，它主要解决了当依赖服务出现建立网络连接或响应延迟，不用无限等待的问题，调用方可以根据事先设计的超时时间中断调用，及时释放关键资源，如Web容器的连接数，数据库连接数等，避免整个系统资源耗尽出现拒绝对外提供服务这种情况。\n\n重试模式，一般和超时模式结合使用，适用于对于下游服务的数据强依赖的场景（不强依赖的场景不建议使用！），通过重试来保证数据的可靠性或一致性，常用于因网络抖动等导致服务调用出现超时的场景。与超时时间设置结合使用后，需要考虑接口的响应时间分布情况，超时时间可以设置为依赖服务接口99.5%响应时间的值，重试次数一般1-2次为宜，否则会导致请求响应时间延长，拖累到整个系统。\n\n一些实现说明：\n\n```java\n    public class RetryCommand<T> {\n        private int maxRetries = 2;// 重试次数 默认2次\n        private long retryInterval = 5;//重试间隔时间ms 默认5ms\n        private Map<String, Object> params;\n\n           public RetryCommand() {\n\n        }\n\n        public RetryCommand(long retryInterval, int maxRetries) {\n               this.retryInterval = retryInterval;\n            this.maxRetries = maxRetries;\n        }\n\n        public T command(Map<String, Object> params){\n              //Some remote service call with timeout\n               serviceA.doSomethingWithTimeOut(timeout);\n        }\n\n        private final T retry() throws RuntimeException {\n            int retryCounter = 0;\n            while (retryCounter < maxRetries) {\n                try {\n                    return command(params);\n                } catch (Exception e) {\n                    retryCounter++;\n                    if (retryCounter >= maxRetries) {\n                        break;\n               }\n            }\n        }\n        throw new RuntimeException(\"Command failed on all of \" + maxRetries + \" retries\");\n    }\n\n        //省略\n    }\n```\n\n## 限流(Rate Limiting/Load Shedder)\n\n限流模式，常用于下游服务容量有限，但又怕出现突发流量猛增（如恶意爬虫，节假日大促等）而导致下游服务因压力过大而拒绝服务的场景。常见的限流模式有控制并发和控制速率，一个是限制并发的数量，一个是限制并发访问的速率。\n\n### 控制并发\n\n属于一种较常见的限流手段，在工程实践中可以通过信号量机制（如Java中的Semaphore）来控制，举个例子：\n\n假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发的读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有十个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，我们就可以使用Semaphore来控制并发数，如：\n\n```java\n    public class SemaphoreTest {\n\n        private static final int THREAD_COUNT = 30;\n\n        private static ExecutorService threadPool = Executors\n            .newFixedThreadPool(THREAD_COUNT);\n\n        private static Semaphore s = new Semaphore(10);\n\n        public static void main(String[] args) {\n            for (int i = 0; i < THREAD_COUNT; i++) {\n                threadPool.execute(new Runnable() {\n                    @Override\n                    public void run() {\n                        try {\n                            s.acquire();\n                            System.out.println(\"save data\");\n                            s.release();\n                        } catch (InterruptedException e) {\n                            e.printStack();\n                        }\n                    }\n                });\n            }\n\n            threadPool.shutdown();\n        }\n    }\n```\n\n在代码中，虽然有30个线程在执行，但是只允许10个并发的执行。Semaphore的构造方法Semaphore(int permits) 接受一个整型的数字，表示可用的许可证数量。Semaphore(10)表示允许10个线程获取许可证，也就是最大并发数是10。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()获取一个许可证，使用完之后调用release()归还许可证，还可以用tryAcquire()方法尝试获取许可证。\n\n### 控制速率\n\n在我们的工程实践中，常见的是使用令牌桶算法来实现这种模式，其他如漏桶算法也可以实现控制速率，但在我们的工程实践中使用不多，这里不做介绍，读者请自行了解。\n\n![令牌桶算法](/assets/images/2016/11/11/service-fault-tolerant-mode/token_bucket.jpg)\n\n在Wikipedia上，令牌桶算法是这么描述的：\n\n1.  每秒会有r个令牌放入桶中，或者说，每过1/r秒桶中增加一个令牌。\n2.  桶中最多存放b个令牌，如果桶满了，新放入的令牌会被丢弃。\n3.  当一个n字节的数据包到达时，消耗n个令牌，然后发送该数据包。\n4.  如果桶中可用令牌小于n，则该数据包将被缓存或丢弃。\n\n令牌桶控制的是一个时间窗口内通过的数据量，在API层面我们常说的QPS、TPS，正好是一个时间窗口内的请求量或者事务量，只不过时间窗口限定在1s罢了。以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。令牌桶的另外一个好处是可以方便的改变速度，一旦需要提高速率，则按需提高放入桶中的令牌的速率。\n\n在我们的工程实践中，通常使用Guava中的Ratelimiter来实现控制速率，如我们不希望每秒的任务提交超过两个：\n\n```java\n    //速率是每秒两个许可\n    final RateLimiter rateLimiter = RateLimiter.create(2.0);\n\n    void submitTasks(List tasks, Executor executor) {\n        for (Runnable task : tasks) {\n            rateLimiter.acquire(); // 也许需要等待\n            executor.execute(task);\n        }\n    }\n```\n\n## 电路熔断器(Circuit Breaker)\n\n在我们的工程实践中，偶尔会遇到一些服务由于网络连接超时，系统有异常或load过高出现暂时不可用等情况，导致对这些服务的调用失败，可能需要一段时间才能修复，这种对请求的阻塞可能会占用宝贵的系统资源，如：内存，线程，数据库连接等等，最坏的情况下会导致这些资源被消耗殆尽，使得系统里不相关的部分所使用的资源也耗尽从而拖累整个系统。在这种情况下，调用操作能够立即返回错误而不是等待超时的发生或者重试可能是一种更好的选择，只有当被调用的服务有可能成功时我们再去尝试。\n\n熔断器模式可以防止我们的系统不断地尝试执行可能会失败的调用，使得我们的系统继续执行而不用等待修正错误，或者浪费CPU时间去等到长时间的超时产生。熔断器模式也可以使我们系统能够检测错误是否已经修正，如果已经修正，系统会再次尝试调用操作。下图是个使用熔断器模式的调用流程：\n\n![熔断器模式](/assets/images/2016/11/11/service-fault-tolerant-mode/circuit1.png)\n\n可以从图中看出，当超时出现的次数达到一定条件后，熔断器会触发打开状态，客户端的下次调用将直接返回，不用等待超时产生。\n\n在熔断器内部，往往有以下几种状态：\n\n![熔断器模式](/assets/images/2016/11/11/service-fault-tolerant-mode/circuit2.png)\n\n1）闭合（closed）状态：该状态下能够对目标服务或方法进行正常的调用。熔断器类维护了一个时间窗口内调用失败的次数，如果某次调用失败，则失败次数加1。如果最近失败次数超过了在给定的时间窗口内允许失败的阈值(可以是数量也可以是比例)，则熔断器类切换到断开(Open)状态。此时熔断器设置了一个计时器，当时钟超过了该时间，则切换到半断开（Half-Open）状态，该睡眠时间的设定是给了系统一次机会来修正导致调用失败的错误。\n\n2）断开(Open)状态：在该状态下，对目标服务或方法的请求会立即返回错误响应，如果设置了fallback方法，则会进入fallback的流程。\n\n3）半断开（Half-Open）状态：允许对目标服务或方法的一定数量的请求可以去调用服务。如果这些请求对服务的调用成功，那么可以认为之前导致调用失败的错误已经修正，此时熔断器切换到闭合状态（并且将错误计数器重置）；如果这一定数量的请求有调用失败的情况，则认为导致之前调用失败的问题仍然存在，熔断器切回到断开方式，然后开始重置计时器来给系统一定的时间来修正错误。半断开状态能够有效防止正在恢复中的服务被突然而来的大量请求再次拖垮。\n\n在我们的工程实践中，熔断器模式往往应用于服务的自动降级，在实现上主要基于Netflix开源的组件Hystrix来实现，下图和代码分别是Hystrix中熔断器的原理和定义，更多了解可以查看Hystrix的源码：\n\n![模式组合](/assets/images/2016/11/11/service-fault-tolerant-mode/circuit3.png)\n\n```java\n    public interface HystrixCircuitBreaker {\n\n        /**\n         * Every {@link HystrixCommand} requests asks this if it is allowed to proceed or not.\n          * <p>\n          * This takes into account the half-open logic which allows some requests through when determining if it should be closed again.\n          *\n          * @return boolean whether a request should be permitted\n          */\n         public boolean allowRequest();\n\n         /**\n          * Whether the circuit is currently open (tripped).\n          *\n          * @return boolean state of circuit breaker\n         */\n         public boolean isOpen();\n\n        /**\n         * Invoked on successful executions from {@link HystrixCommand} as part of feedback mechanism when in a half-open state.\n         */\n        public void markSuccess();\n    }\n```\n\n## 舱壁隔离(Bulkhead Isolation)\n\n在造船行业，往往使用此类模式对船舱进行隔离，利用舱壁将不同的船舱隔离起来，这样如果一个船舱破了进水，只损失一个船舱，其它船舱可以不受影响，而借鉴造船行业的经验，这种模式也在软件行业得到使用。\n\n线程隔离(Thread Isolation)就是这种模式的常见的一个场景。例如，系统A调用了ServiceB/ServiceC/ServiceD三个远程服务，且部署A的容器一共有120个工作线程，采用线程隔离机制，可以给对ServiceB/ServiceC/ServiceD的调用各分配40个线程。当ServiceB慢了，给ServiceB分配的40个线程因慢而阻塞并最终耗尽，线程隔离可以保证给ServiceC/ServiceD分配的80个线程可以不受影响。如果没有这种隔离机制，当ServiceB慢的时候，120个工作线程会很快全部被对ServiceB的调用吃光，整个系统会全部慢下来，甚至出现系统停止响应的情况。\n\n这种Case在我们实践中经常遇到，如某接口由于数据库慢查询，外部RPC调用超时导致整个系统的线程数过高，连接数耗尽等。我们可以使用舱壁隔离模式，为这种依赖服务调用维护一个小的线程池，当一个依赖服务由于响应慢导致线程池任务满的时候，不会影响到其他依赖服务的调用，它的缺点就是会增加线程数。\n\n![舱壁隔离模式](/assets/images/2016/11/11/service-fault-tolerant-mode/bulkhead.png)\n\n无论是超时/重试，熔断器，还是舱壁隔离模式，它们在使用过程中都会出现异常情况，异常情况的处理方式间接影响到用户的体验，针对异常情况的处理也有一种模式支撑，这就是回退(fallback)模式。\n\n## 回退(Fallback)\n\n在超时，重试失败，熔断或者限流发生的时候，为了及时恢复服务或者不影响到用户体验，需要提供回退的机制，常见的回退策略有：\n\n1.  自定义处理：在这种场景下，可以使用默认数据，本地数据，缓存数据来临时支撑，也可以将请求放入队列，或者使用备用服务获取数据等，适用于业务的关键流程与严重影响用户体验的场景，如商家/产品信息等核心服务。\n\n2.  故障沉默（fail-silent）：直接返回空值或缺省值，适用于可降级功能的场景，如产品推荐之类的功能，数据为空也不太影响用户体验。\n\n3.  快速失败（fail-fast）：直接抛出异常，适用于数据非强依赖的场景，如非核心服务超时的处理。\n\n# 应用实例\n\n在实际的工程实践中，这四种模式既可以单独使用，也可以组合使用，为了让读者更好的理解这些模式的应用，下面以Netflix的开源组件Hystrix的流程为例说明。\n\n![模式组合](/assets/images/2016/11/11/service-fault-tolerant-mode/patterns.png)\n\n图中流程的说明:\n\n1.  将远程服务调用逻辑封装进一个HystrixCommand。\n\n2.  对于每次服务调用可以使用同步或异步机制，对应执行execute()或queue()。\n\n3.  判断熔断器(circuit-breaker)是否打开或者半打开状态，如果打开跳到步骤8，进行回退策略，如果关闭进入步骤4。\n\n4.  判断线程池/队列/信号量（使用了舱壁隔离模式）是否跑满，如果跑满进入回退步骤8，否则继续后续步骤5。\n\n5.  run方法中执行了实际的服务调用。\n\n    a. 服务调用发生超时时，进入步骤8。\n\n6.  判断run方法中的代码是否执行成功。\n\n    a. 执行成功返回结果。\n\n    b. 执行中出现错误则进入步骤8。\n\n7.  所有的运行状态(成功，失败，拒绝，超时)上报给熔断器，用于统计从而影响熔断器状态。\n\n8.  进入getFallback()回退逻辑。\n\n    a. 没有实现getFallback()回退逻辑的调用将直接抛出异常。\n\n    b. 回退逻辑调用成功直接返回。\n\n    c. 回退逻辑调用失败抛出异常。\n\n9.  返回执行成功结果。\n\n# 总结\n\n服务容错模式在美团点评系统的稳定性保障方面应用很多，学习模式有助于新人直接利用熟练软件工程师的经验，对于提升系统的稳定性有很大的帮助。服务容错的目的主要是为了防微杜渐，除此之外错误的及时发现和监控其实同等重要。随着技术的演化，新的模式在不断的学习与实践中沉淀出来，美团点评度假技术团队在构建一个高可用高性能的系统目标之外，让系统越来越有弹性（Resilience）也是我们新的追求。\n\n# 参考文献\n\n1.  [Netflix Hystrix Wiki](https://github.com/Netflix/Hystrix/wiki)\n2.  Martin Fowler. [CircuitBreaker](http://martinfowler.com/bliki/CircuitBreaker.html)\n3.  Hanmer R. Patterns for Fault Tolerant Software. Wiley, 2007.\n4.  Nygard M. 发布！软件的设计与部署. 凃鸣 译. 人民邮电出版社, 2015.\n\n---\n\n* Author: 绿麟\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [服务容错模式](http://tech.meituan.com/service-fault-tolerant-pattern.html)","tags":["Design"],"categories":["Service"]},{"title":"Java NIO浅析","url":"%2F2016%2F2016-11-04-java-nio%2F","content":" \nNIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O处理问题的有效方式。\n\n那么NIO的本质是什么样的呢？它是怎样与事件模型结合来解放线程、提高系统吞吐的呢？\n\n本文会从传统的阻塞I/O和线程池模型面临的问题讲起，然后对比几种常见I/O模型，一步步分析NIO怎么利用事件模型处理I/O，解决线程池瓶颈处理海量连接，包括利用面向事件的方式编写服务端/客户端程序。最后延展到一些高级主题，如Reactor与Proactor模型的对比、Selector的唤醒、Buffer的选择等。\n\n注：本文的代码都是伪代码，主要是为了示意，不可用于生产环境。\n\n# 传统BIO模型分析\n\n让我们先回忆一下传统的服务器端同步阻塞I/O处理（也就是BIO，Blocking I/O）的经典编程模型：\n\n```java\n{\n  ExecutorService executor = Excutors.newFixedThreadPollExecutor(100);//线程池\n\n  ServerSocket serverSocket = new ServerSocket();\n  serverSocket.bind(8088);\n  while(!Thread.currentThread.isInturrupted()){//主线程死循环等待新连接到来\n    Socket socket = serverSocket.accept();\n    executor.submit(new ConnectIOnHandler(socket));//为新的连接创建新的线程\n  }\n}\n\nclass ConnectIOnHandler extends Thread{\n   private Socket socket;\n   public ConnectIOnHandler(Socket socket){\n      this.socket = socket;\n   }\n   public void run(){\n      while(!Thread.currentThread.isInturrupted()&&!socket.isClosed()){死循环处理读写事件\n         String someThing = socket.read()....//读取数据\n         if(someThing!=null){\n             ......//处理数据\n             socket.write()....//写数据\n         }\n      }\n   }\n}\n```\n\n这是一个经典的每连接每线程的模型，之所以使用多线程，主要原因在于socket.accept()、socket.read()、socket.write()三个主要函数都是同步阻塞的，当一个连接在处理I/O的时候，系统是阻塞的，如果是单线程的话必然就挂死在那里；但CPU是被释放出来的，开启多线程，就可以让CPU去处理更多的事情。其实这也是所有使用多线程的本质：\n\n1.  利用多核。\n2.  当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。\n\n现在的多线程一般都使用线程池，可以让线程的创建和回收成本相对较低。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的I/O并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。\n\n不过，这个模型最本质的问题在于，严重依赖于线程。但线程是很&quot;贵&quot;的资源，主要表现在：\n\n1.  线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。\n2.  线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。\n3.  线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。\n4.  容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。\n\n所以，当面对十万甚至百万级连接的时候，传统的BIO模型是无能为力的。随着移动端应用的兴起和各种网络游戏的盛行，百万级长连接日趋普遍，此时，必然需要一种更高效的I/O处理模型。\n\n# NIO是怎么工作的\n\n很多刚接触NIO的人，第一眼看到的就是Java相对晦涩的API，比如：Channel，Selector，Socket什么的；然后就是一坨上百行的代码来演示NIO的服务端Demo……瞬间头大有没有？\n\n我们不管这些，抛开现象看本质，先分析下NIO是怎么工作的。\n\n## 常见I/O模型对比\n\n所有的系统I/O都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。\n\n需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻塞是使用CPU的，真正在&quot;干活&quot;，而且这个过程非常快，属于memory copy，带宽通常在1GB/s级别以上，可以理解为基本不耗时。\n\n下图是几种常见I/O模型的对比：\n\n![](/assets/images/2016/11/04/java-nio/nio2.jpg)\n\n以socket.read()为例子：\n\n传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据。\n\n对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。\n\n最新的AIO(Async I/O)里面会更进一步：不但等待就绪是非阻塞的，就连数据从网卡到内存的过程也是异步的。\n\n换句话说，BIO里用户最关心“我要读”，NIO里用户最关心&quot;我可以读了&quot;，在AIO模型里用户更需要关注的是“读完了”。\n\nNIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）。\n\n## 如何结合事件模型使用NIO同步非阻塞特性\n\n回忆BIO模型，之所以需要多线程，是因为在进行I/O操作的时候，一是没有办法知道到底能不能写、能不能读，只能&quot;傻等&quot;，即使通过各种估算，算出来操作系统没有能力进行读写，也没法在socket.read()和socket.write()函数中返回，这两个函数无法进行有效的中断。所以除了多开线程另起炉灶，没有好的办法利用CPU。\n\nNIO的读写函数可以立刻返回，这就给了我们不开线程利用CPU的最好机会：如果一个连接不能读写（socket.read()返回0或者socket.write()返回0），我们可以把这件事记下来，记录的方式通常是在Selector上注册标记位，然后切换到其它就绪的连接（channel）继续进行读写。\n\n下面具体看下如何利用事件模型单线程处理所有I/O请求：\n\nNIO的主要事件有几个：读就绪、写就绪、有新连接到来。\n\n我们首先需要注册当这几个事件到来的时候所对应的处理器。然后在合适的时机告诉事件选择器：我对这个事件感兴趣。对于写操作，就是写不出去的时候对写事件感兴趣；对于读操作，就是完成连接和系统没有办法承载新读入的数据的时；对于accept，一般是服务器刚启动的时候；而对于connect，一般是connect失败需要重连或者直接异步调用connect的时候。\n\n其次，用一个死循环选择就绪的事件，会执行系统调用（Linux 2.6之前是select、poll，2.6之后是epoll，Windows是IOCP），还会阻塞的等待新事件的到来。新事件到来的时候，会在selector上注册标记位，标示可读、可写或者有连接到来。\n\n注意，select是阻塞的，无论是通过操作系统的通知（epoll）还是不停的轮询(select，poll)，这个函数是阻塞的。所以你可以放心大胆地在一个while(true)里面调用这个函数而不用担心CPU空转。\n\n所以我们的程序大概的模样是：\n\n```java\ninterface ChannelHandler{\n   void channelReadable(Channel channel);\n   void channelWritable(Channel channel);\n}\nlass Channel{\n   Socket socket;\n   Event event;//读，写或者连接\n}\n\n   //IO线程主循环:\nclass IoThread extends Thread{\n   public void run(){\n      Channel channel;\n      while(channel=Selector.select()){//选择就绪的事件和对应的连接\n         if(channel.event==accept){\n            registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器\n         }\n         if(channel.event==write){\n            getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件\n         }\n         if(channel.event==read){\n            getChannelHandler(channel).channelReadable(channel);//如果可以读，则执行读事件\n         }\n      }\n   }\n   Map<Channel，ChannelHandler> handlerMap;//所有channel的对应事件处理器\n}\n```\n\n这个程序很简短，也是最简单的Reactor模式：注册所有感兴趣的事件处理器，单线程轮询选择就绪事件，执行事件处理器。\n\n## 优化线程模型\n\n由上面的示例我们大概可以总结出NIO是怎么解决掉线程的瓶颈并处理海量连接的：\n\nNIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I/O操作都是纯CPU操作，没有必要开启多线程。\n\n并且由于线程的节约，连接数大的时候因为线程切换带来的问题也随之解决，进而为处理海量连接提供了可能。\n\n单线程处理I/O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I/O，无疑对效率会有更大的提高。\n\n仔细分析一下我们需要的线程，其实主要包括以下几种：\n\n1.  事件分发器，单线程选择就绪的事件。\n2.  I/O处理器，包括connect、read、write等，这种纯CPU操作，一般开启CPU核心个线程就可以。\n3.  业务线程，在处理完I/O后，业务一般还会有自己的业务逻辑，有的还会有其他的阻塞I/O，如DB操作，RPC等。只要有阻塞，就需要单独的线程。\n\nJava的Selector对于Linux系统来说，有一个致命限制：同一个channel的select不能被并发的调用。因此，如果有多个I/O线程，必须保证：一个socket只能属于一个IoThread，而一个IoThread可以管理多个socket。\n\n另外连接的处理和读写的处理通常可以选择分开，这样对于海量连接的注册和读写就可以分发。虽然read()和write()是比较高效无阻塞的函数，但毕竟会占用CPU，如果面对更高的并发则无能为力。\n\n![](/assets/images/2016/11/04/java-nio/reactor.png)\n\n# NIO在客户端的魔力\n\n通过上面的分析，可以看出NIO在服务端对于解放线程，优化I/O和处理海量连接方面，确实有自己的用武之地。那么在客户端上，NIO又有什么使用场景呢?\n\n常见的客户端BIO+连接池模型，可以建立n个连接，然后当某一个连接被I/O占用的时候，可以使用其他连接来提高性能。\n\n但多线程的模型面临和服务端相同的问题：如果指望增加连接数来提高性能，则连接数又受制于线程数、线程很贵、无法建立很多线程，则性能遇到瓶颈。\n\n## 每连接顺序请求的Redis\n\n对于Redis来说，由于服务端是全局串行的，能够保证同一连接的所有请求与返回顺序一致。这样可以使用单线程＋队列，把请求数据缓冲。然后pipeline发送，返回future，然后channel可读时，直接在队列中把future取回来，done()就可以了。\n\n伪代码如下：\n\n```java\nclass RedisClient Implements ChannelHandler{\n   private BlockingQueue CmdQueue;\n   private EventLoop eventLoop;\n   private Channel channel;\n   class Cmd{\n      String cmd;\n      Future result;\n   }\n   public Future get(String key){\n      Cmd cmd= new Cmd(key);\n      queue.offer(cmd);\n      eventLoop.submit(new Runnable(){\n         List list = new ArrayList();\n         queue.drainTo(list);\n         if(channel.isWritable()){\n            channel.writeAndFlush(list);\n         }\n      });\n   }\n   public void ChannelReadFinish(Channel channel，Buffer Buffer){\n      List result = handleBuffer();//处理数据\n      //从cmdQueue取出future，并设值，future.done();\n   }\n   public void ChannelWritable(Channel channel){\n      channel.flush();\n   }\n}\n```\n\n这样做，能够充分的利用pipeline来提高I/O能力，同时获取异步处理能力。\n\n## 多连接短连接的HttpClient\n\n类似于竞对抓取的项目，往往需要建立无数的HTTP短连接，然后抓取，然后销毁，当需要单机抓取上千网站线程数又受制的时候，怎么保证性能呢?\n\n何不尝试NIO，单线程进行连接、写、读操作？如果连接、读、写操作系统没有能力处理，简单的注册一个事件，等待下次循环就好了。\n\n如何存储不同的请求/响应呢？由于http是无状态没有版本的协议，又没有办法使用队列，好像办法不多。比较笨的办法是对于不同的socket，直接存储socket的引用作为map的key。\n\n## 常见的RPC框架，如Thrift，Dubbo\n\n这种框架内部一般维护了请求的协议和请求号，可以维护一个以请求号为key，结果的result为future的map，结合NIO+长连接，获取非常不错的性能。\n\n# NIO高级主题\n\n## Proactor与Reactor\n\n 一般情况下，I/O 复用机制需要事件分发器（event dispatcher）。 事件分发器的作用，即将那些读写事件源分发给各读写事件的处理者，就像送快递的在楼下喊: 谁谁谁的快递到了， 快来拿吧！开发人员在开始的时候需要在分发器那里注册感兴趣的事件，并提供相应的处理者（event handler)，或者是回调函数；事件分发器在适当的时候，会将请求的事件分发给这些handler或者回调函数。\n\n 涉及到事件分发器的两种模式称为：Reactor和Proactor。 Reactor模式是基于同步I/O的，而Proactor模式是和异步I/O相关的。在Reactor模式中，事件分发器等待某个事件或者可应用或个操作的状态发生（比如文件描述符可读写，或者是socket可读写），事件分发器就把这个事件传给事先注册的事件处理函数或者回调函数，由后者来做实际的读写操作。\n\n 而在Proactor模式中，事件处理者（或者代由事件分发器发起）直接发起一个异步读写操作（相当于请求），而实际的工作是由操作系统来完成的。发起时，需要提供的参数包括用于存放读到数据的缓存区、读的数据大小或用于存放外发数据的缓存区，以及这个请求完后的回调函数等信息。事件分发器得知了这个请求，它默默等待这个请求的完成，然后转发完成事件给相应的事件处理者或者回调。举例来说，在Windows上事件处理者投递了一个异步IO操作（称为overlapped技术），事件分发器等IO Complete事件完成。这种异步模式的典型实现是基于操作系统底层异步API的，所以我们可称之为“系统级别”的或者“真正意义上”的异步，因为具体的读写是由操作系统代劳的。\n\n 举个例子，将有助于理解Reactor与Proactor二者的差异，以读操作为例（写操作类似）。\n\n### 在Reactor中实现读\n\n*   注册读就绪事件和相应的事件处理器。\n*   事件分发器等待事件。\n*   事件到来，激活分发器，分发器调用事件对应的处理器。\n*   事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。\n\n### 在Proactor中实现读：\n\n*   处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。\n*   事件分发器等待操作完成事件。\n*   在分发器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分发器读操作完成。\n*   事件分发器呼唤处理器。\n*   事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分发器。\n\n可以看出，两个模式的相同点，都是对某个I/O事件的事件通知（即告诉某个模块，这个I/O操作可以进行或已经完成)。在结构上，两者也有相同点：事件分发器负责提交IO操作（异步)、查询设备是否可操作（同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下（Proactor)，当回调handler时，表示I/O操作已经完成；同步情况下（Reactor)，回调handler时，表示I/O设备可以进行某个操作（can read 或 can write)。\n\n下面，我们将尝试应对为Proactor和Reactor模式建立可移植框架的挑战。在改进方案中，我们将Reactor原来位于事件处理器内的Read/Write操作移至分发器（不妨将这个思路称为“模拟异步”），以此寻求将Reactor多路同步I/O转化为模拟异步I/O。以读操作为例子，改进过程如下：\n\n*   注册读就绪事件和相应的事件处理器。并为分发器提供数据缓冲区地址，需要读取数据量等信息。\n*   分发器等待事件（如在select()上等待）。\n*   事件到来，激活分发器。分发器执行一个非阻塞读操作（它有完成这个操作所需的全部信息），最后调用对应处理器。\n*   事件处理器处理用户自定义缓冲区的数据，注册新的事件（当然同样要给出数据缓冲区地址，需要读取的数据量等信息），最后将控制权返还分发器。\n如我们所见，通过对多路I/O模式功能结构的改造，可将Reactor转化为Proactor模式。改造前后，模型实际完成的工作量没有增加，只不过参与者间对工作职责稍加调换。没有工作量的改变，自然不会造成性能的削弱。对如下各步骤的比较，可以证明工作量的恒定：\n\n### 标准/典型的Reactor：\n\n*   步骤1：等待事件到来（Reactor负责）。\n*   步骤2：将读就绪事件分发给用户定义的处理器（Reactor负责）。\n*   步骤3：读数据（用户处理器负责）。\n*   步骤4：处理数据（用户处理器负责）。\n\n### 改进实现的模拟Proactor：\n\n*   步骤1：等待事件到来（Proactor负责）。\n*   步骤2：得到读就绪事件，执行读数据（现在由Proactor负责）。\n*   步骤3：将读完成事件分发给用户处理器（Proactor负责）。\n*   步骤4：处理数据（用户处理器负责）。\n对于不提供异步I/O API的操作系统来说，这种办法可以隐藏Socket API的交互细节，从而对外暴露一个完整的异步接口。借此，我们就可以进一步构建完全可移植的，平台无关的，有通用对外接口的解决方案。\n\n代码示例如下：\n\n```java\ninterface ChannelHandler{\n   void channelReadComplate(Channel channel，byte[] data);\n   void channelWritable(Channel channel);\n}\nclass Channel{\n   Socket socket;\n   Event event;//读，写或者连接\n}\n\n//IO线程主循环：\nclass IoThread extends Thread{\n   public void run(){\n      Channel channel;\n      while(channel=Selector.select()){//选择就绪的事件和对应的连接\n         if(channel.event==accept){\n            registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器\n            Selector.interested(read);\n         }\n         if(channel.event==write){\n            getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件\n         }\n         if(channel.event==read){\n            byte[] data = channel.read();\n            if(channel.read()==0){//没有读到数据，表示本次数据读完了\n               getChannelHandler(channel).channelReadComplate(channel，data;//处理读完成事件\n            }\n            if(过载保护){\n               Selector.interested(read);\n            }\n         }\n      }\n   }\n   Map<Channel，ChannelHandler> handlerMap;//所有channel的对应事件处理器\n}\n```\n\n### 主要作用\n\n解除阻塞在Selector.select()/select(long)上的线程，立即返回。\n\n两次成功的select之间多次调用wakeup等价于一次调用。\n\n如果当前没有阻塞在select上，则本次wakeup调用将作用于下一次select——“记忆”作用。\n\n为什么要唤醒？\n\n注册了新的channel或者事件。\n\nchannel关闭，取消注册。\n\n优先级更高的事件触发（如定时器事件），希望及时处理。\n\n### 原理\n\nLinux上利用pipe调用创建一个管道，Windows上则是一个loopback的tcp连接。这是因为win32的管道无法加入select的fd set，将管道或者TCP连接加入select fd set。\n\nwakeup往管道或者连接写入一个字节，阻塞的select因为有I/O事件就绪，立即返回。可见，wakeup的调用开销不可忽视。\n\n## Buffer的选择\n\n通常情况下，操作系统的一次写操作分为两步：\n\n1.  将数据从用户空间拷贝到系统空间。\n2.  从系统空间往网卡写。同理，读操作也分为两步：\n① 将数据从网卡拷贝到系统空间；\n② 将数据从系统空间拷贝到用户空间。\n\n对于NIO来说，缓存的使用可以使用DirectByteBuffer和HeapByteBuffer。如果使用了DirectByteBuffer，一般来说可以减少一次系统空间到用户空间的拷贝。但Buffer创建和销毁的成本更高，更不宜维护，通常会用内存池来提高性能。\n\n如果数据量比较小的中小应用情况下，可以考虑使用heapBuffer；反之可以用directBuffer。\n\n# NIO存在的问题\n\n使用NIO != 高性能，当连接数&lt;1000，并发程度不高或者局域网环境下NIO并没有显著的性能优势。\n\nNIO并没有完全屏蔽平台差异，它仍然是基于各个操作系统的I/O系统实现的，差异仍然存在。使用NIO做网络编程构建事件驱动模型并不容易，陷阱重重。\n\n推荐大家使用成熟的NIO框架，如Netty，MINA等。解决了很多NIO的陷阱，并屏蔽了操作系统的差异，有较好的性能和编程模型。\n\n# 总结\n\n最后总结一下到底NIO给我们带来了些什么：\n\n*   事件驱动模型\n*   避免多线程\n*   单线程处理多任务\n*   非阻塞I/O，I/O读写不再阻塞，而是返回0\n*   基于block的传输，通常比基于流的传输更高效\n*   更高级的IO函数，zero-copy\n*   IO多路复用大大提高了Java网络应用的可伸缩性和实用性\n\n本文抛砖引玉，诠释了一些NIO的思想和设计理念以及应用场景，这只是从冰山一角。关于NIO可以谈的技术点其实还有很多，期待未来有机会和大家继续探讨。\n\n# 作者简介\n\n王烨，现在是美团旅游后台研发组的RD，之前曾经在百度、去哪儿和优酷工作过，专注Java后台开发。对于网络编程和并发编程具有浓厚的兴趣，曾经做过一些基础组件，也翻过一些源码，属于比较典型的宅男技术控。期待能够与更多知己，在coding的路上并肩前行~\n\n---\n\n* Author: 王烨\n* Source: [美团点评技术团队](http://tech.meituan.com)\n* Link: [Java NIO浅析](http://tech.meituan.com/nio.html)\n","tags":["NIO"],"categories":["Java"]},{"title":"自然语言处理","url":"%2F2016%2F2016-10-19-nlp%2F","content":"\n## 自然语言处理的简介\n\n首先，介绍一下什么是自然语言处理（也叫自然语言理解）：\n\n语言学家刘涌泉在《大百科全书(2002)》中对自然语言处理的定义为：“自然语言处理是人工智能领域的主要内容，即利用电子计算机等工具对人类所特有的语言信息（包括口语信息和文字信息）进行各种加工，并建立各种类型的人-机-人系统，自然语言理解是其核心，其中包括语音和语符的自动识别以及语音的自动合成。”\n\n从微观上讲，自然语言理解是指从自然语言到机器(计算机系统)内部之间的一种映射。\n\n从宏观上看，自然语言理解是指机器能够执行人类所期望的某些语言功能。这些功能包括：\n\n* 回答有关提问；计算机正确地回答用自然语言输入的有关问题\n* 提取材料摘要；机器能产生输入文本的摘要\n* 同词语叙述；机器能用不同的词语和句型来复述输入的自然语言信息\n* 不同语言翻译；机器能把一种语言翻译成另外一种语言\n\n## 自然语言处理的关键技术\n\n自然语言处理的关键技术包括：词法分析、句法分析、语义分析、语用分析和语句分析。\n\n### 词法分析\n\n词法分析的主要目的是从句子中切分出单词，找出词汇的各个词素，并确定其词义。\n\n词法分析包括词形和词汇两个方面。一般来讲，词形主要表现在对单词的前缀、后缀等的分析，而词汇则表现在对整个词汇系统的控制。在中文全文检索系统中，词法分析主要表现在对汉语信息进行词语切分，即汉语自动分词技术。通过这种技术能够比较准确的分析用户输入信息的特征，从而完成准确的搜索过程。它是中文全文检索技术的重要发展方向。\n\n不同的语言对词法分析有不同的要求，例如英语和汉语就有较大的差距\n\n汉语中的每个字就是一个词素，所以要找出各个词素是相当容易的，但要切分出各个词就非常难。\n\n如“我们研究所有东西”，可以是“我们—研究所—有—东西”也可是“我们—研究—所有—东西” 。\n\n英语等语言的单词之间是用空格自然分开的，很容易切分一个单词，因而很方便找出句子的每个词汇，不过英语单词有词性、数、时态、派生、变形等变化，因而要找出各个词素就复杂得多，需要对词尾和词头进行分析。如uncomfortable可以是un-comfort-able或uncomfort-able，因为un、comfort、able都是词素。\n\n### 句法分析\n\n句法分析是对用户输入的自然语言进行词汇短语的分析，目的是识别句子的句法结构，实现自动句法分析过程。其基本方法有线图分析法、短语结构分析、完全句法分析、局部句法分析、依存句法分析等。\n\n分析的目的就是找出词、短语等的相互关系以及各自在句子中的作用等，并以一种层次结构来加以表达。这种层次结构可以是从属关系、直接成分关系，也可以是语法功能关系。\n\n句法分析是由专门设计的分析器进行的，其分析过程就是构造句法树的过程，将每个输入的合法语句转换为一棵句法分析树。\n\n一个句子是由各种不同的句子成分组成的。这些成分可以是单词、词组或从句。句子成分还可以按其作用分为主语、谓语、宾语、宾语补语、定语、状语、表语等。这种关系可用一棵树来表示，如对句子： He wrote a book.\n\n可用图示的树型结构表示:\n\n![](/assets/images/2016/10/19/nlp/001.png)\n\n### 语义分析\n\n语义分析是基于自然语言语义信息的一种分析方法，其不仅仅是词法分析和句法分析这样语法水平上的分析，而是涉及到了单词、词组、句子、段落所包含的意义。其目的是从句子的语义结构表示言语的结构。中文语义分析方法是基于语义网络的一种分析方法。语义网络则是一种结构化的，灵活、明确、简洁的表达方式。\n\n### 语用分析\n\n语用分析相对于语义分析又增加了对上下文、语言背景、环境等的分析，从文章的结构中提取到意象、人际关系等的附加信息，是一种更高级的语言学分析。它将语句中的内容与现实生活的细节相关联，从而形成动态的表意结构。\n\n### 语境分析\n\n语境分析主要是指对原查询语篇以外的大量“空隙”进行分析从而更为正确地解释所要查询语言的技术。这些“空隙”包括一般的知识，特定领域的知识以及查询用户的需要等。它将自然语言与客观的物理世界和主观的心理世界联系起来，补充完善了词法、语义、语用分析的不足。\n\n## 自然语言处理的工具\n\n* OpenNLP\n\n   OpenNLP是一个基于Java机器学习工具包，用于处理自然语言文本。支持大多数常用的 NLP 任务，例如：标识化、句子切分、部分词性标注、名称抽取、组块、解析等。\n\n* FudanNLP\n\n   FudanNLP主要是为中文自然语言处理而开发的工具包，也包含为实现这些任务的机器学习算法和数据集。本工具包及其包含数据集使用LGPL3.0许可证。开发语言为Java。\n\n自然语言处理工具的主要功能有：\n\n1. 文本分类、新闻聚类\n2. 中文分词、词性标注、实体识别、关键词抽取、依存句法分析、时间短语识别\n3. 结构化学习、在线学习、层次分类、聚类、精确推理。\n\n## 自然语言处理的过程\n\n获取原始文本-文本预处理-分词-去停用词-特征选择-利用算法进行文本挖掘\n\n文本中起到关键作用的是一些词，甚至主要词就能起到决定文本取向，因此分词是中文文本处理比较重要的部分\n\n中文分词，出现了很多分词的算法，有最大匹配法、最优匹配法、机械匹配法、逆向匹配法、双向匹配法等。 \n\n中科院张华平博士研发的分词工具ICTCLAS，该算法经过众多科学家的认定是当今中文分词中最好的，并且支持用户自定义词典，加入词典；对新词，人名，地名等的发现也具有良好的效果。\n\n常见的分词工具有：word分词器、Ansj分词器、Stanford分词器、FudanNLP分词器、Jieba分词器、Jcseg分词器、MMSeg4j分词器、IKAnalyzer分词器、Paoding分词器、smartcn分词器、HanLP分词器等。\n\n在文本处理建模的预处理过程中，我们得到文本特征维度常常非常大，要得到一个好的模型，需要做两个工作:1、降维。模型的维度常常很大，这会加大模型的运行成本，并且不利于研究人员理解模型。2、去燥。维度很大时，特征之间会相互依赖，甚至很多特征对模型分类是有干扰作用的，去除这一部分特征将对模型有提升作用。特征选择和特征抽取都能完成上面的工作。\n\n在文本处理中常采用特征选择而非特征抽取， 原因是特征选择保持了特征原来的面貌，有利于挖掘人员理解模型。\n\n常见的特征选择算法有以下几种：\n\n* TF-IDF\n\n词频(TF)即为词在一篇文档中出现的频率。\n\n![](/assets/images/2016/10/19/nlp/002.png)\n\n其中T Ft，d表示词t在第d个文档的词频，nt表示词t在文档d出现的次数，Nd表示文档d 中词的总数。 \n\n逆向文档频率(IDF)值衡量词在某个文档中是否有代表性，其计算公式：\n\n![](/assets/images/2016/10/19/nlp/003.png)\n\n其中IDFt是词t的逆向文档频率，D是语料集的总文档数，Dt是包含t的文档数量，加 1是做平滑处理。\n\nTF-IDF是和标签无关的，这意味着计算过程是无监督的，由于TF-IDF无监督的特征，常常被用来表示文档向量空间模型的向量，从而能够运用于文档的相似度计算和关键词提取等。\n\n* 信息增益(Information Gain)\n\n信息增益是信息论中很重要的一个概念。在特征选择中，该方法主要是通过评估词项能够给分类带来多少的信息量，带来的信息量越大，说明该词项越重要。\n\n信息量，也就是熵。对于一个变量X，它可能的取值有n多种，分别是{x1 ，x2 ，...，xn }，每一种取到的概率分别是{p1 ，p2 ，...，pn }，那么X的熵就定义为：\n\n![](/assets/images/2016/10/19/nlp/004.png)\n\n* 互信息(Mutual Information)\n\n互信息是信息论中又一重要的概率，在文本处理中用来说明词t对于类别c的贡献程度，互信息越大则贡献程度越大。互信息计算是类别c关于t后验概率与先验概率的比值的 log。\n\n![](/assets/images/2016/10/19/nlp/005.png)\n\n准备工作完成后，就可以用各种算法进行挖掘，可以对文本、新闻等进行分类、聚类，可以利用KNN算法，朴素贝叶斯算法、决策树算法、神经网络法、线性最小二乘法、K-Means算法等算法。\n\n## 自然语言处理的应用\n\n自然语言处理的范围涉及众多方面，如语音的自动识别与合成，机器翻译，自然语言理解，人机对话，信息检索，文本分类，自动文摘，等等。\n\n这些大致可以归纳为如下四个大的方向：\n\n1. 语言学方向\n\n   它只研究语言及语言处理与计算相关的方面，而不管其在计算机上的具体实现。这个方向最重要的研究领域是语法形式化理论和数学理论。\n\n2. 数据处理方向\n\n   是把自然语言处理作为开发语言研究相关程序以及语言数据处理的学科来研究。这一方向早起的研究有属于数据库的建设、各种机器可读的电子词典的开发，近些年来则有大规模的语料库的涌现。\n\n3. 人工智能和认知科学方向\n\n   在这个方向，自然语言处理被作为在计算机上实现自然语言能力的学科来研究，探索自然语言理解的只能机制和认知机制。这一方向的研究与人工智能以及认知科学关系密切。\n\n4. 语言工程方向\n\n   主要是把自然语言处理作为面向实践的、工程化的语言软件开发来研究，这一方向的研究一般称为“人类语言技术”或者“语言工程”。\n\n## 推荐书籍\n\n《统计自然语言处理(宗成庆)》\n\n参考链接：[信息论：熵与互信息](http://blog.csdn.net/pipisorry/article/details/51695283)","tags":["NLP"],"categories":["NLP"]},{"title":"Categorized overview of Programming Principles & Patterns","url":"%2F2016%2F2016-10-15-programming-principles%2F","content":"\n \n# Programming Principles\n\nEvery programmer benefits from understanding programming principles and patterns. This overview is a reference for myself, and I've just put it here. Maybe it is of help to you during design, discussion, or review. Please note that it's far from complete, and that you often need to make trade-offs between conflicting principles.\n\nThe list was inspired by [The Principles of Good Programming](http://www.artima.com/weblogs/viewpost.jsp?thread=331531). I felt that the list closely, but not completely matches what I would personally put into something similar. Additionally, I wanted a bit more reasoning, details, and links to further resources. [Let me know](https://github.com/webpro/programming-principles/issues) if you have any feedback or suggestions for improvement.\n\n## Contents\n\n### Generic\n\n* [KISS (Keep It Simple Stupid)](#kiss)\n* [YAGNI](#yagni)\n* [Do The Simplest Thing That Could Possibly Work](#do-the-simplest-thing-that-could-possibly-work)\n* [Separation of Concerns](#separation-of-concerns)\n* [Keep Things DRY](#keep-things-dry)\n* [Code For The Maintainer](#code-for-the-maintainer)\n* [Avoid Premature Optimization](#avoid-premature-optimization)\n* [Boy-Scout Rule](#boy-scout-rule)\n\n### Inter-Module/Class\n\n* [Minimise Coupling](#minimise-coupling)\n* [Law of Demeter](#law-of-demeter)\n* [Composition Over Inheritance](#composition-over-inheritance)\n* [Orthogonality](#orthogonality)\n* [Robustness Principle](#robustness-principle)\n\n### Module/Class\n\n* [Maximise Cohesion](#maximise-cohesion)\n* [Liskov Substitution Principle](#liskov-substitution-principle)\n* [Open/Closed Principle](#openclosed-principle)\n* [Single Responsibility Principle](#single-responsibility-principle)\n* [Hide Implementation Details](#hide-implementation-details)\n* [Curly's Law](#curlys-law)\n* [Encapsulate What Changes](#encapsulate-what-changes)\n* [Interface Segregation Principle](#interface-segregation-principle)\n* [Command Query Separation](#command-query-separation)\n\n## KISS\n\nMost systems work best if they are kept simple rather than made complex.\n\nWhy\n\n* Less code takes less time to write, has less bugs, and is easier to modify.\n* Simplicity is the ultimate sophistication.\n* It seems that perfection is reached not when there is nothing left to add, but when there is nothing left to take away.\n\nResources\n\n* [KISS principle](http://en.wikipedia.org/wiki/KISS_principle)\n* [Keep It Simple Stupid (KISS)](http://principles-wiki.net/principles:keep_it_simple_stupid)\n\n## YAGNI\n\nYAGNI stands for \"you aren't gonna need it\": don't implement something until it is necessary.\n\nWhy\n\n* Any work that's only used for a feature that's needed tomorrow, means losing effort from features that need to be done for the current iteration.\n* It leads to code bloat; the software becomes larger and more complicated.\n\nHow\n\n* Always implement things when you actually need them, never when you just foresee that you need them.\n\nResources\n\n* [You Arent Gonna Need It](http://c2.com/xp/YouArentGonnaNeedIt.html)\n* [You’re NOT gonna need it!](http://www.xprogramming.com/Practices/PracNotNeed.html)\n* [You ain't gonna need it](http://en.wikipedia.org/wiki/You_ain't_gonna_need_it)\n\n## Do The Simplest Thing That Could Possibly Work\n\nWhy\n\n* Real progress against the real problem is maximized if we just work on what the problem really is.\n\nHow\n\n* Ask yourself: \"What is the simplest thing that could possibly work?\"\n\nResources\n\n* [Do The Simplest Thing That Could Possibly Work](http://c2.com/xp/DoTheSimplestThingThatCouldPossiblyWork.html)\n\n## Separation of Concerns\n\nSeparation of concerns is a design principle for separating a computer program into distinct sections, such that each section addresses a separate concern. For example the business logic of the application is a concern and the user interface is another concern. Changing the user interface should not require changes to business logic and vice versa.\n\nQuoting [Edsger W. Dijkstra](https://en.wikipedia.org/wiki/Edsger_W._Dijkstra) (1974):\n\n> It is what I sometimes have called \"the separation of concerns\", which, even if not perfectly possible, is yet the only available technique for effective ordering of one's thoughts, that I know of. This is what I mean by \"focusing one's attention upon some aspect\": it does not mean ignoring the other aspects, it is just doing justice to the fact that from this aspect's point of view, the other is irrelevant.\n\nWhy\n\n* Simplify development and maintenance of software applications.\n* When concerns are well-separated, individual sections can be reused, as well as developed and updated independently.\n\nHow\n\n* Break program functionality into separate modules that overlap as little as possible.\n\nResources\n\n* [Separation of Concerns](https://en.wikipedia.org/wiki/Separation_of_concerns)\n\n## Keep things DRY\n\nEvery piece of knowledge must have a single, unambiguous, authoritative representation within a system.\n\nEach significant piece of functionality in a program should be implemented in just one place in the source code. Where similar functions are carried out by distinct pieces of code, it is generally beneficial to combine them into one by abstracting out the varying parts.\n\nWhy\n\n* Duplication (inadvertent or purposeful duplication) can lead to maintenance nightmares, poor factoring, and logical contradictions.\n* A modification of any single element of a system does not require a change in other logically unrelated elements.\n* Additionally, elements that are logically related all change predictably and uniformly, and are thus kept in sync.\n\nHow\n\n* Put business rules, long expressions, if statements, math formulas, metadata, etc. in only one place.\n* Identify the single, definitive source of every piece of knowledge used in your system, and then use that source to generate applicable instances of that knowledge (code, documentation, tests, etc).\n* Apply the [Rule of three](http://en.wikipedia.org/wiki/Rule_of_three_(computer_programming)).\n\nResources\n\n* [Dont Repeat Yourself](http://c2.com/cgi/wiki?DontRepeatYourself)\n* [Don't repeat yourself](http://en.wikipedia.org/wiki/Don't_repeat_yourself)\n* [Don't Repeat Yourself](http://programmer.97things.oreilly.com/wiki/index.php/Don't_Repeat_Yourself)\n\nRelated\n\n* [Abstraction principle](http://en.wikipedia.org/wiki/Abstraction_principle_(computer_programming))\n* [Once And Only Once](http://c2.com/cgi/wiki?OnceAndOnlyOnce) is a subset of DRY (also referred to as the goal of refactoring).\n* [Single Source of Truth](http://en.wikipedia.org/wiki/Single_Source_of_Truth)\n* A violation of DRY is [WET](http://thedailywtf.com/articles/The-WET-Cart) (Write Everything Twice)\n\n## Code For The Maintainer\n\nWhy\n\n* Maintenance is by far the most expensive phase of any project.\n\nHow\n\n* *Be* the maintainer.\n* Always code as if the person who ends up maintaining your code is a violent psychopath who knows where you live.\n* Always code and comment in such a way that if someone a few notches junior picks up the code, they will take pleasure in reading and learning from it.\n* [Don't make me think](http://www.sensible.com/dmmt.html).\n* Use the [Principle of Least Astonishment](http://en.wikipedia.org/wiki/Principle_of_least_astonishment).\n\nResources\n\n* [Code For The Maintainer](http://c2.com/cgi/wiki?CodeForTheMaintainer)\n* [The Noble Art of Maintenance Programming](http://blog.codinghorror.com/the-noble-art-of-maintenance-programming/)\n\n## Avoid Premature Optimization\n\nQuoting [Donald Knuth](http://en.wikiquote.org/wiki/Donald_Knuth):\n\n> Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%.\n\n\nUnderstanding what is and isn’t \"premature\" is critical of course.\n\nWhy\n\n* It is unknown upfront where the bottlenecks will be.\n* After optimization, it might be harder to read and thus maintain.\n\nHow\n\n* [Make It Work Make It Right Make It Fast](http://c2.com/cgi/wiki?MakeItWorkMakeItRightMakeItFast)\n* Don't optimize until you need to, and only after profiling you discover a bottleneck optimise that.\n\nResources\n\n* [Program optimization](http://en.wikipedia.org/wiki/Program_optimization)\n* [Premature Optimization](http://c2.com/cgi/wiki?PrematureOptimization)\n\n## Minimise Coupling\n\nCoupling between modules/components is their degree of mutual interdependence; lower coupling is better. In other words, coupling is the probability that code unit \"B\" will \"break\" after an unknown change to code unit \"A\".\n\nWhy\n\n* A change in one module usually forces a ripple effect of changes in other modules.\n* Assembly of modules might require more effort and/or time due to the increased inter-module dependency.\n* A particular module might be harder to reuse and/or test because dependent modules must be included.\n* Developers might be afraid to change code because they aren't sure what might be affected.\n\nHow\n\n* Eliminate, minimise, and reduce complexity of necessary relationships.\n* By hiding implementation details, coupling is reduced.\n* Apply the [Law of Demeter](#law-of-demeter).\n\nResources\n\n* [Coupling](http://en.wikipedia.org/wiki/Coupling_(computer_programming))\n* [Coupling And Cohesion](http://c2.com/cgi/wiki?CouplingAndCohesion)\n\n## Law of Demeter\n\nDon't talk to strangers.\n\nWhy\n\n* It usually tightens coupling\n* It might reveal too much implementation details\n\nHow\n\nA method of an object may only call methods of:\n\n  1. The object itself.\n  1. An argument of the method.\n  1. Any object created within the method.\n  1. Any direct properties/fields of the object.\n\nResources\n\n* [Law of Demeter](http://en.wikipedia.org/wiki/Law_of_Demeter)\n* [The Law of Demeter Is Not A Dot Counting Exercise](http://haacked.com/archive/2009/07/14/law-of-demeter-dot-counting.aspx/)\n\n## Composition Over Inheritance\n\nWhy\n\n* Less coupling between classes.\n* Using inheritance, subclasses easily make assumptions, and break LSP.\n\nHow\n\n* Test for LSP (substitutability) to decide when to inherit.\n* Compose when there is a \"has a\" (or \"uses a\") relationship, inherit when \"is a\".\n\nResources\n\n* [Favor Composition Over Inheritance](http://blogs.msdn.com/b/thalesc/archive/2012/09/05/favor-composition-over-inheritance.aspx)\n\n## Orthogonality\n\n> The basic idea of orthogonality is that things that are not related conceptually should not be related in the system.\n\nSource: [Be Orthogonal](http://www.artima.com/intv/dry3.html)\n\n> It is associated with simplicity; the more orthogonal the design, the fewer exceptions. This makes it easier to learn, read and write programs in a programming language. The meaning of an orthogonal feature is independent of context; the key parameters are symmetry and consistency.\n\nSource: [Orthogonality](http://en.wikipedia.org/wiki/Orthogonality_(programming))\n\n## Robustness Principle\n\n> Be conservative in what you do, be liberal in what you accept from others\n\nCollaborating services depend on each others interfaces. Often the interfaces need to evolve causing the other end to receive unspecified data. A naive implementation refuses to collaborate if the received data does not strictly follow the specification. A more sophisticated implementation will still work ignoring the data it does not recognize.\n\nWhy\n\n* In order to be able to evolve services you need to ensure that a provider can make changes to support new demands while causing minimal breakage to their existing clients.\n\nHow\n\n* Code that sends commands or data to other machines (or to other programs on the same machine) should conform completely to the specifications, but code that receives input should accept non-conformant input as long as the meaning is clear.\n\nResources\n\n* [Robustness Principle in Wikipedia](https://en.wikipedia.org/wiki/Robustness_principle)\n* [Tolerant Reader](http://martinfowler.com/bliki/TolerantReader.html)\n\n## Maximise Cohesion\n\nCohesion of a single module/component is the degree to which its responsibilities form a meaningful unit; higher cohesion is better.\n\nWhy\n\n* Increased difficulty in understanding modules.\n* Increased difficulty in maintaining a system, because logical changes in the domain affect multiple modules, and because changes in one module require changes in related modules.\n* Increased difficulty in reusing a module because most applications won’t need the random set of operations provided by a module.\n\nHow\n\n* Group related functionalities sharing a single responsibility (e.g. in a class).\n\nResources\n\n* [Cohesion](http://en.wikipedia.org/wiki/Cohesion_(computer_science))\n* [Coupling And Cohesion](http://c2.com/cgi/wiki?CouplingAndCohesion)\n\n## Liskov Substitution Principle\n\nThe LSP is all about expected behavior of objects:\n\n> Objects in a program should be replaceable with instances of their subtypes without altering the correctness of that program.\n\nResources\n\n* [Liskov substitution principle](http://en.wikipedia.org/wiki/Liskov_substitution_principle)\n* [The Liskov Substitution Principle](http://freshbrewedcode.com/derekgreer/2011/12/31/solid-javascript-the-liskov-substitution-principle/)\n\n## Open/Closed Principle\n\nSoftware entities (e.g. classes) should be open for extension, but closed for modification. I.e. such an entity can allow its behavior to be modified without altering its source code.\n\nWhy\n\n* Improve maintainability and stability by minimizing changes to existing code.\n\nHow\n\n* Write classes that can be extended (as opposed to classes that can be modified).\n* Expose only the moving parts that need to change, hide everything else.\n\nResources\n\n* [Open Closed Principle](http://en.wikipedia.org/wiki/Open/closed_principle)\n* [SOLID JavaScript: The Open/Closed Principle](http://freshbrewedcode.com/derekgreer/2011/12/19/solid-javascript-the-openclosed-principle/)\n\n## Single Responsibility Principle\n\nA class should never have more than one reason to change.\n\nLong version: Every class should have a single responsibility, and that responsibility should be entirely encapsulated by the class. Responsibility can be defined as a reason to change, so a class or module should have one, and only one, reason to change.\n\nWhy\n\n* Maintainability: changes should be necessary only in one module or class.\n\nHow\n\n* Apply [Curly's Law](#Curly-s-Law).\n\nResources\n\n* [Single responsibility principle](http://en.wikipedia.org/wiki/Single_responsibility_principle)\n\n## Hide Implementation Details\n\nA software module hides information (i.e. implementation details) by providing an interface, and not leak any unnecessary information.\n\nWhy\n\n* When the implementation changes, the interface clients are using does not have to change.\n\nHow\n\n* Minimize accessibility of classes and members.\n* Don’t expose member data in public.\n* Avoid putting private implementation details into a class’s interface.\n* Decrease coupling to hide more implementation details.\n\nResources\n\n* [Information hiding](http://en.wikipedia.org/wiki/Information_hiding)\n\n## Curly's Law\n\nCurly's Law is about choosing a single, clearly defined goal for any particular bit of code: Do One Thing.\n\n* [Curly's Law: Do One Thing](http://blog.codinghorror.com/curlys-law-do-one-thing/)\n* [The Rule of One or Curly’s Law](http://fortyplustwo.com/2008/09/06/the-rule-of-one-or-curlys-law/)\n\n## Encapsulate What Changes\n\nA good design identifies the hotspots that are most likely to change and encapsulates them behind an API. When an anticipated change then occurs, the modifications are kept local.\n\nWhy\n\n* To minimize required modifications when a change occurs\n\nHow\n\n* Encapsulate the concept that varies behind an API\n* Possibly separate the varying concept into its own module\n\nResources\n\n* [Encapsulate the Concept that Varies](http://principles-wiki.net/principles:encapsulate_the_concept_that_varies)\n* [Encapsulate What Varies](http://blogs.msdn.com/b/steverowe/archive/2007/12/26/encapsulate-what-varies.aspx)\n* [Information Hiding](https://en.wikipedia.org/wiki/Information_hiding)\n\n## Interface Segregation Principle\n\nReduce fat interfaces into multiple smaller and more specific client specific interfaces. An interface should be more dependent on the code that calls it than the code that implements it. \n\nWhy\n\n* If a class implements methods that are not needed the caller needs to know about the method implementation of that class. For example if a class implements a method but simply throws then the caller will need to know that this method shouldn't actually be called.\n\nHow\n\n* Avoid fat interfaces. Classes should never have to implement methods that violate the [Single responsibility principle](#single-responsibility-principle).\n\nResources\n\n* [Interface segregation principle](https://en.wikipedia.org/wiki/Interface_segregation_principle)\n\n## Boy-Scout Rule\n\nThe Boy Scouts of America have a simple rule that we can apply to our profession: \"Leave the campground cleaner than you found it\". The boy-scout rule states that we should always leave the code cleaner than we found it.\n\nWhy\n\n* When making changes to an existing codebase the code quality tends to degrade, accumulating technical debt. Following the boyscout rule, we should mind the quality with each commit. Technical debt is resisted by continuous refactoring, no matter how small.\n\nHow\n\n* With each commit make sure it does not degrade the codebase quality.\n* Any time someone sees some code that isn't as clear as it should be, they should take the opportunity to fix it right there and then.\n\nResources\n\n* [Opportunistic Refactoring](http://martinfowler.com/bliki/OpportunisticRefactoring.html)\n\n## Command Query Separation\n\nThe Command Query Separation principle states that each method should be either a command that performs an action or a query that returns data to the caller but not both. Asking a question should not modify the answer.\n\nWith this principle applied the programmer can code with much more confidence. The query methods can be used anywhere and in any order since they do not mutate the state. With commands one has to be more careful.\n\nWhy\n\n* By clearly separating methods into queries and commands the programmer can code with additional confidence without knowing each method's implementation details.\n\nHow\n\n* Implement each method as either a query or a command\n* Apply naming convention to method names that implies whether the method is a query or a command\n\nResources\n\n* [Command Query Separation in Wikipedia](https://en.wikipedia.org/wiki/Command%E2%80%93query_separation)\n* [Command Query Separation by Martin Fowler](http://martinfowler.com/bliki/CommandQuerySeparation.html)\n\n参考链接：\n\n* [The Principles of Good Programming](http://www.artima.com/weblogs/viewpost.jsp?thread=331531)\n* [Categorized overview of Programming Principles & Patterns](https://github.com/webpro/programming-principles)\n\n---\n\n原文链接：[Programming Principles](http://webpro.github.io/programming-principles/)","tags":["Patterns"],"categories":["Programming"]},{"title":"地方政府财政税收收入预测模型经验","url":"%2F2016%2F2016-10-14-model-local-government-finance-tax-revenue%2F","content":"\n\n### 说明\n\n主要内容是基于某省财政项目的预测模型项目的一些经验和心得。\n\n### 税改历史\n\n该项目的大体背景是基于税费营改增后对地方财政收入的影响做出预测，是典型的通过大数据的方式和手段，解决政府问题的项目。\n\n先普及一下我国的税改历史，以便大家了解我们在做模型时所要考虑的问题的复杂性。\n\n* 1994年分税制施行，地方财权得到了确认。但在二十来年的地方财政管理实践中也出现了诸如区域不平衡和财政竞争等问题。对于公共财政管理者而言，实现对财政收入的精细化控制和预测，是稳定地方财政和经济发展的一项要务。\n* 2012年12月1日，在上海交通运输业和部分现代服务业开展营业税改征增值税试点。\n* 2012年8月1日起至年底，国务院将扩大营改增试点至北京、江苏、安徽、福建、广东、天津、浙江、湖北8省（市）；\n* 2013年8月1日，“营改增”范围已推广到全国试行，将广播影视服务业纳入试点范围。\n* 2014年1月1日起，将铁路运输和邮政服务业纳入营业税改征增值税试点，至此交通运输业已全部纳入营改增范围；\n* 2016年5月1日起，我国全面推开营改增试点，将建筑业、房地产业、金融业、生活服务业全部纳入营改增试点，至此，营业税退出历史舞台，增值税制度将更加规范。\n\n做预测建模，最重要的是需要有时间上连续的数据。可由于税制的改革，人为的造成了数据的不连续性和不完整性，在设计模型时，无形中增加了很大的难度。\n\n今年的“营改增”，更是造成了及其大的数据问题，对预测建模提出了新的挑战。\n\n“营改增”是指将以前缴纳营业税的应税项目改为缴纳增值税，仅对服务或者产品增值的一部分进行缴税，以减少重复缴税的情况。“营改增”的实行，完善了中国流转税的税制，有效解决了双重征税的问题，破解了混合销售、兼营造成的征管困境。“营改增”的实行使小规模纳税人税收减少明显，使一般纳税人税收略有下降；在对企业的结构和管理模式上也都有深刻影响。\n\n因此，在全国开展“营改增”的大环境下，企业、行业、政府都正在或开始经历一场崭新而深刻的变革。如何利用已有试点数据来把握政策改革带来的影响以及对未来进行预测，是当前政府与财税部门的一大痛点。\n\n发现了用户的痛点，解决痛点。\n\n下面简单介绍一下该项目的背景：\n\n某省为更加全面深入掌握市县财源信息，科学分析今后财政收入趋势，更加精准地发挥参谋职能，拟建设集财源信息采集、查询、分析、预测等功能为一体的市县财源库，为省级和市县财政决策提供支持。\n\n为实现其目标，该项目需要建设3大基础平台。\n\n1. 建立财源信息采集平台，实现各市县财政部门负责的财源信息定期录入以及省财政相关处室局部分信息补充录入或审核修改。\n2. 建立系统数据分析平台，能够根据需要，生成各类统计表或统计图，直观反映现阶段财源发展或收入增长变化情况。\n3. 建立财源收入预测平台，能够利用现成数据或预计数据，相对准确地预测今后一段时期收入增长趋势。\n\n有了这3大平台，就可以为数据分析与挖掘提供足够的弹药。\n\n依托上述“三大平台”，实现“三大功能”：\n\n1. 查询功能。根据用户的财源信息需求，即时获取重点企业各项指标数据信息，方便日常工作查询。\n2. 分析功能。便于财源信息数据分析利用，能够分市县、分产业、分行业、分规模分析收入增长或变化情况，科学合理监测财源发展。\n3. 预测功能。基于财源指标数据与收入增长之间的相关性分析，建立收入趋势预测分析模型，能够预测下一年度或今后一段时期财源变动或收入增长情况，为领导决策以及今后政策出台或调整提供参考。\n\n为实现上述“三大功能”需求，需要采集以下五类指标数据信息：\n\n1. 基本信息\n\n    主要包括：入库企业名称、地址、登记注册时间、法人代表、主营范围、所属产业、所属行业、分支机构、注册资本、员工人数等。\n\n2. 财务指标\n\n    主要包括入库企业资产、负债、营业收入、净利润、利润率、销售价格、主要原材料成本等。\n\n3. 税收指标\n\n    主要包括入库企业增值税、消费税、企业所得税、个人所得税、房产税、土地使用税、印花税、城建税、教育费附加等。\n\n4. 投入产出指标\n\n    主要包括入库企业投资额、工资及奖金、工时、主要原材料、能源（包括用电量）以及产品产量、销售量、销售收入、工业总增加值（总产值）等。\n\n5. 财政收入指标\n\n    主要包括全省以及各市县地方财政收入、税收收入、其他收入以及各税种收入情况等。\n\n在明确了项目的建设目标后，明确了所要解决的问题和理解了相应的数据字段信息后，我们变可以开始相应的建模工作了。\n\n由于财政经济系统运行于整个地区的国民经济环境之中，因此，在考虑财政指标的同时，模型还引入了一些财政系统以外的对财政指标变化影响较大的宏观经济指标作为外生变量，首先预测这些宏观指标，然后根据它们的发展趋势，以及与财政重要指标的关联程度来分析和确认财政财力系统主要指标预测的合理性。\n\n数据维度的增加对建模工作的开展是把双刃剑。维度多会导致维度灾难，难以发现数据特征。因此，我们采用了目前先进的组合预测建模方式去解决问题。既能实现较低维度数据的分析与挖掘，又要考虑数据在高维空间上的稀疏性特点。\n\n![](/assets/images/2016/10/14/model-local-government-finance-tax-revenue/001.jpg)\n\n将传统的时间序列分析，与机器学习的SVM和神经网络有效的结合在一起。完成建模工作。\n\n模型设计图最左边部分就是基于传统的时间序列分析和财政上常用的“基年法”进行的常规预测。\n\n由于增加了企业的财务数据信息和纳税信息，右侧部分是对传统分析预测方法所进行的修正。\n\n这套混合，组合建模方法也是目前世界先进的，解决大数据建模的方法。\n\n该预测模型在设计上实现了两个功能：\n\n1. 通过优化了的组合预测模型对财政收入总体及部分进行预测；\n2. 利用某省积累的部分营改增试点行业历史数据训练模型，对营改增全面实行后的影响进行估计与预测；\n\n全部模型设计分为四个步骤：\n\n1. 利用企业数据库数据，对不同行业不同税种的行业财源进行机器学习算法框架内的预测；\n2. 通过组合预测模型，对财政收入中的企业税收部分进行预测，并结合上一步结果进行修正；\n3. 通过组合预测模型，对企业税占财政收入比例进行预测，并结合上一步结果估计政府财政收入；\n4. 通过组合预测模型，对地方政府公共财政预算收入进行预测，并结合上一步结果进行优化。\n\n下面解释整个建模的思路：\n\n建模一定要有相关的理论基础和业务基础，会在稍后的叙述中将这些理论列出来。先普及一个概念，以便讲解建模思路。\n\n地方财政总收入（全口径，如北京市财政收入）= 地方财政收入+上划中央收入 = 地方一般预算财政收入 + 基金预算收入（包括政府性基金收入和社会保险基金收入）+ 上划中央收入（注：包含有基金收入的财政总收入叫做全口径财政收入，否则仅叫财政总收入。）\n\n所以财政收入，不仅仅是税收，还包括其他很多项内容。\n\n建模思路讲解正式开始：\n\n1. 财政收入数据是典型的时间序列型数据，且由于经济发展具有连续性，故采用计量经济学的时间序列分析方法对经济指标进行分析和预测是被理论和实践证实了的有效预测方法之一。为了优化预测结果，在时间序列模型（如指数平滑）之外，采用回归、SVM等算法建立组合预测模型。\n\n2. 由于财政收入数据量及维度较少，考虑使用企业税收预测对政府财政收入预测进行修正，理由如下：\n\na) 企业税收是政府财政收入的主要来源；\n\nb) 财源库内五类数据指标中有四类都与企业相关，数据量相对丰富，且粒度较细；\n\nc) 通过对企业所处细分行业的单项税收进行预测，引入更丰富的变量和机器学习算法，可以实现对预测模型更加精细化的调控；\n\n3. 对企业税收收入的预测：\n\na) 通过国家颁布的行业划分标准、税种分类标准、纳税属性、以及分类算法对每个行业内不同群组的不同税种进行细分，形成行业财源画像；\n\nb) 以行业财源画像属性数据、宏观经济数据、国际经济数据作为自变量，以行业财源数据作为因变量，进行模型构建。由于计划引入的数据维度较多，考虑采用SVM、神经网络等算法进行计算，并综合优化预测结果。\n\n4. 以组合预测模型对企业税的不同税种进行预测。由于“营改增”试行，对应行业营业税与增值税较以往会发生较大改变，通过拆分计算，可以更好地捕捉到税改对税收的影响。\n\n5. 使用由行业财源画像得出的预测结果对企业税各税种的预测进行优化。\n\n6. 以组合预测模型对企业税的财政占比进行预测。\n\n7. 结合企业税收预测和企业税的财政占比预测形成基于企业税的财政收入预测。\n\n8. 对组合预测模型计算的政府财政收入预测结果进行修正。\n\n基于上述思路所创建的模型，理论上经得起推敲。实践中也有相比常规方法更好的效果。\n\n所使用的数据科学理论基础如下：\n\n* 一些关于预测方法精确度回顾和调查指出，大部分关于预测方法研究的文献都认为简单的时间序列模型并不一定比复杂模型差。\n* 还有一些文献则认为不考虑数据趋势或者季节变化的移动自平均以及单指数平滑模型非常的好。\n* 因果分析法(包括回归分析)的一个最大优点在于它能够提供一种使政策制定者通过对收入预测过程以及预测方法的了解过程系统地掌握经济原理。\n* 支持向量机(Support Vector Machines, SVM)，在解决小样本、非线性及高维模式识别问题中表现出了许多特有的优势，并能够应用推广到函数拟合等其他机器学习问题中，支持向量机成功地解决了高维问题和局部极值问题。\n* 在经济系统预测中，包括在电力负荷预测中，组合预测模型的表现较单一预测模型效果要好。\n\n历史年度地方财政经济数据，所使用的数据介绍如下：\n\n* 地方财政收入指标数据\n\n主要包括：全省以及各市县地方财政收入、税收收入、其他收入以及各税种收入情况等。\n\n* 地方经济数据\n\n主要包括：人口数量、GDP、人均收入、住宅（新建/二手）每平米均价、商业地产每平米均价等。\n\n历史年度地方企业数据\n\n* 基本信息\n\n主要包括：入库企业名称、地址、登记注册时间、法人代表、主营范围、所属产业、所属行业、分支机构、注册资本、员工人数等。\n\n* 财务指标\n\n主要包括入库企业资产、负债、营业收入、净利润、利润率、销售价格、主要原材料成本等。\n\n* 税收指标\n\n主要包括入库企业增值税、消费税、企业所得税、个人所得税、房产税、土地使用税、印花税、城建税、教育费附加等。\n\n* 投入产出指标\n\n主要包括入库企业投资额、工资及奖金、工时、主要原材料、能源（包括用电量）以及产品产量、销售量、销售收入、工业总增加值（总产值）等。\n\n宏观经济数据\n\n主要包括：历史年度通货膨胀率、利率、全国GDP、全国人均收入、CPI、上证综指、深证综指等。\n\n国际经济数据\n\n主要包括：人民币对美元汇率、恒生指数、日经指数、道琼斯指数、纳斯达克指数等。\n\n所参考的政策类数据如下：\n\n    政策类数据\n    税制改革类政策\n    宏观调控类政策\n\n政策对预测模型的准确率影响很大，所以必须要考虑进去。\n\n该模型的主要创新点如下：\n\n* 以对企业税收的预测对财政收入预测进行优化；\n* 通过对行业财源进行细分及画像，可以引入更丰富的变量对企业的财源能力进行估计；\n* 通过引入宏观经济等政策性变量，可以较好地捕捉政策变化对某行业财源以及政府财政收入的影响；\n* 通过对企业税进行税种划分预测，可以较好地捕捉到税改（如“营改增”）对行业财源的影响，并为将来进一步积累数据优化模型留出拓展空间。\n\n该模型的设计也并不完美，会存在一定的潜在问题。但是我们也有相对应的解决方案。\n\n潜在问题和对策\n\n* 财政收入数据量较小。由于现行税制是1994年实行的，有效时间序列样本最多仅有21年数据（21条观测值）。即使通过机器学习方法对行业财源进行细分与模拟，在时间维度上的训练样本仍然有限。可以考虑根据城市或行业对企业进行分组，做交叉验证。\n* 在深入到行业层级的数据之后，实现了训练样本容量扩大的同时，也引入了额外的估计误差，而这种误差会在随后的计算中被累加。虽然通过有监督的学习方式，可以对误差进行控制，但时间维度上的数据有限性仍然会局限训练效果。由于SVM算法对小样本具有更好的适应性，在此考虑使用SVM进行模型建立，辅以人工神经网络算法。\n* 由于国家政策的改变或新政策的实行不具有重复性，故无法对模型就某项政策的影响效果进行组间训练。若模拟效果不好，考虑再向上一层，对全行业进行估计，以此对冲掉不同企业对政策的反馈情况。待新政实行较长时间后，积累了足够多的数据，再尝试深入研究。\n\n今后我们会尝试在更多领域进行组合建模的尝试。\n\n基于传统信息化信息孤岛的问题，以及计算能力不足的瓶颈，组合建模是相对合理的建模计算解决方法。\n\n既考虑目前的信息化硬件环境，也考虑大数据的计算能力。\n\n地方政府财政收入结构\n\n地方财政总收入（全口径，如北京市财政收入）= 地方财政收入+上划中央收入 = 地方一般预算财政收入 + 基金预算收入（包括政府性基金收入和社会保险基金收入）+ 上划中央收入（注：包含有基金收入的财政总收入叫做全口径财政收入，否则仅叫财政总收入。）\n \n地方一般预算财政收入：通过一定的形式和程序，有计划有组织并由国家支配的纳入预算管理的资金。包括：\n\n（1） 税收收入。国内增值税的25%、营业税、企业所得税（纳入分享范围的企业所得税的40%+未纳入分享范围企业全部所得税）、个人所得税的40%、资源税、城市维护建设税、房产税、印花税（证券印花税的3%+其余印花税的全部）、城镇土地使用税、土地增值税、车船税、耕地占用税、契税、烟叶税、其他税收收入。\n\n（2） 非税收入。专项收入、行政事业性收费收入、罚没收入、国有资本经营收入、国有资源有偿使用收入、其他收入。\n \n基金预算收入：指按规定收取，转入或通过当年财政安排，由财政管理并具有指定用途的政府性基金预算收入等。主要包括：工业交通部门、商贸部门、文教部门、农业部门、其他部门的基金收入和社会保障基金收入、地方财政税费附加收入、基金预算调拨收入等。\n \n行政区本级财政收入指的是行政区本级政府与下级政府之间经过分享、返还之后可供行政区本级政府支配的财政收入。如，北京市财政收入中还包含了下面区县的财政收入，北京市政府本级财政收入仅占其中的一部分。\n\n![](/assets/images/2016/10/14/model-local-government-finance-tax-revenue/002.jpg)\n\n企业税在地方政府一般预算财政收入中的角色\n\n由于我国改革开放，各地方经济的发展极不平衡。企业税在各地方政府的财政收入中所占比例跨度也非常大。目前没有统一的衡量标准和计量方法。非税收入在地方财政收入所占比重也相对不透明。以罚款，基金收入，土地出让金等方式所带来的财政收入，由于担心发布所带来的社会负面效应，一般不予公开。目前争议比较大，因此企业税在地方政府财政收入中所处的角色也不尽相同。\n\n财政学理论基础\n\n长期以来,我国对来年预算收入的制定都采用“基数法”,即以上年预算收入数作为基数,以一定的增长率来计算,并考虑一些特殊因素进行调整,而在对关键的增长率进行确定时,大多数地方政府都采取在GDP增长率基础上进行相应调整的方法。这种方法割裂了财政收入与经济系统各变量之间的复杂关系,并不能够客观地反映财政收入的数量,对政府预算制定的指导作用有限。因此,通过更合理、更科学的预测方法和技术,结合财政经济以及税收经济理论,建立相应的地方财政收入预测模型,获得更准确的预测数据,对于国家和地方政府编制合理的预算报告、进行宏观经济调控、监测税源稳定情况等都具有非常重要的意义和作用。\n\n这是我们在建模过程中所涉及到的一些理论基础和业务基础知识。\n","tags":["Model"],"categories":["Machine-Learning"]},{"title":"分布式会话跟踪系统架构设计与实践","url":"%2F2016%2F2016-10-14-distributed-session-tracking-system-architecture-design-and-practice%2F","content":"\n**本文整理自美团点评技术沙龙第08期：大规模集群的服务治理设计与实践。**\n\n美团点评技术沙龙由美团点评技术团队主办，每月一期。每期沙龙邀请美团点评及其它互联网公司的技术专家分享来自一线的实践经验，覆盖各主要技术领域。\n\n目前沙龙会分别在北京、上海和厦门等地举行，要参加下一次最新沙龙活动？赶快关注微信公众号“美团点评技术团队”。\n\n这期沙龙主要内容有：分布式服务通信框架及服务治理系统、分布式监控系统实践、分布式会话跟踪系统架构设计与实践，特邀美恰CTO讲解时下热门话题“微服务”。其中既包括关键系统设计、在美团点评内部的实践经验，也包括一些项目在业界开源的运营实践。\n\n# 前言\n\n随着美团点评的业务发展，公司的分布式系统变得越来越复杂，我们亟需一个工具能够梳理内部服务之间的关系，感知上下游服务的形态。比如一次请求的流量从哪个服务而来、最终落到了哪个服务中去？服务之间是RPC调用，还是HTTP调用？一次分布式请求中的瓶颈节点是哪一个，等等。\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace1.png)\n\n# 简介\n\nMTrace，美团点评内部的分布式会话跟踪系统，其核心理念就是调用链：通过一个全局的ID将分布在各个服务节点上的同一次请求串联起来，还原原有的调用关系、追踪系统问题、分析调用数据、统计系统指标。这套系统借鉴了2010年Google发表的一篇论文《dapper》，并参考了Twitter的Zipkin以及阿里的Eagle Eye的实现。\n\n那么我们先来看一下什么是调用链，调用链其实就是将一次分布式请求还原成调用链路。显式的在后端查看一次分布式请求的调用情况，比如各个节点上的耗时、请求具体打到了哪台机器上、每个服务节点的请求状态，等等。它能反映出一次请求中经历了多少个服务以及服务层级等信息（比如你的系统A调用B，B调用C，那么这次请求的层级就是3），如果你发现有些请求层级大于10，那这个服务很有可能需要优化了。\n\n## 网络优化\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace2.png)\n\n如上图所示，红框内显示了一次分布式请求经过各个服务节点的具体IP，通过该IP就可以查询一次分布式请求是否有跨机房调用等信息，优化调用链路的网络结构。\n\n## 瓶颈查询\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace3.png)\n\n再比如上图，红框部分显示的是系统调用的瓶颈节点，由于该节点的耗时，导致了整个系统调用的耗时延长，因此该节点需要进行优化，进而优化整个系统的效率。这种问题通过调用链路能很快发现下游服务的瓶颈节点；但是假如没有这样的系统，我们会怎样做呢？首先我会发现下游服务超时造成了我的服务超时，这时我会去找这个下游服务的负责人，然后该负责人发现也不是他自己服务的问题，而是他们调用了其他人的接口造成的问题，紧接着他又去找下游的服务负责人。我们都知道跨部门之间的沟通成本很高的，这么找下去会花费大量的不必要时间，而有了MTrace之后，你只需要点开链路就能发现超时问题的瓶颈所在。\n\n## 优化链路\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace4.png)\n\n我们再来看下上面这张图，红框部分都是同一个接口的调用，一次请求调用相同的接口10几次甚至是几十次，这是我们不想看到的事情，那么整个系统能不能对这样的请求进行优化，比如改成批量接口或者提高整个系统调用的并行度？在美团点评内部我们会针对这样的链路进行筛选分析，然后提供给业务方进行优化。\n\n## 异常log绑定\n\n通过MTrace不仅能做上述这些事情，通过它的特性，还能携带很多业务感兴趣的数据。因为MTrace可以做到数据和一次请求的绑定以及数据在一次请求的网络中传递。比如一些关键的异常log，一般服务的异常log很有可能是因为上游或者下游的异常造成的，那就需要我们手动地对各个不同服务的异常log做mapping。看这次的异常log对应到上游服务的哪个log上，是不是因为上游传递的一些参数造成了该次异常？而通过MTrace就可以将请求的参数、异常log等信息通过traceId进行绑定，很容易地就把这些信息聚合到了一起，方便业务端查询问题。\n\n## 透明传输数据\n\n业务端往往有这样的需求，它希望一些参数能在一次分布式请求一直传递下去，并且可以在不同的RPC中间件间传递。MTrace对该类需求提供了两个接口：\n\n```\nput(map<String, String> data)\nputOnce(map<String, String> data)\n```\n\n* put 接口：参数可以在一次分布式请求中一直传递。\n* putOnce 接口：参数在一次分布式请求中只传递一级。\n\n如下图所示\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace5.png)\n\n* 左侧绿色部分是put接口，service中调用了put接口传递了uid=123456这个参数，它会在网络中一直传递，可以在服务A中通过get(&quot;uid&quot;)的方式获取参数值，也可以在服务C中通过get(&quot;uid&quot;)的方式获取参数值。\n* 右侧蓝色部分是putOnce接口，service中调用了putOnce接口传递pid=11111，它只会传递一级，可以在服务B中通过get(&quot;pid&quot;)的方式获取参数值，但是在服务D中就获取不到pid的值了。\n\n以上的两种接口可以用于业务自定义传递数据，比如通过传递一个服务标识，用于AB test，下游的所有服务获取到test的标识就会走test的策略，即上游服务可以传递一些参数，控制所有下游服务的逻辑。当然业务也可以通过该接口传递一些临时性的数据。\n\n# 系统架构\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace6.png)\n\n主要分为三层：数据埋点上报、数据收集计算、数据前端展示。\n\n## 基本概念\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace7.png)\n\n### traceId\n\n全局唯一，64位整数，用于标识一次分布式请求，会在RPC调用的网络中传递。\n\n### spanId\n\n签名方式生成:0, 0.1, 0.1.1, 0.2。用于标识一次RPC在分布式请求中的位置，比如0.2就是0节点服务调用的第二个服务。\n\n### annotation\n\n业务端自定义埋点，业务感兴趣的想上传到后端的数据，比如该次请求的用户ID等。\n\n## 数据埋点\n\n### 埋点SDK\n\n提供统一的SDK，在各个中间件中埋点，生成traceID等核心数据，上报服务的调用数据信息。\n\n* 生成调用上下文；\n* 同步调用上下文存放在ThreadLocal, 异步调用通过显式调用API的方式支持；\n* 网络中传输关键埋点数据，用于中间件间的数据传递，支持Thrift, HTTP协议。\n\n业内有些系统是使用注解的方式实现的埋点，这种方式看似很优雅，但是需要业务方显式依赖一些AOP库，这部分很容易出现问题，因为AOP方式太过透明，导致查问题很麻烦，而且业务方配置的东西越多越容易引起一些意想不到的问题，所以我们的经验是尽量在各个统一的中间件中进行显式埋点，虽然会导致代码间耦合度增加，但是方便后续定位问题。其次，为了整个框架的统一，MTrace并非仅支持Java一种语言，而AOP的特性很多语言是不支持的。\n\nAgent\n\n* 透传数据，用作数据转发；\n* 做流量控制；\n* 控制反转，很多策略可以通过agent实现，而不需要每次都升级业务代码中的SDK。\n\nAgent仅仅会转发数据，由Agent判断将数据转发到哪里，这样就可以通过Agent做数据路由、流量控制等操作。也正是由于Agent的存在，使得我们可以在Agent层实现一些功能，而不需要业务端做SDK的升级，要知道业务端SDK升级的过程是很缓慢的，这对于整个调用链的系统来说是不可接受的，因为MTrace整个系统是针对庞大的分布式系统而言的，有一环的服务缺失也会造成一定的问题。\n\n目前MTrace支持的中间件有:\n\n* 公司内部RPC中间件\n* http中间件\n* mysql中间件\n* tair中间件\n* mq中间件\n\n### 数据埋点的四个阶段：\n\n* Client Send: 客户端发起请求时埋点，需要传递一些参数，比如服务的方法名等\n\n```java\nSpan span = Tracer.clientSend(param);\n```\n\n* Server Recieve: 服务端接收请求时埋点，需要回填一些参数，比如traceId，spanId\n\n```java\nTracer.serverRecv(param);\n```\n\n* ServerSend: 服务端返回请求时埋点，这时会将上下文数据传递到异步上传队列中\n\n```java\nTracer.serverSend();\n```\n\n* Client Recieve: 客户端接收返回结果时埋点，这时会将上下文数据传递到异步上传队列中\n\n```java\nTracer.clientRecv();\n```\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace8.png)\n\n### 埋点上下文\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace9.png)\n\n上图CS、SR为创建上下文的位置，CR、SS为归档上下文的位置。\n\n### 上下文归档\n\n上下文归档，会把上下文数据异步上传到后端，为了减轻对业务端的影响，上下文上报采用的是异步队列的方式，数据不会落地，直接通过网络形式传递到后端服务，在传递之前会对数据做一层压缩，主要是压缩比很可观，可以达到10倍以上，所以就算牺牲一点CPU资源也是值得的。具体上报的数据如图所示：\n\n![](/assets/images/2016/10/14/distributed-session-tracking-system-architecture-design-and-practice/mtrace10.png)\n\n我们之前在数据埋点时遇到了一些问题：\n\n* 异步调用\n\n  * 异步IO造成的线程切换，不能通过ThreadLocal传递上下文。\n  * 显式的通过API进行埋点传递，切换前保存，切换后还原。\n  * 提供封装好的ThreadPool库。\n\n* 数据量大，每天千亿级别的数据\n\n  * 批量上报\n  * 数据压缩\n  * 极端情况下采样\n\n## 数据存储\n\n### Kafka使用\n\n我们在SDK与后端服务之间加了一层Kafka，这样做既可以实现两边工程的解耦，又可以实现数据的延迟消费。我们不希望因为瞬时QPS过高而引起的数据丢失，当然为此也付出了一些实效性上的代价。\n\n### 实时数据Hbase\n\n调用链路数据的实时查询主要是通过Hbase，使用traceID作为RowKey，能天然的把一整条调用链聚合在一起，提高查询效率。\n\n### 离线数据Hive\n\n离线数据主要是使用Hive，可以通过SQL进行一些结构化数据的定制分析。比如链路的离线形态，服务的出度入度(有多少服务调用了该服务，该服务又调用了多少下游服务)\n\n## 前端展示\n\n前端展示，主要遇到的问题是NTP同步的问题，因为调用链的数据是从不同机器上收集上来的，那么聚合展示的时候就会有NTP时间戳不同步的问题，这个问题很难解决，于是我们采取的方式是前端做一层适配，通过SpanId定位调用的位置而不是时间，比如0.2一定是发生在0.1这个Span之后的调用，所以如果时间出现漂移，就会根据SpanId做一次校正。即判断时间顺序的优先级为最高是spanid,然后是时间戳。\n\n# 总结\n\n核心概念：调用链；\n\n用途：定位系统瓶颈，优化系统结构、统计系统指标、分析系统数据；\n\n架构：埋点上报、收集计算、展示分析。\n\n分布式会话跟踪系统主要的特点就是能关联服务之间的联动关系，通过这层关系可以延伸出来很多有意义的分析数据，统计数据。为优化系统结构，查询系统瓶颈问题带来了极大的便利。\n \n---\n\n* 原文链接：[分布式会话跟踪系统架构设计与实践](http://tech.meituan.com/mt-mtrace.html)\n","tags":["Tracking"],"categories":["Distributed"]},{"title":"深入浅出解析大数据Lambda架构","url":"%2F2016%2F2016-10-10-bigdata-lambda-framework%2F","content":"\n## 前言\n\nHadoop的出现让人们尝到了大数据技术的甜头，它的批处理能力已经被工业界充分认可，但是它的延迟性也一直为大家所诟病。随着各行各业的发展，越来越多的业务要求大数据系统既可以处理历史数据，又可以进行实时计算。比如电商推荐系统，当你在京东浏览商品时，京东会根据你的浏览、加车、收藏、删除等行为，实时为你推荐商品。要实现这个功能，推荐引擎首先需要根据历史数据预先离线计算推荐模型，然后从消息队列中实时拉取用户行为数据，结合两者，实时生成推荐结果。\n\n再举一个智慧交通系统的例子。在智慧交通系统中，需要对未年检、未报废等危险车辆进行实时预警，这就要求该系统预先根据历史数据删选出未年检或未报废的车辆信息库，然后将道路上实时获取到的车辆信息与车辆信息库进行对比，判断有没有违章车辆。\n\n面对这样复杂的业务需求，开发者首先需要一个比较好的架构设计思路，在架构设计完成后再做相应的技术选型。目前业界有几个知名的架构设计来处理此类需求，如Lambda和Summingbird，但是它们在架构的设计上又有比较大的不同。就目前而言，Summingbird和Lambda架构都考虑到了实时计算和批处理相结合的问题，只不过Summingbird主张以统一的方式来执行代码，有关两者的区别，大家可以自行上网了解一下，这里我们只讨论Lambda架构。\n\n## 背景介绍\n\nLambda架构是Nathan Marz提出的一个实时大数据处理框架。Nathan Marz是著名的实时大数据处理框架Storm的作者，Lambda架构就是其根据多年分布式大数据系统的经验总结提炼而成。\n\nNathan Marz 在Big Data:Principles and best practices of scalable real-time data systems一书中提到了很多实时大数据系统的关键特性，包括容错性，健壮性，低延迟，可扩展，通用性，方便查询等，Lambda就是其根据这些特性设计的一个实时大数据框架。需要注意的是，Lambda并不是一个具有实体的软件产品，而是一个指导大数据系统搭建的架构模型，因此，用户可以根据自己的需要，在Lambda的三层模型中，任意集成Hadoop，Kafka，Storm，Spark，Hbase等各类大数据组件，或者选用商用软件来构建系统。\n\n## 原理讲解\n\n### 大数据系统的特性\n\n在讲大数据系统的特性之前，我们先来分析一下数据系统的本质。\n\nNathan Marz认为，数据系统的本质是“查询+数据”，用公式表达如下：\n\n```\nQuery = Function ( All Data )\n```\n\n数据系统其实是一个提供了数据存储和数据查询功能的系统。在数据存储过程中，数据可能会发生丢失，在数据查询的过程中，查询也可能出现错误，因此，数据系统必须能够应对这些问题，这就是我们所说的数据系统的容错性和健壮性。除此之外，随着数据的规模越来越大，查询越来越复杂，我们希望数据系统是易于扩展的，并且是可维护的，最好查询仍然是低延迟的，至此，我们就可以来总结一下大数据系统的关键特性了，具体如下：  \n\n1. 容错性和健壮性：对于分布式系统来说，保证人为操作不出错，程序也不出错是不可能的，因此，大数据系统必须对这样的错误有足够的适应能力。\n2. 低延迟：很多应用对于读和写操作的延时要求非常高，要求对更新和查询的响应是低延时的。\n3. 横向扩容：当数据量/负载增大时，系统可以采用scale out（通过增加机器的个数），而不是scale up（通过增强机器的性能）来维持性能。\n4. 可扩展：当系统需要增加一些新功能或者新特性时，所花费的代价比较小。\n5. 方便查询：数据系统的本质是“查询+数据”，因此，数据系统应具备方便、快速的数据查询功能。\n6. 易于维护：系统要想做到易于维护，其关键是控制其复杂性，越是复杂的系统越容易出错、越难维护。\n\n### Lambda架构的三层模型\n\n前面提到，Query = Function(All Data)，那么大数据系统的关键问题就变成了：如何实时地在任意大数据集上进行查询？如果单纯地对全体数据集进行在线查询，那么计算代价会很大，延迟也会很高，比如Hadoop。\n\nLambda的做法是将大数据系统架构拆分成了三层：Batch Layer，Speed Layer和Serving Layer。Lambda的分层结构图如图1所示：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/001.jpg)\n\n图1  Lambda分层结构图\n\n#### a. Batch Layer  \n\n既然对全体数据集进行在线查询，计算代价会很高，那么如果对查询事先进行预计算，生成对应的Views，并且对Views建立索引，这样，查询的速度会提高很多，这就是Batch Layer所做的事。\n\nBatch Layer层采用不可变模型对所有数据进行了存储，并且根据不同的业务需求，对数据进行了不同的预查询，生成对应的Batch Views，这些Batch Views提供给上层的Serving Layer进行进一步的查询。另外，每隔一段时间都会进行一次预查询，对Batch Views进行更新，Batch Views更新完成后，会立即更新到Serving Layer中去。\n\n预查询的过程是一个批处理的过程，因此，这一层可以选择诸如Hadoop这样的组件。Batch Layer层的结构图如图2所示：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/002.jpg)\n\n图2  Batch Layer结构图\n\n#### b. Speed Layer\n\n如上一节中提到，预查询的过程是一个批处理的过程，该过程花费的时间会比较长，在该过程中，Serving Layer使用的仍然是旧版本的Batch Views，那么仅仅依靠Batch Layer这一层，新进入系统的数据将无法参与最后结果的计算，因此，Marz为Lambda设计了Speed Layer层来处理增量的实时数据。\n\nSpeed Layer和Batch Layer比较类似，对数据计算生成Realtime Views，其主要的区别是：\n\n第一，Speed Layer处理的数据是最近的增量数据流，Batch Layer处理的是全体数据集。\n\n第二，Speed Layer为了效率，接收到新数据时，就更新Realtime Views，并且采用的是Incremental Updates（增量计算模型），而Batch Layer则是根据全体离线数据集得到Batch Views，采用的是Recomputation Updates（重新计算模型）。\n\n#### c. Serving Layer\n\nServing Layer用于响应用户的查询请求，它将Batch Views和Realtime Views的结果进行了合并，得到最后的结果，返回给用户，图3给出了Lambda的整体架构图：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/003.jpg)\n\n图3  Lambda架构图\n\n概括起来，Lambda架构通过Batch Layer和Speed Layer的分层设计来实现在一个系统内同时支持实时和批处理业务，并且通过Serving Layer在逻辑上统一了两种数据源的接口，让应用能够以一个统一的数据视图来开发和部署，从而达到数据和应用的融合。\n\n在每个Layer的实际设计中，开发人员可以根据自身的需求来选择合适的组件或者产品来构建相应的系统，目前有很多开源组件可以用于构建此类系统，如Storm/Spark Streaming/Flink可以用来构建Speed Layer，Spark/MapReduce可以用于构建Batch Layer，HBase/Redis/MongoDB可以用于存储。\n\n由于一套系统需要同时处理实时业务和批处理业务，并且两批业务之间有比较明确的数据耦合，Lambda系统本身的技术复杂度非常高，选择方案的时候需要充分考虑系统构建成本以及稳定性。从笔者了解的情况看，选择开源技术来构建类似系统，目前国内只有很少的成功商业实践。对于技术实力不那么强的企业，选择一个可靠的商业软件往往是个更合适的选择。星环科技在这方面有非常不错的成功经验，结合着Transwarp Data Hub的技术优势，我们帮助客户在智慧交通系统领域完成了非常大规模的实际业务部署。下文我们将以某一个项目来做具体的案例分析，来描述如何使用TDH来完成一个用于大规模生产业务的Lambda系统。\n\n## 案例分析\n\n本案例为某省的智慧交通系统。\n\n### 系统各层组件的选型\n\n根据上面的介绍，Lambda架构包括三层，其中Batch Layer负责数据集的存储和批处理的执行，数据存储我们选择Hyperbase。Hyperbase支持快速高并发的查询，可以方便用户做一些精确类查询（如根据车牌号检索等）。由于此项目还有一些统计类的业务需求，我们选择将部分数据在HDFS上保留一份用作后期的分析之用，Inceptor的强大的数据分析能力可以帮助用户在任意维度上做复杂的数据分析工作。\n\nSpeed Layer主要负责对数据的实时处理，可以使用Transwarp Stream。此外，Kafka选择使用Transwarp Kafka 0.9版本，由于增加了Kafka队列内的kerberos安全认证功能，消息队列中的数据更安全。\n\nHDFS和Hyperbase的数据通过SQL以及JDBC接口开放给用户，企业可以开发Serving Layer中自身需要的业务。由于这些应用程序是具体的企业内部业务，此处不做讨论。\n\n### 系统各层机器规划\n\n有了上面的组件选型，下面我们可以进行机器规划。主要考虑的是以下几个方面：\n\n### 存储能力\n\n就某地市而言，每天约有1000w的过车记录产生，高峰时期每秒能约有1w条过车记录产生，每条过车记录对应的结构化数据约有30个字段，大小为200Byte；每天还有50w张左右大小约为500KB的图片数据，按照规划数据需要存储的周期为2年，因此对集群容量要求如下：\n\n结构化数据存储三份、图片数据存储两份，2年的数据总量约为：\n\n```\n(1000w * 200B *3  +  50 w * 500KB * 2) * 365 * 2  =  344TB\n```\n\n每台机器有8个硬盘，每个硬盘容量为3TB，则需要数据节点数为：\n\n```\n344TB / (3TB*8) = 15台\n```\n\n另外，Hadoop分布式存储集群需要2台管理节点。\n\n### 实时计算的需求\n\n目前需要进行实时处理的业务包括：\n\na. 实时检测业务：逾期未年检、黑名单、逾期未报废、凌晨2点到5点上路行驶的客运车辆、车主驾驶证无效车辆等。\n\nb. 实时分析业务：包括流量统计、旅行时间分析、套牌车检测、区间测速等。\n\n其中实时检测业务以及套牌车检测等要求在秒级别反馈结果以对违法行为进行实时拦截；分析业务要求在分钟级别更新结果。\n\n按照每秒1w条过车记录计算，总共有20+个流处理业务（比对和复杂分析）同时运行，预估需要实时处理集群机器6台。\n\n另外，所有的过车记录都会预先被接入Kafka分布式消息处理集群，每条记录写入3份，保存7天，预估需要Kafka集群机器4台。\n\n### 批处理分析要求\n\n除了实时处理业务之外，还需要对历史数据进行统计分析，对于时间跨度在一个月内的统计分析需要在秒级返回结果；对于时间跨度在三个月以上的复杂统计分析需要在分钟级别返回结果。   \n\n依据上述的要求分析，给出机器数目和配置参考图如下：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/004.jpg)\n\n图4 某智能交通系统的配置情况\n\n### 系统架构\n\n该智慧交通系统的架构图如图5所示：\n\n![](/assets/images/2016/10/10/bigdata-lambda-framework/005.jpg)\n\n图5  智能交通的整体架构图\n\n前端卡口会实时采集过往车辆信息，采集到的车辆信息首先被接入Kafka分布式消息总线。Kafka分布式消息总线，会对这些数据进行归类分拣，分发给不同的服务集群，比如实时入库服务集群、未年检车监控服务集群等。\n\n假设有部分数据被送入到了未年检车监控服务集群中，该集群需要将待检查车辆与车辆数据库进行数据比对。为了减少数据比对时间，该系统预先根据历史数据生成了未年检车辆数据库，由Batch Layer层的批处理引擎完成。待检查车辆只需与未年检车辆数据库进行在线比对即可，如果发现违章车辆，则进行标记显示，并进行预警。\n\n### 系统支持的业务\n\n#### 1. 实时监控预警任务\n\n实时监控预警业务主要由Speed Layer层的Transwarp Stream负责，按照技术可以分为以下三类：\n\na. ETL功能\n\n   将实时采集的过车数据，按照一定的清洗转化规则进行处理，转化成规范的记录后写入后端存储Hyperbase和 Holodesk。其中Hyperbase为持久化的列式存储，保存所有的历史过车数据；Holodesk为临时存储，提供高速的分析能力，可以保存一周以内的短期数据。\n\nb. 实时检测业务\n\n   最简单的检测规则可以直接根据过车记录判断，例如凌晨2点到5点行驶的车辆；其次是和一些基础表进行比对的业务，例如黑名单车辆/未年检车辆检测，需要事先进行预查询，生成并保存相应的黑名单车辆表/未年检车辆表。 \n\nc. 实时分析业务\n\n   实时统计业务如流量统计，通常基于窗口技术实现。例如需要统计分钟流量、小时流量，可以设定一个长度为1分钟的滚动窗口，统计每分钟的流量，并基于分钟流量对小时流量进行更新。\n\n### 2. 数据统计分析业务\n\na. 基于全量历史数据的统计分析\n\n   通过Inceptor组件能够对存储在Hyperbase中的数据使用SQL语句进行统计分析，比如统计一天的车流量，一个月的碰撞次数等。Hyperbase的Rowkey具有去重的功能，可以帮助用户得到精准的统计结果。\n\nb. 基于临时数据的交互式分析\n\n   除了一些固定的统计报表之外，还需要处理一些突发的临时性统计业务。例如伴随车分析，就是统计出一段时间内和某个车一同行驶的车辆，这在犯罪分析中有很大的作用。TDH中的Holodesk组件能够很好处理这部分业务需求，创建Holodesk上的一张有窗口限制的表（例如窗口长度为1周，超过1周的数据将被删除），通过Transwarp Stream将数据实时写入Holodesk，前端通过Inceptor的SQL实现交互式分析。\n\n## 结语\n\nLambda架构是大数据中一个非常重要的设计，但是由于原理的抽象和系统的复杂性，大数据从业人员要设计出一个有生产质量的Lambda系统是非常有挑战性的。本文通过原理的梳理和具体商业的剖析，希望给读者一个总体的思路，如何从无到有设计出一个有效的系统，同时满足实时和离线业务的需求，帮助企业从数据中创造更大的价值。\n\n---\n\n* Author: BigDater\n* Source: [微信公众号：大数据开放实验室](http://weixin.qq.com/r/mjvM1CPEGH5nrWe3926I)\n* Link: [深入浅出解析大数据Lambda架构](http://mp.weixin.qq.com/s?__biz=MzIzNzU0ODEwOA==&mid=2247483775&idx=1&sn=c482d1e788854f7ba83cdccc9f031ab9&chksm=e8c7a65cdfb02f4a3b482987dcad71423adb69c6a339df1f0dea8cbd29be878d93975ae1a3c2&scene=21#wechat_redirect)","tags":["Framework"],"categories":["Lambda"]},{"title":"分布式系统互斥性与幂等性问题的分析与解决","url":"%2F2016%2F2016-09-29-distributed-system-mutually-exclusive-idempotence-cerberus-gtis%2F","content":"\n### 前言\n\n随着互联网信息技术的飞速发展，数据量不断增大，业务逻辑也日趋复杂，对系统的高并发访问、海量数据处理的场景也越来越多。如何用较低成本实现系统的高可用、易伸缩、可扩展等目标就显得越发重要。为了解决这一系列问题，系统架构也在不断演进。传统的集中式系统已经逐渐无法满足要求，分布式系统被使用在更多的场景中。\n\n分布式系统由独立的服务器通过网络松散耦合组成。在这个系统中每个服务器都是一台独立的主机，服务器之间通过内部网络连接。分布式系统有以下几个特点：\n\n* 可扩展性：可通过横向水平扩展提高系统的性能和吞吐量。\n\n* 高可靠性：高容错，即使系统中一台或几台故障，系统仍可提供服务。\n\n* 高并发性：各机器并行独立处理和计算。\n\n* 廉价高效：多台小型机而非单台高性能机。\n\n然而，在分布式系统中，其环境的复杂度、网络的不确定性会造成诸如时钟不一致、“拜占庭将军问题”（Byzantine failure）等。存在于集中式系统中的机器宕机、消息丢失等问题也会在分布式环境中变得更加复杂。\n\n基于分布式系统的这些特征，有两种问题逐渐成为了分布式环境中需要重点关注和解决的典型问题：\n\n* 互斥性问题。\n\n* 幂等性问题。\n\n今天我们就针对这两个问题来进行分析。\n\n### 互斥性问题\n\n先看两个常见的例子：\n\n**例1**：某服务记录关键数据X，当前值为100。A请求需要将X增加200；同时，B请求需要将X减100。\n\n在理想的情况下，A先读取到X=100，然后X增加200，最后写入X=300。B请求接着从读取X=300，减少100，最后写入X=200。\n\n然而在真实情况下，如果不做任何处理，则可能会出现：A和B同时读取到X=100；A写入之前B读取到X；B比A先写入等等情况。\n\n**例2**：某服务提供一组任务，A请求随机从任务组中获取一个任务；B请求随机从任务组中获取一个任务。\n\n在理想的情况下，A从任务组中挑选一个任务，任务组删除该任务，B从剩下的的任务中再挑一个，任务组删除该任务。\n\n同样的，在真实情况下，如果不做任何处理，可能会出现A和B挑中了同一个任务的情况。\n\n以上的两个例子，都存在操作互斥性的问题。互斥性问题用通俗的话来讲，就是对共享资源的抢占问题。如果不同的请求对同一个或者同一组资源读取并修改时，无法保证按序执行，无法保证一个操作的原子性，那么就很有可能会出现预期外的情况。因此操作的互斥性问题，也可以理解为一个需要保证时序性、原子性的问题。\n\n在传统的基于数据库的架构中，对于数据的抢占问题往往是通过数据库事务（ACID）来保证的。在分布式环境中，出于对性能以及一致性敏感度的要求，使得分布式锁成为了一种比较常见而高效的解决方案。\n\n事实上，操作互斥性问题也并非分布式环境所独有，在传统的多线程、多进程情况下已经有了很好的解决方案。因此在研究分布式锁之前，我们先来分析下这两种情况的解决方案，以期能够对分布式锁的解决方案提供一些实现思路。\n\n#### 多线程环境解决方案及原理\n\n1. **解决方案**\n\n《Thinking in Java》书中写到：\n\n> 基本上所有的并发模式在解决线程冲突问题的时候，都是采用序列化访问共享资源的方案。\n\n在多线程环境中，线程之间因为公用一些存储空间，冲突问题时有发生。解决冲突问题最普遍的方式就是用互斥锁把该资源或对该资源的操作保护起来。\n\nJava JDK中提供了两种互斥锁Lock和synchronized。不同的线程之间对同一资源进行抢占，该资源通常表现为某个类的普通成员变量。因此，利用ReentrantLock或者synchronized将共享的变量及其操作锁住，即可基本解决资源抢占的问题。\n\n下面来简单聊一聊两者的实现原理。\n\n2. **原理**\n\n**ReentrantLock**\n\nReentrantLock主要利用CAS+CLH队列来实现。它支持公平锁和非公平锁，两者的实现类似。\n\n* CAS：Compare and Swap，比较并交换。CAS有3个操作数：内存值V、预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。该操作是一个原子操作，被广泛的应用在Java的底层实现中。在Java中，CAS主要是由sun.misc.Unsafe这个类通过JNI调用CPU底层指令实现。\n\n* CLH队列：带头结点的双向非循环链表(如下图所示)：\n\n![](/assets/images/2016/09/29/distributed-system-mutually-exclusive-idempotence-cerberus-gtis/clh_queue.png)\n\nReentrantLock的基本实现可以概括为：先通过CAS尝试获取锁。如果此时已经有线程占据了锁，那就加入CLH队列并且被挂起。当锁被释放之后，排在CLH队列队首的线程会被唤醒，然后CAS再次尝试获取锁。在这个时候，如果：\n\n* 非公平锁：如果同时还有另一个线程进来尝试获取，那么有可能会让这个线程抢先获取；\n\n* 公平锁：如果同时还有另一个线程进来尝试获取，当它发现自己不是在队首的话，就会排到队尾，由队首的线程获取到锁。\n\n下面分析下两个片段：\n\n```java\nfinal boolean nonfairTryAcquire(int acquires) {\n    final Thread current = Thread.currentThread();\n    int c = getState();\n    if (c == 0) {\n        if (compareAndSetState(0, acquires)) {\n            setExclusiveOwnerThread(current);\n            return true;\n        }\n    }\n    else if (current == getExclusiveOwnerThread()) {\n        int nextc = c + acquires;\n        if (nextc < 0) // overflow\n            throw new Error(\"Maximum lock count exceeded\");\n        setState(nextc);\n        return true;\n    }\n    return false;\n}\n```\n\n在尝试获取锁的时候，会先调用上面的方法。如果状态为0，则表明此时无人占有锁。此时尝试进行set，一旦成功，则成功占有锁。如果状态不为0，再判断是否是当前线程获取到锁。如果是的话，将状态+1，因为此时就是当前线程，所以不用CAS。这也就是可重入锁的实现原理。\n\n```java\nfinal boolean acquireQueued(final Node node, int arg) {\n    boolean failed = true;\n    try {\n        boolean interrupted = false;\n        for (;;) {\n            final Node p = node.predecessor();\n            if (p == head && tryAcquire(arg)) {\n                setHead(node);\n                p.next = null; // help GC\n                failed = false;\n                return interrupted;\n            }\n            if (shouldParkAfterFailedAcquire(p, node) &&\n                parkAndCheckInterrupt())\n                interrupted = true;\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\nprivate final boolean parkAndCheckInterrupt() {\n    LockSupport.park(this);\n    return Thread.interrupted();\n}\n```\n\n该方法是在尝试获取锁失败加入CHL队尾之后，如果发现前序节点是head，则CAS再尝试获取一次。否则，则会根据前序节点的状态判断是否需要阻塞。如果需要阻塞，则调用LockSupport的park方法阻塞该线程。\n\n**synchronized**\n\n在Java语言中存在两种内建的synchronized语法：synchronized语句、synchronized方法。\n\n* synchronized语句：当源代码被编译成字节码的时候，会在同步块的入口位置和退出位置分别插入monitorenter和monitorexit字节码指令;\n\n* synchronized方法：在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1。这个在specification中没有明确说明。\n\n在Java虚拟机的specification中，有关于monitorenter和monitorexit字节码指令的详细描述：http://docs.oracle.com/Javase/specs/jvms/se7/html/jvms-6.html#jvms-6.5.monitorenter 。\n\n**monitorenter**\n\n> The objectref must be of type reference.\n> \n> Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:\n> \n> * If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.\n> \n> * If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.\n> \n> * If another thread already owns the monitor associated with objectref, the thread blocks until the monitor's entry count is zero, then tries again to gain ownership.\n\n每个对象都有一个锁，也就是监视器（monitor）。当monitor被占有时就表示它被锁定。线程执行monitorenter指令时尝试获取对象所对应的monitor的所有权，过程如下：\n\n* 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者;\n\n* 如果线程已经拥有了该monitor，只是重新进入，则进入monitor的进入数加1;\n\n* 如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。\n\n**monitorexit**\n\n> The objectref must be of type reference.\n> \n> The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref.\n> \n> The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so.\n\n执行monitorexit的线程必须是相应的monitor的所有者。\n\n指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权。\n\n在JDK1.6及其之前的版本中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的。然而在现实中的大部分情况下，同步方法是运行在单线程环境（无锁竞争环境）。如果每次都调用Mutex Lock将严重的影响程序的性能。因此在JDK 1.6之后的版本中对锁的实现做了大量的优化，这些优化在很大程度上减少或避免了Mutex Lock的使用。\n\n3. **多进程的解决方案**\n\n在多道程序系统中存在许多进程，它们共享各种资源，然而有很多资源一次只能供一个进程使用，这便是临界资源。多进程中的临界资源大致上可以分为两类，一类是物理上的真实资源，如打印机；一类是硬盘或内存中的共享数据，如共享内存等。而进程内互斥访问临界资源的代码被称为临界区。\n\n针对临界资源的互斥访问，JVM层面的锁就已经失去效力了。在多进程的情况下，主要还是利用操作系统层面的进程间通信原理来解决临界资源的抢占问题。比较常见的一种方法便是使用信号量（Semaphores）。\n\n信号量在POSIX标准下有两种，分别为有名信号量和无名信号量。无名信号量通常保存在共享内存中，而有名信号量是与一个特定的文件名称相关联。信号量是一个整数变量，有计数信号量和二值信号量两种。对信号量的操作，主要是P操作（wait）和V操作（signal）。\n\n* P操作：先检查信号量的大小，若值大于零，则将信号量减1，同时进程获得共享资源的访问权限，继续执行；若小于或者等于零，则该进程被阻塞后，进入等待队列。\n\n* V操作：该操作将信号量的值加1，如果有进程阻塞着等待该信号量，那么其中一个进程将被唤醒。\n\n举个例子，设信号量为1，当一个进程A在进入临界区之前，先进行P操作。发现值大于零，那么就将信号量减为0，进入临界区执行。此时，若另一个进程B也要进去临界区，进行P操作，发现信号量等于0，则会被阻塞。当进程A退出临界区时，会进行V操作，将信号量的值加1，并唤醒阻塞的进程B。此时B就可以进入临界区了。\n\n这种方式，其实和多线程环境下的加解锁非常类似。因此用信号量处理临界资源抢占，也可以简单地理解为对临界区进行加锁。\n\n通过上面的一些了解，我们可以概括出解决互斥性问题，即资源抢占的基本方式为：\n\n*对共享资源的操作前后（进入退出临界区）加解锁，保证不同线程或进程可以互斥有序的操作资源。*\n\n加解锁方式，有显式的加解锁，如ReentrantLock或信号量；也有隐式的加解锁，如synchronized。那么在分布式环境中，为了保证不同JVM不同主机间不会出现资源抢占，那么同样只要对临界区加解锁就可以了。\n\n然而在多线程和多进程中，锁已经有比较完善的实现，直接使用即可。但是在分布式环境下，就需要我们自己来实现分布式锁。\n\n4. **分布式环境下的解决方案——分布式锁**\n\n首先，我们来看看分布式锁的基本条件。\n\n**分布式锁条件**\n\n**4.1 基本条件**\n\n再回顾下多线程和多进程环境下的锁，可以发现锁的实现有很多共通之处，它们都需要满足一些最基本的条件：\n\n* 需要有存储锁的空间，并且锁的空间是可以访问到的。\n\n* 锁需要被唯一标识。\n\n* 锁要有至少两种状态。\n\n仔细分析这三个条件：\n\n* 存储空间\n\n锁是一个抽象的概念，锁的实现，需要依存于一个可以存储锁的空间。在多线程中是内存，在多进程中是内存或者磁盘。更重要的是，这个空间是可以被访问到的。多线程中，不同的线程都可以访问到堆中的成员变量；在多进程中，不同的进程可以访问到共享内存中的数据或者存储在磁盘中的文件。但是在分布式环境中，不同的主机很难访问对方的内存或磁盘。这就需要一个都能访问到的外部空间来作为存储空间。\n\n最普遍的外部存储空间就是数据库了，事实上也确实有基于数据库做分布式锁（行锁、version乐观锁），如quartz集群架构中就有所使用。除此以外，还有各式缓存如Redis、Tair、Memcached、Mongodb，当然还有专门的分布式协调服务Zookeeper，甚至是另一台主机。只要可以存储数据、锁在其中可以被多主机访问到，那就可以作为分布式锁的存储空间。\n\n* 唯一标识\n\n不同的共享资源，必然需要用不同的锁进行保护，因此相应的锁必须有唯一的标识。在多线程环境中，锁可以是一个对象，那么对这个对象的引用便是这个唯一标识。多进程环境中，信号量在共享内存中也是由引用来作为唯一的标识。但是如果不在内存中，失去了对锁的引用，如何唯一标识它呢？上文提到的有名信号量，便是用硬盘中的文件名作为唯一标识。因此，在分布式环境中，只要给这个锁设定一个名称，并且保证这个名称是全局唯一的，那么就可以作为唯一标识。\n\n* 至少两种状态\n\n为了给临界区加锁和解锁，需要存储两种不同的状态。如ReentrantLock中的status，0表示没有线程竞争，大于0表示有线程竞争；信号量大于0表示可以进入临界区，小于等于0则表示需要被阻塞。因此只要在分布式环境中，锁的状态有两种或以上：如有锁、没锁；存在、不存在等等，均可以实现。\n\n有了这三个条件，基本就可以实现一个简单的分布式锁了。下面以数据库为例，实现一个简单的分布式锁：\n\n数据库表，字段为锁的ID（唯一标识），锁的状态（0表示没有被锁，1表示被锁）。\n\n伪代码为：\n\n```java\nlock = mysql.get(id);\nwhile(lock.status == 1) {\n    sleep(100);\n}\nmysql.update(lock.status = 1);\ndoSomething();\nmysql.update(lock.status = 0);\n```\n\n**4.2 问题**\n\n以上的方式即可以实现一个粗糙的分布式锁，但是这样的实现，有没有什么问题呢？\n\n* 问题1：锁状态判断原子性无法保证\n\n从读取锁的状态，到判断该状态是否为被锁，需要经历两步操作。如果不能保证这两步的原子性，就可能导致不止一个请求获取到了锁，这显然是不行的。因此，我们需要保证锁状态判断的原子性。\n\n* 问题2：网络断开或主机宕机，锁状态无法清除\n\n假设在主机已经获取到锁的情况下，突然出现了网络断开或者主机宕机，如果不做任何处理该锁将仍然处于被锁定的状态。那么之后所有的请求都无法再成功抢占到这个锁。因此，我们需要在持有锁的主机宕机或者网络断开的时候，及时的释放掉这把锁。\n\n* 问题3：无法保证释放的是自己上锁的那把锁\n\n在解决了问题2的情况下再设想一下，假设持有锁的主机A在临界区遇到网络抖动导致网络断开，分布式锁及时的释放掉了这把锁。之后，另一个主机B占有了这把锁，但是此时主机A网络恢复，退出临界区时解锁。由于都是同一把锁，所以A就会将B的锁解开。此时如果有第三个主机尝试抢占这把锁，也将会成功获得。因此，我们需要在解锁时，确定自己解的这个锁正是自己锁上的。\n\n**4.3 进阶条件**\n\n如果分布式锁的实现，还能再解决上面的三个问题，那么就可以算是一个相对完整的分布式锁了。然而，在实际的系统环境中，还会对分布式锁有更高级的要求。\n\n* 可重入：线程中的可重入，指的是外层函数获得锁之后，内层也可以获得锁，ReentrantLock和synchronized都是可重入锁；衍生到分布式环境中，一般仍然指的是线程的可重入，在绝大多数分布式环境中，都要求分布式锁是可重入的。\n\n* 惊群效应（Herd Effect）：在分布式锁中，惊群效应指的是，在有多个请求等待获取锁的时候，一旦占有锁的线程释放之后，如果所有等待的方都同时被唤醒，尝试抢占锁。但是这样的情况会造成比较大的开销，那么在实现分布式锁的时候，应该尽量避免惊群效应的产生。\n\n* 公平锁和非公平锁：不同的需求，可能需要不同的分布式锁。非公平锁普遍比公平锁开销小。但是业务需求如果必须要锁的竞争者按顺序获得锁，那么就需要实现公平锁。\n\n* 阻塞锁和自旋锁：针对不同的使用场景，阻塞锁和自旋锁的效率也会有所不同。阻塞锁会有上下文切换，如果并发量比较高且临界区的操作耗时比较短，那么造成的性能开销就比较大了。但是如果临界区操作耗时比较长，一直保持自旋，也会对CPU造成更大的负荷。\n\n保留以上所有问题和条件，我们接下来看一些比较典型的实现方案。\n\n**4.4 典型实现**\n\n**4.4.1 ZooKeeper的实现**\n\nZooKeeper（以下简称“ZK”）中有一种节点叫做顺序节点，假如我们在/lock/目录下创建3个节点，ZK集群会按照发起创建的顺序来创建节点，节点分别为/lock/0000000001、/lock/0000000002、/lock/0000000003。\n\nZK中还有一种名为临时节点的节点，临时节点由某个客户端创建，当客户端与ZK集群断开连接，则该节点自动被删除。EPHEMERAL_SEQUENTIAL为临时顺序节点。\n\n根据ZK中节点是否存在，可以作为分布式锁的锁状态，以此来实现一个分布式锁，下面是分布式锁的基本逻辑：\n\n* 客户端调用create()方法创建名为“/dlm-locks/lockname/lock-”的临时顺序节点。\n\n* 客户端调用getChildren(“lockname”)方法来获取所有已经创建的子节点。\n\n* 客户端获取到所有子节点path之后，如果发现自己在步骤1中创建的节点是所有节点中序号最小的，那么就认为这个客户端获得了锁。\n\n* 如果创建的节点不是所有节点中需要最小的，那么则监视比自己创建节点的序列号小的最大的节点，进入等待。直到下次监视的子节点变更的时候，再进行子节点的获取，判断是否获取锁。\n\n释放锁的过程相对比较简单，就是删除自己创建的那个子节点即可，不过也仍需要考虑删除节点失败等异常情况。\n\n开源的基于ZK的Menagerie的源码就是一个典型的例子：https://github.com/sfines/menagerie 。\n\nMenagerie中的lock首先实现了可重入锁，利用ThreadLocal存储进入的次数，每次加锁次数加1，每次解锁次数减1。如果判断出是当前线程持有锁，就不用走获取锁的流程。\n\n通过tryAcquireDistributed方法尝试获取锁，循环判断前序节点是否存在，如果存在则监视该节点并且返回获取失败。如果前序节点不存在，则再判断更前一个节点。如果判断出自己是第一个节点，则返回获取成功。\n\n为了在别的线程占有锁的时候阻塞，代码中使用JUC的condition来完成。如果获取尝试锁失败，则进入等待且放弃localLock，等待前序节点唤醒。而localLock是一个本地的公平锁，使得condition可以公平的进行唤醒，配合循环判断前序节点，实现了一个公平锁。\n\n这种实现方式非常类似于ReentrantLock的CHL队列，而且zk的临时节点可以直接避免网络断开或主机宕机，锁状态无法清除的问题，顺序节点可以避免惊群效应。这些特性都使得利用ZK实现分布式锁成为了最普遍的方案之一。\n\n**4.4.2 Redis的实现**\n\nRedis的分布式缓存特性使其成为了分布式锁的一种基础实现。通过Redis中是否存在某个锁ID，则可以判断是否上锁。为了保证判断锁是否存在的原子性，保证只有一个线程获取同一把锁，Redis有SETNX（即SET if Not eXists）和GETSET（先写新值，返回旧值，原子性操作，可以用于分辨是不是首次操作）操作。\n\n为了防止主机宕机或网络断开之后的死锁，Redis没有ZK那种天然的实现方式，只能依赖设置超时时间来规避。\n\n以下是一种比较普遍但不太完善的Redis分布式锁的实现步骤（与下图一一对应）：\n\n* 线程A发送SETNX lock.orderid 尝试获得锁，如果锁不存在，则set并获得锁。\n\n* 如果锁存在，则再判断锁的值（时间戳）是否大于当前时间，如果没有超时，则等待一下再重试。\n\n* 如果已经超时了，在用GETSET lock.{orderid} 来尝试获取锁，如果这时候拿到的时间戳仍旧超时，则说明已经获得锁了。\n\n* 如果在此之前，另一个线程C快一步执行了上面的操作，那么A拿到的时间戳是个未超时的值，这时A没有如期获得锁，需要再次等待或重试。\n\n![](/assets/images/2016/09/29/distributed-system-mutually-exclusive-idempotence-cerberus-gtis/redis_lock.png)\n\n该实现还有一个需要考虑的问题是全局时钟问题，由于生产环境主机时钟不能保证完全同步，对时间戳的判断也可能会产生误差。\n\n以上是Redis的一种常见的实现方式，除此以外还可以用SETNX+EXPIRE来实现。Redisson是一个官方推荐的Redis客户端并且实现了很多分布式的功能。它的分布式锁就提供了一种更完善的解决方案，源码：https://github.com/mrniko/redisson 。\n\n**4.4.3 Tair的实现**\n\nTair和Redis的实现类似，Tair客户端封装了一个expireLock的方法：通过锁状态和过期时间戳来共同判断锁是否存在，只有锁已经存在且没有过期的状态才判定为有锁状态。在有锁状态下，不能加锁，能通过大于或等于过期时间的时间戳进行解锁。\n\n采用这样的方式，可以不用在Value中存储时间戳，并且保证了判断是否有锁的原子性。更值得注意的是，由于超时时间是由Tair判断，所以避免了不同主机时钟不一致的情况。\n\n以上的几种分布式锁实现方式，都是比较常见且有些已经在生产环境中应用。随着应用环境越来越复杂，这些实现可能仍然会遇到一些挑战。\n\n* **强依赖于外部组件**：分布式锁的实现都需要依赖于外部数据存储如ZK、Redis等等，因此一旦这些外部组件出现故障，那么分布式锁就不可用了。\n\n* **无法完全满足需求**：不同分布式锁的实现，都有相应的特点，对于一些需求并不能很好的满足，如实现公平锁、给等待锁加超时时间等等。\n\n基于以上问题，结合多种实现方式，我们开发了Cerberus（得名自希腊神话里守卫地狱的猛犬），致力于提供灵活可靠的分布式锁。\n\n**4.4 Cerberus分布式锁**\n\nCerberus有以下几个特点。\n\n**4.4.1 特点一：一套接口多种引擎** \n\nCerberus分布式锁使用了多种引擎实现方式（Tair、ZK、未来支持Redis），支持使用方自主选择所需的一种或多种引擎。这样可以结合引擎特点，选择符合实际业务需求和系统架构的方式。\n\nCerberus分布式锁将不同引擎的接口抽象为一套，屏蔽了不同引擎的实现细节。使得使用方可以专注于业务逻辑，也可以任意选择并切换引擎而不必更改任何的业务代码。\n\n如果使用方选择了一种以上的引擎，那么以配置顺序来区分主副引擎。以下是使用主引擎的推荐：\n\n| 功能需求 | Tair | ZK |\n| ------- | ---- | -- |\n| 并发量高 | ✔ |  |\n| 响应时间敏感 | ✔|  |\n| 临界区执行时间长 |  | ✔ |\n| 公平锁 |  | ✔ |\n| 非公平锁 | ✔ |  |\n| 读写锁 |  | ✔ |\n\n**4.4.2 特点二：使用灵活、学习成本低**\n\n下面是Cerberus的lock方法，这些方法和JUC的ReentrantLock的方式保持一致，使用非常灵活且不需要额外的学习时间。\n\n* void lock();\n\n获取锁，如果锁被占用，将禁用当前线程，并且在获得锁之前，该线程将一直处于阻塞状态。\n\n* boolean tryLock();\n\n仅在调用时锁为空闲状态才获取该锁。\n\n如果锁可用，则获取锁，并立即返回值 true。如果锁不可用，则此方法将立即返回值 false。\n\n* boolean tryLock(long time, TimeUnit unit) throws InterruptedException;\n\n如果锁在给定的等待时间内空闲，并且当前线程未被中断，则获取锁。\n\n如果在给定时间内锁可用，则获取锁，并立即返回值 true。如果在给定时间内锁一直不可用，则此方法将立即返回值false。\n\n* void lockInterruptibly() throws InterruptedException;\n\n获取锁，如果锁被占用，则一直等待直到线程被中断或者获取到锁。\n\n* void unlock();\n\n释放当前持有的锁。\n\n**4.4.3 特点三：支持一键降级**\n\nCerberus提供了实时切换引擎的接口:\n\n* String switchEngine()\n\n   转换分布式锁引擎，按配置的引擎的顺序循环转换。\n\n   返回值：返回当前的engine名字，如：\"zk\"。\n\n* String switchEngine(String engineName)\n\n   转换分布式锁引擎，切换为指定的引擎。\n\n   参数：engineName - 引擎的名字，同配置bean的名字，\"zk\"/\"tair\"。\n\n   返回值：返回当前的engine名字，如：\"zk\"。\n\n当使用方选择了两种引擎，平时分布式锁会工作在主引擎上。一旦所依赖的主引擎出现故障，那么使用方可以通过自动或者手动方式调用该切换引擎接口，平滑的将分布式锁切换到另一个引擎上以将风险降到最低。自动切换方式可以利用Hystrix实现。手动切换推荐的一个方案则是使用美团点评基于Zookeeper的基础组件MCC，通过监听MCC配置项更改，来达到手动将分布式系统所有主机同步切换引擎的目的。需要注意的是，切换引擎目前并不会迁移原引擎已有的锁。这样做的目的是出于必要性、系统复杂度和可靠性的综合考虑。在实际情况下，引擎故障到切换引擎，尤其是手动切换引擎的时间，要远大于分布式锁的存活时间。作为较轻量级的Cerberus来说，迁移锁会带来不必要的开销以及较高的系统复杂度。鉴于此，如果想要保证在引擎故障后的绝对可靠，那么则需要结合其他方案来进行处理。\n\n除此以外，Cerberus还提供了内置公用集群，免去搭建和配置集群的烦恼。Cerberus也有一套完善的应用授权机制，以此防止业务方未经评估使用，对集群造成影响。\n\n目前，Cerberus分布式锁已经持续迭代了8个版本，先后在美团点评多个项目中稳定运行。\n\n### 幂等性问题\n\n所谓幂等，简单地说，就是对接口的多次调用所产生的结果和调用一次是一致的。扩展一下，这里的接口，可以理解为对外发布的HTTP接口或者Thrift接口，也可以是接收消息的内部接口，甚至是一个内部方法或操作。\n\n那么我们为什么需要接口具有幂等性呢？设想一下以下情形：\n\n* 在App中下订单的时候，点击确认之后，没反应，就又点击了几次。在这种情况下，如果无法保证该接口的幂等性，那么将会出现重复下单问题。\n\n* 在接收消息的时候，消息推送重复。如果处理消息的接口无法保证幂等，那么重复消费消息产生的影响可能会非常大。\n\n在分布式环境中，网络环境更加复杂，因前端操作抖动、网络故障、消息重复、响应速度慢等原因，对接口的重复调用概率会比集中式环境下更大，尤其是重复消息在分布式环境中很难避免。Tyler Treat也在《You Cannot Have Exactly-Once Delivery》一文中提到：\n\n> Within the context of a distributed system, you cannot have exactly-once message delivery.\n\n分布式环境中，有些接口是天然保证幂等性的，如查询操作。有些对数据的修改是一个常量，并且无其他记录和操作，那也可以说是具有幂等性的。其他情况下，所有涉及对数据的修改、状态的变更就都有必要防止重复性操作的发生。通过间接的实现接口的幂等性来防止重复操作所带来的影响，成为了一种有效的解决方案。\n\n**GTIS**\n\nGTIS就是这样的一个解决方案。它是一个轻量的重复操作关卡系统，它能够确保在分布式环境中操作的唯一性。我们可以用它来间接保证每个操作的幂等性。它具有如下特点：\n\n* 高效：低延时，单个方法平均响应时间在2ms内，几乎不会对业务造成影响；\n\n* 可靠：提供降级策略，以应对外部存储引擎故障所造成的影响；提供应用鉴权，提供集群配置自定义，降低不同业务之间的干扰；\n\n* 简单：接入简捷方便，学习成本低。只需简单的配置，在代码中进行两个方法的调用即可完成所有的接入工作；\n\n* 灵活：提供多种接口参数、使用策略，以满足不同的业务需求。\n\n**实现原理**\n\n**基本原理**\n\nGTIS的实现思路是将每一个不同的业务操作赋予其唯一性。这个唯一性是通过对不同操作所对应的唯一的内容特性生成一个唯一的全局ID来实现的。基本原则为：相同的操作生成相同的全局ID；不同的操作生成不同的全局ID。\n\n生成的全局ID需要存储在外部存储引擎中，数据库、Redis亦或是Tair等等均可实现。考虑到Tair天生分布式和持久化的优势，目前的GTIS存储在Tair中。其相应的key和value如下：\n\n* key：将对于不同的业务，采用APP_KEY+业务操作内容特性生成一个唯一标识trans_contents。然后对唯一标识进行加密生成全局ID作为Key。\n\n* value：current_timestamp + trans_contents，current_timestamp用于标识当前的操作线程。\n\n判断是否重复，主要利用Tair的SETNX方法，如果原来没有值则set且返回成功，如果已经有值则返回失败。\n\n**内部流程**\n\nGTIS的内部实现流程为：\n\n* 业务方在业务操作之前，生成一个能够唯一标识该操作的transContents，传入GTIS；\n\n* GTIS根据传入的transContents，用MD5生成全局ID；\n\n* GTIS将全局ID作为key，current_timestamp+transContents作为value放入Tair进行setNx，将结果返回给业务方；\n\n* 业务方根据返回结果确定能否开始进行业务操作；\n\n* 若能，开始进行操作；若不能，则结束当前操作；\n\n* 业务方将操作结果和请求结果传入GTIS，系统进行一次请求结果的检验；\n\n* 若该次操作成功，GTIS根据key取出value值，跟传入的返回结果进行比对，如果两者相等，则将该全局ID的过期时间改为较长时间；\n\n* GTIS返回最终结果。\n\n**实现难点**\n\nGTIS的实现难点在于如何保证其判断重复的可靠性。由于分布式环境的复杂度和业务操作的不确定性，在上一章节分布式锁的实现中考虑的网络断开或主机宕机等等问题，同样需要在GTIS中设法解决。这里列出几个典型的场景：\n\n* 如果操作执行失败，理想的情况应该是另一个相同的操作可以立即进行。因此，需要对业务方的操作结果进行判断，如果操作失败，那么就需要立即删除该全局ID；\n\n* 如果操作超时或主机宕机，当前的操作无法告知GTIS操作是否成功。那么我们必须引入超时机制，一旦长时间获取不到业务方的操作反馈，那么也需要该全局ID失效；\n\n* 结合上两个场景，既然全局ID会失效并且可能会被删除，那就需要保证删除的不是另一个相同操作的全局ID。这就需要将特殊的标识记录下来，并由此来判断。这里所用的标识为当前时间戳。\n\n可以看到，解决这些问题的思路，也和上一章节中的实现有很多类似的地方。除此以外，还有更多的场景需要考虑和解决，所有分支流程如下:\n\n![](/assets/images/2016/09/29/distributed-system-mutually-exclusive-idempotence-cerberus-gtis/gtis_principle.jpg)\n\n**使用说明**\n\n使用时，业务方只需要在操作的前后调用GTIS的前置方法和后置方法，如下图所示。如果前置方法返回可进行操作，则说明此时无重复操作，可以进行。否则则直接结束操作。\n\n![](/assets/images/2016/09/29/distributed-system-mutually-exclusive-idempotence-cerberus-gtis/gtis_use.png)\n\n使用方需要考虑的主要是下面两个参数：\n\n* 空间全局性：业务方输入的能够标志操作唯一性的内容特性，可以是唯一性的String类型的ID，也可以是map、POJO等形式。如订单ID等\n\n* 时间全局性：确定在多长时间内不允许重复，1小时内还是一个月内亦或是永久。\n\n此外，GTIS还提供了不同的故障处理策略和重试机制，以此来降低外部存储引擎异常对系统造成的影响。\n\n目前，GTIS已经持续迭代了7个版本，距离第一个版本有近1年之久，先后在美团点评多个项目中稳定运行。\n\n**结语**\n\n在分布式环境中，操作互斥性问题和幂等性问题非常普遍。经过分析，我们找出了解决这两个问题的基本思路和实现原理，给出了具体的解决方案。\n\n针对操作互斥性问题，常见的做法便是通过分布式锁来处理对共享资源的抢占。分布式锁的实现，很大程度借鉴了多线程和多进程环境中的互斥锁的实现原理。只要满足一些存储方面的基本条件，并且能够解决如网络断开等异常情况，那么就可以实现一个分布式锁。目前已经有基于Zookeeper和Redis等存储引擎的比较典型的分布式锁实现。但是由于单存储引擎的局限，我们开发了基于ZooKeeper和Tair的多引擎分布式锁Cerberus，它具有使用灵活方便等诸多优点，还提供了完善的一键降级方案。\n\n针对操作幂等性问题，我们可以通过防止重复操作来间接的实现接口的幂等性。GTIS提供了一套可靠的解决方法：依赖于存储引擎，通过对不同操作所对应的唯一的内容特性生成一个唯一的全局ID来防止操作重复。\n\n目前Cerberus分布式锁、GTIS都已应用在生产环境并平稳运行。两者提供的解决方案已经能够解决大多数分布式环境中的操作互斥性和幂等性的问题。值得一提的是，分布式锁和GTIS都不是万能的，它们对外部存储系统的强依赖使得在环境不那么稳定的情况下，对可靠性会造成一定的影响。在并发量过高的情况下，如果不能很好的控制锁的粒度，那么使用分布式锁也是不太合适的。总的来说，分布式环境下的业务场景纷繁复杂，要解决互斥性和幂等性问题还需要结合当前系统架构、业务需求和未来演进综合考虑。Cerberus分布式锁和GTIS也会持续不断地迭代更新，提供更多的引擎选择、更高效可靠的实现方式、更简捷的接入流程，以期满足更复杂的使用场景和业务需求。\n\n---\n\n* 原文链接：[分布式系统互斥性与幂等性问题的分析与解决](http://tech.meituan.com/distributed-system-mutually-exclusive-idempotence-cerberus-gtis.html)\n","tags":["Idempotency"],"categories":["Distributed"]},{"title":"一篇好TM长的关于配置中心的文章","url":"%2F2016%2F2016-09-28-config-center%2F","content":"\n## 配置(Configuration)\n\n配置(Configuration) 这个概念每个技术人都不陌生，可以说一个不提供几个配置参数的系统都不好意思上线跟别的系统打招呼。那么为什么会是这个样子呢，究其本质是我们人类无法掌控和预知一切，映射到软件领域上，我们总是需要对系统的某些功能特性预留出一些控制的线头，以便我们在未来需要的时候，可以人为的拨弄这些线头从而控制系统的行为特征，我把它叫做 “_系统运行时(runtime)飞行姿态的动态调整_“。\n\n举个简单的例子：logLevel = INFO\n\n系统正常飞行的时候，我们希望其只输出INFO级别的日志信息，在生产环境中我们甚至希望只输出WARNING/ERROR级别的日志，系统出毛病了，再将日志输出动态的调整成包含诊断信息的DEBUG级别或者TRACE级别。\n\n![](/assets/images/2016/09/28/config-center/001.png)\n\n## 软件的老友 - 配置文件\n\n在那个单机即系统的时代，我们基本都是在用配置文件来存储配置项，一个配置项，就是如上面的logLevel那样的一个含有 = 表达式，如下:\n\n```\nconfig_key = config_value  // value1 or value2, you can choose one from the config_value set\n```\n\n一般来说`config_value`应该是一个有限空间的值集合，应该是有选择余地的，如果`config_value`没得选择，那么我只能认为这个配置项一定特么在逗我。而一个配置文件一般是一组配置项的集合或者叫配置集，一个系统根据逻辑模块划分，可以有1到多个配置文件。如下图 :\n\n![](/assets/images/2016/09/28/config-center/002.png)\n\n在集中式开发时代，配置文件基本足够用了，因为那时配置的管理通常不会成为一个很大的问题，简单一点来说，系统上了生产之后，如果需要修改一个配置，登录到这台生产机器上，vi修改这个配置文件，然后reload一下并不是什么很大的负担。\n\n如下图:\n\n![](/assets/images/2016/09/28/config-center/003.png)\n\n所以曾经的企业级应用架构标准J2EE里并没有制定关于配置管理这一块的任何标准。\n当然一些Follow J2EE标准的厂商，如以前Oracle的中间件WebLogic在实际实践时，因为很多大企业客户的环境也挺复杂的，所以WebLogic在这一块还是做了一些工作，其支持一个叫做Deployment Plan的特性，如下图:\n\n![](/assets/images/2016/09/28/config-center/004.png)\n\n其背后的本质就是开发人员(dev)打出来的应用war包里面的配置文件都是一些PlaceHolder, 在部署人员(ops)部署war包的时候，为目标环境提供与之匹配的的depoloy plan xml文件，WebLogic Server本身在deploy这个stage将war包配置项的placeholder值替换成plan里面的值。\n\n## 分布式系统给系统配置管理带来的挑战\n\n关于什么是分布式系统，本文不再赘述，毫无疑问今天阿里的系统就是一个大型的、服务化的、复杂的、分布式系统实现之一。在这个领域有3本书值得反复阅读&lt;&lt;分布式系统概念与设计&gt;&gt; &lt;&lt;分布式系统原理与泛型&gt;&gt; 以及 Distributed Systems For System Architects，有意思的是这三本书只有最后一本在21.3小节简单的提了一下 Configuration Of Distributed Systems，里面简单的说了一下静态配置和动态配置的概念和区别 “…System configuration may be static or dynamic…”. 这说明什么? 这说明我们阿里技术人包括我们中间件今天面临的很多问题和领域已经进入深水区，已经没有人会直接给你提供这个领域清晰的解决方案，我们自己正站在前沿，而我们的成功的或者失败的探索，其经验和成果都应该总结并分享给整个业界。\n\n在过去的大约15年左右，软件工程学在如何持续演进软件以适应一直要变的需求的方法论上有了很多的突破和大量的实践，在这个领域，从面向对象设计方法论，到极限编程，到敏捷开发、持续集成、单元测试等等，理论和实践都已经比较成熟了，关键是配合这一套方法论的配套的工具和软件集都变得非常的成熟。\n\n这里面的一个非常有意思的东西是关于系统的演进或者进化论(Software Evolution),一个系统或者说软件从被创造出来之后会经历研发、测试、到最后的go live，上了生产系统。那么这个之后，如何持续并且无痛的为其添加新行为或者调整已有行为的表现特征? 这确实非常复杂，尤其是要达到无痛的这个目标，毕竟线上系统，调整即意味着可能出故障。系统的动态配置管理毫无疑问是其中的一个小部分，如果每一个系统行为的任何一个微调都需要将整个系统停机，重启或者甚至重新构建、发布部署来实现，那要达到无痛这个目标恐怕难度更高。\n\n在分布式系统中，一次构建、发布、上线是非常非常重的一个过程，它不像单机时代那样重启一台机器、一个进程就可以了，在分布式系统中，它涉及到将软件包(例如war)分发到可能超过几千台机器，然后将几千台机器上的应用进程一一重启这么一个过程，超过2000台机器的一个应用一次完整的发布过程需要多长时间，相信很多核心系统的小二都深有体会。\n\n那么如何在不停应用集群的情况下，调整整个集群的运行时的行为特征（即系统运行时的飞行姿态），是一个分布式系统必须回答的一个问题。从这个角度讲, 我们认为:\n\n![](/assets/images/2016/09/28/config-center/005.png)\n\n现在我们很容易理解，其实我们平时常见的分布式系统的配置变更，诸如:\n\n*   线程池、连接池大小\n*   开关、预案、限流配置\n*   toggleFeature\n*   数据源主备容灾切换\n*   路由规则\n*   我是等等等等\n\n背后的本质都是在做分布式系统运行时行为特征（飞行姿态）的调整。\n\n## 每一个分布式系统都应该有一个动态配置管理系统\n\n是的，你一定注意到了，这里的说法跟图片上的有点不一样，这里想强调的是，未必都需要配置中心，在一个分布式系统规模还较小时，比如一个公司就二个应用集群，那无论你是用配置文件+auto-reload还是用redis，zookeeper什么都可以，这个动态配置管理系统不一定要是一个独立存在的，可以跟其它的系统，例如注册中心，甚至作为消息中间件的一个子系统都没有关系。但是重要的是知道一定要有这么一个东西，它给自己的系统提供了动态调整行为的能力，而配置管理系统基本固有的特性一定要实现。\n\n## 动态配置和静态配置的区别\n\n曾经我也傻傻分不清楚其区别是啥，这很正常。动态和静态这是一个相对的概念，海枯石烂，永远不变的那不叫配置，可能是撩妹的鬼话,即使这个配置可能是放在一个看起来很像配置文件的文本里，配置一定是可能修改其值的，而是否是动态配置主要是看这个配置是不是跟应用的版本构建发布(build-deploy lifetime)强绑定的。如果一个配置项，跟软件的版本构建是不耦合的，在应用进程运行时，可能需要变更配置值的就是动态配置，哪怕是变更频率可能非常低，也许你设计了一个配置项，发现最后下来3年也没变更过一次，那也是动态配置，相反，配置变更只发生在软件版本构建和发布的那个点，那么就是静态配置，哪怕你构建很频繁，1个小时就来一回，那也是个静态配置，举个简单的例子:\n\n```\nbuild-version = 3.4.6-1569965\n```\n\n这个配置项，永远只在某个软件版本被构建出来时会变更其值，一旦这个版本被构建出来，并且在程序运行时，是一定没有变更诉求的，这就是一个跟构建绑定的静态配置。而文章开始时举得logLevel的例子，则是一个动态配置的例子。\n\n所以看一下你的系统的配置项，你会发现动态配置其实更多，而跟行为演进相关的几乎都是动态配置。\n\n## 为什么是淘宝\n\n我在进来阿里做Diamond之后，思考过一个有意思的事情，为什么独立的配置中心这个东西会首先出现在淘宝? 你去国内著名的竞价排名搜索引擎百度上搜”配置中心”，你会发现信息不是特别多，但是排在前面的都是XDiamond, SuperDiamond这种Diamond一族, 反正我们没有为让配置中心跟Diamond这个名字关联给百度付过1毛钱，所以这个搜索结果应该是个自然结果，侧面也反应了在国内说起配置中心在生产上大规模运用是独此一家，别无分号。\n\n而在业界，如下图，Spring Boot/Cloud微服务将注册中心(discovery service)和配置中心(configuration service)提出来还处在布道阶段,\n\n![](/assets/images/2016/09/28/config-center/006.png)\n\n而且从Spring的实现方式的技术局限性来看，应该是还没有哪个公司基于这个配置中心的方案在生产上实际支持大规模分布式系统，毕竟，翻遍所有blog和文章，还没有哪个老外开始提到，这个基于git的方案应该怎么去做多数据中心以及容灾相关的非功能性需求。\n\n回到那个问题，为什么是淘宝，我们都知道在国内业界淘宝率先开启了去IOE,全面采用MYSQL，在这个过程中，在国内，大规模的系统性的解决分库分表这个命题的毫无疑问是阿里以及阿里中间件，在这个过程中，诞生了业内著名的TDDL.而与TDDL关联的一个核心问题是，分库分表之后，这多个库的数据源的配置信息存放在哪里，并对应用屏蔽多库这个事实? 好吧后面的事情也许你知道了，放在配置中心里! 但还是要提的是曾经并没有Diamond, 都在注册中心（ConfigServer）里，后来Diamond从ConfigServer分了出来，这个过程，很多人看到的是数据是持久化和非持久化的区别以及当时产品的稳定性方面的考量，直到今天也还是如此，但是，通过这么多年实践和演进下来，才恍然大悟，拆分的背后其实是服务发现(Service Discovery)和动态配置管理服务(Dynamic Configuration Management)根本就是两个不同的东西，而在当时可能仅是一种直觉。\n\n## 莫道君行早，更有早行人\n\n有时候我们会因为在某个领域我们走的早一点而产生一点点的”优越感”和“虚荣感”, 曾经我们以为Dynamic Configuration For Distributed System这个领域的实践我们不能说在业界独占鳌头，但是绝对位居前列。但是下面这两个老哥再次提醒我们，技术人踏实前行，不要有不必要的想法:\n\n![](/assets/images/2016/09/28/config-center/007.png)\n\n这两位老哥在1985年4月，在IEEE TRANSACTIONS ON SOFTWARE ENGINEERING 上发表了一篇名为 Dynamic Configuration for Distributed Systems的论文(Paper)，奶奶的，1985年！！什么概念，当时我4岁，还在玩泥巴,穿开裆裤。而Diamond现在的主力技术架构研发同学都还没出生呢！！我们能做的,只能是向这两位前辈再次致敬！\n\n在这篇论文中，虽然从现在的观点来看，当时人们对分布式系统的认识跟现在有很大的区别，但是其中的问题识别的非常的准确:\n\n“….Dynamic systemc onfiguration is the ability to modify and extend a system while it is running. The facility is a requirement in large distributed systems where it may not be possible or economic to stop the entire system to allow modification to part of its hardware or software. It is also useful during production of the system to aid incremental integration of component parts, and during operation to aid system evolution.The paper introduces a model of the configuration process which permits dynamic incremental modification and extension. Using this model we determine the properties required by languages and their execution environments to support dynamic configuration…”\n\n并且很清晰的区分了静态配置和动态配置的基本模型:\n\n![](/assets/images/2016/09/28/config-center/008.png)\n\n## 配置与环境\n\n另一个值得从技术上玩味的是关于“配置”的“环境”属性，这个表达可能有点抽象，比较难理解，这有点像技术上常提的一个叫Context的概念，很多Component会关联一个Context，Component+Context才是一个完整的运行时故事。环境恰恰也是热帖中大家可能会产生的疑问之一，为何Diamond会暴露这么多的环境让应用去选择? 而进一步对中间件更熟稔一点的人会问，在单元化场景中，为何注册中心是一个大集群模式，而配置中心又是一个小集群模式?\n\n另一方面，多个环境恰恰也是加重分布式系统需要依赖一个独立的配置管理系统的要素之一，可以说哪个公司的环境越复杂，分布式应用和服务越多，哪个公司诞生出独立的配置中心系统的可能性也就越大。\n\n举几个容易理解的表述，来帮助理解配置的环境属性，\n\n> “在开发环境中将logLevel设置为DEBUG,在预发环境logLevel设置为INFO,生产环境里logLevel设置为WARNING”\n> \n> “在日常环境执行线程池的最大线程数应该设置为15，而生产环境上这个值应该大一点，默认设为150”\n> \n> “在线上环境中，中心机房，应用数据源需要连接A库，而S机房，应用应该就近连接使用B库”\n> \n> “只有在T环境，双向同步开关才应该关闭”\n> \n> “这次的改动有点大，新的特性仅在线上的H单元把该特性开放出来，其它的单元环境先不要开放出来”\n\n是的，相信你一定发现了，我们的某个配置项，其具体的值域的定义往往跟具体的环境相关联，现实中相当一部分配置在不同的环境必须设定不同的值，但是也有相当的另一部分配置在不同的环境要设定为完全一致的值。所以从某个应用的视角看，其100个配置项，可能有50个是每个环境要不同的值的，而另50个是不区分环境，所有环境其配置值都是需要完全一致的。这种异化给配置管理系统的设计带来了复杂性，而且这个最终语义的解释，很显然不应该在配置中心系统本身，应该交给应用，配置管理系统应该做的是提供方便的交互方式保证这两种不同的一致性诉求同时得到很好的满足，这种诉求分为3个方面，如下示意图:\n\n是的，相信你一定发现了，我们的某个配置项，其具体的值域的定义往往跟具体的环境相关联，现实中相当一部分配置在不同的环境必须设定不同的值，但是也有相当的另一部分配置在不同的环境要设定为完全一致的值。所以从某个应用的视角看，其100个配置项，可能有50个是每个环境要不同的值的，而另50个是不区分环境，所有环境其配置值都是需要完全一致的。这种异化给配置管理系统的设计带来了复杂性，而且这个最终语义的解释，很显然不应该在配置中心系统本身，应该交给应用，配置管理系统应该做的是提供方便的交互方式保证这两种不同的一致性诉求同时得到很好的满足，这种诉求分为3个方面，如下示意图:\n\n![](/assets/images/2016/09/28/config-center/009.png)\n\nDiamond 这三个能力都有提供，其中1，2一般都是在配置中心的提供的客户端类库和OPS中体现。其中3这个实现是比较困难的，因为多个环境之间一般来说，都是有一些诸如远距离网络或者网络隔离之类的物理约束的，要做分布式一致性以及诸如分区容忍性之类的考量，目前Diamond只支持线上多单元一致性约束规则，但是因为历史原因大家没有真正用起来，规则本身的抽象度也不够好，不够通用。现在我们正在做改造，未来会将一致性规则做的更通用，后面会引导大家用起来，这样对于那些多环境保持一致的那些配置项，环境复杂性就可以对应用屏蔽掉，如果一个应用的配置项全是要各环境一致的，那么你就有福了，天空飘来五个字，”这么多环境就不是个事”。\n\n另外，一个配置中心也应该具备的能力是配置集的导出\\导入功能，可以让应用将A环境中的配置集方便的导出和导入到环境B中的能力，这对3个场景都有重大意义，一个场景是线上的配置值是经过实践验证的，现在在日常或者预发新建了应用环境，希望将线上的配置copy到线下用起来，第二个是，线下的应用终于调通要发预发或线上了，调较好的配置希望一下子发到线上去，当然这个根据我们的经验，一定要慎重，第三个是新建站或者机房，应用需要在新的机房将所有配置迁移过去，Diamond很快就会将这种能力开放出来。\n\n![](/assets/images/2016/09/28/config-center/010.png)\n\n理解了上面讲的这些，相信你就更能理解Spring Framework 里的两把刷子(抽象） Environment 和 PropertySource 是咋回事了, 详细参见:\n\nSpring 3.1 M1: Unified Property Management\n\n[https://spring.io/blog/2011/02/15/spring-3-1-m1-unified-property-management/](https://spring.io/blog/2011/02/15/spring-3-1-m1-unified-property-management/)\n\n## 配置的三个属性\n\n* 环境属性\n* 稀疏变更属性\n* 快速传播\n\n环境属性我们上文已经讨论过。\n\n稀疏变更讲的是配置的变更基本上都是稀疏的，因为系统的行为不可能非常频繁的需要动态调整，你每100毫秒调整一次系统的行为，估计系统要对你骂娘了。\n\n而快速传播讲的是配置不变则已，一变往往要求目标集群的所有节点要几乎同时收到变更，然后几乎整齐划一的统一调整行为。切库的场景来讲，主备切换之后，应用集群写新的主库这个行为切换的稀稀拉拉，整个收敛了一天，应用肯定是受不了的，而这个属性决定了对配置中心对配置变更推送SLA的高要求。\n\n## 配置中心(Diamond)和注册中心(ConfigServer)的不同\n\n在我们的眼里，用土话讲，这就是乌龟与王八的区别，想用拜金一点的话讲，这就是金条和钻石的区别，说的洋气一点这叫Apple and Pear，但是当初起的名字的给我们带来了大麻烦，现在我们的服务注册中心现在叫Config Server, 你说坑不坑。不过很多中间件产品的名字同时承载了一段8年的历史，这名字也体现中间件持续做技术产品，坚持就是一种力量的信念在里面，n代人持续发展一个产品，说实话，只管生不管养的现象在中间件不能说没有，但确实是很少的。1个8年的产品就像八岁的孩子，已经上小学了，硬要给它改个名字，从朱屎山改成朱宝山，他的同学认不认还要打个非常大的问号，而且还要跑到派出所重新上户口，也是个麻烦事。\n\n所以产品的取名字有大学问和大恐怖，大家取名之前一定要找算命先生给好好算一算，本来我在成为码农之前那也是仙风道骨，江湖人送外号郭半仙，那时候可以钉钉发个红包找我算一下。但成为码农之后嘛，就特么不说了，说起来全是泪，以前get到的很多技能点全丢了，现在就瞅着电脑和代码最顺眼。\n\n2者具体的不同，参见未来会写的&lt;&lt;应用配置中心和服务注册中心究竟有什么不一样?&gt;&gt;\n\n## 关于配置，业界最新动态\n\n业界著名的专职配置中心产品几乎没有（Diamond傲娇ing~）, 基本都是在用git, redis, zookeeper, consul 这些凑活着搞一下，所以要了解配置中心的同学，直接了解Diamond就可以了。:-)\n\n但是针对于配置管理的客户端编程类库这一块有一些类库牛吹得是很大的，感兴趣的同学可以了解一下:\n\n* Apache Commons Configuration （[https://commons.apache.org/proper/commons-configuration/](https://commons.apache.org/proper/commons-configuration/)）\n\n这个类库是在是太繁琐了，用起来总感觉有点杀鸡用牛刀，力用的太大的感觉。\n\n* owner （[http://owner.aeonbits.org/](http://owner.aeonbits.org/)）\n\n简单易上手，特性看起来很多，但是在很多关键常用的特性反倒是没有。\n\n* cfg4j ([http://www.cfg4j.org/](http://www.cfg4j.org/))\n\n简单易上手，cfg4j 支持跟多种后端集成，做配置中心的解决方案，api设计也非常的不错，我们正在设计的新diamond annotation api的时候借鉴了不少其想法。\n\n* Spring Framework ([http://docs.spring.io/spring/docs/current/spring-framework-reference/htmlsingle/#__propertysource](http://docs.spring.io/spring/docs/current/spring-framework-reference/htmlsingle/#__propertysource))\n\nSpring的东西一般都还是很不错的，如果你的应用本身在用Spring，毫无疑问，就这个了，用上面的那些类库实在没有必要。\n\n* Spring Cloud Config Server\n\n![](/assets/images/2016/09/28/config-center/011.png)\n\n如果你仔细读一下其内容，而你又了解Diamond的话，你会发现这就是Diamond这些年在解决的问题啊，Spring 终于从大量配置文件逐渐走向了配置中心（externalized configuration in a distributed system），而这一次我们走在了前面。\n\n看看owner 的宣传，\n\n![](/assets/images/2016/09/28/config-center/012.png)\n\nJava 他妈 properties reinvented！ Java Properties的重新发明！ 屌不屌?! 我僧僧的觉得，我们中国码农有时候就是差了这种提炼和升华的能力，刚入行时觉得维护和修改前人留下的烂代码实在是个很苦逼，很Low的事情，但是Martin Fowler把这叫做”重构”，然后还写了一本书，然后我们读了之后，居然还觉得他妈的，讲的真的非常的有道理！把改烂代码变成叫重构之后，有了理论指导，突然觉得这真是个高逼格的事情！\n\n## 配置(configuration)与元数据(metadata)\n\n很多人没有这种这两个概念的区分，但是对于配置中心，二者其实是有微妙的差别的.\n\n配置如前文有阐述，配置的修改基本上都是由人来驱动，并且在ops上实现变更。\n\n![](/assets/images/2016/09/28/config-center/013.png)\n\n而元数据的本质是一小段程序元数据，它很多时候是程序产生，程序消费，由程序通过调用Diamond的客户端api来实现变更，中间不会有ops 或者人的介入。\n\n![](/assets/images/2016/09/28/config-center/014.png)\n\n知道这个有什么意义？毫无疑问，配置这种需求选型比较明确，而元数据这种，可以选的pub-sub系统太多了，诸如消息队列产品，分布式coordinator产品如zookeeper, 带pub-sub 能力的k-v store 如Redis等等都可以，所以如果是元数据这种，选什么需要慎重，其间运用之妙，存乎一心，要充分评估和把握自己的需求。\n\nDiamond 不光是应用配置存储，其目前存储的数据，很大一部分是metadata，所以Diamond 其实也是一个元数据存储中心。\n\n## 结束语\n\n这么长的文章，你居然能坚持看到这里，说明你是真正的、脱离了低级趣味的，纯粹的码农，猿类中的精英！配置中心，它没有高精尖的技术，难懂的算法，海量的数据，做这个东西只需要一个精神就够了。\n\n![](/assets/images/2016/09/28/config-center/015.png)\n\nowner之前一直在搞配置文件的支持，现在owner也开始转型搞跟zookeeper集成之类的，做配置中心的解决方案了，所以本文开头说业界正在走向配置中心解决方案不是在忽悠，是确实是这个趋势。\n\n---\n\n* 原文链接：[一篇好TM长的关于配置中心的文章](http://jm.taobao.org/2016/09/28/an-article-about-config-center/)\n","tags":["Diamond"],"categories":["Configuration"]},{"title":"The Neural Network Zoo","url":"%2F2016%2F2016-09-14-neural-network-zoo%2F","content":"\nWith new neural network architectures popping up every now and then, it&#8217;s hard to keep track of them all. Knowing all the abbreviations being thrown around (DCIGN, BiLSTM, DCGAN, anyone?) can be a bit overwhelming at first.\n\nSo I decided to compose a cheat sheet containing many of those architectures. Most of these are neural networks, some are completely different beasts. Though all of these architectures are presented as novel and unique, when I drew the node structures&#8230; their underlying relations started to make more sense.\n\n![neuralnetworks](/assets/images/2016/09/14/neural-network-zoo/neuralnetworks.png)\n\nOne problem with drawing them as node maps: it doesn&#8217;t really show how they&#8217;re used. For example, variational autoencoders (VAE) may look just like autoencoders (AE), but the training process is actually quite different. The use-cases for trained networks differ even more, because VAEs are generators, where you insert noise to get a new sample. AEs, simply map whatever they get as input to the closest training sample they &#8220;remember&#8221;. I should add that this overview is in no way clarifying how each of the different node types work internally (but that&#8217;s a topic for another day).\n\nIt should be noted that while most of the abbreviations used are generally accepted, not all of them are. RNNs sometimes refer to recursive neural networks, but most of the time they refer to recurrent neural networks. That&#8217;s not the end of it though, in many places you&#8217;ll find RNN used as placeholder for any recurrent architecture, including LSTMs, GRUs and even the bidirectional variants. AEs suffer from a similar problem from time to time, where VAEs and DAEs and the like are called simply AEs. Many abbreviations also vary in the amount of &#8220;N&#8221;s to add at the end, because you could call it a convolutional neural network but also simply a convolutional network (resulting in CNN or CN).\n\nComposing a complete list is practically impossible, as new architectures are invented all the time. Even if published it can still be quite challenging to find them even if you&#8217;re looking for them, or sometimes you just overlook some. So while this list may provide you with some insights into the world of AI, please, by no means take this list for being comprehensive; especially if you read this post long after it was written.\n\nFor each of the architectures depicted in the picture, I wrote a _very, very_ brief description. You may find some of these to be useful if you&#8217;re quite familiar with some architectures, but you aren&#8217;t familiar with a particular one.\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/ff.png)\n\n**Feed forward neural networks (FF or FFNN) and perceptrons (P)** are very straight forward, they feed information from the front to the back (input and output, respectively). Neural networks are often described as having layers, where each layer consists of either input, hidden or output cells in parallel. A layer alone never has connections and in general two adjacent layers are fully connected (every neuron form one layer to every neuron to another layer). The simplest somewhat practical network has two input cells and one output cell, which can be used to model logic gates. One usually trains FFNNs through back-propagation, giving the network paired datasets of &#8220;what goes in&#8221; and &#8220;what we want to have coming out&#8221;. This is called supervised learning, as opposed to unsupervised learning where we only give it input and let the network fill in the blanks. The error being back-propagated is often some variation of the difference between the input and the output (like MSE or just the linear difference). Given that the network has enough hidden neurons, it can theoretically always model the relationship between the input and output. Practically their use is a lot more limited but they are popularly combined with other networks to form new networks.\n\n_Rosenblatt, Frank. &#8220;The perceptron: a probabilistic model for information storage and organization in the brain.&#8221; Psychological review 65.6 (1958): 386._\n\n[Original Paper PDF](http://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/rbf.png)\n\n**Radial basis function (RBF)** networks are FFNNs with radial basis functions as activation functions. There&#8217;s nothing more to it. Doesn&#8217;t mean they don&#8217;t have their uses, but most FFNNs with other activation functions don&#8217;t get their own name. This mostly has to do with inventing them at the right time.\n\n_Broomhead, David S., and David Lowe. Radial basis functions, multi-variable functional interpolation and adaptive networks. No. RSRE-MEMO-4148. ROYAL SIGNALS AND RADAR ESTABLISHMENT MALVERN (UNITED KINGDOM), 1988._\n\n[Original Paper PDF](http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA196234)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/hn.png)\n\nA **Hopfield network (HN)** is a network where every neuron is connected to every other neuron; it is a completely entangled plate of spaghetti as even all the nodes function as everything. Each node is input before training, then hidden during training and output afterwards. The networks are trained by setting the value of the neurons to the desired pattern after which the weights can be computed. The weights do not change after this. Once trained for one or more patterns, the network will always converge to one of the learned patterns because the network is only stable in those states. Note that it does not always conform to the desired state (it&#8217;s not a magic black box sadly). It stabilises in part due to the total &#8220;energy&#8221; or &#8220;temperature&#8221; of the network being reduced incrementally during training. Each neuron has an activation threshold which scales to this temperature, which if surpassed by summing the input causes the neuron to take the form of one of two states (usually -1 or 1, sometimes 0 or 1). Updating the network can be done synchronously or more commonly one by one. If updated one by one, a fair random sequence is created to organise which cells update in what order (fair random being all options (n) occurring exactly once every n items). This is so you can tell when the network is stable (done converging), once every cell has been updated and none of them changed, the network is stable (annealed). These networks are often called associative memory because the converge to the most similar state as the input; if humans see half a table we can image the other half, this network will converge to a table if presented with half noise and half a table.\n\n_Hopfield, John J. &#8220;Neural networks and physical systems with emergent collective computational abilities.&#8221; Proceedings of the national academy of sciences 79.8 (1982): 2554-2558._\n\n[Original Paper PDF](https://bi.snu.ac.kr/Courses/g-ai09-2/hopfield82.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/mc.png)\n\n**Markov chains (MC or discrete time Markov Chain, DTMC)** are kind of the predecessors to BMs and HNs. They can be understood as follows: from this node where I am now, what are the odds of me going to any of my neighbouring nodes? They are memoryless (i.e. Markov Property) which means that every state you end up in depends completely on the previous state. While not really a neural network, they do resemble neural networks and form the theoretical basis for BMs and HNs. MC aren&#8217;t always considered neural networks, as goes for BMs, RBMs and HNs. Markov chains aren&#8217;t always fully connected either.\n\n_Hayes, Brian. &#8220;First links in the Markov chain.&#8221; American Scientist 101.2 (2013): 252._\n\n[Original Paper PDF](http://www.americanscientist.org/libraries/documents/201321152149545-2013-03Hayes.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/bm.png)\n\n**Boltzmann machines (BM)** are a lot like HNs, but: some neurons are marked as input neurons and others remain &#8220;hidden&#8221;. The input neurons become output neurons at the end of a full network update. It starts with random weights and learns through back-propagation, or more recently through contrastive divergence (a Markov chain is used to determine the gradients between two informational gains). Compared to a HN, the neurons mostly have binary activation patterns. As hinted by being trained by MCs, BMs are stochastic networks. The training and running process of a BM is fairly similar to a HN: one sets the input neurons to certain clamped values after which the network is set free (it doesn&#8217;t get a sock). While free the cells can get any value and we repetitively go back and forth between the input and hidden neurons. The activation is controlled by a global temperature value, which if lowered lowers the energy of the cells. This lower energy causes their activation patterns to stabilise. The network reaches an equilibrium given the right temperature.\n\n_Hinton, Geoffrey E., and Terrence J. Sejnowski. &#8220;Learning and releaming in Boltzmann machines.&#8221; Parallel distributed processing: Explorations in the microstructure of cognition 1 (1986): 282-317._\n\n[Original Paper PDF](https://www.researchgate.net/profile/Terrence_Sejnowski/publication/242509302_Learning_and_relearning_in_Boltzmann_machines/links/54a4b00f0cf256bf8bb327cc.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/rbm.png)\n\n**Restricted Boltzmann machines (RBM)** are remarkably similar to BMs (surprise) and therefore also similar to HNs. The biggest difference between BMs and RBMs is that RBMs are a better usable because they are more restricted. They don&#8217;t trigger-happily connect every neuron to every other neuron but only connect every different group of neurons to every other group, so no input neurons are directly connected to other input neurons and no hidden to hidden connections are made either. RBMs can be trained like FFNNs with a twist: instead of passing data forward and then back-propagating, you forward pass the data and then backward pass the data (back to the first layer). After that you train with forward-and-back-propagation.\n\n_Smolensky, Paul. Information processing in dynamical systems: Foundations of harmony theory. No. CU-CS-321-86. COLORADO UNIV AT BOULDER DEPT OF COMPUTER SCIENCE, 1986._\n\n[Original Paper PDF](http://www.dtic.mil/cgi-bin/GetTRDoc?Location=U2&#038;doc=GetTRDoc.pdf&#038;AD=ADA620727)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/ae.png)\n\n**Autoencoders (AE)** are somewhat similar to FFNNs as AEs are more like a different use of FFNNs than a fundamentally different architecture. The basic idea behind autoencoders is to encode information (as in compress, not encrypt) automatically, hence the name. The entire network always resembles an hourglass like shape, with smaller hidden layers than the input and output layers. AEs are also always symmetrical around the middle layer(s) (one or two depending on an even or odd amount of layers). The smallest layer(s) is|are almost always in the middle, the place where the information is most compressed (the chokepoint of the network). Everything up to the middle is called the encoding part, everything after the middle the decoding and the middle (surprise) the code. One can train them using backpropagation by feeding input and setting the error to be the difference between the input and what came out. AEs can be built symmetrically when it comes to weights as well, so the encoding weights are the same as the decoding weights.\n\n_Bourlard, Hervé, and Yves Kamp. &#8220;Auto-association by multilayer perceptrons and singular value decomposition.&#8221; Biological cybernetics 59.4-5 (1988): 291-294._\n\n[Original Paper PDF](https://pdfs.semanticscholar.org/f582/1548720901c89b3b7481f7500d7cd64e99bd.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/sae.png)\n\n**Sparse autoencoders (SAE)** are in a way the opposite of AEs. Instead of teaching a network to represent a bunch of information in less &#8220;space&#8221; or nodes, we try to encode information in more space. So instead of the network converging in the middle and then expanding back to the input size, we blow up the middle. These types of networks can be used to extract many small features from a dataset. If one were to train a SAE the same way as an AE, you would in almost all cases end up with a pretty useless identity network (as in what comes in is what comes out, without any transformation or decomposition). To prevent this, instead of feeding back the input, we feed back the input plus a sparsity driver. This sparsity driver can take the form of a threshold filter, where only a certain error is passed back and trained, the other error will be &#8220;irrelevant&#8221; for that pass and set to zero. In a way this resembles spiking neural networks, where not all neurons fire all the time (and points are scored for biological plausibility).\n\n_Marc’Aurelio Ranzato, Christopher Poultney, Sumit Chopra, and Yann LeCun. &#8220;Efficient learning of sparse representations with an energy-based model.&#8221; Proceedings of NIPS. 2007._\n\n[Original Paper PDF](https://papers.nips.cc/paper/3112-efficient-learning-of-sparse-representations-with-an-energy-based-model.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/vae.png)\n\n**Variational autoencoders (VAE)** have the same architecture as AEs but are &#8220;taught&#8221; something else: an approximated probability distribution of the input samples. It&#8217;s a bit back to the roots as they are bit more closely related to BMs and RBMs. They do however rely on Bayesian mathematics regarding probabilistic inference and independence, as well as a re-parametrisation trick to achieve this different representation. The inference and independence parts make sense intuitively, but they rely on somewhat complex mathematics. The basics come down to this: take influence into account. If one thing happens in one place and something else happens somewhere else, they are not necessarily related. If they are not related, then the error propagation should consider that. This is a useful approach because neural networks are large graphs (in a way), so it helps if you can rule out influence from some nodes to other nodes as you dive into deeper layers.\n\n_Kingma, Diederik P., and Max Welling. &#8220;Auto-encoding variational bayes.&#8221; arXiv preprint arXiv:1312.6114 (2013)._\n\n[Original Paper PDF](https://arxiv.org/pdf/1312.6114v10.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/dae.png)\n\n**Denoising autoencoders (DAE)** are AEs where we don&#8217;t feed just the input data, but we feed the input data with noise (like making an image more grainy). We compute the error the same way though, so the output of the network is compared to the original input without noise. This encourages the network not to learn details but broader features, as learning smaller features often turns out to be &#8220;wrong&#8221; due to it constantly changing with noise.\n\n_Vincent, Pascal, et al. &#8220;Extracting and composing robust features with denoising autoencoders.&#8221; Proceedings of the 25th international conference on Machine learning. ACM, 2008._\n\n[Original Paper PDF](http://machinelearning.org/archive/icml2008/papers/592.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/dbn.png)\n\n**Deep belief networks (DBN)** is the name given to stacked architectures of mostly RBMs or VAEs. These networks have been shown to be effectively trainable stack by stack, where each AE or RBM only has to learn to encode the previous network. This technique is also known as greedy training, where greedy means making locally optimal solutions to get to a decent but possibly not optimal answer. DBNs can be trained through contrastive divergence or back-propagation and learn to represent the data as a probabilistic model, just like regular RBMs or VAEs. Once trained or converged to a (more) stable state through unsupervised learning, the model can be used to generate new data. If trained with contrastive divergence, it can even classify existing data because the neurons have been taught to look for different features.\n\n_Bengio, Yoshua, et al. &#8220;Greedy layer-wise training of deep networks.&#8221; Advances in neural information processing systems 19 (2007): 153._\n\n[Original Paper PDF](https://papers.nips.cc/paper/3048-greedy-layer-wise-training-of-deep-networks.pdf\n)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/cnn.png)\n\n**Convolutional neural networks (CNN or deep convolutional neural networks, DCNN)** are quite different from most other networks. They are primarily used for image processing but can also be used for other types of input such as as audio. A typical use case for CNNs is where you feed the network images and the network classifies the data, e.g. it outputs &#8220;cat&#8221; if you give it a cat picture and &#8220;dog&#8221; when you give it a dog picture. CNNs tend to start with an input &#8220;scanner&#8221; which is not intended to parse all the training data at once. For example, to input an image of 200 x 200 pixels, you wouldn&#8217;t want a layer with 40 000 nodes. Rather, you create a scanning input layer of say 20 x 20 which you feed the first 20 x 20 pixels of the image (usually starting in the upper left corner). Once you passed that input (and possibly use it for training) you feed it the next 20 x 20 pixels: you move the scanner one pixel to the right. Note that one wouldn&#8217;t move the input 20 pixels (or whatever scanner width) over, you&#8217;re not dissecting the image into blocks of 20 x 20, but rather you&#8217;re crawling over it. This input data is then fed through convolutional layers instead of normal layers, where not all nodes are connected to all nodes. Each node only concerns itself with close neighbouring cells (how close depends on the implementation, but usually not more than a few). These convolutional layers also tend to shrink as they become deeper, mostly by easily divisible factors of the input (so 20 would probably go to a layer of 10 followed by a layer of 5). Powers of two are very commonly used here, as they can be divided cleanly and completely by definition: 32, 16, 8, 4, 2, 1. Besides these convolutional layers, they also often feature pooling layers. Pooling is a way to filter out details: a commonly found pooling technique is max pooling, where we take say 2 x 2 pixels and pass on the pixel with the most amount of red. To apply CNNs for audio, you basically feed the input audio waves and inch over the length of the clip, segment by segment. Real world implementations of CNNs often glue an FFNN to the end to further process the data, which allows for highly non-linear abstractions. These networks are called DCNNs but the names and abbreviations between these two are often used interchangeably.\n\n_LeCun, Yann, et al. &#8220;Gradient-based learning applied to document recognition.&#8221; Proceedings of the IEEE 86.11 (1998): 2278-2324._\n\n[Original Paper PDF](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/dn.png)\n\n**Deconvolutional networks (DN)**, also called inverse graphics networks (IGNs), are reversed convolutional neural networks. Imagine feeding a network the word &#8220;cat&#8221; and training it to produce cat-like pictures, by comparing what it generates to real pictures of cats. DNNs can be combined with FFNNs just like regular CNNs, but this is about the point where the line is drawn with coming up with new abbreviations. They may be referenced as deep deconvolutional neural networks, but you could argue that when you stick FFNNs to the back and the front of DNNs that you have yet another architecture which deserves a new name. Note that in most applications one wouldn&#8217;t actually feed text-like input to the network, more likely a binary classification input vector. Think &lt;0, 1&gt; being cat, &lt;1, 0&gt; being dog and &lt;1, 1&gt; being cat and dog. The pooling layers commonly found in CNNs are often replaced with similar inverse operations, mainly interpolation and extrapolation with biased assumptions (if a pooling layer uses max pooling, you can invent exclusively lower new data when reversing it).\n\n_Zeiler, Matthew D., et al. &#8220;Deconvolutional networks.&#8221; Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on. IEEE, 2010._\n\n[Original Paper PDF](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/dcign.png)\n\n**Deep convolutional inverse graphics networks (DCIGN)** have a somewhat misleading name, as they are actually VAEs but with CNNs and DNNs for the respective encoders and decoders. These networks attempt to model &#8220;features&#8221; in the encoding as probabilities, so that it can learn to produce a picture with a cat and a dog together, having only ever seen one of the two in separate pictures. Similarly, you could feed it a picture of a cat with your neighbours&#8217; annoying dog on it, and ask it to remove the dog, without ever having done such an operation. Demo&#8217;s have shown that these networks can also learn to model complex transformations on images, such as changing the source of light or the rotation of a 3D object. These networks tend to be trained with back-propagation.\n\n_Kulkarni, Tejas D., et al. &#8220;Deep convolutional inverse graphics network.&#8221; Advances in Neural Information Processing Systems. 2015._\n\n[Original Paper PDF](https://arxiv.org/pdf/1503.03167v4.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/gan.png)\n\n**Generative adversarial networks (GAN)** are from a different breed of networks, they are twins: two networks working together. GANs consist of any two networks (although often a combination of FFs and CNNs), with one tasked to generate content and the other has to judge content. The discriminating network receives either training data or generated content from the generative network. How well the discriminating network was able to correctly predict the data source is then used as part of the error for the generating network. This creates a form of competition where the discriminator is getting better at distinguishing real data from generated data and the generator is learning to become less predictable to the discriminator. This works well in part because even quite complex noise-like patterns are eventually predictable but generated content similar in features to the input data is harder to learn to distinguish. GANs can be quite difficult to train, as you don&#8217;t just have to train two networks (either of which can pose it&#8217;s own problems) but their dynamics need to be balanced as well. If prediction or generation becomes to good compared to the other, a GAN won&#8217;t converge as there is intrinsic divergence.\n\n_Goodfellow, Ian, et al. &#8220;Generative adversarial nets.&#8221; Advances in Neural Information Processing Systems. 2014._\n\n[Original Paper PDF](https://arxiv.org/pdf/1406.2661v1.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/rnn.png)\n\n**Recurrent neural networks (RNN)** are FFNNs with a time twist: they are not stateless; they have connections between passes, connections through time. Neurons are fed information not just from the previous layer but also from themselves from the previous pass. This means that the order in which you feed the input and train the network matters: feeding it &#8220;milk&#8221; and then &#8220;cookies&#8221; may yield different results compared to feeding it &#8220;cookies&#8221; and then &#8220;milk&#8221;. One big problem with RNNs is the vanishing (or exploding) gradient problem where, depending on the activation functions used, information rapidly gets lost over time, just like very deep FFNNs lose information in depth. Intuitively this wouldn&#8217;t be much of a problem because these are just weights and not neuron states, but the weights through time is actually where the information from the past is stored; if the weight reaches a value of 0 or 1 000 000, the previous state won&#8217;t be very informative. RNNs can in principle be used in many fields as most forms of data that don&#8217;t actually have a timeline (i.e. unlike sound or video) can be represented as a sequence. A picture or a string of text can be fed one pixel or character at a time, so the time dependent weights are used for what came before in the sequence, not actually from what happened x seconds before. In general, recurrent networks are a good choice for advancing or completing information, such as autocompletion.\n\n_Elman, Jeffrey L. &#8220;Finding structure in time.&#8221; Cognitive science 14.2 (1990): 179-211._\n\n[Original Paper PDF](https://crl.ucsd.edu/~elman/Papers/fsit.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/lstm.png)\n\n**Long / short term memory (LSTM)** networks try to combat the vanishing / exploding gradient problem by introducing gates and an explicitly defined memory cell. These are inspired mostly by circuitry, not so much biology. Each neuron has a memory cell and three gates: input, output and forget. The function of these gates is to safeguard the information by stopping or allowing the flow of it. The input gate determines how much of the information from the previous layer gets stored in the cell. The output layer takes the job on the other end and determines how much of the next layer gets to know about the state of this cell. The forget gate seems like an odd inclusion at first but sometimes it&#8217;s good to forget: if it&#8217;s learning a book and a new chapter begins, it may be necessary for the network to forget some characters from the previous chapter. LSTMs have been shown to be able to learn complex sequences, such as writing like Shakespeare or composing primitive music. Note that each of these gates has a weight to a cell in the previous neuron, so they typically require more resources to run.\n\n_Hochreiter, Sepp, and Jürgen Schmidhuber. &#8220;Long short-term memory.&#8221; Neural computation 9.8 (1997): 1735-1780._\n\n[Original Paper PDF](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/gru.png)\n\n**Gated recurrent units (GRU)** are a slight variation on LSTMs. They have one less gate and are wired slightly differently: instead of an input, output and a forget gate, they have an update gate. This update gate determines both how much information to keep from the last state and how much information to let in from the previous layer. The reset gate functions much like the forget gate of an LSTM but it&#8217;s located slightly differently. They always send out their full state, they don&#8217;t have an output gate. In most cases, they function very similarly to LSTMs, with the biggest difference being that GRUs are slightly faster and easier to run (but also slightly less expressive). In practice these tend to cancel each other out, as you need a bigger network to regain some expressiveness which then in turn cancels out the performance benefits. In some cases where the extra expressiveness is not needed, GRUs can outperform LSTMs.\n\n_Chung, Junyoung, et al. &#8220;Empirical evaluation of gated recurrent neural networks on sequence modeling.&#8221; arXiv preprint arXiv:1412.3555 (2014)._\n\n[Original Paper PDF](https://arxiv.org/pdf/1412.3555v1.pdf)\n\n* * *\n\n&nbsp;\n\n![](/assets/images/2016/09/14/neural-network-zoo/ntm.png)\n\n**Neural Turing machines (NTM)** can be understood as an abstraction of LSTMs and an attempt to un-black-box neural networks (and give us some insight in what is going on in there). Instead of coding a memory cell directly into a neuron, the memory is separated. It&#8217;s an attempt to combine the efficiency and permanency of regular digital storage and the efficiency and expressive power of neural networks. The idea is to have a content-addressable memory bank and a neural network that can read and write from it. The &#8220;Turing&#8221; in Neural Turing Machines comes from them being Turing complete: the ability to read and write and change state based on what it reads means it can represent anything a Universal Turing Machine can represent.\n\n_Graves, Alex, Greg Wayne, and Ivo Danihelka. &#8220;Neural turing machines.&#8221; arXiv preprint arXiv:1410.5401 (2014)._\n\n[Original Paper PDF](https://arxiv.org/pdf/1410.5401v2.pdf)\n\n* * *\n\n**Bidirectional recurrent neural networks, bidirectional long / short term memory networks and bidirectional gated recurrent units (BiRNN, BiLSTM and BiGRU respectively)** are not shown on the chart because they look exactly the same as their unidirectional counterparts. The difference is that these networks are not just connected to the past, but also to the future. As an example, unidirectional LSTMs might be trained to predict the word &#8220;fish&#8221; by being fed the letters one by one, where the recurrent connections through time remember the last value. A BiLSTM would also be fed the next letter in the sequence on the backward pass, giving it access to future information. This trains the network to fill in gaps instead of advancing information, so instead of expanding an image on the edge, it could fill a hole in the middle of an image.\n\n_Schuster, Mike, and Kuldip K. Paliwal. &#8220;Bidirectional recurrent neural networks.&#8221; IEEE Transactions on Signal Processing 45.11 (1997): 2673-2681._\n\n[Original Paper PDF](http://www.di.ufpe.br/~fnj/RNA/bibliografia/BRNN.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/drn.png)\n\n**Deep residual networks (DRN)** are very deep FFNNs with extra connections passing input from one layer to a later layer (often 2 to 5 layers) as well as the next layer. Instead of trying to find a solution for mapping some input to some output across say 5 layers, the network is enforced to learn to map some input to some output + some input. Basically, it adds an identity to the solution, carrying the older input over and serving it freshly to a later layer. It has been shown that these networks are very effective at learning patterns up to 150 layers deep, much more than the regular 2 to 5 layers one could expect to train. However, it has been proven that these networks are in essence just RNNs without the explicit time based construction and they&#8217;re often compared to LSTMs without gates.\n\n_He, Kaiming, et al. &#8220;Deep residual learning for image recognition.&#8221; arXiv preprint arXiv:1512.03385 (2015)._\n\n[Original Paper PDF](https://arxiv.org/pdf/1512.03385v1.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/esn.png)\n\n**Echo state networks (ESN)** are yet another different type of (recurrent) network. This one sets itself apart from others by having random connections between the neurons (i.e. not organised into neat sets of layers), and they are trained differently. Instead of feeding input and back-propagating the error, we feed the input, forward it and update the neurons for a while, and observe the output over time. The input and the output layers have a slightly unconventional role as the input layer is used to prime the network and the output layer acts as an observer of the activation patterns that unfold over time. During training, only the connections between the observer and the (soup of) hidden units are changed.\n\n_Jaeger, Herbert, and Harald Haas. &#8220;Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication.&#8221; science 304.5667 (2004): 78-80._\n\n[Original Paper PDF](https://pdfs.semanticscholar.org/8922/17bb82c11e6e2263178ed20ac23db6279c7a.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/elm.png)\n\n**Extreme learning machines (ELM)** are basically FFNNs but with random connections. They look very similar to LSMs and ESNs, but they are not recurrent nor spiking. They also do not use backpropagation. Instead, they start with random weights and train the weights in a single step according to the least-squares fit (lowest error across all functions). This results in a much less expressive network but it&#8217;s also much faster than backpropagation.\n\n_Cambria, Erik, et al. &#8220;Extreme learning machines [trends &#038; controversies].&#8221; IEEE Intelligent Systems 28.6 (2013): 30-59._\n\n[Original Paper PDF](http://www.ntu.edu.sg/home/egbhuang/pdf/ieee-is-elm.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/lsm.png)\n\n**Liquid state machines (LSM)** are similar soups, looking a lot like ESNs. The real difference is that LSMs are a type of spiking neural networks: sigmoid activations are replaced with threshold functions and each neuron is also an accumulating memory cell. So when updating a neuron, the value is not set to the sum of the neighbours, but rather added to itself. Once the threshold is reached, it releases its&#8217; energy to other neurons. This creates a spiking like pattern, where nothing happens for a while until a threshold is suddenly reached.\n\n_Maass, Wolfgang, Thomas Natschläger, and Henry Markram. &#8220;Real-time computing without stable states: A new framework for neural computation based on perturbations.&#8221; Neural computation 14.11 (2002): 2531-2560._\n\n[Original Paper PDF](https://web.archive.org/web/20120222154641/http://ramsesii.upf.es/seminar/Maass_et_al_2002.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/svm.png)\n\n**Support vector machines (SVM)** find optimal solutions for classification problems. Classically they were only capable of categorising linearly separable data; say finding which images are of Garfield and which of Snoopy, with any other outcome not being possible. During training, SVMs can be thought of as plotting all the data (Garfields and Snoopys) on a graph (2D) and figuring out how to draw a line between the data points. This line would separate the data, so that all Snoopys are on one side and the Garfields on the other. This line moves to an optimal line in such a way that the margins between the data points and the line are maximised on both sides. Classifying new data would be done by plotting a point on this graph and simply looking on which side of the line it is (Snoopy side or Garfield side). Using the kernel trick, they can be taught to classify n-dimensional data. This entails plotting points in a 3D plot, allowing it to distinguish between Snoopy, Garfield AND Simon&#8217;s cat, or even higher dimensions distinguishing even more cartoon characters. SVMs are not always considered neural networks.\n\n_Cortes, Corinna, and Vladimir Vapnik. &#8220;Support-vector networks.&#8221; Machine learning 20.3 (1995): 273-297._\n\n[Original Paper PDF](http://image.diku.dk/imagecanon/material/cortes_vapnik95.pdf)\n\n* * *\n\n![](/assets/images/2016/09/14/neural-network-zoo/kn.png)\n\nAnd finally, **Kohonen networks (KN, also self organising (feature) map, SOM, SOFM)** &#8220;complete&#8221; our zoo. KNs utilise competitive learning to classify data without supervision. Input is presented to the network, after which the network assesses which of its neurons most closely match that input. These neurons are then adjusted to match the input even better, dragging along their neighbours in the process. How much the neighbours are moved depends on the distance of the neighbours to the best matching units. KNs are sometimes not considered neural networks either.\n\n_Kohonen, Teuvo. &#8220;Self-organized formation of topologically correct feature maps.&#8221; Biological cybernetics 43.1 (1982): 59-69._\n\n[Original Paper PDF](http://cioslab.vcu.edu/alg/Visualize/kohonen-82.pdf)\n\n* * *\n\nAny feedback and criticism is welcome. At the Asimov Institute we do deep learning research and development, so be sure to follow us on [twitter](http://www.twitter.com/asimovinstitute) for future updates and posts! Thank you for reading!\n\n[UPDATE 15 sept 2016] I would like to thank everybody for their insights and corrections, all feedback is hugely appreciated. I will add links and a couple more suggested networks in a future update, stay tuned.\n\n[UPDATE 29 sept 2016] Added links and citations to all the original papers. A follow up post is planned, since I found at least 9 more architectures. I will not include them in this post for better consistency in terms of content.\n\n---\n\n* Author: [FJODOR VAN VEEN](http://www.asimovinstitute.org/author/fjodorvanveen/)\n* Source: [THE ASIMOV INSTITUTE](http://www.asimovinstitute.org/)\n* Link: [THE NEURAL NETWORK ZOO](http://www.asimovinstitute.org/neural-network-zoo/)\n","tags":["Neural-Network"],"categories":["Deep-Learning"]},{"title":"常用推荐算法（50页干货）","url":"%2F2016%2F2016-09-08-common-recommendation-algorithm%2F","content":"\n内容主要围绕电商中用到的一些推荐算法，参考了Xavier Amatriain在CMU的Machine Learning暑期学校上的讲授的内容。\n\n![](/assets/images/2016/09/08/common-recommendation-algorithm/1.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/2.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/3.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/4.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/5.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/6.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/7.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/8.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/9.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/10.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/11.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/12.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/13.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/14.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/15.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/16.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/17.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/18.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/19.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/20.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/21.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/22.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/23.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/24.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/25.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/26.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/27.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/28.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/29.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/30.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/31.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/32.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/33.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/34.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/35.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/36.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/37.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/38.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/39.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/40.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/41.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/42.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/43.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/44.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/45.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/46.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/47.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/48.jpg)\n![](/assets/images/2016/09/08/common-recommendation-algorithm/49.jpg)\n\n---\n\n* 原文链接：[常用推荐算法（50页干货）](http://mp.weixin.qq.com/s?src=3&timestamp=1476027251&ver=1&signature=dLgAoBsKg8-yyZDhqIpk7uHXpKEqxm9qEV36xu8QxjtLFBYx1JbN65c5lQNpyS2s-DmOtjubBugx6HQmZbSl*Z9Rclsqh3bWhNZ-Tuf3blRdt-ahtLmThghft*aHDMGJ6iz*oyUWRrZvSa3VfQUBzBR8AEDY72O29Vuy22AXk-k=)\n","tags":["Recommendation"],"categories":["Machine-Learning"]},{"title":"分布式事务：不过是在一致性、吞吐量和复杂度之间，做一个选择","url":"%2F2016%2F2016-09-08-distributed-transaction%2F","content":"\n# 背景\n\n这是一个开撕的话题，我经历过太多的关于分布式事务的需求：“有没有简便的方案，像使用数据库事务那样，解决分布式数据一致性的问题”。特别是微服务架构流行的今天，一次交易需要跨越多个“服务”、多个数据库来实现，传统的技术手段，已经无法应对和满足微服务情况下这些复杂的场景了。针对微服务下的交易业务如何保障数据一致性，本文尽量做到理论结合实际，将我们在实际产品中用到的分布式事务实现机制，和大家扒一扒，希望能帮助到读者。\n\n谈到分布式事务，必须先把”CAP\"拿出来说说事......，当然还有”BASE\"......\n\n从架构的角度来看，业务拆分（数据分区）、数据一致性、性能（可用性）永远是个平衡的艺术：\n\n* 1）在微服务架构下，为了获得更高的性能与灵活性，将业务应用拆分为多个，交易跨多个微服务编排，数据一致性的问题产生；\n* 2）为了解决数据一致性问题，需要采用不同的事务机制来保障，这又会产生性能（可用性）问题；\n\n在计算机世界里，为了解决一件事情，另外的问题就会接踵而至，从另一个层面印证了IT架构永远是一种平衡的艺术。\n\n“BASE”其核心思想是根据业务特点，采用适当的方式来使系统达到最终一致性(Eventualconsistency)；在互联网领域，通常需要牺牲强一致性来换取系统的高可用性，只需要保证数据的“最终一致”，只是这个最终时间需要在用户可以接受的范围内；但在金融相关的交易领域，仍然需要采用强一致性的方式来保障交易的准确性与可靠性。\n \n# 分布式事务介绍\n\n接下来为大家介绍业界常见的事务处理模式，包括两阶段提交、三阶段提交、Sagas长事务、补偿模式、可靠事件模式（本地事件表、外部事件表）、可靠事件模式（非事务消息、事务消息）、TCC等。不同的事务模型支持不同的数据一致性。如果读者对这几种分布式事务比较熟悉，可以直接参考下图并结合自身业务需求选择合适的事务模型。\n\n![](/assets/images/2016/09/08/distributed-transaction/001.jpg)\n\n## 一、两阶段提交、三阶段提交\n\n这种分布式事务解决方案目前在各种技术平台上已经比较成熟：JavaEE架构下面的JTA事务（各应用服务器均提供了实现，tomcat除外）。\n\n目前两阶段提交、三阶段提交存在如下的局限性，并不适合在微服务架构体系下使用：\n\n* 1）所有的操作必须是事务性资源（比如数据库、消息队列、EJB组件等），存在使用局限性（微服务架构下多数使用HTTP协议），比较适合传统的单体应用；\n* 2）由于是强一致性，资源需要在事务内部等待，性能影响较大，吞吐率不高，不适合高并发与高性能的业务场景；\n\n## 二、Sagas长事务\n\n在Sagas事务模型中，一个长事务是由一个预先定义好执行顺序的子事务集合和他们对应的补偿子事务集合组成的。典型的一个完整的交易由T1、T2、......、Tn等多个业务活动组成，每个业务活动可以是本地操作、或者是远程操作，所有的业务活动在Sagas事务下要么全部成功，要么全部回滚，不存在中间状态。\n\n![](/assets/images/2016/09/08/distributed-transaction/002.jpg)\n\nSagas事务模型的实现机制：\n\n1. 每个业务活动都是一个原子操作；\n2. 每个业务活动均提供正反操作；\n3. 任何一个业务活动发生错误，按照执行的反顺序，实时执行反操作，进行事务回滚；\n4. 回滚失败情况下，需要记录待冲正事务日志，通过重试策略进行重试；\n5. 冲正重试依然失败的场景，提供定时冲正服务器，对回滚失败的业务进行定时冲正；\n6. 定时冲正依然失败的业务，等待人工干预；\n\nSagas长事务模型支持对数据一致性要求比较高的场景比较适用，由于采用了补偿的机制，每个原子操作都是先执行任务，避免了长时间的资源锁定，能做到实时释放资源，性能相对有保障。\n\nSagas长事务方式如果由业务去实现，复杂度与难度并存。在我们实际使用过程中，开发了一套支持Sagas事务模型的框架来支撑业务快速交付。\n\n![](/assets/images/2016/09/08/distributed-transaction/003.jpg)\n\n开发人员：业务只需要进行交易编排，每个原子操作提供正反交易；\n\n配置人员：可以针对异常类型设定事务回滚策略（哪些异常纳入事务管理、哪些异常不纳入事务管理）；每个原子操作的流水是否持久化（为了不同性能可以支持缓存、DB、以及扩展其它持久化方式）；以及冲正选项配置（重试次数、超时时间、是否实时冲正、定时冲正等）；\n\nSagas事务框架：提供事务保障机制，负责原子操作的流水落地，原子操作的执行顺序，提供实时冲正、定时冲正、事务拦截器等基础能力；\n\nSagas框架的核心是IBusinessActivity、IAtomicAction。IBusinessActivity完成原子活动的enlist()、delist()、prepare()、commit()、rollback()等操作；IAtomicAction主要完成对状态上下文、正反操作执行。\n\n![](/assets/images/2016/09/08/distributed-transaction/004.jpg)\n\n限于文章篇幅，本文不对具体实现做详述；后面找时间可以详细介绍基于Sagas长事务模型具体的实现框架。\n\nSagas长事务需要交易提供反操作，支持事务的强一致性，由于没有在整个事务周期内锁定资源，对性能影响较小，适合对数据要求比较高的场景中使用。\n\n## 三、补偿模式\n\nSagas长事务模型本质上是补偿机制的复杂实现，如果实际业务场景上不需要复杂的Sagas事务框架支撑，可以在业务中实现简单的补偿模式。补偿过程往往也同样需要实现最终一致性，需要保证取消服务至少被调用一次和取消服务必须实现幂等性。补偿模式可以参见同事田向阳的技术文章《微服务架构下数据一致性保证（三）》（相关文章：微服务架构下数据一致性保障(一)   微服务架构下数字一致性保证(二)）\n\n![](/assets/images/2016/09/08/distributed-transaction/005.jpg)\n\n补偿机制不推荐在复杂场景（需要多个交易的编排）下使用，优点是非常容易提供回滚，而且依赖的服务也非常少，与Sagas长事务比较来看，使用起来更简便；缺点是会造成代码量庞大，耦合性高，对应无法提供反操作的交易不适合。\n\n## 四、可靠时间模式（本地事件表、外地事件表）\n\n可靠事件模式属于事件驱动架构，当某件重要事情发生时，例如更新一个业务实体，微服务会向消息代理发布一个事件。消息代理会向订阅事件的微服务推送事件，当订阅这些事件的微服务接收此事件时，就可以完成自己的业务，也可能会引发更多的事件发布。\n\n![](/assets/images/2016/09/08/distributed-transaction/006.jpg)\n\n可靠事件模式在于保证可靠事件投递和避免重复消费，靠事件投递定义为:\n\n1）每个服务原子性的业务操作和发布事件;\n2）消息代理确保事件传递至少一次；避免重复消费要求服务实现幂等性。\n\n基于事件模式，需要重点考虑的是事件的可靠到达，在我们产品实际支持过程中，通常有本地事件表、外部事件表两种模式：\n\n1. 本地事件表方法将事件和业务数据保存在同一个数据库中，使用一个额外的“事件恢复”服务来恢复事件，由本地事务保证更新业务和发布事件的原子性。考虑到事件恢复可能会有一定的延时，服务在完成本地事务后可立即向消息代理发布一个事件。\n\n![](/assets/images/2016/09/08/distributed-transaction/007.jpg)\n\n1）微服务在同一个本地事务中记录业务数据和事件；\n\n2）微服务实时发布一个事件立即通知关联的业务服务，如果事件发布成功立即删除记录的事件；\n\n3）事件恢复服务定时从事件表中恢复未发布成功的事件，重新发布，重新发布成功才删除记录的事件；\n\n其中第2条的操作主要是为了增加发布事件的实时性，由第三条保证事件一定被发布。\n\n本地事件表方式业务系统和事件系统耦合比较紧密，额外的事件数据库操作也会给数据库带来额外的压力，可能成为瓶颈。\n\n2. 外部事件表方法将事件持久化到外部的事件系统，事件系统需提供实时事件服务以接受微服务发布事件，同时事件系统还需要提供事件恢复服务来确认和恢复事件。\n\n![](/assets/images/2016/09/08/distributed-transaction/008.jpg)\n\n1）业务服务在事务提交前，通过实时事件服务向事件系统请求发送事件，事件系统只记录事件并不真正发送；     \n\n2）业务服务在提交后，通过实时事件服务向事件系统确认发送，事件得到确认后，事件系统才真正发布事件到消息代理；\n\n3）业务服务在业务回滚时，通过实时事件向事件系统取消事件；\n\n4）如果业务服务在发送确认或取消之前停止服务了怎么办呢？事件系统的事件恢复服务会定期找到未确认发送的事件向业务服务查询状态，根据业务服务返回的状态决定事件是要发布还是取消；\n\n该方式将业务系统和事件系统独立解耦，都可以独立伸缩。但是这种方式需要一次额外的发送操作，并且需要发布者提供额外的查询接口。\n \n基于可靠事件的事务保障模式可以有很多的变种实现，比如对消息可靠性不高的话，有如下做法：\n1）将本地表的方式换做缓存方式；\n为了提高消息投递的效率，可以：\n2）多次消息合并投递模式；\n为了提供强一致性的事务保障，甚至可以采用：\n3）本地消息表持久化（保障发方法消息可靠落地）+远程消息表持久化（保障接收方消息可靠落地）结合的模式。\n   \n在我们的流程产品中针对业务和流程的分布式事务解决方案就采用了多次消息合并投递+本地缓存+远程消息表持久化的模式，接下来为大家介绍具体的使用方式。\n\n使用场景\n在实际业务项目中通常采用业务与流程分布式部署的模式，业务系统通过远程接口访问流程引擎，业务数据同流程数据存放到各自的数据库中。 \n\n![](/assets/images/2016/09/08/distributed-transaction/009.jpg)\n\n在这种场景中，如果业务系统的流程操作和业务操作交叉在一起，当流程操作成功，而业务操作失败时，就会造成业务回滚，而流程在引擎端已经创建，导致业务系统和流程引擎状态不一致。       \n\n![](/assets/images/2016/09/08/distributed-transaction/010.jpg)\n\n在业务应用中对一个事务中的流程操作采用本地缓存+批量投递+远程落地的模式（如果需要在客户端确保消息可靠性，可以将本地缓存换成本地表的方式）；在流程引擎端在消息投递来之后，做了消息表落地的工作，保障可靠执行。在我们流程产品中流程引擎对外提供的客户端提供了统一的分布式事务API，和使用传统本地事务一样进行操作，保证了透明性，简化开发人员的复杂度。分布式事务API支持两种协议模式：\n\n1. http+二进制序列化的模式\n2. WebService模式\n\n后续我们会增加Restful风格的接口。\n     \n可靠事件模式在互联网公司中有着较大规模的应用，该方式适合的业务场景非常广泛，而且能够做到数据的最终一致性，缺点是该模式实现难度较大，依赖数据库实现可靠性，在高并发场景下可能存在性能瓶颈，需要在公司层面搭建一套标准的可靠事件框架来支撑。\n\n## 五、可靠事件模式（非事务消息、事务消息）\n\n可靠事件模式的事件通知可以采用消息的模式来实现，其实现原理和本地事件表、外部事件表一致，本文就不在详述。目前常用的消息框架ActiveMQ、RabbitMQ、Kafka、RocketMQ可以用来作为消息投递的渠道。注意：Kafka通常不适合，因为Kafka的设计存在丢消息的场景。\n\n目前市面上支持事务的消息产品比较少，RocketMQ虽然实现了可靠的事务模式，但并没有开源出来、没有开源出来、没有开源出来，顺便说一下国内的开源有太多需要改进的空间（关键点不开源，开源后没有持续的投入）。\n  \n## 六、TCC模式\n\n一个完整的TCC业务由一个主业务服务和若干个从业务服务组成，主业务服务发起并完成整个业务活动，TCC模式要求从服务提供三个接口：Try、Confirm、Cancel。·\n\n![](/assets/images/2016/09/08/distributed-transaction/011.jpg)\n\n1) Try：完成所有业务检查\n\n预留必须业务资源     \n\n2) Confirm：真正执行业务\n\n不作任何业务检查；只使用Try阶段预留的业务资源；Confirm操作满足幂等性；\n\n3) Cancel：\n\n释放Try阶段预留的业务资源；Cancel操作满足幂等性；\n\n整个TCC业务分成两个阶段完成：\n\n![](/assets/images/2016/09/08/distributed-transaction/012.jpg)\n\n第一阶段：主业务服务分别调用所有从业务的try操作，并在活动管理器中登记所有从业务服务。当所有从业务服务的try操作都调用成功或者某个从业务服务的try操作失败，进入第二阶段。\n\n第二阶段：活动管理器根据第一阶段的执行结果来执行confirm或cancel操作。如果第一阶段所有try操作都成功，则活动管理器调用所有从业务活动的confirm操作。否则调用所有从业务服务的cancel操作。\n\nTCC模式的详细描述可以参见同事田向阳的技术文章《微服务架构下数据一致性保证（三）》\n     \n需要注意的是第二阶段confirm或cancel操作本身也是满足最终一致性的过程，在调用confirm或cancel的时候也可能因为某种原因（比如网络）导致调用失败，所以需要活动管理支持重试的能力，同时这也就要求confirm和cancel操作具有幂等性。\n     \n# 总结\n\n六种分布式事务的实现模式从数据一致性、事务级别、吞吐量、实现的复杂度各有优劣，下图为大家提供选择依据。\n\n![](/assets/images/2016/09/08/distributed-transaction/013.jpg)\n\n站在架构设计的角度，针对数据一致性需要把业务因素考虑进来，这有利于团队在技术上作出更合理的选择。根据具体业务场景，评估出业务对事务的优先级，更有利于作出架构上的取舍。我们经常接触的证券、金融、支付等行业，对数据一致性要求极高，需要严格的实时保证要求；但对于基于社交类的应用场景，可以采用局部实时一致，最终全局一致的能力。因此大家在实践过程中，一定要把技术与业务结合，选择适合自身业务的技术方案。\n \n# 关于作者：\n\n刘相 EAII-企业架构创新研究院 专家委员\n\n计算机应用技术硕士，现任普元软件产品部副总兼SOA产品线总经理。十年IT行业经验，专注于企业软件平台，在SOA、分布式计算、企业架构设计等领域。先后主导公司EOS7、Portal、云PAAS平台、云流程平台、BPM等系列产品的开发和设计工作。著有国内首本解析SpringBatch的中文原创图书《SpringBatch批处理框架》。个人爱好：阅读，慢跑。\n\n---\n\n* Author: 刘相\n* Source: [EAII企业架构创新研究院](http://eaworld.io)\n* Link: [分布式事务：不过是在一致性、吞吐量和复杂度之间，做一个选择](https://mp.weixin.qq.com/s/ONXodrh5XYu5M65mAuKUIA)\n","tags":["Transation"],"categories":["Distributed"]},{"title":"HDFS NameNode 内存全景","url":"%2F2016%2F2016-08-26-hdfs-namenode%2F","content":"\n### 一、概述\n\n从整个HDFS系统架构上看，NameNode是其中最重要、最复杂也是最容易出现问题的地方，而且一旦NameNode出现故障，整个Hadoop集群就将处于不可服务的状态，同时随着数据规模和集群规模地持续增长，很多小量级时被隐藏的问题逐渐暴露出来。所以，从更高层次掌握NameNode的内部结构和运行机制尤其重要。除特别说明外，本文基于社区版本Hadoop-2.4.1[1][2]，虽然2.4.1之后已经有多次版本迭代，但是基本原理相同。\n\nNameNode管理着整个HDFS文件系统的元数据。从架构设计上看，元数据大致分成两个层次：Namespace管理层，负责管理文件系统中的树状目录结构以及文件与数据块的映射关系；块管理层，负责管理文件系统中文件的物理块与实际存储位置的映射关系BlocksMap，如图1所示[1]。Namespace管理的元数据除内存常驻外，也会周期Flush到持久化设备上FsImage文件；BlocksMap元数据只在内存中存在；当NameNode发生重启，首先从持久化设备中读取FsImage构建Namespace，之后根据DataNode的汇报信息重新构造BlocksMap。这两部分数据结构是占据了NameNode大部分JVM Heap空间。\n\n![](/assets/images/2016/08/26/hdfs-namenode/hdfs.png)\n\n图1 HDFS结构图\n\n除了对文件系统本身元数据的管理之外，NameNode还需要维护整个集群的机架及DataNode的信息、Lease管理以及集中式缓存引入的缓存管理等等。这几部分数据结构空间占用相对固定，且占用较小。\n\n测试数据显示，Namespace目录和文件总量到2亿，数据块总量到3亿后，常驻内存使用量超过90GB。\n\n### 二、内存全景\n\n如前述，NameNode整个内存结构大致可以分成四大部分：Namespace、BlocksMap、NetworkTopology及其它，图2为各数据结构内存逻辑分布图示。\n\n![](/assets/images/2016/08/26/hdfs-namenode/namenodemem.png)\n\n图2 NameNode内存全景图\n\nNamespace：维护整个文件系统的目录树结构及目录树上的状态变化；\n\nBlockManager：维护整个文件系统中与数据块相关的信息及数据块的状态变化；\n\nNetworkTopology：维护机架拓扑及DataNode信息，机架感知的基础；\n\n其它：\n\nLeaseManager：读写的互斥同步就是靠Lease实现，支持HDFS的Write-Once-Read-Many的核心数据结构；\n\nCacheManager：Hadoop 2.3.0引入的集中式缓存新特性，支持集中式缓存的管理，实现memory-locality提升读性能；\n\nSnapshotManager：Hadoop 2.1.0引入的Snapshot新特性，用于数据备份、回滚，以防止因用户误操作导致集群出现数据问题；\n\nDelegationTokenSecretManager：管理HDFS的安全访问；\n\n另外还有临时数据信息、统计信息metrics等等。\n\nNameNode常驻内存主要被Namespace和BlockManager使用，二者使用占比分别接近50%。其它部分内存开销较小且相对固定，与Namespace和BlockManager相比基本可以忽略。\n\n### 三、内存分析\n\n#### 3.1 Namespace\n\n与单机文件系统相似，HDFS对文件系统的目录结构也是按照树状结构维护，Namespace保存了目录树及每个目录/文件节点的属性。除在内存常驻外，这部分数据会定期flush到持久化设备上，生成一个新的FsImage文件，方便NameNode发生重启时，从FsImage及时恢复整个Namespace。图3所示为Namespace内存结构。前述集群中目录和文件总量即整个Namespace目录树中包含的节点总数，可见Namespace本身其实是一棵非常巨大的树。\n\n![](/assets/images/2016/08/26/hdfs-namenode/namespace.png)\n\n图3 Namespace内存结构\n\n在整个Namespace目录树中存在两种不同类型的INode数据结构：INodeDirectory和INodeFile。其中INodeDirectory标识的是目录树中的目录，INodeFile标识的是目录树中的文件。由于二者均继承自INode，所以具备大部分相同的公共信息INodeWithAdditionalFields，除常用基础属性外，其中还提供了扩展属性features，如Quota、Snapshot等均通过Feature增加，如果以后出现新属性也可通过Feature方便扩展。不同的是，INodeFile特有的标识副本数和数据块大小组合的header（2.6.1之后又新增了标识存储策略ID的信息）及该文件包含的有序Blocks数组；INodeDirectory则特有子节点的列表children。这里需要特别说明children是默认大小为5的ArrayList，按照子节点name有序存储，虽然在插入时会损失一部分写性能，但是可以方便后续快速二分查找提高读性能，对一般存储系统，读操作比写操作占比要高。具体的继承关系见图4所示。\n\n![](/assets/images/2016/08/26/hdfs-namenode/inode.png)\n\n图4 INode继承关系\n\n#### 3.2 BlockManager\n\nBlocksMap在NameNode内存空间占据很大比例，由BlockManager统一管理，相比Namespace，BlockManager管理的这部分数据要复杂的多。Namespace与BlockManager之间通过前面提到的INodeFile有序Blocks数组关联到一起。图5所示BlockManager管理的内存结构。\n\n![](/assets/images/2016/08/26/hdfs-namenode/blockmanager.png)\n\n图5 BlockManager管理的内存结构\n\n每一个INodeFile都会包含数量不等的Block，具体数量由文件大小及每一个Block大小（默认为64M）比值决定，这些Block按照所在文件的先后顺序组成BlockInfo数组，如图5所示的BlockInfo[A~K]，BlockInfo维护的是Block的元数据，结构如图6所示，数据本身是由DataNode管理，所以BlockInfo需要包含实际数据到底由哪些DataNode管理的信息，这里的核心是名为triplets的Object数组，大小为3*replicas，其中replicas是Block副本数量。triplets包含的信息：\n\n* triplets[i]：Block所在的DataNode；\n\n* triplets[i+1]：该DataNode上前一个Block；\n\n* triplets[i+2]：该DataNode上后一个Block；\n\n其中i表示的是Block的第i个副本，i取值[0,replicas)。\n\n![](/assets/images/2016/08/26/hdfs-namenode/blockinfo.png)\n\n图6 BlockInfo继承关系\n\n从前面描述可以看到BlockInfo几块重要信息：文件包含了哪些Block，这些Block分别被实际存储在哪些DataNode上，DataNode上所有Block前后链表关系。\n\n如果从信息完整度来看，以上数据足够支持所有关于HDFS文件系统的正常操作，但还存在一个使用场景较多的问题：不能通过blockid快速定位Block，所以引入了BlocksMap。\n\nBlocksMap底层通过LightWeightGSet实现，本质是一个链式解决冲突的哈希表。为了避免rehash过程带来的性能开销，初始化时，索引空间直接给到了整个JVM可用内存的2%，并且不再变化。集群启动过程，DataNode会进行BR（BlockReport），根据BR的每一个Block计算其HashCode，之后将对应的BlockInfo插入到相应位置逐渐构建起来巨大的BlocksMap。前面在INodeFile里也提到的BlockInfo集合，如果我们将BlocksMap里的BlockInfo与所有INodeFile里的BlockInfo分别收集起来，可以发现两个集合完全相同，事实上BlocksMap里所有的BlockInfo就是INodeFile中对应BlockInfo的引用；通过Block查找对应BlockInfo时，也是先对Block计算HashCode，根据结果快速定位到对应的BlockInfo信息。至此涉及到HDFS文件系统本身元数据的问题基本上已经解决了。\n\n前面提到部分都属于静态数据部分，NameNode内存中所有数据都要随读写情况发生变化，BlockManager当然也需要管理这部分动态数据。主要是当Block发生变化不符合预期时需要及时调整Blocks的分布。这里涉及几个核心的数据结构：\n\nexcessReplicateMap：若某个Block实际存储的副本数多于预设副本数，这时候需要删除多余副本，这里多余副本会被置于excessReplicateMap中。excessReplicateMap是从DataNode的StorageID到Block集合的映射集。\n\nneededReplications：若某个Block实际存储的副本数少于预设副本数，这时候需要补充缺少副本，这里哪些Block缺少多少个副本都统一存在neededReplications里，本质上neededReplications是一个优先级队列，缺少副本数越多的Block之后越会被优先处理。\n\ninvalidateBlocks：若某个Block即将被删除，会被置于invalidateBlocks中。invalidateBlocks是从DataNode的StorageID到Block集合的映射集。如某个文件被客户端执行了删除操作，该文件所属的所有Block会先被置于invalidateBlocks中。\n\ncorruptReplicas：有些场景Block由于时间戳/长度不匹配等等造成Block不可用，会被暂存在corruptReplicas中，之后再做处理。\n\n前面几个涉及到Block分布情况动态变化的核心数据结构，这里的数据实际上是过渡性质的，BlockManager内部的ReplicationMonitor线程（图5标识Thread/Monitor）会持续从其中取出数据并通过逻辑处理后分发给具体的DatanodeDescriptor对应数据结构（3.3 NetworkTopology里会有简单介绍），当对应DataNode的心跳过来之后，NameNode会遍历DatanodeDescriptor里暂存的数据，将其转换成对应指令返回给DataNode，DataNode收到任务并执行完成后再反馈回NameNode，之后DatanodeDescriptor里对应信息被清除。如BlockB预设副本数为3，由于某种原因实际副本变成4（如之前下线的DataNode D重新上线，其中B正好有BlockB的一个副本数据），BlockManager能及时发现副本变化，并将多余的DataNode D上BlockB副本放置到excessReplicateMap中，ReplicationMonitor线程定期检查时发现excessReplicateMap中数据后将其移到DataNode D对应DatanodeDescriptor中invalidateBlocks里，当DataNode D下次心跳过来后，随心跳返回删除Block B的指令，DataNode D收到指令实际删除其上的Block B数据并反馈回NameNode，此后BlockManager将DataNode D上的Block B从内存中清除，至此Block B的副本符合预期，整个流程如图7所示。\n\n![](/assets/images/2016/08/26/hdfs-namenode/blockreplica.png)\n\n图7 副本数异常时处理过程\n\n#### 3.3 NetworkTopology\n\n前面多次提到Block与DataNode之间的关联关系，事实上NameNode确实还需要管理所有DataNode，不仅如此，由于数据写入前需要确定数据块写入位置，NameNode还维护着整个机架拓扑NetworkTopology。图8所示内存中机架拓扑图。\n\n![](/assets/images/2016/08/26/hdfs-namenode/networktopology.png)\n\n图8 NetworkTopology内存结构\n\n从图8可以看出这里包含两个部分：机架拓扑结构NetworkTopology和DataNode节点信息。其中树状的机架拓扑是根据机架感知（一般都是外部脚本计算得到）在集群启动完成后建立起来，整个机架的拓扑结构在NameNode的生命周期内一般不会发生变化；另一部分是比较关键的DataNode信息，BlockManager已经提到每一个DataNode上的Blocks集合都会形成一个双向链表，更准确的应该是DataNode的每一个存储单元DatanodeStorageInfo上的所有Blocks集合会形成一个双向链表，这个链表的入口就是机架拓扑结构叶子节点即DataNode管理的DatanodeStorageInfo。此外由于上层应用对数据的增删查随时发生变化，随之DatanodeStorageInfo上的Blocks也会动态变化，所以NetworkTopology上的DataNode对象还会管理这些动态变化的数据结构，如replicateBlocks/recoverBlocks/invalidateBlocks，这些数据结构正好和BlockManager管理的动态数据结构对应，实现了数据的动态变化由BlockManager传达到DataNode内存对象最后通过指令下达到物理DataNode实际执行的流动过程，流程在3.2 BlockManager已经介绍。\n\n这里存在一个问题，为什么DatanodeStorageInfo下所有Block之间会以双向链表组织，而不是其它数据结构？如果结合实际场景就不难发现，对每一个DatanodeStorageInfo下Block的操作集中在快速增加/删除（Block动态增减变化）及顺序遍历（BlockReport期间），所以双向链表是非常合适的数据结构。\n\n#### 3.4 LeaseManager\n\nLease 机制是重要的分布式协议，广泛应用于各种实际的分布式系统中。HDFS支持Write-Once-Read-Many，对文件写操作的互斥同步靠Lease实现。Lease实际上是时间约束锁，其主要特点是排他性。客户端写文件时需要先申请一个Lease，一旦有客户端持有了某个文件的Lease，其它客户端就不可能再申请到该文件的Lease，这就保证了同一时刻对一个文件的写操作只能发生在一个客户端。NameNode的LeaseManager是Lease机制的核心，维护了文件与Lease、客户端与Lease的对应关系，这类信息会随写数据的变化实时发生对应改变。\n\n![](/assets/images/2016/08/26/hdfs-namenode/leasemanager.png)\n\n图9 LeaseManager的内存数据结构\n\n图9所示为LeaseManager内存结构，包括以下三个主要核心数据结构：\n\nsortedLeases：Lease集合，按照时间先后有序组织，便于检查Lease是否超时；\n\nleases：客户端到Lease的映射关系；\n\nsortedLeasesByPath：文件路径到Lease的映射关系；\n\n其中每一个写数据的客户端会对应一个Lease，每个Lease里包含至少一个标识文件路径的Path。Lease本身已经维护了其持有者（客户端）及该Lease正在操作的文件路径集合，之所以增加了leases和sortedLeasesByPath为提高通过Lease持有者或文件路径快速索引到Lease的性能。\n\n由于Lease本身的时间约束特性，当Lease发生超时后需要强制回收，内存中与该Lease相关的内容要被及时清除。超时检查及超时后的处理逻辑由LeaseManager.Monitor统一执行。LeaseManager中维护了两个与Lease相关的超时时间：软超时（softLimit）和硬超时（hardLimit），使用场景稍有不同。\n\n正常情况下，客户端向集群写文件前需要向NameNode的LeaseManager申请Lease；写文件过程中定期更新Lease时间，以防Lease过期，周期与softLimit相关；写完数据后申请释放Lease。整个过程可能发生两类问题：（1）写文件过程中客户端没有及时更新Lease时间；（2）写完文件后没有成功释放Lease。两个问题分别对应为softLimit和hardLimit。两种场景都会触发LeaseManager对Lease超时强制回收。如果客户端写文件过程中没有及时更新Lease超过softLimit时间后，另一客户端尝试对同一文件进行写操作时触发Lease软超时强制回收；如果客户端写文件完成但是没有成功释放Lease，则会由LeaseManager的后台线程LeaseManager.Monitor检查是否硬超时后统一触发超时回收。不管是softLimit还是hardLimit超时触发的强制Lease回收，处理逻辑都一样：FSNamesystem.internalReleaseLease，逻辑本身比较复杂，这里不再展开，简单的说先对Lease过期前最后一次写入的Block进行检查和修复，之后释放超时持有的Lease，保证后面其它客户端的写入能够正常申请到该文件的Lease。\n\nNameNode内存数据结构非常丰富，这里对几个重要的数据结构进行了简单的描述，除了前面罗列之外，其实还有如SnapShotManager/CacheManager等，由于其内存占用有限且有一些特性还尚未稳定，这里不再展开。\n\n### 四、问题\n\n随着集群中数据规模的不断积累，NameNode内存占用随之成比例增长。不可避免的NameNode内存将逐渐成为集群发展的瓶颈，并开始暴漏诸多问题。\n\n1、启动时间变长。NameNode的启动过程可以分成FsImage数据加载、editlogs回放、Checkpoint、DataNode的BlockReport几个阶段。数据规模较小时，启动时间可以控制在~10min以内，当元数据规模达到5亿（Namespace中INode数超过2亿，Block数接近3亿），FsImage文件大小将接近到20GB，加载FsImage数据就需要~14min，Checkpoint需要~6min，再加上其它阶段整个重启过程将持续~50min，极端情况甚至超过60min，虽然经过多轮优化重启过程已经能够稳定在~30min，但也非常耗时。如果数据规模继续增加，启动过程将同步增加。\n\n2、性能开始下降。HDFS文件系统的所有元数据相关操作基本上均在NameNode端完成，当数据规模的增加致内存占用变大后，元数据的增删改查性能会出现下降，且这种下降趋势会因规模效应及复杂的处理逻辑被放大，相对复杂的RPC请求（如addblock）性能下降更加明显。\n\n3、NameNode JVM FGC（Full GC）风险较高。主要体现在两个方面：（1）FGC频率增加；（2）FGC时间增加且风险不可控。针对NameNode的应用场景，目前看CMS内存回收算法比较主流，正常情况下，对超过100GB内存进行回收处理时，可以控制到秒级别的停顿时间，但是如果回收失败被降级到串行内存回收时，应用的停顿时间将达到数百秒，这对应用本身是致命的。\n\n4、超大JVM Heap Size调试问题。如果线上集群性能表现变差，不得不通过分析内存才能得到结论时，会成为一件异常困难的事情。且不说Dump本身极其费时费力，Dump超大内存时存在极大概率使NameNode不可服务。\n\n针对NameNode内存增长带来的诸多问题，社区和业界都在持续关注并尝试不同的解决方案。整体上两个思路：（1）扩展NameNode分散单点负载；（2）引入外部系统支持NameNode内存数据。\n\n从2010年开始社区就投入大量精力持续解决，Federation方案[3]通过对NameNode进行水平扩展分散单点负载的方式解决NameNode的问题，经过几年的发展该方案逐渐稳定，目前已经被业界广泛使用。除此之外，社区也在尝试将Namespace存储值外部的KV存储系统如LevelDB[4]，从而降低NameNode内存负载。\n\n除社区外，业界也在尝试自己的解决方案。Baidu HDFS2[5]将元数据管理通过主从架构的集群形式提供服务，本质上是将原生NameNode管理的Namespace和BlockManagement进行物理拆分。其中Namespace负责管理整个文件系统的目录树及文件到BlockID集合的映射关系，BlockID到DataNode的映射关系是按照一定的规则分到多个服务节点分布式管理，这种方案与Lustre有相似之处（Hash-based Partition）。Taobao HDFS2[6]尝试过采用另外的思路，借助高速存储设备，将元数据通过外存设备进行持久化存储，保持NameNode完全无状态，实现NameNode无限扩展的可能。其它类似的诸多方案不一而足。\n\n尽管社区和业界均对NameNode内存瓶颈有成熟的解决方案，但是不一定适用所有的场景，尤其是中小规模集群。结合实践过程和集群规模发展期可能遇到的NameNode内存相关问题这里有几点建议：\n\n1. 合并小文件。正如前面提到，目录/文件和Block均会占用NameNode内存空间，大量小文件会降低内存使用效率；另外，小文件的读写性能远远低于大文件的读写，主要原因对小文件读写需要在多个数据源切换，严重影响性能。\n\n2. 调整合适的BlockSize。主要针对集群内文件较大的业务场景，可以通过调整默认的Block Size大小（参数：dfs.blocksize，默认128M），降低NameNode的内存增长趋势。\n\n3. HDFS Federation方案。当集群和数据均达到一定规模时，仅通过垂直扩展NameNode已不能很好的支持业务发展，可以考虑HDFS Federation方案实现对NameNode的水平扩展，在解决NameNode的内存问题的同时通过Federation可以达到良好的隔离性，不会因为单一应用压垮整集群。\n\n### 五、总结\n\nNameNode在整个HDFS系统架构中占据举足轻重的位置，内部数据和处理逻辑相对复杂，本文简单梳理了NameNode的内存全景及对其中几个关键数据结构，从NameNode内存核心数据视角对NameNode进行了简单的解读，并结合实际场景介绍了随着数据规模的增加，NameNode内存可能遇到的问题及业界各种可借鉴的解决方案。在后续的《HDFS NameNode内存详解》中，我们会详细解读NameNode的几个关键数据结构，分析各数据结构在JVM Heap使用占比情况。\n\n### 六、参考\n\n[1] Apache Hadoop, 2016, [https://hadoop.apache.org/](https://hadoop.apache.org/).\n[2] Apache Hadoop Source Code, 2014, [https://github.com/apache/hadoop/tree/branch-2.4.1/](https://github.com/apache/hadoop/tree/branch-2.4.1/).\n[3] HDFS Federation, 2011, [https://issues.apache.org/jira/browse/HDFS-1052](https://issues.apache.org/jira/browse/HDFS-1052).\n[4] NemeNode Scalability, 2013, [https://issues.apache.org/jira/browse/HDFS-5389](https://issues.apache.org/jira/browse/HDFS-5389).\n[5] Baidu HDFS2, 2013, [http://static.zhizuzhefu.com/wordpress_cp/uploads/2013/04/a9.pdf](http://static.zhizuzhefu.com/wordpress_cp/uploads/2013/04/a9.pdf).\n[6] Taobao HDFS2, 2012, [https://github.com/taobao/ADFS](https://github.com/taobao/ADFS).\n\n---\n\n* 原文链接：[HDFS NameNode 内存全景](http://tech.meituan.com/namenode.html)\n","tags":["NameNode"],"categories":["HDFS"]},{"title":"算法的性能分析","url":"%2F2016%2F2016-08-20-algorithm-performance%2F","content":"\n在程序设计中算法的性能分析是非常重要的，针对一个具体的问题可能提出若干种不同的算法实现。如何从这些算法种找出性能最优的那个？或者说针对一个具体的算法如何评论它的优劣？这里要涉及的一个问题就是如何对算法的性能进行评价？评价算法的性能主要从两个方面着手：\n\n1. 算法的执行时间\n2. 算法所占用的存储空间\n\n这两个指标分别对应算法的`时间复杂度`与`空间复杂度`，下面分别来说.\n\n# 算法的时间复杂度\n\n## 定义\n\n算法的时间复杂度的目的是为了近似的评估算法的执行时间，因为要准确测量一个算法的执行时间多少是非常困难的，它受到计算机软硬件环境的影响。它的定义是这样的:\n\n`T(n) = O(f(n))`\n\n它表示随问题规模n的增大，算法的执行时间的增长率和算法中语句的总的执行次数`f(n)`的增长率相同，称作算法的渐近时间复杂度，简称时间复杂度。其中这里O来表示数量级，`f(n)`一般是算法中频度最大的语句频度.\n\n## 如何求时间复杂度\n\n要求算法的时间复杂度, 关键就在于找到这个算法中执行频度最大的那条语句`f(n)`, 找到了`f(n)`那么时间复杂度`T(n)`自然就出来了.\n\n下面举例说明:\n\n1. 常数阶\n\n```\nO(1)\n\ntemp = i;\ni = j;\nj = temp;\n```\n\n以上3条语句的语句频度都为1, 而且该程序段的执行时间是一个与问题规模`n`无关的常数. 这种类型的算法的时间复杂度:`T(n)=O(1)`.\n\n2. 线性型\n\n```\nO(n)\n\nfor (int i = 0; i < n; i++){\n  n++; //频度最大\n}\n```\n\n很显然这种类型的算法的语句频度与问题规模n刚好是呈正线性相关的, 时间复杂度为`T(n) = O(n)`.\n\n3. 平方型\n\n```\nO(n2)\n\nint[] a = {3, 2, 4, 7, ..., n}\nfor(int i = 0; i < n - 1; i++){\n\tfor (int j = i + 1; j < n; j++){\n\t\tif(a[i] > a[j]){ // do swap, f(n)= n * n\n\t\t\tint temp = a[i]; //频度最大\n\t\t\ta[i] = a[j];\n\t\t\ta[j] = temp;\n\t\t}\n\t}\n}\n```\n\n当有若干个循环语句时, 算法的时间复杂度是由嵌套最深的循环语句中最内层的语句的频度`f(n)`决定.而忽略其它嵌套层次更低的循环.\n\n4. 立方型\n\n```\nO(n3)\n\nfor i..n\n  for ...\n    for ...\n      do something... //频度最大\n```\n\n## 常见的时间复杂度\n\n    O(1)常数型\n    O(log2n)对数型\n    O(nlog2n)二维型\n    O(n)线性型\n    O(n2)平方型\n    O(n3)立方型\n    O(2n)指数型\n\n![时间复杂度图示](/assets/images/2016/08/20/algorithm-performance/algorithm.jpeg)\n\n一般情况下, 随问题规模`n`的增大, 时间复杂度`T(n)`增长最慢的算法为最优算法. 以上几种算法随`n`的不断最加时间复杂度增加越来越快, 因此一般应该选择使用`O(nk)`的算法. 避免使用指数阶的算法.\n\n## 最坏时间复杂度与平均时间复杂度\n\n算法的时间复杂度不仅与问题规模`n`相关还与输入实例的初始状态有关.\n\n看个例子:\n\n```\nT(n) = O(n)\n\ni = n - 1;\nwhile(i >= 0 && (a[i] != k))\n  i--;\n```\n\n上述算法的时间复杂度不仅与`n`相关还与输入的数组a及k的取值情况相关:\n\n最坏情况: 数组`a`中没有与`k`相等的元素.则语句3的频度`f(n) = n`, 时间复杂度`T(n) = O(n)`\n\n最好情况: 或`a`中最后一个元素等于`k`,则语句3的频度`f(n) = 0`, 时间复杂度`T(n) = O(1)`\n\n一般不特别说明, 讨论的时间复杂度均是最坏情况下的时间复杂度, 这样做的原因是能够保证算法在任何输入实例情况下都能够被考虑到. 而平均时间复杂度是指所有可能的输入实例均以等概率出现的情况下的时间复杂度.\n\n因此上述算法的时间复杂度为: `O(n)`\n\n# 算法的空间复杂度\n\n## 辅助存储空间\n\n一般情况下, 一个程序在机器上执行时, 除了需要存储本身所需要的代码/输入数据外, 还需要一些对数据进行操作的辅助存储空间.其中输入数据所占用的具体空间取决于问题本身, 与算法无关. 因此我们所讨论的空间复杂度只与该算法在实现时所需要的辅助空间单元个数相关. 即 空间复杂度讨论的是算法所需要的辅助存储空间.\n\n## 定义\n\n算法的空间复杂度`S(n)`定义为该算法所耗费的存储空间的数量级, 它是问题规模n的函数, 记作:\n\n`S(n) = O(f(n))`\n\n若算法执行时间时所需要的辅助空间相对于输入数据量而言是一个常数, 则称这个算法为原地工作, 辅助空间为`O(1)`. 看个例子:\n将一维数组`a`中的`n`个数据逆序存放到原数组中, 下面是两种算法:\n\n[算法1]\n\n```\nS(n) = O(n)\n\nfor(i = 0; i < n; i++)\n  b[i] = a[n - i - 1];\nfor(i = 0; i < n; i++)\n  a[i] = b[i]\n```\n\n[算法2]\n\n```\nS(n) = O(1)\n\nfor(i=0; i < n/2; i++){\n  t = a[i];\n  a[i] = a[n - i - 1];\n  a[n - i - 1] = t;\n}\n```\n\n算法1的空间复杂度为`O(n)`, 需要一个大小为`n`的辅助数组`b`\n\n算法2的空间复杂度为`O(1)`, 仅需要一个变量`t`, 与问题规模`n`无关\n\n# 总结\n\n算法的空间复杂度与时间复杂度合称为算法的复杂度. 面对不同的算法如何选择主要就从这两个方面去考虑, 理想情况是一个算法的时间与空间复杂度都小, 但这是很难做到的, 面对不同的情况要具体问题具体分析: 是以时间换空间, 还是以空间换时间.\n\n# 参考\n\n[数据结构-用C语言描述](https://book.douban.com/subject/10506484/)\n\n---\n\n* Author: [CoderGhui](https://ghui.me/)\n* Link: [算法的性能分析](https://ghui.me/post/2016/08/algorithm_performance/)","tags":["Performance"],"categories":["Algorithm"]},{"title":"分布式队列编程优化篇","url":"%2F2016%2F2016-08-05-distributed-queue-based-programming-optimization%2F","content":"\n## 前言\n\n“分布式队列编程”是一个系列文，之前我们已经发布了《分布式队列编程模型、实战》，主要剖析了分布式队列编程模型的需求来源、定义、结构以及其变化多样性；根据作者在新美大实际工作经验，给出了队列式编程在分布式环境下的一些具体应用。本文将重点阐述工程师运用分布式队列编程构架的时候，在生产者、分布式队列以及消费者这三个环节的注意点以及优化建议。\n\n确定采用分布式队列编程模型之后，主体架构就算完成了，但工程师的工作还远远未结束。天下事必做于细，细节是一个不错的架构向一个优秀的系统进阶的关键因素。优化篇选取了作者以及其同事在运用分布式队列编程模型架构时所碰到的典型问题和解决方案。这里些问题出现的频率较高，如果你经验不够，很可能会“踩坑”。希望通过这些讲解，帮助读者降低分布式队列编程模型的使用门槛。本文将对分布式队列编程模型的三种角色：生产者（Producer），分布式队列（Queue），消费者（Consumer）分别进行优化讨论。\n\n## 生产者优化\n\n在分布式队列编程中，生产者往往并非真正的生产源头，只是整个数据流中的一个节点，这种生产者的操作是处理－转发（Process-Forward）模式。\n\n这种模式给工程师们带来的第一个问题是吞吐量问题。这种模式下运行的生产者，一边接收上游的数据，一边将处理完的数据发送给下游。本质上，它是一个非常经典的数学问题，其抽象模型是一些没有盖子的水箱，每个水箱接收来自上一个水箱的水，进行处理之后，再将水发送到下一个水箱。工程师需要预测水源的流量、每个环节水箱的处理能力、水龙头的排水速度，最终目的是避免水溢出水箱，或者尽可能地减小溢出事件的概率。实际上流式编程框架以及其开发者花了大量的精力去处理和优化这个问题。下文的缓存优化和批量写入优化都是针对该问题的解决方案。\n\n第二个需要考虑的问题是持久化。由于各种原因，系统总是会宕机。如果信息比较敏感，例如计费信息、火车票订单信息等，工程师们需要考虑系统宕机所带来的损失，找到让损失最小化的解决方案。持久化优化重点解决这一类问题。\n\n### 缓存优化\n\n处于“处理－转发”模式下运行的生产者往往被设计成请求驱动型的服务，即每个请求都会触发一个处理线程，线程处理完后将结果写入分布式队列。如果由于某种原因队列服务不可用，或者性能恶化，随着新请求的到来，生产者的处理线程就会产生堆积。这可能会导致如下两个问题：\n\n* 系统可用性降低。由于每个线程都需要一定的内存开销，线程过多会使系统内存耗尽，甚至可能产生雪崩效应导致最终完全不可用。\n\n* 信息丢失。为了避免系统崩溃，工程师可能会给请求驱动型服务设置一个处理线程池，设置最大处理线程数量。这是一种典型的降级策略，目的是为了系统崩溃。但是，后续的请求会因为没有处理线程而被迫阻塞，最终可能产生信息丢失。例如：对于广告计费采集，如果采集系统因为线程耗尽而不接收客户端的计费行为，这些计费行为就会丢失。\n\n缓解这类问题的思路来自于CAP理论，即通过降低一致性来提高可用性。生产者接收线程在收到请求之后第一时间不去处理，直接将请求缓存在内存中（牺牲一致性），而在后台启动多个处理线程从缓存中读取请求、进行处理并写入分布式队列。与线程所占用的内存开销相比，大部分的请求所占内存几乎可以忽略。通过在接收请求和处理请求之间增加一层内存缓存，可以大大提高系统的处理吞吐量和可扩展性。这个方案本质上是一个内存生产者消费者模型。\n\n### 批量写入优化\n\n如果生产者的请求过大，写分布式队列可能成为性能瓶颈，有如下几个因素：\n\n* 队列自身性能不高。\n\n* 分布式队列编程模型往往被应用在跨机房的系统里面，跨机房的网络开销往往容易成为系统瓶颈。\n\n* 消息确认机制往往会大大降低队列的吞吐量以及响应时间。\n\n如果在处理请求和写队列之间添加一层缓存，消息写入程序批量将消息写入队列，可以大大提高系统的吞吐量。原因如下：\n\n* 批量写队列可以大大减少生产者和分布式队列的交互次数和消息传输量。特别是对于高吞吐小载荷的消息实体，批量写可以显著降低网络传输量。\n\n* 对于需要确认机制的消息，确认机制往往会大大降低队列的吞吐量以及响应时间，某些高敏感的消息需要多个消息中间件代理同时确认，这近一步恶化性能。在生产者的应用层将多条消息批量组合成一个消息体，消息中间件就只需要对批量消息进行一次确认，这可能会数量级的提高消息传输性能。\n\n### 持久化优化\n\n通过添加缓存，消费者服务的吞吐量和可用性都得到了提升。但缓存引入了一个新问题——内存数据丢失。对于敏感数据，工程师需要考虑如下两个潜在问题：\n\n* 如果内存中存在未处理完的请求，而某些原因导致生产者服务宕机，内存数据就会丢失而可能无法恢复。\n\n* 如果分布式队列长时间不可用，随着请求数量的不断增加，最终系统内存可能会耗尽而崩溃，内存的消息也可能丢失。\n\n所以缓存中的数据需要定期被持久化到磁盘等持久层设备中，典型的持久化触发策略主要有两种：\n\n* 定期触发，即每隔一段时间进行一次持久化。\n\n* 定量触发，即每当缓存中的请求数量达到一定阈值后进行持久化。\n   是否需要持久化优化，以及持久化策略应该由请求数据的敏感度、请求量、持久化性能等因素共同决定。\n\n## 中间件选型\n\n分布式队列不等同于各种开源的或者收费的消息中间件，甚至在一些场景下完全不需要使用消息中间件。但是，消息中间件产生的目的就是解决消息传递问题，这为分布式队列编程架构提供了很多的便利。在实际工作中，工程师们应该将成熟的消息中间件作为队列的首要备选方案。\n\n本小节对消息中间件的功能、模型进行阐述，并给出一些消息中间件选型、部署的具体建议。\n\n### 中间件的功能\n\n明白一个系统的每个具体功能是设计和架构一个系统的基础。典型的消息中间件主要包含如下几个功能：\n\n* 消息接收\n\n* 消息分发\n\n* 消息存储\n\n* 消息读取\n\n### 概念模型\n\n抽象的消息中间件模型包含如下几个角色：\n\n* 发送者和接收者客户端（Sender/Receiver Client），在具体实施过程中，它们一般以库的形式嵌入到应用程序代码中。\n\n* 代理服务器（Broker Server），它们是与客户端代码直接交互的服务端代码。\n\n* 消息交换机（Exchanger），接收到的消息一般需要通过消息交换机（Exchanger）分发到具体的消息队列中。\n\n* 消息队列，一般是一块内存数据结构或持久化数据。\n\n概念模型如下图：\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/messagequeue.png)\n\n为了提高分发性能，很多消息中间件把消息代理服务器的拓扑图发送到发送者和接收者客户端（Sender/Receiver Client），如此一来，发送源可以直接进行消息分发。\n\n### 选型标准\n\n要完整的描述消息中间件各个方面非常困难，大部分良好的消息中间件都有完善的文档，这些文档的长度远远超过本文的总长度。但如下几个标准是工程师们在进行消息中间件选型时经常需要考虑和权衡的。\n\n#### 性能\n\n性能主要有两个方面需要考虑：吞吐量（Throughput）和响应时间（Latency）。\n\n不同的消息队列中间件的吞吐量和响应时间相差甚远，在选型时可以去网上查看一些性能对比报告。\n\n对于同一种中间件，不同的配置方式也会影响性能。主要有如下几方面的配置：\n\n* 是否需要确认机制，即写入队列后，或从队列读取后，是否需要进行确认。确认机制对响应时间的影响往往很大。\n\n* 能否批处理，即消息能否批量读取或者写入。批量操作可以大大减少应用程序与消息中间件的交互次数和消息传递量，大大提高吞吐量。\n\n* 能否进行分区（Partition）。将某一主题消息队列进行分区，同一主题消息可以有多台机器并行处理。这不仅仅能影响消息中间件的吞吐量，还决定着消息中间件是否具备良好的可伸缩性（Scalability）。\n\n* 是否需要进行持久化。将消息进行持久化往往会同时影响吞吐量和响应时间。\n\n#### 可靠性\n\n可靠性主要包含：可用性、持久化、确认机制等。\n\n高可用性的消息中间件应该具备如下特征：\n\n* 消息中间件代理服务器（Broker）具有主从备份。即当一台代理服务宕机之后，备用服务器能接管相关的服务。\n\n* 消息中间件中缓存的消息是否有备份、并持久化。\n   根据CAP理论，高可用、高一致性以及网络分裂不可兼得。根据作者的观察，大部分的消息中间件在面临网络分裂的情况下下，都很难保证数据的一致性以及可用性。 很多消息中间件都会提供一些可配置策略，让使用者在可用性和一致性之间做权衡。\n\n高可靠的消息中间件应该确保从发送者接收到的消息不会丢失。中间件代理服务器的宕机并不是小概率事件，所以保存在内存中的消息很容易发生丢失。大部分的消息中间件都依赖于消息的持久化去降低消息丢失损失，即将接收到的消息写入磁盘。即使提供持久化，仍有两个问题需要考虑：\n\n* 磁盘损坏问题。长时间来看，磁盘出问题的概率仍然存在。\n\n* 性能问题。与操作内存相比，磁盘I/O的操作性能要慢几个数量级。频繁持久化不仅会增加响应时间，也会降低吞吐量。\n   解决这两个问题的一个解决方案就是：多机确认，定期持久化。即消息被缓存在多台机器的内存中，只有每台机器都确认收到消息，才跟发送者确认（很多消息中间件都会提供相应的配置选项，让用户设置最少需要多少台机器接收到消息）。由于多台独立机器同时出故障的概率遵循乘法法则，指数级降低，这会大大提高消息中间件的可靠性。\n\n确认机制本质上是通讯的握手机制（Handshaking）。如果没有该机制，消息在传输过程中丢失将不会被发现。高敏感的消息要求选取具备确认机制的消息中间件。当然如果没有接收到消息中间件确认完成的指令，应用程序需要决定如何处理。典型的做法有两个：\n\n* 多次重试。\n\n* 暂存到本地磁盘或其它持久化媒介。\n\n#### 客户端接口所支持语言\n\n采用现存消息中间件就意味着避免重复造轮子。如果某个消息中间件未能提供对应语言的客户端接口，则意味着极大的成本和兼容性问题。\n\n#### 投递策略（Delivery policies）\n\n投递策略指的是一个消息会被发送几次。主要包含三种策略：最多一次（At most Once ）、最少一次（At least Once）、仅有一次（Exactly Once）。\n\n在实际应用中，只考虑消息中间件的投递策略并不能保证业务的投递策略，因为接收者在确认收到消息和处理完消息并持久化之间存在一个时间窗口。例如，即使消息中间件保证仅有一次（Exactly Once），如果接收者先确认消息，在持久化之前宕机，则该消息并未被处理。从应用的角度，这就是最多一次（At most Once）。反之，接收者先处理消息并完成持久化，但在确认之前宕机，消息就要被再次发送，这就是最少一次（At least Once）。 如果消息投递策略非常重要，应用程序自身也需要仔细设计。\n\n## 消费者优化\n\n消费者是分布式队列编程中真正的数据处理方，数据处理方最常见的挑战包括：有序性、串行化（Serializability）、频次控制、完整性和一致性等。\n\n### 挑战\n\n#### 有序性\n\n在很多场景下，如何保证队列信息的有序处理是一个棘手的问题。如下图，假定分布式队列保证请求严格有序，请求ri2和ri1都是针对同一数据记录的不同状态，ri2的状态比ri1的状态新。T1、T2、T3和T4代表各个操作发生的时间，并且 T1 < T2 < T3 < T4（\"<\"代表早于）。\n\n采用多消费者架构，这两条记录被两个消费者（Consumer1和Consumer2）处理后更新到数据库里面。Consumer1虽然先读取ri1但是却后写入数据库，这就导致，新的状态被老的状态覆盖，所以多消费者不保证数据的有序性。\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/sequence.png)\n\n#### 串行化\n\n很多场景下，串行化是数据处理的一个基本需求，这是保证数据完整性、可恢复性、事务原子性等的基础。为了在并行计算系统里实现串行化，一系列的相关理论和实践算法被提出。对于分布式队列编程架构，要在在多台消费者实现串行化非常复杂，无异于重复造轮子。\n\n#### 频次控制\n\n有时候，消费者的消费频次需要被控制，可能的原因包括：\n\n* 费用问题。如果每次消费所引起的操作都需要收费，而同一个请求消息在队列中保存多份，不进行频次控制，就会导致无谓的浪费。\n\n* 性能问题。每次消费可能会引起对其他服务的调用，被调用服务希望对调用量有所控制，对同一个请求消息的多次访问就需要有所控制。\n\n#### 完整性和一致性\n\n完整性和一致性是所有多线程和多进程的代码都面临的问题。在多线程或者多进程的系统中考虑完整性和一致性往往会大大地增加代码的复杂度和系统出错的概率。\n\n### 单例服务优化\n\n几乎所有串行化理论真正解决的问题只有一个：性能。 所以，在性能允许的前提下，对于消费者角色，建议采用单实例部署。通过单实例部署，有序性、串行化、完整性和一致性问题自动获得了解决。另外，单实例部署的消费者拥有全部所需信息，它可以在频次控制上采取很多优化策略。\n\n天下没有免费的午餐。同样，单实例部署并非没有代价，它意味着系统可用性的降低，很多时候，这是无法接受的。解决可用性问题的最直接的思路就是冗余（Redundancy）。最常用的冗余方案是Master-slave架构，不过大部分的Master-slave架构都是Active/active模式，即主从服务器都提供服务。例如，数据库的Master-slave架构就是主从服务器都提供读服务，只有主服务器提供写服务。大部分基于负载均衡设计的Master-slave集群中，主服务器和从服务器同时提供相同的服务。这显然不满足单例服务优化需求。有序性和串行化需要Active/passive架构，即在某一时刻只有主实例提供服务，其他的从服务等待主实例失效。这是典型的领导人选举架构，即只有获得领导权的实例才能充当实际消费者，其他实例都在等待下一次选举。采用领导人选举的Active/passive架构可以大大缓解纯粹的单实例部署所带来的可用性问题。\n\n令人遗憾的是，除非工程师们自己在消费者实例里面实现Paxos等算法，并在每次消息处理之前都执行领导人选举。否则，理论上讲，没有方法可以保障在同一个时刻只有一个领导者。而对每个消息都执行一次领导人选举，显然性能不可行。实际工作中，最容易出现的问题时机发生在领导人交接过程中，即前任领导人实例变成辅助实例，新部署实例开始承担领导人角色。为了平稳过渡，这两者之间需要有一定的通讯机制，但是，无论是网络分区（Network partition）还是原领导人服务崩溃都会使这种通讯机制变的不可能。\n\n对于完整性和一致性要求很高的系统，我们需要在选举制度和交接制度这两块进行优化。\n\n#### 领导人选举架构\n\n典型的领导人选举算法有Paxos、ZAB（ ZooKeeper Atomic Broadcast protocol）。为了避免重复造轮子，建议采用ZooKeeper的分布式锁来实现领导人选举。典型的ZooKeeper实现算法如下（摘自参考资料[4]）：\n\n> Let ELECTION be a path of choice of the application. To volunteer to be a leader:\n> \n> 1.Create znode z with path \"ELECTION/guid-n_\" with both SEQUENCE and EPHEMERAL flags;\n> 2.Let C be the children of \"ELECTION\", and i be the sequence number of z;\n> 3.Watch for changes on \"ELECTION/guid-n_j\", where j is the largest sequence number such that j < i and n_j is a znode in C;\n> \n> Upon receiving a notification of znode deletion:\n> \n> 1.Let C be the new set of children of ELECTION;\n> 2.If z is the smallest node in C, then execute leader procedure;\n> 3.Otherwise, watch for changes on \"ELECTION/guid-n_j\", where j is the largest sequence number such that j < i and n_j is a znode in C;\n\n#### 领导人交接架构\n\n领导人选举的整个过程发生在ZooKeeper集群中，各个消费者实例在这场选举中只充当被告知者角色（Learner）。领导人选举算法，只能保证最终只有一个Leader被选举出来，并不保障被告知者对Leader的理解是完全一致的。本质上，上文的架构里，选举的结果是作为令牌（Token）传递给消费者实例，消费者将自身的ID与令牌进行对比，如果相等，则开始执行消费操作。所以当发生领导人换届的情况，不同的Learner获知新Leader的时间并不同。例如，前任Leader如果因为网络问题与ZooKeeper集群断开，前任Leader只能在超时后才能判断自己是否不再承担Leader角色了，而新的Leader可能在这之前已经产生。另一方面，即使前任Leader和新Leader同时接收到新Leader选举结果，某些业务的完整性要求迫使前任Leader仍然完成当前未完成的工作。以上的讲解非常抽象，生活中却给了一些更加具体的例子。众所周知，美国总统候选人在选举结束后并不直接担任美国总统，从选举到最终承担总统角色需要一个过渡期。对于新当选Leader的候选人而言，过渡期间称之为加冕阶段（Inauguration）。对于即将卸任的Leader，过渡期称为交接阶段（HandOver）。所以一个基于领导人选举的消费者从加冕到卸任经历三个阶段：Inauguration、Execution、HandOver。在加冕阶段，新领导需要进行一些初始化操作。Execution阶段是真正的队列消息处理阶段。在交接阶段，前任领导需要进行一些清理操作。\n\n类似的，为了解决领导人交接问题，所有的消费者从代码实现的角度都需要实现类似ILeaderCareer接口。这个接口包含三个方发inaugurate()，handOver()和execute（）。某个部署实例（Learner）在得知自己承担领导人角色后，需要调用inaugurate()方法，进行加冕。主要的消费逻辑通过不停的执行execute（）实现，当确认自己不再承担领导人之后，执行handOver()进行交接。\n\n```java\npublic interface ILeaderCareer {\n    public void inaugurate();\n    public void handOver();\n    public boolean execute();\n}\n```\n\n如果承担领导人角色的消费者，在执行execute（）阶段得知自己将要下台，根据消息处理的原子性，该领导人可以决定是否提前终止操作。如果整个消息处理是一个原子性事务，直接终止该操作可以快速实现领导人换届。否则，前任领导必须完成当前消息处理后，才进入交接阶段。这意味着新的领导人，在inaugurate()阶段需要进行一定时间的等待。\n\n### 排重优化\n\n频次控制是一个经典问题。对于分布式队列编程架构，相同请求重复出现在队列的情况并不少见。如果相同请求在队列中重复太多，排重优化就显得很必要。分布式缓存更新是一个典型例子，所有请求都被发送到队列中用于缓存更新。如果请求符合典型的高斯分布，在一段时间内会出现大量重复的请求，而同时多线程更新同一请求缓存显然没有太大的意义。\n\n排重优化是一个算法，其本质是基于状态机的编程，整个讲解通过模型、构思和实施三个步骤完成。\n\n#### 模型\n\n进行排重优化的前提是大量重复的请求。在模型这一小节，我们首先阐述重复度模型、以及不同重复度所导致的消费模型，最后基于这两个模型去讲解排重状态机。\n\n##### 重复度模型\n\n首先我们给出最小重复长度的概念。同一请求最小重复长度：同一请求在队列中的重复出现的最小间距。例如，请求ri第一次出现在位置3，第二次出现在10，最小重复长度等于7。\n\n是否需要进行排重优化取决于队列中请求的重复度。由于不同请求之间并不存在重复的问题，不失一般性，这里的模型只考了单个请求的重复度，重复度分为三个类：无重复、稀疏重复、高重复。\n\n* 无重复：在整个请求过程，没有任何一个请求出现一次以上。\n* 稀疏重复：主要的请求最小重复长度大于消费队列长度。\n* 高重复：大量请求最小重复长度小于消费队列长度。\n\n对于不同的重复度，会有不同的消费模型。\n\n##### 无重复消费模型\n\n在整个队列处理过程中，所有的请求都不相同，如下图：\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/nondup.png)\n\n##### 稀疏重复消费模型\n\n当同一请求最小重复长度大于消费者队列长度，如下图。假定有3个消费者，Consumer1将会处理r1，Consumer2将会处理r2，Consumer3将会处理r3，如果每个请求处理的时间严格相等，Consumer1在处理完r1之后，接着处理r4，Consumer2将会处理r2之后会处理r1。虽然r1被再次处理，但是任何时刻，只有这一个消费者在处理r1，不会出现多个消费者同时处理同一请求的场景。\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/sparsedup.png)\n\n##### 高重复消费模型\n\n如下图，仍然假定有3个消费者，队列中前面4个请求都是r1，它会同时被3个消费者线程处理：\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/highdup.png)\n\n显然，对于无重复和稀疏重复的分布式队列，排重优化并不会带来额外的好处。排重优化所针对的对象是高重复消费模型，特别是对于并行处理消费者比较多的情况，重复处理同一请求，资源消耗极大。\n\n##### 排重状态机\n\n排重优化的主要对象是高重复的队列，多个消费者线程或进程同时处理同一个幂等请求只会浪费计算资源并延迟其他待请求处理。所以，排重状态机的一个目标是处理唯一性，即：同一时刻，同一个请求只有一个消费者处理。如果消费者获取一条请求消息，但发现其他消费者正在处理该消息，则当前消费者应该处于等待状态。如果对同一请求，有一个消费者在处理，一个消费者在等待，而同一请求再次被消费者读取，再次等待则没有意义。所以，状态机的第二个目标是等待唯一性，即：同一时刻，同一个请求最多只有一个消费者处于等待状态。总上述，状态机的目标是：处理唯一性和等待唯一性。我们把正在处理的请求称为头部请求，正在等待的请求称为尾部请求。\n\n由于状态机的处理单元是请求，所以需要针对每一个请求建立一个排重状态机。基于以上要求，我们设计的排重状态机包含4个状态Init，Process，Block，Decline。各个状态之间转化过程如下图：\n\n![](/images/2016/08/05/distributed_queue_based_programming_optimization/dedup-automate.png)\n\n* 状态机创建时处于Init状态。\n\n* 对Init状态进行Enqueue操作，即接收一个请求，开始处理（称为头部请求），状态机进入Process状态。\n\n* 状态机处于Process状态，表明当前有消费者正在处理头部请求。此时，如果进行Dequeue操作，即头部请求处理完成，返回Init状态。如果进行Enqueue操作，即另一个消费者准备处理同一个请求，状态机进入Block状态（该请求称为尾部请求）。\n\n* 状态机处于Block状态，表明头部请求正在处理，尾部请求处于阻塞状态。此时，进行Dequeue操作，即头部请求处理完成，返回Process状态，并且尾部请求变成头部请求，原尾部请求消费者结束阻塞状态，开始处理。进行Enqueue操作，表明一个新的消费者准备处理同一个请求，状态机进入Decline状态。\n\n* 状态机进入Decline状态，根据等待唯一性目标，处理最新请求的消费者将被抛弃该消息，状态机自动转换回Block状态。\n\n#### 构思\n\n状态机描述的是针对单个请求操作所引起状态变化，排重优化需要解决队列中所有请求的排重问题，需要对所有请求的状态机进行管理。这里只考虑单虚拟机内部对所有请求状态机的管理，对于跨虚拟机的管理可以采用类似的方法。对于多状态机管理主要包含三个方面：一致性问题、完整性问题和请求缓存驱逐问题。\n\n##### 一致性问题\n\n一致性在这里要求同一请求的不同消费者只会操作一个状态机。由于每个请求都产生一个状态机，系统将会包含大量的状态机。为了兼顾性能和一致性，我们采用ConcurrentHashMap保存所有的状态机。用ConcurrentHashMap而不是对整个状态机队列进行加锁，可以提高并行处理能力，使得系统可以同时操作不同状态机。为了避免处理同一请求的多消费者线程同时对ConcurrentHashMap进行插入所导致状态机不一致问题，我们利用了ConcurrentHashMap的putIfAbsent（）方法。代码方案如下，key2Status用于存储所有的状态机。消费者在处理请求之前，从状态机队列中读取排重状态机TrafficAutomate。如果没有找到，则创建一个新的状态机，并通过putIfAbsent（）方法插入到状态机队列中。\n\n```java\nprivate ConcurrentHashMap<T, TrafficAutomate> key2Status = new ConcurrentHashMap();\nTrafficAutomate trafficAutomate = key2Status.get(key);\nif(trafficAutomate == null)\n{\n    trafficAutomate = new TrafficAutomate();\n    TrafficAutomate oldAutomate = key2Status.putIfAbsent(key, trafficAutomate);\n    if(oldAutomate != null)\n    {\n        trafficAutomate = oldAutomate;\n    }\n}\n```\n\n##### 完整性问题\n\n完整性要求保障状态机Init，Process，Block，Decline四种状态正确、状态之间的转换也正确。由于状态机的操作非常轻量级，兼顾完整性和降低代码复杂度，我们对状态机的所有方法进行加锁。\n\n##### 请求缓存驱逐问题（Cache Eviction）\n\n如果不同请求的数量太多，内存永久保存所有请求的状态机的内存开销太大。所以，某些状态机需要在恰当的时候被驱逐出内存。这里有两个思路：\n\n* 当状态机返回Init状态时，清除出队列。\n\n* 启动一个后台线程，定时扫描状态机队列，采用LRU等标准缓存清除机制。\n\n##### 标识问题\n\n每个请求对应于一个状态机，不同的状态机采用不同的请求进行识别。\n\n对于同一状态机的不同消费者，在单虚拟机方案中，我们采用线程id进行标识。\n\n#### 实施\n\n排重优化的主要功能都是通过排重状态机（TrafficAutomate）和状态机队列（QueueCoordinator）来实施的。排重状态机描述的是针对单个请求的排重问题，状态机队列解决所有请求状态机的排重问题。\n\n##### 状态机实施（TrafficAutomate）\n\n根据状态机模型，其主要操作为enQueue和deQueue，其状态由头部请求和尾部请求的状态共同决定，所以需要定义两个变量为head和tail，用于表示头部请求和尾部请求。为了确保多线程操作下状态机的完整性（Integraty），所有的操作都将加上锁。\n\n###### enQueue操作\n\n当一个消费者执行enQueue操作时：如果此时尾部请求不为空，根据等待唯一性要求，返回DECLINE，当前消费者应该抛弃该请求；如果头部请求为空，返回ACCPET，当前消费者应该立刻处理该消息；否则，返回BLOCK，该消费者应该等待，并不停的查看状态机的状态，一直到头部请求处理完成。enQueue代码如下：\n\n```java\nsynchronized ActionEnum enQueue(long id)\n{ \n    if(tail != INIT_QUEUE_ID)\n    {\n        return DECLINE;\n    }\n\n    if(head == INIT_QUEUE_ID)\n    {\n        head = id;\n        return ACCEPT;\n    }\n    else\n    {\n        tail = id;\n        return BLOCK;\n    }\n｝\n```\n\n###### deQueue操作\n\n对于deQueue操作，首先将尾部请求赋值给头部请求，并将尾部请求置为无效。deQueue代码如下：\n\n```java\nsynchronized boolean deQueue(long id)\n{\n        head = tail;\n        tail = INIT_QUEUE_ID;\n        return true;\n}\n```\n\n##### 状态机队列实施(QueueCoordinator)\n\n###### 接口定义\n\n状态机队列集中管理所有请求的排重状态机，所以其操作和单个状态机一样，即enQueue和deQueuqe接口。这两个接口的实现需要识别特定请求的状态机，所以它们的入参应该是请求。为了兼容不同类型的请求消息，我们采用了Java泛型编程。接口定义如下：\n\n```java\npublic interface QueueCoordinator<T> {\n\n    public boolean enQueue(T key);\n\n    public void deQueue(T key);\n\n}\n```\n\n###### enQueue操作\n\nenQueue操作过程如下：\n\n首先，根据传入的请求key值，获取状态机， 如果不存在则创建一个新的状态机，并保存在ConcurrentHashMap中。\n\n接下来，获取线程id作为该消费者的唯一标识，并对对应状态机进行enQueue操作。\n\n如果状态机返回值为ACCEPT或者DECLINE，返回业务层处理代码，ACCEPT意味着业务层需要处理该消息，DECLINE表示业务层可以抛弃当前消息。如果状态机返回值为Block，则该线程保持等待状态。\n\n异常处理。在某些情况下，头部请求线程可能由于异常，未能对状态机进行deQueue操作（作为组件提供方，不能假定所有的规范被使用方实施）。为了避免处于阻塞状态的消费者无期限地等待，建议对状态机设置安全超时时限。超过了一定时间后，状态机强制清空头部请求，返回到业务层，业务层开始处理该请求。\n\n代码如下：\n\n```java\npublic boolean enQueue(T key) {\n    _loggingStastic();\n\n    TrafficAutomate trafficAutomate = key2Status.get(key);\n    if(trafficAutomate == null)\n    {\n        trafficAutomate = new TrafficAutomate();\n        TrafficAutomate oldAutomate = key2Status.putIfAbsent(key, trafficAutomate);\n        if(oldAutomate != null)\n        {\n            trafficAutomate = oldAutomate;\n        }\n    }\n    long threadId = Thread.currentThread().getId();\n\n    ActionEnum action = trafficAutomate.enQueue(threadId);\n\n    if(action == DECLINE)\n    {\n        return false;\n    }\n    else if (action == ACCEPT)\n    {\n        return true;\n    }\n    //Blocking status means some other thread are working on this key, so just wait till timeout\n    long start = System.currentTimeMillis();\n    long span = 0;\n    do {\n        _nonExceptionSleep(NAP_TIME_IN_MILL);\n\n        if(trafficAutomate.isHead(threadId))\n        {\n            return true;\n        }\n\n        span = System.currentTimeMillis() - start;\n    }while(span <= timeout);\n\n    //remove head so that it won't block the queue for too long\n    trafficAutomate.evictHeadByForce(threadId);\n\n    return true;\n}\n```\n\n###### deQueue操作\n\ndeQueue操作首先从ConcurrentHashMap获取改请求所对应的状态机，接着获取该线程的线程id，对状态机进行deQueue操作。\n\nenQueue代码如下：\n\n```java\npublic void deQueue(T key) {\n    TrafficAutomate trafficAutomate = key2Status.get(key);\n\n    if(trafficAutomate == null)\n    {\n        logger.error(\"key {} doesn't exist \", key);\n        return;\n    }\n\n    long threadId = Thread.currentThread().getId();\n\n    trafficAutomate.deQueue(threadId)；\n}\n```\n\n##### 源代码\n\n完整源代码可以在[QueueCoordinator](https://github.com/dinglau2008/QueueCoordinator/tree/master/src)获取。\n\n## 参考资料\n\n[1] Rabbit MQ, [Highly Available Queues](https://www.rabbitmq.com/ha.html).\n[2] IBM Knowledge Center, [Introduction to message queuing](https://www.ibm.com/support/knowledgecenter/SSFKSJ_8.0.0/com.ibm.mq.pro.doc/q002620_.htm).\n[3] Wikipedia, [Serializability](https://en.wikipedia.org/wiki/Serializability).\n[4] Hadoop, [ZooKeeper Recipes and Solutions](https://zookeeper.apache.org/doc/trunk/recipes.html#sc_leaderElection).\n[5] [Apache Kafka](http://kafka.apache.org/documentation.html#introduction).\n[6] Lamport L, [Paxos Made Simple](http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf).\n\n---\n\n* 原文链接：[分布式队列编程优化篇](http://tech.meituan.com/distributed_queue_based_programming-optimization.html)\n","tags":["Distributed"],"categories":["Distributed"]},{"title":"深度学习中的激活函数导引","url":"%2F2016%2F2016-08-01-deep-learning-activation-function-guide%2F","content":"\n\n近年来，深度学习在计算机视觉领域取得了引人注目的成果，其中一个重要因素是激活函数的发展。新型激活函数ReLU克服了梯度消失，使得深度网络的直接监督式训练成为可能。本文将对激活函数的历史和近期进展进行总结和概括。\n\n### 激活函数的定义与作用\n\n在人工神经网络中，神经元节点的激活函数定义了对神经元输出的映射，简单来说，神经元的输出（例如，全连接网络中就是输入向量与权重向量的内积再加上偏置项）经过激活函数处理后再作为输出。加拿大蒙特利尔大学的Bengio教授在 ICML 2016 的文章[1]中给出了激活函数的定义：激活函数是映射 h:R→R，且几乎处处可导。\n\n神经网络中激活函数的主要作用是提供网络的非线性建模能力，如不特别说明，激活函数一般而言是非线性函数。假设一个示例神经网络中仅包含线性卷积和全连接运算，那么该网络仅能够表达线性映射，即便增加网络的深度也依旧还是线性映射，难以有效建模实际环境中非线性分布的数据。加入（非线性）激活函数之后，深度神经网络才具备了分层的非线性映射学习能力。因此，激活函数是深度神经网络中不可或缺的部分。\n\n### 激活函数的历史发展与近期进展\n\n从定义来看，几乎所有的连续可导函数都可以用作激活函数。但目前常见的多是分段线性和具有指数形状的非线性函数。下文将依次对它们进行总结。\n\n**Sigmoid**\n\nSigmoid 是使用范围最广的一类激活函数，具有指数函数形状 。正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/1.jpg)\n\n可见，sigmoid 在定义域内处处可导，且两侧导数逐渐趋近于0，即：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/2.jpg)\n\nBengio 教授等[1]将具有这类性质的激活函数定义为软饱和激活函数。与极限的定义类似，饱和也分为左饱和与右饱和：\n\n左饱和：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/3.jpg)\n\n右饱和：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/4.jpg)\n\n与软饱和相对的是硬饱和激活函数，即：\n\n```\nf'(x)=0，当 |x| > c，其中 c 为常数。\n```\n\n同理，硬饱和也分为左饱和和右饱和。常见的 ReLU 就是一类左侧硬饱和激活函数。\n\nSigmoid 的软饱和性，使得深度神经网络在二三十年里一直难以有效的训练，是阻碍神经网络发展的重要原因。具体来说，由于在后向传递过程中，sigmoid向下传导的梯度包含了一个f'(x) 因子（sigmoid关于输入的导数），因此一旦输入落入饱和区，f'(x) 就会变得接近于0，导致了向底层传递的梯度也变得非常小。此时，网络参数很难得到有效训练。这种现象被称为梯度消失。一般来说， sigmoid 网络在 5 层之内就会产生梯度消失现象[2]。梯度消失问题至今仍然存在，但被新的优化方法有效缓解了，例如DBN中的分层预训练，Batch Normalization的逐层归一化，Xavier和MSRA权重初始化等代表性技术。\n\nSigmoid 的饱和性虽然会导致梯度消失，但也有其有利的一面。例如它在物理意义上最为接近生物神经元。 (0, 1) 的输出还可以被表示作概率，或用于输入的归一化，代表性的如Sigmoid交叉熵损失函数\n\n**tanh**\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/5.jpg)\n\n可见，tanh(x)=2sigmoid(2x)-1，也具有软饱和性。Xavier在文献[2]中分析了sigmoid与tanh的饱和现象及特点，具体见原论文。此外，文献 [3] 中提到tanh 网络的收敛速度要比sigmoid快。因为 tanh 的输出均值比 sigmoid 更接近 0，SGD会更接近 natural gradient[4]（一种二次优化技术），从而降低所需的迭代次数。\n\n**ReLU**\n\n虽然2006年Hinton教授提出通过分层无监督预训练解决深层网络训练困难的问题，但是深度网络的直接监督式训练的最终突破，最主要的原因是采用了新型激活函数ReLU[5, 6]。与传统的sigmoid激活函数相比，ReLU能够有效缓解梯度消失问题，从而直接以监督的方式训练深度神经网络，无需依赖无监督的逐层预训练，这也是2012年深度卷积神经网络在ILSVRC竞赛中取得里程碑式突破的重要原因之一。\n\nReLU的 正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/6.jpg)\n\n可见，ReLU 在x<0 时硬饱和。由于 x>0时导数为 1，所以，ReLU 能够在x>0时保持梯度不衰减，从而缓解梯度消失问题。但随着训练的推进，部分输入会落入硬饱和区，导致对应权重无法更新。这种现象被称为“神经元死亡”。\n\nReLU还经常被“诟病”的一个问题是输出具有偏移现象[7]，即输出均值恒大于零。偏移现象和 神经元死亡会共同影响网络的收敛性。本文作者公开在arxiv的文章[8]中的实验表明，如果不采用Batch Normalization，即使用 MSRA 初始化30层以上的ReLU网络，最终也难以收敛。相对的，PReLU和ELU网络都能顺利收敛，这两种改进的激活函数将在后面介绍。实验所用代码见https://github.com/Coldmooon/Code-for-MPELU/ 。\n\nReLU另外一个性质是提供神经网络的稀疏表达能力，在Bengio教授的Deep Sparse Rectifier Neural Network[6]一文中被认为是ReLU带来网络性能提升的原因之一。但后来的研究发现稀疏性并非性能提升的必要条件，文献 RReLU [9]也指明了这一点。\n\nPReLU[10]、ELU[7]等激活函数不具备这种稀疏性，但都能够提升网络性能。本文作者在文章[8]中给出了一些实验比较结果。首先，在cifar10上采用NIN网络，实验结果为 PReLU > ELU > ReLU，稀疏性并没有带来性能提升。其次，在 ImageNet上采用类似于[11] 中model E的15 层网络，实验结果则是ReLU最好。为了验证是否是稀疏性的影响，以 LReLU [12]为例进一步做了四次实验，负半轴的斜率分别为1，0.5，0.25,  0.1，需要特别说明的是，当负半轴斜率为1时，LReLU退化为线性函数，因此性能损失最大。实验结果展现了斜率大小与网络性能的一致性。综合上述实验可知，ReLU的稀疏性与网络性能之间并不存在绝对正负比关系。\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/7.jpg)\n\n**PReLU**\n\nPReLU [10]是ReLU 和 LReLU的改进版本，具有非饱和性：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/8.jpg)\n\n与LReLU相比，PReLU中的负半轴斜率a可学习而非固定。原文献建议初始化a为0.25，不采用正则。个人认为，是否采用正则应当视具体的数据库和网络，通常情况下使用正则能够带来性能提升。\n\n虽然PReLU 引入了额外的参数，但基本不需要担心过拟合。例如，在上述cifar10+NIN实验中， PReLU比ReLU和ELU多引入了参数，但也展现了更优秀的性能。所以实验中若发现网络性能不好，建议从其他角度寻找原因。\n\n与ReLU相比，PReLU收敛速度更快。因为PReLU的输出更接近0均值，使得SGD更接近natural gradient。证明过程参见原文[10]。\n\n此外，作者在ResNet 中采用ReLU，而没有采用新的PReLU。这里给出个人浅见，不一定正确，仅供参考。首先，在上述LReLU实验中，负半轴斜率对性能的影响表现出一致性。对PReLU采用正则将激活值推向0也能够带来性能提升。这或许表明，小尺度或稀疏激活值对深度网络的影响更大。其次，ResNet中包含单位变换和残差两个分支。残差分支用于学习对单位变换的扰动。如果单位变换是最优解，那么残差分支的扰动应该越小越好。这种假设下，小尺度或稀疏激活值对深度网络的影响更大。此时，ReLU或许是比PReLU更好的选择。\n\n**RReLU**\n\n数学形式与PReLU类似，但RReLU[9]是一种非确定性激活函数，其参数是随机的。这种随机性类似于一种噪声，能够在一定程度上起到正则效果。作者在cifar10/100上观察到了性能提升。\n\n**Maxout**\n\nMaxout[13]是ReLU的推广，其发生饱和是一个零测集事件（measure zero event）。正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/9.jpg)\n\nMaxout网络能够近似任意连续函数，且当w2,b2,…,wn,bn为0时，退化为ReLU。 其实，Maxout的思想在视觉领域存在已久。例如，在HOG特征里有这么一个过程：计算三个通道的梯度强度，然后在每一个像素位置上，仅取三个通道中梯度强度最大的数值，最终形成一个通道。这其实就是Maxout的一种特例。\n\nMaxout能够缓解梯度消失，同时又规避了ReLU神经元死亡的缺点，但增加了参数和计算量。\n\n**ELU**\n\nELU[7]融合了sigmoid和ReLU，具有左侧软饱性。其正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/10.jpg)\n\n右侧线性部分使得ELU能够缓解梯度消失，而左侧软饱能够让ELU对输入变化或噪声更鲁棒。ELU的输出均值接近于零，所以收敛速度更快。经本文作者实验，ELU的收敛性质的确优于ReLU和PReLU。在cifar10上，ELU 网络的loss 降低速度更快；在 ImageNet上，不加 Batch Normalization 30 层以上的 ReLU 网络会无法收敛，PReLU网络在MSRA的Fan-in （caffe ）初始化下会发散，而 ELU 网络在Fan-in/Fan-out下都能收敛 。实验代码见https://github.com/Coldmooon/Code-for-MPELU/。\n\n论文的另一个重要贡献是分析了Bias shift 现象与激活值的关系，证明了降低Bias shift 等价于把激活值的均值推向0。\n\n**Noisy Activation Functions**\n\nengio教授在ICML 2016 提出了一种激活策略[1]，可用于多种软饱和激活函数，例如 sigmoid和 tanh。\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/11.jpg)\n\n当激活函数发生饱和时， 网络参数还能够在两种动力下继续更新：正则项梯度和噪声梯度。引入适当的噪声能够扩大SGD的参数搜索范围，从而有机会跳出饱和区。在激活函数中引入噪声的更早工作可追溯到[5]，但文献[5]的工作并不考虑噪声引入的时间和大小。本篇的特点在于，只在饱和区才引入噪声，且噪声量与饱和程度相关——原式与泰勒展开式一次项之差 δ。算法1中g表示sigmoid，用于归一化 δ。注意，ReLU的 δ恒为0，无法直接加噪声，所以作者把噪声加在了输入上。\n\n**CReLU**\n\nCReLU [14]是Wenling Shang 发表在 ICML 2016的工作，本篇同样提出了一种激活策略:\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/12.jpg)\n\n其中，[] 表示 ReLU（其他亦可）。\n\n作者在观察第一层滤波器（filter）时发现，滤波器相位具有成对现象（pair-grouping phenomenon）。这一发现揭示了网络的底层学到了一些冗余滤波器来提取输入的正负相位信息的可能性。因此可以考虑采用适当的操作移除这些冗余滤波器。对此，作者提出了CReLU，将激活函数的输入额外做一次取反，等价于将输入相位旋转180°。这种策略可以看作在网络中加入相位的先验。实验在cifar10上观察到能以更少的参数获得性能提升。\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/13.jpg)\n\n使用CReLU时，要有意识的将滤波器数量减半，否则， 网络参数变为2倍。\n\n**MPELU**\n\nMPELU[8]是我们组的工作，将分段线性与ELU统一到了一种形式下。在NIN+CIFAR10，本文作者发现ELU与LReLU性能一致，而与PReLU差距较大。经过分析，ELU泰勒展开的一次项就是LReLU。当在ELU前加入BN让输入集中在0均值附近， 则ELU与LReLU之差——泰勒展开高次项会变小，粗略估计，约55.57%的激活值误差小于0.01。因此，受PReLU启发，令α可学习能够提高性能。此外，引入参数β能够进一步控制ELU的函数形状。正式定义为：\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/14.jpg)\n\nα 和 β可以使用正则。α, β 固定为1时，MPELU 退化为 ELU； β 固定为很小的值时，MPELU 近似为 PReLU；当α=0，MPELU 等价于 ReLU。\n\nMPELU 的优势在于同时具备 ReLU、PReLU和 ELU的优点。首先，MPELU具备ELU的收敛性质，能够在无 Batch Normalization 的情况下让几十层网络收敛。其次，作为一般化形式， MPELU较三者的推广能力更强。简言之，MPELU = max(ReLU, PReLU, ELU)。\n\n![](/assets/images/2016/08/01/deep-learning-activation-function-guide/15.jpg)\n\n当前对ELU网络普遍采用的初始化方法是 MSRA。这在实际中是可行的，只是不具备理论解释性。我们的工作利用泰勒公式和MSRA的推导过程，为ELU网络初始化提供了理论解释。此外，Dmytro 提出了 LSUV[15]，理论上可以用于 ELU/MPELU 的初始化。但在30/52层ELU网络上，发现 LSUV 会导致ELU网络在几次迭代之内发散，网络文件见https://github.com/Coldmooon/Code-for-MPELU/。\n\n### 总结\n\n深度学习的快速发展，催生了形式各异的激活函数。面对琳琅满目的成果，如何做出选择目前尚未有统一定论，仍需依靠实验指导。一般来说，在分类问题上建议首先尝试 ReLU，其次ELU，这是两类不引入额外参数的激活函数。然后可考虑使用具备学习能力的PReLU和本文作者提出的MPELU，并使用正则化技术，例如应该考虑在网络中增加Batch Normalization层。\n\n本文围绕深度卷积神经网络结构，对十余种激活函数进行了总结，相关代码可在作者的github主页上下载：https://github.com/Coldmooon/Code-for-MPELU/。个人浅见如有疏漏之处，请诸位读者不吝斧正。\n\n### 致谢\n\n这是一次严肃又愉快的写作过程，本文作者在撰稿过程中得到了两位审稿人的建设性意见，改善了文章的可读性，并提示了若干重要的引证文献，在此特表感谢！\n\n### 参考文献\n\n1. Gulcehre, C., et al., Noisy Activation Functions, in ICML 2016. 2016.\n2. Glorot, X. and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. AISTATS 2010.\n3. LeCun, Y., et al., Backpropagation applied to handwritten zip code recognition. Neural computation, 1989. 1(4): p. 541-551.\n4. Amari, S.-I., Natural gradient works efficiently in learning. Neural computation, 1998. 10(2): p. 251-276.\n5. Nair, V. and G.E. Hinton. Rectified linear units improve Restricted Boltzmann machines. ICML 2010.\n6. Glorot, X., A. Bordes, and Y. Bengio. Deep Sparse Rectifier Neural Networks.AISTATS 2011.\n7. Djork-Arné Clevert, T.U., Sepp Hochreiter. Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs). ICLR 2016.\n8. Li, Y., et al., Improving Deep Neural Network with Multiple Parametric Exponential Linear Units. arXiv preprint arXiv:1606.00305, 2016.\n9. Xu, B., et al. Empirical Evaluation of Rectified Activations in Convolutional Network. ICML Deep Learning Workshop 2015.\n10. He, K., et al. Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification. ICCV 2015.\n11. He, K. and J. Sun Convolutional Neural Networks at Constrained Time Cost. CVPR 2015.\n12. Maas, A.L., Awni Y. Hannun, and Andrew Y. Ng. Rectifier nonlinearities improve neural network acoustic models. in ICML 2013.\n13. Goodfellow, I.J., et al. Maxout Networks.  ICML 2013..\n14. Shang, W., et al., Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units.ICML 2016.\n15. Mishkin, D. and J. Matas All you need is a good init. ICLR 2016.\n\n### 关于作者\n\n李扬，北京邮电大学电子工程学院通信与网络中心实验室博士生，导师范春晓教授。本科毕业于合肥工业大学光信息科学与技术专业，硕士师从北京邮电大学杨义先教授学习并从事信息安全项目研发。2015年转向深度学习领域，目前专注于深度学习及其在目标检测的应用。\n\n---\n\n* 原文链接：[深度学习中的激活函数导引](http://mp.weixin.qq.com/s?src=3&timestamp=1474434369&ver=1&signature=H36Q3gNgtCqDZLQEQ3aTx9evHu1fKDFx7LCR*LcRieFfHes3XFUZg8GWgpz-RnxEfnw*KF-WQwRpDpzuYgepbW9yM4VOifeaHoqs4PHxzE-9pkI0pYNMniqgNSdKZp-AdP3EbAROmFXlVZR7MZ*28kP8qJCraKtzfatkP62PatY=)\n","tags":["Activation-Function"],"categories":["Deep-Learning"]},{"title":"分布式队列编程：模型、实战","url":"%2F2016%2F2016-07-29-distributed-queue-based-programming%2F","content":"\n\n## 介绍\n\n作为一种基础的抽象数据结构，队列被广泛应用在各类编程中。大数据时代对跨进程、跨机器的通讯提出了更高的要求，和以往相比，分布式队列编程的运用几乎已无处不在。但是，这种常见的基础性的事物往往容易被忽视，使用者往往会忽视两点：\n\n* 使用分布式队列的时候，没有意识到它是队列。\n\n* 有具体需求的时候，忘记了分布式队列的存在。\n\n文章首先从最基础的需求出发，详细剖析分布式队列编程模型的需求来源、定义、结构以及其变化多样性。通过这一部分的讲解，作者期望能在两方面帮助读者：一方面，提供一个系统性的思考方法，使读者能够将具体需求关联到分布式队列编程模型，具备进行分布式队列架构的能力；另一方面，通过全方位的讲解，让读者能够快速识别工作中碰到的各种分布式队列编程模型。\n\n文章的第二部分实战篇。根据作者在新美大实际工作经验，给出了队列式编程在分布式环境下的一些具体应用。这些例子的基础模型并非首次出现在互联网的文档中，但是所有的例子都是按照挑战、构思、架构三个步骤进行讲解的。这种讲解方式能给读者一个“从需求出发去构架分布式队列编程”的旅程。\n\n## 分布式队列编程模型\n\n模型篇从基础的需求出发，去思考何时以及如何使用分布式队列编程模型。建模环节非常重要，因为大部分中高级工程师面临的都是具体的需求，接到需求后的第一个步骤就是建模。通过本篇的讲解，希望读者能够建立起从需求到分布式队列编程模型之间的桥梁。\n\n### 何时选择分布式队列\n\n通讯是人们最基本的需求，同样也是计算机最基本的需求。对于工程师而言，在编程和技术选型的时候，更容易进入大脑的概念是RPC、RESTful、Ajax、Kafka。在这些具体的概念后面，最本质的东西是“通讯”。所以，大部分建模和架构都需要从“通讯”这个基本概念开始。当确定系统之间有通讯需求的时候，工程师们需要做很多的决策和平衡，这直接影响工程师们是否会选择分布式队列编程模型作为架构。从这个角度出发，影响建模的因素有四个：When、Who、Where、How。\n\n#### When：同步VS异步\n\n通讯的一个基本问题是：发出去的消息什么时候需要被接收到？这个问题引出了两个基础概念：“同步通讯”和“异步通讯”。根据理论抽象模型，同步通讯和异步通讯最本质的差别来自于时钟机制的有无。同步通讯的双方需要一个校准的时钟，异步通讯的双方不需要时钟。现实的情况是，没有完全校准的时钟，所以没有绝对的同步通讯。同样，绝对异步通讯意味着无法控制一个发出去的消息被接收到的时间点，无期限的等待一个消息显然毫无实际意义。所以，实际编程中所有的通讯既不是“同步通讯”也不是“异步通讯”；或者说，既是“同步通讯”也是“异步通讯”。特别是对于应用层的通讯，其底层架构可能既包含“同步机制”也包含“异步机制”。判断“同步”和“异步”消息的标准问题太深，而不适合继续展开。作者这里给一些启发式的建议：\n\n* 发出去的消息是否需要确认，如果不需要确认，更像是异步通讯，这种通讯有时候也称为单向通讯（One-Way Communication）。\n\n* 如果需要确认，可以根据需要确认的时间长短进行判断。时间长的更像是异步通讯，时间短的更像是同步通讯。当然时间长短的概念是纯粹的主观概念，不是客观标准。\n\n* 发出去的消息是否阻塞下一个指令的执行，如果阻塞，更像是同步，否则，更像是异步。\n\n无论如何，工程师们不能生活在混沌之中，不做决定往往是最坏的决定。当分析一个通讯需求或者进行通讯构架的时候，工程师们被迫作出“同步”还是“异步”的决定。当决策的结论是“异步通讯”的时候，分布式队列编程模型就是一个备选项。\n\n#### Who：发送者接收者解耦\n\n在进行通讯需求分析的时候，需要回答的另外一个基本问题是：消息的发送方是否关心谁来接收消息，或者反过来，消息接收方是否关心谁来发送消息。如果工程师的结论是：消息的发送方和接收方不关心对方是谁、以及在哪里，分布式队列编程模型就是一个备选项。因为在这种场景下，分布式队列架构所带来的解耦能给系统架构带来这些好处：\n\n* 无论是发送方还是接收方，只需要跟消息中间件通讯，接口统一。统一意味着降低开发成本。\n\n* 在不影响性能的前提下，同一套消息中间件部署，可以被不同业务共享。共享意味着降低运维成本。\n\n* 发送方或者接收方单方面的部署拓扑的变化不影响对应的另一方。解藕意味着灵活和可扩展。\n\n#### Where：消息暂存机制\n\n在进行通讯发送方设计的时候，令工程师们苦恼的问题是：如果消息无法被迅速处理掉而产生堆积怎么办、能否被直接抛弃？如果根据需求分析，确认存在消息积存，并且消息不应该被抛弃，就应该考虑分布式队列编程模型构架，因为队列可以暂存消息。\n\n#### How：如何传递\n\n对通讯需求进行架构，一系列的基础挑战会迎面而来，这包括：\n\n* 可用性，如何保障通讯的高可用。\n\n* 可靠性，如何保证消息被可靠地传递。\n\n* 持久化，如何保证消息不会丢失。\n\n* 吞吐量和响应时间。\n\n* 跨平台兼容性。\n   除非工程师对造轮子有足够的兴趣，并且有充足的时间，采用一个满足各项指标的分布式队列编程模型就是一个简单的选择。\n\n### 分布式队列编程定义\n\n很难给出分布式队列编程模型的精确定义，由于本文偏重于应用，作者并不打算完全参照某个标准的模型。总体而言：分布式队列编程模型包含三类角色：发送者（Sender）、分布式队列（Queue）、接收者（Receiver）。发送者和接收者分别指的是生产消息和接收消息的应用程序或服务。\n\n需要重点明确的概念是分布式队列，它是提供以下功能的应用程序或服务：1. 接收“发送者”产生的消息实体；2. 传输、暂存该实体；3. 为“接收者”提供读取该消息实体的功能。特定的场景下，它当然可以是Kafka、RabbitMQ等消息中间件。但它的展现形式并不限于此，例如：\n\n* 队列可以是一张数据库的表，发送者将消息写入表，接收者从数据表里读消息。\n\n* 如果一个程序把数据写入Redis等内存Cache里面，另一个程序从Cache里面读取，缓存在这里就是一种分布式队列。\n\n* 流式编程里面的的数据流传输也是一种队列。\n\n* 典型的MVC（Model–view–controller）设计模式里面，如果Model的变化需要导致View的变化，也可以通过队列进行传输。这里的分布式队列可以是数据库，也可以是某台服务器上的一块内存。\n\n### 抽象模型\n\n最基础的分布式队列编程抽象模型是点对点模型，其他抽象构架模型居于改基本模型上各角色的数量和交互变化所导致的不同拓扑图。具体而言，不同数量的发送者、分布式队列以及接收者组合形成了不同的分布式队列编程模型。记住并理解典型的抽象模型结构对需求分析和建模而言至关重要，同时也会有助于学习和深入理解开源框架以及别人的代码。\n\n#### 点对点模型（Point-to-point）\n\n基础模型中，只有一个发送者、一个接收者和一个分布式队列。如下图所示：\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/point2point.png)\n\n#### 生产者消费者模型（Producer–consumer）\n\n如果发送者和接收者都可以有多个部署实例，甚至不同的类型；但是共用同一个队列，这就变成了标准的生产者消费者模型。在该模型，三个角色一般称之为生产者（Producer）、分布式队列（Queue）、消费者（Consumer）。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/producer-consumer.png)\n\n#### 发布订阅模型（PubSub）\n\n如果只有一类发送者，发送者将产生的消息实体按照不同的主题（Topic）分发到不同的逻辑队列。每种主题队列对应于一类接收者。这就变成了典型的发布订阅模型。在该模型，三个角色一般称之为发布者（Publisher），分布式队列（Queue），订阅者（Subscriber）。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/pubsub.png)\n\n#### MVC模型\n\n如果发送者和接收者存在于同一个实体中，但是共享一个分布式队列。这就很像经典的MVC模型。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/mvc.png)\n\n### 编程模型\n\n为了让读者更好地理解分布式队列编程模式概念，这里将其与一些容易混淆的概念做一些对比 。\n\n#### 分布式队列模型编程和异步编程\n\n分布式队列编程模型的通讯机制一般是采用异步机制，但是它并不等同于异步编程。\n\n首先，并非所有的异步编程都需要引入队列的概念，例如：大部分的操作系统异步I/O操作都是通过硬件中断（ Hardware Interrupts）来实现的。\n\n其次，异步编程并不一定需要跨进程，所以其应用场景并不一定是分布式环境。\n\n最后，分布式队列编程模型强调发送者、接收者和分布式队列这三个角色共同组成的架构。这三种角色与异步编程没有太多关联。\n\n#### 分布式队列模式编程和流式编程\n\n随着Spark Streaming，Apache Storm等流式框架的广泛应用，流式编程成了当前非常流行的编程模式。但是本文所阐述的分布式队列编程模型和流式编程并非同一概念。\n\n首先，本文的队列编程模式不依赖于任何框架，而流式编程是在具体的流式框架内的编程。\n\n其次，分布式队列编程模型是一个需求解决方案，关注如何根据实际需求进行分布式队列编程建模。流式框架里的数据流一般都通过队列传递，不过，流式编程的关注点比较聚焦，它关注如何从流式框架里获取消息流，进行map、reduce、 join等转型（Transformation）操作、生成新的数据流，最终进行汇总、统计。\n\n## 分布式队列编程实战篇\n\n这里所有的项目都是作者在新美大工作的真实案例。实战篇的关注点是训练建模思路，所以这些例子都按照挑战、构思、架构三个步骤进行讲解。受限于保密性要求，有些细节并未给出，但这些细节并不影响讲解的完整性。另一方面，特别具体的需求容易让人费解，为了使讲解更加顺畅，作者也会采用一些更通俗易懂的例子。通过本篇的讲解，希望和读者一起去实践“如何从需求出发去构架分布式队列编程模型”。\n\n需要声明的是，这里的解决方案并不是所处场景的最优方案。但是，任何一个稍微复杂的问题，都没有最优解决方案，更谈不上唯一的解决方案。实际上，工程师每天所追寻的只是在满足一定约束条件下的可行方案。当然不同的约束会导致不同的方案，约束的松弛度决定了工程师的可选方案的宽广度。\n\n### 信息采集处理\n\n信息采集处理应用广泛，例如：广告计费、用户行为收集等。作者碰到的具体项目是为广告系统设计一套高可用的采集计费系统。\n\n典型的广告CPC、CPM计费原理是：收集用户在客户端或者网页上的点击和浏览行为，按照点击和浏览进行计费。计费业务有如下典型特征：\n\n* 采集者和处理者解耦，采集发生在客户端，而计费发生在服务端。\n\n* 计费与钱息息相关。\n\n* 重复计费意味着灾难。\n\n* 计费是动态实时行为，需要接受预算约束，如果消耗超过预算，则广告投放需要停止。\n\n* 用户的浏览和点击量非常大。\n\n#### 挑战\n\n计费业务的典型特征给我们带来了如下挑战：\n\n* 高吞吐量－－广告的浏览和点击量非常巨大，我们需要设计一个高吞吐量的采集架构。\n\n* 高可用性－－计费信息的丢失意味着直接的金钱损失。任何处理服务器的崩溃不应该导致系统不可用。\n\n* 高一致性要求－－计费是一个实时动态处理过程，但要受到预算的约束。收集到的浏览和点击行为如果不能快速处理，可能会导致预算花超，或者点击率预估不准确。所以采集到的信息应该在最短的时间内传输到计费中心进行计费。\n\n* 完整性约束－－这包括反作弊规则，单个用户行为不能重复计费等。这要求计费是一个集中行为而非分布式行为。\n\n* 持久化要求－－计费信息需要持久化，避免因为机器崩溃而导致收集到的数据产生丢失。\n\n#### 构思\n\n采集的高可用性意味着我们需要多台服务器同时采集，为了避免单IDC故障，采集服务器需要部署在多IDC里面。\n\n实现一个高可用、高吞吐量、高一致性的信息传递系统显然是一个挑战，为了控制项目开发成本，采用开源的消息中间件进行消息传输就成了必然选择。\n\n完整性约束要求集中进行计费，所以计费系统发生在核心IDC。\n\n计费服务并不关心采集点在哪里，采集服务也并不关心谁进行计费。\n\n根据以上构思，我们认为采集计费符合典型的“生产者消费者模型”。\n\n架构\n\n采集计费系统架构图如下：\n\n* 用户点击浏览收集服务（Click/View Collector）作为生产者部署在多个机房里，以提高收集服务可用性。\n\n* 每个机房里采集到的数据通过消息队列中间件发送到核心机房IDC_Master。\n\n* Billing服务作为消费者部署在核心机房集中计费。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/infomation-collector.png)\n\n采用此架构，我们可以在如下方面做进一步优化：\n\n* 提高可扩展性，如果一个Billing部署实例在性能上无法满足要求，可以对采集的数据进行主题分区（Topic Partition）计费，即采用发布订阅模式以提高可扩展性（Scalability）。\n\n* 全局排重和反作弊。采用集中计费架构解决了点击浏览排重的问题，另一方面，这也给反作弊提供了全局信息。\n\n* 提高计费系统的可用性。采用下文单例服务优化策略，在保障计费系统集中性的同时，提高计费系统可用性。\n\n### 分布式缓存更新（Distributed Cache Replacement）\n\n缓存是一个非常宽泛的概念，几乎存在于系统各个层级。典型的缓存访问流程如下：\n\n* 接收到请求后，先读取缓存，如果命中则返回结果。\n\n* 如果缓存不命中，读取DB或其它持久层服务，更新缓存并返回结果。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/cache-replacement.png)\n\n对于已经存入缓存的数据，其更新时机和更新频率是一个经典问题，即缓存更新机制（Cache Replacement Algorithms ）。典型的缓存更新机制包括：近期最少使用算法（LRU）、最不经常使用算法（LFU）。这两种缓存更新机制的典型实现是：启动一个后台进程，定期清理最近没有使用的，或者在一段时间内最少使用的数据。由于存在缓存驱逐机制，当一个请求在没有命中缓存时，业务层需要从持久层中获取信息并更新缓存，提高一致性。\n\n#### 挑战\n\n分布式缓存给缓存更新机制带来了新的问题：\n\n* 数据一致性低。分布式缓存中键值数量巨大，从而导致LRU或者LFU算法更新周期很长。在分布式缓存中，拿LRU算法举例，其典型做法是为每个Key值设置一个生存时间（TTL），生存时间到期后将该键值从缓存中驱逐除去。考虑到分布式缓存中庞大的键值数量，生存时间往往会设置的比较长，这就导致缓存和持久层数据不一致时间很长。如果生存时间设置过短，大量请求无法命中缓存被迫读取持久层，系统响应时间会急剧恶化。\n\n* 新数据不可用。在很多场景下，由于分布式缓存和持久层的访问性能相差太大，在缓存不命中的情况下，一些应用层服务不会尝试读取持久层，而直接返回空结果。漫长的缓存更新周期意味着新数据的可用性就被牺牲了。从统计的角度来讲，新键值需要等待半个更新周期才会可用。\n\n#### 构思\n\n根据上面的分析，分布式缓存需要解决的问题是：在保证读取性能的前提下，尽可能地提高老数据的一致性和新数据的可用性。如果仍然假定最近被访问的键值最有可能被再次访问（这是LRU或者LFU成立的前提），键值每次被访问后触发一次异步更新就是提高可用性和一致性最早的时机。无论是高性能要求还是业务解耦都要求缓存读取和缓存更新分开，所以我们应该构建一个单独的集中的缓存更新服务。集中进行缓存更新的另外一个好处来自于频率控制。由于在一段时间内，很多类型访问键值的数量满足高斯分布，短时间内重复对同一个键值进行更新Cache并不会带来明显的好处，甚至造成缓存性能的下降。通过控制同一键值的更新频率可以大大缓解该问题，同时有利于提高整体数据的一致性，参见“排重优化”。\n\n综上所述，业务访问方需要把请求键值快速传输给缓存更新方，它们之间不关心对方的业务。要快速、高性能地实现大量请求键值消息的传输，高性能分布式消息中间件就是一个可选项。这三方一起组成了一个典型的分布式队列编程模型。\n\n#### 架构\n\n如下图，所有的业务请求方作为生产者，在返回业务代码处理之前将请求键值写入高性能队列。Cache Updater作为消费者从队列中读取请求键值，将持久层中数据更新到缓存中。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/distributed-cache-replacement.png)\n\n采用此架构，我们可以在如下方面做进一步优化：\n\n* 提高可扩展性，如果一个Cache Updater在性能上无法满足要求，可以对键值进行主题分区（Topic Partition）进行并行缓存更新，即采用发布订阅模式以提高可扩展性（Scalability）。\n\n* 更新频率控制。缓存更新都集中处理，对于发布订阅模式，同一类主题（Topic）的键值集中处理。Cache Updater可以控制对同一键值的在短期内的更新频率（参见下文排重优化）。\n\n### 后台任务处理\n\n典型的后台任务处理应用包括工单处理、火车票预订系统、机票选座等。我们所面对的问题是为运营人员创建工单。一次可以为多个运营人员创建多个工单。这个应用场景和火车票购买非常类似。工单相对来说更加抽象，所以，下文会结合火车票购买和运营人员工单分配这两种场景同时讲解。典型的工单创建要经历两个阶段：数据筛选阶段、工单创建阶段。例如，在火车票预订场景，数据筛选阶段用户选择特定时间、特定类型的火车，而在工单创建阶段，用户下单购买火车票。\n\n#### 挑战\n\n工单创建往往会面临如下挑战：\n\n* 数据一致性问题。以火车票预订为例，用户筛选火车票和最终购买之间往往有一定的时延，意味着两个操作之间数据是不一致的。在筛选阶段，工程师们需决定是否进行车票锁定，如果不锁定，则无法保证出票成功。反之，如果在筛选地时候锁定车票，则会大大降低系统效率和出票吞吐量。\n\n* 约束问题。工单创建需要满足很多约束，主要包含两种类型：动态约束，与操作者的操作行为有关，例如购买几张火车票的决定往往发生在筛选最后阶段。隐性约束，这种约束很难通过界面进行展示，例如一个用户购买了5张火车票，这些票应该是在同一个车厢的临近位置。\n\n* 优化问题。工单创建往往是约束下的优化，这是典型的统筹优化问题，而统筹优化往往需要比较长的时间。\n\n* 响应时间问题。对于多任务工单，一个请求意味着多个任务产生。这些任务的创建往往需要遵循事务性原则，即All or Nothing。在数据层面，这意味着工单之间需要满足串行化需求（Serializability）。大数据量的串行化往往意味着锁冲突延迟甚至失败。无论是延迟机制所导致的长时延，还是高创建失败率，都会大大伤害用户体验。\n\n#### 构思\n\n如果将用户筛选的最终规则做为消息存储下来，并发送给工单创建系统。此时，工单创建系统将具备创建工单所需的全局信息，具备在满足各种约束的条件下进行统筹优化的能力。如果工单创建阶段采用单实例部署，就可以避免数据锁定问题，同时也意味着没有锁冲突，所以也不会有死锁或任务延迟问题。\n\n居于以上思路，在多工单处理系统的模型中，筛选阶段的规则创建系统将充当生产者角色，工单创建系统将充当消费者角色，筛选规则将作为消息在两者之间进行传递。这就是典型的分布式队列编程架构。根据工单创建量的不同，可以采用数据库或开源的分布式消息中间件作为分布式队列。\n\n#### 架构\n\n该架构流程如下图：\n\n* 用户首选进行规则创建，这个过程主要是一些搜索筛选操作；\n\n* 用户点击工单创建，TicketRule Generator将把所有的筛选性组装成规则消息并发送到队列里面去；\n\n* Ticket Generator作为一个消费者，实时从队列中读取工单创建请求，开始真正创建工单。\n\n![](/assets/images/2016/07/29/distributed_queue_based_programming/ticket-generation.png)\n\n采用该架构，我们在数据锁定、运筹优化、原子性问题都能得到比较好成果：\n\n* 数据锁定推迟到工单创建阶段，可以减少数据锁定范围，最大程度的降低工单创建对其他在线操作的影响范围。\n\n* 如果需要进行统筹优化，可以将Ticket Generator以单例模式进行部署（参见单例服务优化）。这样，Ticket Generator可以读取一段时间内的工单请求，进行全局优化。例如，在我们的项目中，在某种条件下，运营人员需要满足分级公平原则，即相同级别的运营人员的工单数量应该接近，不同级别的运营人员工单数量应该有所区分。如果不集中进行统筹优化，实现这种优化规则将会很困难。\n\n* 保障了约束完整性。例如，在我们的场景里面，每个运营人员每天能够处理的工单是有数量限制的，如果采用并行处理的方式，这种完整性约束将会很难实施。\n\n## 预告\n\n下周我们会推出优化篇，重点阐述在工程师在运用分布式队列编程构架的时候，在生产者、分布式队列以及消费者这三个环节的注意点以及优化建议，欢迎关注！\n\n## 参考资料\n\n[1] RabbitMQ, [Highly Available Queues](https://www.rabbitmq.com/ha.html).\n[2] IBM Knowledge Center, [Introduction to message queuing](https://www.ibm.com/support/knowledgecenter/SSFKSJ_8.0.0/com.ibm.mq.pro.doc/q002620_.htm).\n[3] Wikipedia, [Serializability](https://en.wikipedia.org/wiki/Serializability).\n[4] Hadoop, [ZooKeeper Recipes and Solutions](https://zookeeper.apache.org/doc/trunk/recipes.html#sc_leaderElection).\n[5] [Apache Kafka](http://kafka.apache.org/documentation.html#introduction).\n[6] Lamport L, [Paxos Made Simple](http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf).\n\n---\n\n* 原文链接：[分布式队列编程：模型、实战](http://tech.meituan.com/distributed_queue_based_programming.html)\n","tags":["Distributed"],"categories":["Distributed"]},{"title":"Approaching (Almost) Any Machine Learning Problem","url":"%2F2016%2F2016-07-18-approaching-almost-any-machine-learning-problem%2F","content":"\nAn average data scientist deals with loads of data daily. Some say over 60-70% time is spent in data cleaning, munging and bringing data to a suitable format such that machine learning models can be applied on that data. This post focuses on the second part, i.e., applying machine learning models, including the preprocessing steps. The pipelines discussed in this post come as a result of over a hundred machine learning competitions that I’ve taken part in. It must be noted that the discussion here is very general but very useful and there can also be very complicated methods which exist and are practised by professionals.\n\nWe will be using python!\n\n# Data\n\nBefore applying the machine learning models, the data must be converted to a tabular form. This whole process is the most time consuming and difficult process and is depicted in the figure below.\n\n![abhishek_1](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_1.png)\n\nThe machine learning models are then applied to the tabular data. Tabular data is most common way of representing data in machine learning or data mining. We have a data table, rows with different samples of the data or X and labels, y. The labels can be single column or multi-column, depending on the type of problem. We will denote data by X and labels by y.\n\n# Types of labels\n\nThe labels define the problem and can be of different types, such as:\n\n*   Single column, binary values (classification problem, one sample belongs to one class only and there are only two classes)\n*   Single column, real values (regression problem, prediction of only one value)\n*   Multiple column, binary values (classification problem, one sample belongs to one class, but there are more than two classes)\n*   Multiple column, real values (regression problem, prediction of multiple values)\n*   And multilabel (classification problem, one sample can belong to several classes)\n\n# Evaluation Metrics\n\nFor any kind of machine learning problem, we must know how we are going to evaluate our results, or what the evaluation metric or objective is. For example in case of a skewed binary classification problem we generally choose area under the receiver operating characteristic curve (ROC AUC or simply AUC). In case of multi-label or multi-class classification problems, we generally choose categorical cross-entropy or multiclass log loss and mean squared error in case of regression problems.\n\nI won’t go into details of the different evaluation metrics as we can have many different types, depending on the problem.\n\n# The Libraries\n\nTo start with the machine learning libraries, install the basic and most important ones first, for example, numpy and scipy.\n\n*   To see and do operations on data: pandas ([http://pandas.pydata.org/](http://pandas.pydata.org/))\n*   For all kinds of machine learning models: scikit-learn ([http://scikit-learn.org/stable/](http://scikit-learn.org/stable/))\n*   The best gradient boosting library: xgboost ([https://github.com/dmlc/xgboost](https://github.com/dmlc/xgboost))\n*   For neural networks: keras ([http://keras.io/](http://keras.io/))\n*   For plotting data: matplotlib ([http://matplotlib.org/](http://matplotlib.org/))\n*   To monitor progress: tqdm ([https://pypi.python.org/pypi/tqdm](https://pypi.python.org/pypi/tqdm))\n\nI don’t use Anaconda ([https://www.continuum.io/downloads](https://www.continuum.io/downloads)). It’s easy and does everything for you, but I want more freedom. The choice is yours. 🙂\n\n# The Machine Learning Framework\n\nIn 2015, I came up with a framework for automatic machine learning which is still under development and will be released soon. For this post, the same framework will be the basis. The framework is shown in the figure below:\n\n![Figure from: A. Thakur and A. Krohn-Grimberghe, AutoCompete: A Framework for Machine Learning Competitions, AutoML Workshop, International Conference on Machine Learning 2015.](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_2.png)\n\nFigure from: A. Thakur and A. Krohn-Grimberghe, AutoCompete: A Framework for Machine Learning Competitions, AutoML Workshop, International Conference on Machine Learning 2015.\n\nIn the framework shown above, the pink lines represent the most common paths followed. After we have extracted and reduced the data to a tabular format, we can go ahead with building machine learning models.\n\nThe very first step is identification of the problem. This can be done by looking at the labels. One must know if the problem is a binary classification, a multi-class or multi-label classification or a regression problem. After we have identified the problem, we split the data into two different parts, a training set and a validation set as depicted in the figure below.\n\n![abhishek_3](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_3.png)\n\nThe splitting of data into training and validation sets “must” be done according to labels. In case of any kind of classification problem, use stratified splitting. In python, you can do this using scikit-learn very easily.\n\n![abhishek_4](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_4.png)\n\nIn case of regression task, a simple K-Fold splitting should suffice. There are, however, some complex methods which tend to keep the distribution of labels same for both training and validation set and this is left as an exercise for the reader.\n\n![abhishek_5](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_5.png)\n\nI have chosen the eval_size or the size of the validation set as 10% of the full data in the examples above, but one can choose this value according to the size of the data they have.\n\nAfter the splitting of the data is done, leave this data out and don’t touch it. Any operations that are applied on training set must be saved and then applied to the validation set. Validation set, in any case, should not be joined with the training set. Doing so will result in very good evaluation scores and make the user happy but instead he/she will be building a useless model with very high overfitting.\n\nNext step is identification of different variables in the data. There are usually three types of variables we deal with. Namely, numerical variables, categorical variables and variables with text inside them. Let’s take example of the popular Titanic dataset ([https://www.kaggle.com/c/titanic/data](https://www.kaggle.com/c/titanic/data)).\n\n![abhishek_6](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_6.png)\n\nHere, survival is the label. We have already separated labels from the training data in the previous step. Then, we have pclass, sex, embarked. These variables have different levels and thus they are categorical variables. Variables like age, sibsp, parch, etc are numerical variables. Name is a variable with text data but I don’t think it’s a useful variable to predict survival.\n\nSeparate out the numerical variables first. These variables don’t need any kind of processing and thus we can start applying normalization and machine learning models to these variables.\n\nThere are two ways in which we can handle categorical data:\n\n*   Convert the categorical data to labels\n\n![abhishek_7](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_7.png)\n\n*   Convert the labels to binary variables (one-hot encoding)\n\n![abhishek_8](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_8.png)\n\nPlease remember to convert categories to numbers first using LabelEncoder before applying OneHotEncoder on it.\n\nSince, the Titanic data doesn’t have good example of text variables, let’s formulate a general rule on handling text variables. We can combine all the text variables into one and then use some algorithms which work on text data and convert it to numbers.\n\nThe text variables can be joined as follows:\n\n![abhishek_9](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_9.png)\n\nWe can then use CountVectorizer or TfidfVectorizer on it:\n\n![abhishek_10](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_10.png)\n\nor,\n\n![abhishek_11](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_11.png)\n\nThe TfidfVectorizer performs better than the counts most of the time and I have seen that the following parameters for TfidfVectorizer work almost all the time.\n\n![abhishek_12](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_12.png)\n\nIf you are applying these vectorizers only on the training set, make sure to dump it to hard drive so that you can use it later on the validation set.\n\n![abhishek_13](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_13.png)\n\nNext, we come to the stacker module. Stacker module is not a model stacker but a feature stacker. The different features after the processing steps described above can be combined using the stacker module.\n\n![abhishek_14](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_14.png)\n\nYou can horizontally stack all the features before putting them through further processing by using numpy hstack or sparse hstack depending on whether you have dense or sparse features.\n\n![abhishek_15](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_15.png)\n\nAnd can also be achieved by FeatureUnion module in case there are other processing steps such as pca or feature selection (we will visit decomposition and feature selection later in this post).\n\n![abhishek_16](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_16.png)\n\nOnce, we have stacked the features together, we can start applying machine learning models. At this stage only models you should go for should be ensemble tree based models. These models include:\n\n*   RandomForestClassifier\n*   RandomForestRegressor\n*   ExtraTreesClassifier\n*   ExtraTreesRegressor\n*   XGBClassifier\n*   XGBRegressor\n\nWe cannot apply linear models to the above features since they are not normalized. To use linear models, one can use Normalizer or StandardScaler from scikit-learn.\n\nThese normalization methods work only on dense features and don’t give very good results if applied on sparse features. Yes, one can apply StandardScaler on sparse matrices without using the mean (parameter: with_mean=False).\n\nIf the above steps give a “good” model, we can go for optimization of hyperparameters and in case it doesn’t we can go for the following steps and improve our model.\n\nThe next steps include decomposition methods:\n\n![abhishek_17](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_17.png)\n\nFor the sake of simplicity, we will leave out LDA and QDA transformations. For high dimensional data, generally PCA is used decompose the data. For images start with 10-15 components and increase this number as long as the quality of result improves substantially. For other type of data, we select 50-60 components initially (we tend to avoid PCA as long as we can deal with the numerical data as it is).\n\n![abhishek_18](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_18.png)\n\nFor text data, after conversion of text to sparse matrix, go for Singular Value Decomposition (SVD). A variation of SVD called TruncatedSVD can be found in scikit-learn.\n\n![abhishek_decomp](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_decomp.png)\n\nThe number of SVD components that generally work for TF-IDF or counts are between 120-200. Any number above this might improve the performance but not substantially and comes at the cost of computing power.\n\nAfter evaluating further performance of the models, we move to scaling of the datasets, so that we can evaluate linear models too. The normalized or scaled features can then be sent to the machine learning models or feature selection modules.\n\n![abhishek_19](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_19.png)\n\nThere are multiple ways in which feature selection can be achieved. One of the most common way is greedy feature selection (forward or backward). In greedy feature selection we choose one feature, train a model and evaluate the performance of the model on a fixed evaluation metric. We keep adding and removing features one-by-one and record performance of the model at every step. We then select the features which have the best evaluation score. One implementation of greedy feature selection with AUC as evaluation metric can be found here: [https://github.com/abhishekkrthakur/greedyFeatureSelection](https://github.com/abhishekkrthakur/greedyFeatureSelection). It must be noted that this implementation is not perfect and must be changed/modified according to the requirements.\n\nOther faster methods of feature selection include selecting best features from a model. We can either look at coefficients of a logit model or we can train a random forest to select best features and then use them later with other machine learning models.\n\n![abhishek_20](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_20.png)\n\nRemember to keep low number of estimators and minimal optimization of hyper parameters so that you don’t overfit.\n\nThe feature selection can also be achieved using Gradient Boosting Machines. It is good if we use xgboost instead of the implementation of GBM in scikit-learn since xgboost is much faster and more scalable.\n\n![abhishek_21](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_21.png)\n\nWe can also do feature selection of sparse datasets using RandomForestClassifier / RandomForestRegressor and xgboost.\n\nAnother popular method for feature selection from positive sparse datasets is chi-2 based feature selection and we also have that implemented in scikit-learn.\n\n![abhishek_22](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_22.png)\n\nHere, we use chi2 in conjunction with SelectKBest to select 20 features from the data. This also becomes a hyperparameter we want to optimize to improve the result of our machine learning models.\n\nDon’t forget to dump any kinds of transformers you use at all the steps. You will need them to evaluate performance on the validation set.\n\nNext (or intermediate) major step is model selection + hyperparameter optimization.\n\n![abhishek_23](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_23.png)\n\nWe generally use the following algorithms in the process of selecting a machine learning model:\n\n*   **Classification**:\n\n  *  Random Forest\n  *  GBM\n  *  Logistic Regression\n  *  Naive Bayes\n  *  Support Vector Machines\n  *  k-Nearest Neighbors\n\n*   **Regression**\n\n  *  Random Forest\n  *  GBM\n  *  Linear Regression\n  *  Ridge\n  *  Lasso\n  *  SVR\n\nWhich parameters should I optimize? How do I choose parameters closest to the best ones? These are a couple of questions people come up with most of the time. One cannot get answers to these questions without experience with different models + parameters on a large number of datasets. Also people who have experience are not willing to share their secrets. Luckily, I have quite a bit of experience too and I’m willing to give away some of the stuff.\n\nLet’s break down the hyperparameters, model wise:\n\n![abhishek_24](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_24.png)\n\nRS* = Cannot say about proper values, go for Random Search in these hyperparameters.\n\nIn my opinion, and strictly my opinion, the above models will out-perform any others and we don’t need to evaluate any other models.\n\nOnce again, remember to save the transformers:\n\n![abhishek_25](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_25.png)\n\nAnd apply them on validation set separately:\n\n![abhishek_26](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek_26.png)\n\nThe above rules and the framework has performed very well in most of the datasets I have dealt with. Of course, it has also failed for very complicated tasks. Nothing is perfect and we keep on improving on what we learn. Just like in machine learning.\n\nGet in touch with me with any doubts: abhishek4 [at] gmail [dot] com\n\n# Bio\n\n![Abhishek Thakur](/assets/images/2016/07/18/approaching-almost-any-machine-learning-problem/abhishek.png)\n\n[Abhishek Thakur](https://www.kaggle.com/abhishek), competitions grandmaster.\n**[Abhishek Thakur](https://www.kaggle.com/abhishek)** works as a Senior Data Scientist on the Data Science team at [Searchmetrics Inc](http://www.searchmetrics.com/). At Searchmetrics, Abhishek works on some of the most interesting data driven studies, applied machine learning algorithms and deriving insights from huge amount of data which require a lot of data munging, cleaning, feature engineering and building and optimization of machine learning models.\n\nIn his free time, he likes to take part in machine learning competitions and has taken part in over 100 competitions. His research interests include automatic machine learning, deep learning, hyperparameter optimization, computer vision, image analysis and retrieval and pattern recognition.\n\n---\n\n* Author: [Abhishek Thakur](https://www.linkedin.com/in/abhisvnit/)\n* Link: [Approaching (Almost) Any Machine Learning Problem](https://www.linkedin.com/pulse/approaching-almost-any-machine-learning-problem-abhishek-thakur)\n","tags":["Machine-Learning"],"categories":["Machine-Learning"]}]